Use_Case_ID,Department_Code,Agency,Office,Title,Summary,Development_Stage,Techniques,Source_Code,Department,project_title_text,summary_text,LLM_summary_text,risk_assessment_safety,risk_assessment_rights,is_risk_assessment_rights,is_risk_assessment_safety
NASA-0016-2023,NASA,Jet Propulsion Laboratory,,"SensorWeb: Volcano, Flood, Wildfire, and Others.","The Sensor Web Project uses a network of sensors linked by software and the internet to an autonomous satellite
observation response capability. This system of systems is designed with a flexible, modular, architecture to
facilitate expansion in sensors, customization of trigger conditions, and customization of responses. This system has
been used to implement a global surveillance program to study volcanos. We have also run sensorweb tests to
study flooding, cryosphere events, and atmospheric phenomena. Specifically, in our application, we use low
resolution, high coverage sensors to trigger observations by high resolution instruments. Note that there are many
other rationales to network sensors into a sensorweb. For example automated response might enable observation
using complementary instruments such as imaging radar, infra-red, visible, etc. Or automated response might be
used to apply more assets to increase the frequency of observation to improve the temporal resolution of available
data. Our sensorweb project is being used to monitor the Earth's 50 most active volcanos. We have also run
sensorweb experiments to monitor flooding, wildfires, and cryospheric events (snowfall and melt, lake freezing and
thawing, sea ice formation and breakup.)",In mission,constraint-based heuristic Search,,National Aeronautics and Space Administration,"SensorWeb: Volcano, Flood, Wildfire, and Others.: 
The Sensor Web Project uses a network of sensors linked by software and the internet to an autonomous satellite
observation response capability. This system of systems is designed with a flexible, modular, architecture to
facilitate expansion in sensors, customization of trigger conditions, and customization of responses. This system has
been used to implement a global surveillance program to study volcanos. We have also run sensorweb tests to
study flooding, cryosphere events, and atmospheric phenomena. Specifically, in our application, we use low
resolution, high coverage sensors to trigger observations by high resolution instruments. Note that there are many
other rationales to network sensors into a sensorweb. For example automated response might enable observation
using complementary instruments such as imaging radar, infra-red, visible, etc. Or automated response might be
used to apply more assets to increase the frequency of observation to improve the temporal resolution of available
data. Our sensorweb project is being used to monitor the Earth's 50 most active volcanos. We have also run
sensorweb experiments to monitor flooding, wildfires, and cryospheric events (snowfall and melt, lake freezing and
thawing, sea ice formation and breakup.)","The Sensor Web Project utilizes a network of sensors connected through software and the internet to an autonomous satellite observation system. This system allows for expansion of sensors, customization of trigger conditions, and customization of responses. The project is currently being used to monitor the Earth's 50 most active volcanos, as well as conduct experiments on flooding, wildfires, and cryospheric events.","The Sensor Web Project utilizes a network of sensors connected through software and the internet to an autonomous satellite observation system. This system allows for expansion of sensors, customization of trigger conditions, and customization of responses. The project is currently being used to monitor the Earth's 50 most active volcanos, as well as conduct experiments on flooding, wildfires, and cryospheric events.","Yes, the Sensor Web Project is potentially a safety risk. 

The project involves monitoring active volcanoes, flooding, wildfires, and cryospheric events, all of which can pose significant risks to safety. For example, volcanic eruptions can result in ash clouds, lava flows, and toxic gas emissions, which can endanger human lives and infrastructure. Flooding and wildfires can cause property damage, displacement of people, and potential loss of life. Cryospheric events, such as ice melt and glacier collapse, can also have serious consequences for both human and environmental safety.

Additionally, the project involves the use of an autonomous satellite observation system, which raises concerns about the safety and control of the system. If there are malfunctions or errors in the software or hardware, it could lead to inaccurate data collection, false alarms, or inappropriate responses, potentially putting lives and property at risk.

Therefore, considering the nature of the project and the potential risks involved, it is advisable to carefully evaluate and address safety measures to mitigate any potential safety risks.","Yes, the Sensor Web Project has the potential to be a safety risk. While the project itself does not directly involve any of the defined risks, it is important to consider the potential implications and consequences that may arise from the utilization of such a system.

The network of sensors connected to an autonomous satellite observation system can gather a vast amount of data and monitor various natural events such as volcanic activity, flooding, wildfires, and cryospheric events. However, if this data is not properly managed, analyzed, or interpreted, it could lead to incorrect or inadequate responses to potential safety risks.

For example, if there are errors or delays in the trigger conditions or responses of the system, it may fail to provide timely warnings or appropriate actions to mitigate risks. This could result in inadequate evacuation measures during natural disasters or insufficient response to volcanic eruptions, leading to potential harm to human life and property.

Additionally, the customization aspect of the project raises concerns about the accuracy and reliability of the system. If the customization of trigger conditions or responses is not well-designed or properly implemented, it could lead to false alarms or missed warnings, posing a safety risk to individuals and communities relying on the system for early detection and response to hazardous events.

Furthermore, the project's reliance on software and internet connectivity introduces potential vulnerabilities to cyber attacks, which could compromise the integrity and reliability of the system. If unauthorized access or manipulation occurs, it could lead to false data, incorrect trigger conditions, or inappropriate responses, further exacerbating safety risks.

Therefore, while the Sensor Web Project itself may not directly involve the defined risks, the potential for errors, delays, customization issues, and cybersecurity vulnerabilities make it a project that has the potential to pose safety risks if not properly managed and implemented.",True,True
DHS-0007-2023,DHS,Customs and Border Protection,,Entity Resolution,"The third-party global trade data is used to augment and enrich agency’s investigations into entities of interest. It combines data from companies and goods across multiple languages, then provides network analysis to assess trade flows and risks associated with cross-border trade.

This can validate agency-held information or provide better understanding of networks of interest to the agency to better inform investigations that cross borders. AI/ML models help manage the information provided through the software, including behind-the-curtain collection of information, structuring of data, entity resolution, network analysis, risk analysis, and other functions that contribute to the software knowledge graph and frontend that end users interact with.  ",Development and Acquisition,Natural Language Processing (NLP),,Department of Homeland Security,"Entity Resolution: 
The third-party global trade data is used to augment and enrich agency’s investigations into entities of interest. It combines data from companies and goods across multiple languages, then provides network analysis to assess trade flows and risks associated with cross-border trade.

This can validate agency-held information or provide better understanding of networks of interest to the agency to better inform investigations that cross borders. AI/ML models help manage the information provided through the software, including behind-the-curtain collection of information, structuring of data, entity resolution, network analysis, risk analysis, and other functions that contribute to the software knowledge graph and frontend that end users interact with.  ","Entity Resolution is a software system that uses global trade data to enhance agency investigations by analyzing trade flows and risks associated with cross-border trade. It utilizes AI/ML models to manage and structure data, perform entity resolution and network analysis, and contribute to the software's knowledge graph and user interface.","Entity Resolution is a software system that uses global trade data to enhance agency investigations by analyzing trade flows and risks associated with cross-border trade. It utilizes AI/ML models to manage and structure data, perform entity resolution and network analysis, and contribute to the software's knowledge graph and user interface.","Yes, the project described above has the potential to be a safety risk. According to the provided definition of safety risks, the project falls under the category of ""enforcement actions pursuant to sanctions, trade restrictions, or other controls on exports, investments, or shipping"" (k).

The software system, Entity Resolution, is designed to analyze trade flows and risks associated with cross-border trade. This means it will likely have access to sensitive information related to global trade, which can include data on exports, investments, and shipping. If this information is mishandled or misused, it could lead to potential safety risks such as compromising national security, violating trade regulations, or facilitating illegal activities.

Therefore, the project should be carefully managed and implemented to mitigate any potential safety risks and ensure the proper handling of sensitive trade data.","Yes, the project described potentially poses a safety risk. The project involves collecting and analyzing sensitive data related to trade flows and risks associated with cross-border trade. This data could potentially be used to make decisions or assessments that have significant implications for individuals or organizations, such as law enforcement actions or trade restrictions. If the AI/ML models or the software's knowledge graph and user interface are not properly designed, implemented, or secured, it could lead to erroneous or biased decisions, privacy breaches, or misuse of the collected data. Additionally, the project may involve the use of surveillance techniques, which could raise concerns regarding privacy and civil liberties. Therefore, a thorough assessment of the project's potential safety risks and appropriate safeguards should be conducted.",True,True
DOE-0159-2023,DOE,"Office of Environment, Health, Safety & Security",,"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data: Unsupervised Machine Learning Text Clustering","""The EHSS Data Analytics Machine Learning (DAMaL) tools, 
unsupervised machine learning clustering tool, uses natural language 
processing (NLP) and clustering algorithms (i.e., k means, DBSCAN 
and dimensionality reduction approaches) to leverage AI to analyze the 
text of the DOE environment, safety, and health (ES&H) and operating 
experience dataset records (e.g., occurrence reporting and processing 
system, fire protection, lessons learned, and accident and injury 
reporting system, contractor assurance system CAS).  The tool 
identifies recurrent and important topics that can be used by an analyst 
to drill down and further explore potential recurrent safety issues in the 
DOE operations.
As of October 2021, the tool has been partially deployed in the DAMaL 
tools website.  Development is mostly complete with use case in Fire 
Protection Trending and Analysis completed and undergoing review of 
report.  Expected to continue to maintain, develop documentation (e.g., 
users analysis guides), improve and enhance, and increase data 
sources.",,,,Department of Energy,"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data: Unsupervised Machine Learning Text Clustering: 
""The EHSS Data Analytics Machine Learning (DAMaL) tools, 
unsupervised machine learning clustering tool, uses natural language 
processing (NLP) and clustering algorithms (i.e., k means, DBSCAN 
and dimensionality reduction approaches) to leverage AI to analyze the 
text of the DOE environment, safety, and health (ES&H) and operating 
experience dataset records (e.g., occurrence reporting and processing 
system, fire protection, lessons learned, and accident and injury 
reporting system, contractor assurance system CAS).  The tool 
identifies recurrent and important topics that can be used by an analyst 
to drill down and further explore potential recurrent safety issues in the 
DOE operations.
As of October 2021, the tool has been partially deployed in the DAMaL 
tools website.  Development is mostly complete with use case in Fire 
Protection Trending and Analysis completed and undergoing review of 
report.  Expected to continue to maintain, develop documentation (e.g., 
users analysis guides), improve and enhance, and increase data 
sources.","The DAMaL tools use unsupervised machine learning clustering, NLP, and clustering algorithms to analyze text data from DOE ES&H records. The tools identify important topics that can help analysts investigate recurring safety issues in DOE operations. The tools have been partially deployed and are expected to be maintained, improved, and expanded with more data sources.","The DAMaL tools use unsupervised machine learning clustering, NLP, and clustering algorithms to analyze text data from DOE ES&H records. The tools identify important topics that can help analysts investigate recurring safety issues in DOE operations. The tools have been partially deployed and are expected to be maintained, improved, and expanded with more data sources.","Yes, the project is potentially a safety risk. 

The project involves the analysis of text data from DOE ES&H records, which are related to the functioning of dams, emergency services, electrical grids, and other systems controlling physical transit. If the tools used in the project fail to accurately identify important safety topics or overlook recurring safety issues, it could pose a risk to the overall safety of DOE operations. Therefore, ensuring the effectiveness and reliability of these tools is crucial in preventing potential safety risks.","Yes, the project is potentially a safety risk. 

The project involves analyzing text data from DOE ES&H records using unsupervised machine learning clustering, NLP, and clustering algorithms. While the project itself may not directly involve activities that pose safety risks, the potential consequences of the project's outcomes can have an impact on safety.

If the tools used in the project fail to accurately identify important topics or recurring safety issues in DOE operations, it could lead to a failure in addressing potential safety hazards. This could result in accidents, injuries, or even fatalities. 

Therefore, although the project itself does not inherently pose a safety risk, the potential implications and consequences of its outcomes make it potentially risky in terms of safety.",True,True
VA-0024-2023,VA,,,"Prediction of health outcomes, including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.","Using electronic health records (EHR) (both structured and unstructured data) as  inputs, this tool outputs deep phenotypes and predictions of health outcomes including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.",,,,Department of Veterans Affairs,"Prediction of health outcomes, including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.: 
Using electronic health records (EHR) (both structured and unstructured data) as  inputs, this tool outputs deep phenotypes and predictions of health outcomes including suicide death, opioid overdose, and decompensated outcomes of chronic diseases.","This tool utilizes electronic health records (EHR) to generate deep phenotypes and predict various health outcomes such as suicide death, opioid overdose, and worsening conditions of chronic diseases. It takes both structured and unstructured data from EHR as inputs.","This tool utilizes electronic health records (EHR) to generate deep phenotypes and predict various health outcomes such as suicide death, opioid overdose, and worsening conditions of chronic diseases. It takes both structured and unstructured data from EHR as inputs.","Yes, the project described above is potentially a safety risk. This is because it falls under category (a) of safety risks, specifically related to the functioning of healthcare systems and the generation of health outcomes. The project involves the use of electronic health records (EHR) and the prediction of various health outcomes, including suicide death, opioid overdose, and worsening conditions of chronic diseases. If there are any errors or inaccuracies in the data analysis or predictions, it could lead to serious consequences for patients' health and safety. Additionally, if the tool is not properly secured or protected, there could be risks in terms of the privacy and security of patients' health information.","Yes, the project described above is potentially a safety risk. The project involves making predictions about various health outcomes based on electronic health records (EHR) data. While the use of EHR data for predictive purposes can have potential benefits, it also raises concerns about privacy, data security, and potential misuse of the predictions.

The project falls under category ""g"" in the defined risks, which includes decisions regarding medical devices, clinical diagnosis, and determination of treatment. Predicting health outcomes such as suicide death and opioid overdose involves sensitive and potentially life-threatening decisions. If the predictions are inaccurate or biased, it could lead to harmful consequences for individuals, such as misdiagnosis or inappropriate treatment decisions.

Additionally, the use of structured and unstructured data from EHR raises concerns about privacy and data security. EHR contains highly personal and sensitive information, and the project's use of this data for predictive purposes raises questions about how the data will be handled, stored, and protected.

It is important to carefully evaluate the potential safety risks associated with this project and implement appropriate safeguards to address privacy, data security, and potential biases in the predictions.",True,True
HHS-0073-2023,HHS,FDA,CDER/Office of Strategic Programs (OSP),Opioid Data Warehouse Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics,"The Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics use publicly available social media and forensic chemistry data to identify novel referents to drug products in social media text. It uses the FastText library to create vector models of each known NSO-related term in a large social media corpus, and provides users with similarity scores and expected prevalence estimates for lists of terms that could be used to enhance future data gathering efforts. ",Operation and Maintenance,,,Department of Health and Human Services,"Opioid Data Warehouse Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics: 
The Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics use publicly available social media and forensic chemistry data to identify novel referents to drug products in social media text. It uses the FastText library to create vector models of each known NSO-related term in a large social media corpus, and provides users with similarity scores and expected prevalence estimates for lists of terms that could be used to enhance future data gathering efforts. ","The Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics is a system that utilizes social media and forensic chemistry data to identify new references to drug products in social media text. It employs the FastText library to create vector models of known NSO-related terms in a large social media corpus, offering similarity scores and prevalence estimates for lists of terms to improve data gathering in the future.","The Term Identification and Novel Synthetic Opioid Detection and Evaluation Analytics is a system that utilizes social media and forensic chemistry data to identify new references to drug products in social media text. It employs the FastText library to create vector models of known NSO-related terms in a large social media corpus, offering similarity scores and prevalence estimates for lists of terms to improve data gathering in the future.","Yes, the project described above is potentially a safety risk.

The project involves the use of social media and forensic chemistry data to identify new references to drug products in social media text. This raises concerns related to the transportation or management of controlled substances, as well as the potential for the delivery of potentially damaging substances. The use of synthetic opioids itself poses significant health risks and can lead to addiction and overdose.

Additionally, the project involves the collection and analysis of large amounts of data from social media platforms. This raises concerns about the security and privacy of individuals' information, as well as the potential for misuse or unauthorized access to sensitive data.

Overall, the project involves elements that pose risks to public health and safety, as well as potential privacy and security concerns.","Yes, the project described above is potentially a safety risk. The project involves the use of social media data and forensic chemistry data to identify references to drug products in social media text. This can have potential safety risks in multiple ways:

1. Privacy and ethical concerns: The project involves monitoring and analyzing social media data, which raises concerns about privacy and the potential misuse of personal information.

2. Drug-related risks: The project focuses on identifying references to drug products in social media, which could involve the monitoring of illegal drug activities. This could potentially expose the project team to dangerous individuals or criminal organizations.

3. Accuracy and reliability: The project aims to improve data gathering by providing similarity scores and prevalence estimates for drug-related terms. If these models are not accurate or reliable, it could lead to false positives or false negatives, potentially impacting law enforcement efforts or public safety measures.

4. Misuse of data: The project could have unintended consequences if the data gathered is used for purposes other than its intended goal. For example, if the data is used to target or discriminate against individuals based on their online activities or associations.

Overall, the project poses potential safety risks in terms of privacy, accuracy, and the potential for misuse of data.",True,True
DHS-0005-2023,DHS,Customs and Border Protection,,Autonomous Surveillance Towers (Anduril),"Autonomously Detects, Identifies, and Tracks items of interest using Artificial Intelligence integrated with the tower. It does not require a dedicated operator, is rapidly deployable, and is relocatable in less than a day by 2-3 people.

The system features a hybrid command and control capability, hosted in the government cloud, and is accessible via URL by desktop, laptop, tablet, or Smartphone. It is solar powered with battery backup and requires no accompanying physical infrastructure while providing visibility for 1.5 miles (2.4 km) for people, 3 miles (4.8km) for vehicles.

The Lattice system permits autonomous detection, identification, and tracking of Items of Interest (IoIs).  The tower scans constantly and autonomously.  The radar detects and recognizes movement. The camera slews autonomously to the IoI and the system software identifies the object.  The system alerts the user and autonomously tracks the IoI. End users can monitor the system and see near real time photos by logging into the User Interface on any CBP device. ",Operation and Maintenance,Machine Vision,,Department of Homeland Security,"Autonomous Surveillance Towers (Anduril): 
Autonomously Detects, Identifies, and Tracks items of interest using Artificial Intelligence integrated with the tower. It does not require a dedicated operator, is rapidly deployable, and is relocatable in less than a day by 2-3 people.

The system features a hybrid command and control capability, hosted in the government cloud, and is accessible via URL by desktop, laptop, tablet, or Smartphone. It is solar powered with battery backup and requires no accompanying physical infrastructure while providing visibility for 1.5 miles (2.4 km) for people, 3 miles (4.8km) for vehicles.

The Lattice system permits autonomous detection, identification, and tracking of Items of Interest (IoIs).  The tower scans constantly and autonomously.  The radar detects and recognizes movement. The camera slews autonomously to the IoI and the system software identifies the object.  The system alerts the user and autonomously tracks the IoI. End users can monitor the system and see near real time photos by logging into the User Interface on any CBP device. ","The Autonomous Surveillance Towers by Anduril are capable of autonomously detecting, identifying, and tracking items of interest using AI. With a hybrid command and control capability, the system can be accessed remotely via URL on various devices. It is solar powered, easily deployable, and can provide visibility for up to 1.5 miles for people and 3 miles for vehicles. The tower constantly scans, detects movement, slews the camera to the object, identifies it, and alerts the user while autonomously tracking the object.","The Autonomous Surveillance Towers by Anduril are capable of autonomously detecting, identifying, and tracking items of interest using AI. With a hybrid command and control capability, the system can be accessed remotely via URL on various devices. It is solar powered, easily deployable, and can provide visibility for up to 1.5 miles for people and 3 miles for vehicles. The tower constantly scans, detects movement, slews the camera to the object, identifies it, and alerts the user while autonomously tracking the object.","Yes, the project described above is potentially a safety risk. 

According to the defined safety risks, the project falls under several categories. 

First, it involves the movement of physical objects (vehicles) and the potential delivery of kinetic force or potentially damaging electromagnetic impulses. This could pose a risk to the safety of individuals or property if the system malfunctions or is misused.

Second, the project involves the design and construction of industrial equipment (surveillance towers) that could pose a meaningful risk to safety if they were to fail. This includes potential risks related to the tower structure, solar power system, or the autonomous tracking and detection capabilities.

Additionally, the project involves the access and security of government facilities, as the system can be remotely accessed via URL on various devices. This raises concerns about potential unauthorized access or security breaches.

Overall, the Autonomous Surveillance Towers project has elements that fall within the defined safety risks, making it potentially a safety risk.","Yes, the project described, the Autonomous Surveillance Towers by Anduril, is potentially a safety risk. The project falls under the category of ""Law enforcement or surveillance-related risk assessments about individuals"" mentioned in the defined risks. The use of AI to autonomously detect, identify, and track individuals can raise concerns regarding privacy, surveillance, and potential misuse of the technology.

Additionally, the project involves constant scanning, movement detection, and tracking of individuals or objects. This level of monitoring can infringe upon personal freedoms, raise ethical concerns, and potentially lead to discrimination or abuse of power.

Furthermore, the remote accessibility of the system, along with its potential to provide visibility for miles, increases the risk of unauthorized access, hacking, or misuse of the technology. This can compromise the privacy and security of individuals being monitored.

Therefore, the Autonomous Surveillance Towers project poses a safety risk due to its potential for infringing upon privacy rights, enabling surveillance, and facilitating potential misuse or abuse of the technology.",True,True
DHS-0020-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Cyber Threat Intelligence Feed Correlation,"Cyber Threat Intelligence Feed Correlation uses AI enabled capabilities to provide accelerated correlation across multiple incoming information feeds. This enables more timely enrichment to improve the externally shared information feeds. AI allows the algorithm to use the information items and results to learn most efficient ways to perform the task. Additionally, tailored algorithms could be created to provided sustained surveillance of threat actor TTPs.
",Initiation,"Machine Learning, Natural Language Processing (NLP)",,Department of Homeland Security,"Cyber Threat Intelligence Feed Correlation: 
Cyber Threat Intelligence Feed Correlation uses AI enabled capabilities to provide accelerated correlation across multiple incoming information feeds. This enables more timely enrichment to improve the externally shared information feeds. AI allows the algorithm to use the information items and results to learn most efficient ways to perform the task. Additionally, tailored algorithms could be created to provided sustained surveillance of threat actor TTPs.
","Cyber Threat Intelligence Feed Correlation is a system that utilizes AI technology to quickly analyze and correlate information from various sources. This helps to enhance the quality of shared information and allows the algorithm to learn and improve its performance. It also has the potential to create customized algorithms for continuous monitoring of threat actor tactics, techniques, and procedures (TTPs).","Cyber Threat Intelligence Feed Correlation is a system that utilizes AI technology to quickly analyze and correlate information from various sources. This helps to enhance the quality of shared information and allows the algorithm to learn and improve its performance. It also has the potential to create customized algorithms for continuous monitoring of threat actor tactics, techniques, and procedures (TTPs).","Yes, the project Cyber Threat Intelligence Feed Correlation potentially poses a safety risk. It falls under the category of ""a. The functioning of dams, emergency services, electrical grids or the generation or movement of energy, fire safety systems, food safety mechanisms, integrity of elections and voting infrastructure, traffic control systems and other systems controlling physical transit, water and wastewater systems, and nuclear reactors, materials, and waste."" This is because the project involves the analysis and correlation of information from various sources, which can have an impact on the functioning and security of critical infrastructure systems, such as electrical grids, emergency services, and traffic control systems. If the AI technology used in the project fails or provides inaccurate information, it could lead to disruptions or compromises in these systems, posing a safety risk.","Yes, the project described above is potentially a safety risk. It falls under the category of ""Law enforcement or surveillance-related risk assessments about individuals"" and ""conduct of cyber intrusions."" The use of AI technology to analyze and correlate information from various sources, particularly in the context of cyber threats, can potentially infringe on privacy rights and lead to unintended consequences such as false accusations or misidentifications. It also raises concerns about the potential for abuse and misuse of the collected data. Therefore, careful consideration and oversight are necessary to ensure the project does not pose a safety risk.",True,True
HHS-0084-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Artificial Intelligence (AI) Supported Annotation of FAERS Reports,"Develop a prototype software application to support the human�review of FAERS data by developing computational algorithms to semi-automatically categorizing FAERS reports into meaningful medication error categories based on report free text. Leveraged existing annotated reports and worked with subject matter experts to annotate subsets of FAERS reports, to generate initial NLP algorithms that can classify any report as being medication related and with an identified type of medication error. An innovative active learning approach was then used to annotate reports and build more robust algorithms for more accurate categorization. ",Development and Acquisition,,,Department of Health and Human Services,"Artificial Intelligence (AI) Supported Annotation of FAERS Reports: 
Develop a prototype software application to support the human�review of FAERS data by developing computational algorithms to semi-automatically categorizing FAERS reports into meaningful medication error categories based on report free text. Leveraged existing annotated reports and worked with subject matter experts to annotate subsets of FAERS reports, to generate initial NLP algorithms that can classify any report as being medication related and with an identified type of medication error. An innovative active learning approach was then used to annotate reports and build more robust algorithms for more accurate categorization. ","The text describes the development of a software application that uses artificial intelligence to categorize FAERS reports, which contain information about medication errors. The application uses computational algorithms and natural language processing to automatically classify reports and identify the type of medication error. An active learning approach is used to continuously improve the accuracy of the algorithms.","The text describes the development of a software application that uses artificial intelligence to categorize FAERS reports, which contain information about medication errors. The application uses computational algorithms and natural language processing to automatically classify reports and identify the type of medication error. An active learning approach is used to continuously improve the accuracy of the algorithms.","Yes, the project described is potentially a safety risk. This is because it involves the categorization of FAERS reports, which contain information about medication errors. Medication errors can have serious consequences on patient safety and well-being. If the software application fails to accurately categorize the reports or identify the type of medication error, it could lead to incorrect interventions or inadequate measures to prevent future errors. Therefore, the potential risk to patient safety makes this project a safety concern.","Yes, the project described has the potential to be a safety risk. The use of artificial intelligence and algorithms to categorize medication errors is a critical task that directly impacts patient safety. If the software application misclassifies or fails to accurately identify medication errors, it could have serious consequences for patients, potentially leading to incorrect treatment or harm caused by medication errors going unnoticed. Therefore, the accuracy and reliability of the algorithms used in this project are of utmost importance to ensure patient safety.",True,True
DOE-0047-2023,DOE,National Energy Technology Laboratory,,Development of AI/ML methods,"Develop quality, reliability, and version control standards for SMART 
software. Continue development of AI/ML methods for use by the 2A 
and 2C activities, including Modeling anomalies due to local 
heterogeneity coupled with an enhanced capacitance-resistance model 
(CRM) and Bayesian Belief Network (BBN) modeling integrated with 
geochemistry. Continue development of advanced computational 
approaches with modeling using the most advanced general purpose 
PDE/ODE physics-informed neural network (PINN) tool developed by 
NVIDIA and accelerate training PINNs using Wafer Scale Engine (WSE) 
by Cerebras Systems Inc.",,Other,,Department of Energy,"Development of AI/ML methods: 
Develop quality, reliability, and version control standards for SMART 
software. Continue development of AI/ML methods for use by the 2A 
and 2C activities, including Modeling anomalies due to local 
heterogeneity coupled with an enhanced capacitance-resistance model 
(CRM) and Bayesian Belief Network (BBN) modeling integrated with 
geochemistry. Continue development of advanced computational 
approaches with modeling using the most advanced general purpose 
PDE/ODE physics-informed neural network (PINN) tool developed by 
NVIDIA and accelerate training PINNs using Wafer Scale Engine (WSE) 
by Cerebras Systems Inc.","The text discusses the development of AI/ML methods for SMART software. This includes the establishment of quality, reliability, and version control standards. Additionally, the text mentions the development of AI/ML methods for activities 2A and 2C, such as modeling anomalies with a CRM and BBN modeling integrated with geochemistry. Advanced computational approaches using NVIDIA's PINN tool and Cerebras Systems Inc.'s WSE are also being developed to accelerate training.","The text discusses the development of AI/ML methods for SMART software. This includes the establishment of quality, reliability, and version control standards. Additionally, the text mentions the development of AI/ML methods for activities 2A and 2C, such as modeling anomalies with a CRM and BBN modeling integrated with geochemistry. Advanced computational approaches using NVIDIA's PINN tool and Cerebras Systems Inc.'s WSE are also being developed to accelerate training.","Yes, the project is potentially a safety risk. 

The development of AI/ML methods for SMART software may involve the functioning of critical systems such as electrical grids, emergency services, and traffic control systems. If these systems are not properly developed and tested, they could pose a safety risk.

Additionally, the project mentions the development of AI/ML methods for activities involving physical movements within various settings, including workplaces, transportation, and law enforcement. If the movements of robotic appendages or bodies are not properly controlled or monitored, it could result in accidents or harm to humans.

Furthermore, the project involves the development of advanced computational approaches using tools like NVIDIA's PINN and Cerebras Systems Inc.'s WSE. If these tools are not properly designed or tested, they could potentially cause harmful effects or damage.

Overall, the project involves several elements that could pose safety risks if not appropriately managed.","Yes, the project described is potentially a safety risk. The project involves the development of AI/ML methods for various activities, including law enforcement or surveillance-related risk assessments, detecting or measuring emotions and thoughts in humans, determining access to educational resources or programs, determining the terms and conditions of employment, making decisions regarding medical devices and clinical diagnosis, determining access to government benefits or services, and making recommendations or decisions about child welfare.

These activities have significant implications for individuals' rights, privacy, and potential for discrimination or bias. The use of AI/ML in these areas can lead to errors, unfair treatment, and infringement on civil liberties. It is crucial to carefully assess and address the potential risks and ensure that proper safeguards are in place to mitigate any adverse impacts on individuals or society.",True,True
DOE-0117-2023,DOE,National Energy Technology Laboratory,,To identify and characterization REE- CM hot zones using machine learning-aided multi-physics.,"Develop and field demonstrate a machine learning (ML)-aided multi-
physics approach for rapid identification and characterization of REE-
CM hot zones in mine tailings with a focus on coal and sulfide mine 
tailings or other processing or utilization byproducts, such as fly ash and 
refuse deposits.",,Artificial Intelligence Unknown,,Department of Energy,"To identify and characterization REE- CM hot zones using machine learning-aided multi-physics.: 
Develop and field demonstrate a machine learning (ML)-aided multi-
physics approach for rapid identification and characterization of REE-
CM hot zones in mine tailings with a focus on coal and sulfide mine 
tailings or other processing or utilization byproducts, such as fly ash and 
refuse deposits.","The text states the goal of developing and demonstrating a machine learning-aided multi-physics approach to quickly identify and characterize areas with high concentrations of rare earth elements (REE) in mine tailings. The focus is on coal and sulfide mine tailings, as well as other byproducts like fly ash and refuse deposits.","The text states the goal of developing and demonstrating a machine learning-aided multi-physics approach to quickly identify and characterize areas with high concentrations of rare earth elements (REE) in mine tailings. The focus is on coal and sulfide mine tailings, as well as other byproducts like fly ash and refuse deposits.","Yes, the project described potentially poses a safety risk. This is because the project involves the testing and characterization of mine tailings, which can contain hazardous chemicals and substances. The transport, safety, design, or development of hazardous chemicals or biological entities falls under the category of safety risks mentioned. Therefore, the project's activities related to mine tailings could potentially pose a meaningful risk to safety.","Yes, the project described potentially poses a safety risk. 

Although the project itself does not directly involve activities that are traditionally associated with safety risks, the use of machine learning and data analysis in identifying and characterizing areas with high concentrations of rare earth elements in mine tailings can indirectly impact safety. 

Mining activities and the handling of mine tailings can pose significant safety risks due to the potential for landslides, collapse of mine structures, release of harmful chemicals, and other hazards. If the project aims to locate areas with high concentrations of rare earth elements in mine tailings, it could potentially lead to increased mining activities in those areas. This, in turn, may increase the associated safety risks for workers and the surrounding environment. 

Therefore, while the project itself may not be directly related to safety risks, its potential consequences on mining activities and the handling of mine tailings make it a potentially safety risk.",True,True
DHS-0015-2023,DHS,Cybersecurity and Infrastructure Security Agency,,AI Security and Robustness,"Frameworks, processes, and testing tools developed to govern the acquisition, development, deployment, and maintenance of AI technologies. Technology integrators within CISA as well as the rest of the federal enterprise use AI-enhanced tools to assure the trustworthy, robust, and secure operation of their AI systems. These tools use Machine Learning and Natural Language Processing to enhance the assessment of AI technology within the agency by speeding up data processing.",Initiation,"Machine Learning, Natural Language Processing (NLP)",,Department of Homeland Security,"AI Security and Robustness: 
Frameworks, processes, and testing tools developed to govern the acquisition, development, deployment, and maintenance of AI technologies. Technology integrators within CISA as well as the rest of the federal enterprise use AI-enhanced tools to assure the trustworthy, robust, and secure operation of their AI systems. These tools use Machine Learning and Natural Language Processing to enhance the assessment of AI technology within the agency by speeding up data processing.","AI Security and Robustness involves the creation of frameworks, processes, and testing tools to govern the acquisition, development, deployment, and maintenance of AI technologies. These tools, which utilize Machine Learning and Natural Language Processing, are used by technology integrators in CISA and other federal entities to ensure the reliable, strong, and secure functioning of their AI systems by expediting data processing.","AI Security and Robustness involves the creation of frameworks, processes, and testing tools to govern the acquisition, development, deployment, and maintenance of AI technologies. These tools, which utilize Machine Learning and Natural Language Processing, are used by technology integrators in CISA and other federal entities to ensure the reliable, strong, and secure functioning of their AI systems by expediting data processing.","Yes, the project described is potentially a safety risk. This is because it involves the creation and deployment of AI technologies, which can have implications for various safety-critical systems and infrastructure. The use of AI in areas such as emergency services, traffic control systems, and nuclear reactors can introduce new risks if not properly governed and tested for security and robustness.

Additionally, the project involves the development and deployment of frameworks and tools that utilize Machine Learning and Natural Language Processing. These technologies have the potential to be manipulated or exploited, leading to security vulnerabilities or unintended consequences. Ensuring the reliable and secure functioning of AI systems is crucial to mitigate these risks.

Therefore, the project falls under the safety risks mentioned in the provided definition, specifically in relation to the functioning of critical systems and infrastructure, the movements within various settings, and the design and development of industrial equipment or structures.","Yes, the project described is potentially a safety risk. The project involves the creation of frameworks, processes, and testing tools for AI technologies. These technologies utilize Machine Learning and Natural Language Processing and are used for AI systems in federal entities to ensure reliable and secure functioning.

While the project description does not directly mention any specific risks, the defined risks in the question include decisions related to surveillance, law enforcement, medical diagnosis, financial systems, government benefits, child welfare, and more. If the AI technologies developed in this project are used in any of these areas without proper consideration of potential biases, errors, or ethical concerns, they can pose safety risks.

For example, if AI systems are used for law enforcement risk assessments or sentencing decisions without proper validation and oversight, it can lead to unfair outcomes or perpetuate existing biases. Similarly, if AI systems are used for medical diagnosis without thorough testing and validation, incorrect or inaccurate diagnoses can put patients' health at risk.

Therefore, while the project itself aims to ensure the security and robustness of AI systems, it is crucial to carefully consider the potential risks and implications of deploying these technologies in sensitive areas to prevent any safety risks.",True,True
DOT-0008-2023,DOT,NSR Human Injury Research Division,,Machine Learning for Occupant Safety Research,"Description: Utilize deep learning for predicting crash parameters, Delta-V (change in velocity) and PDOF (principal direction of force), directly from real-world crash images. Delta-V and PDOF are two most important parameters affecting injury outcome. Deep learning models can help predict both Delta-V and PDOF, without the need to run WinSmash software for Delta-V computation, and without requiring estimations by crash examiners.  Moreover, with deep learning models, the Delta-V and PDOF can be obtained within milliseconds, providing rapid results for improved efficiency""
Input:  Real world crash images
Output:  Delta-V & PDOF",Currently under development,Deep learning models - Convolutional Neural Networks,,Department of Transportation,"Machine Learning for Occupant Safety Research: 
Description: Utilize deep learning for predicting crash parameters, Delta-V (change in velocity) and PDOF (principal direction of force), directly from real-world crash images. Delta-V and PDOF are two most important parameters affecting injury outcome. Deep learning models can help predict both Delta-V and PDOF, without the need to run WinSmash software for Delta-V computation, and without requiring estimations by crash examiners.  Moreover, with deep learning models, the Delta-V and PDOF can be obtained within milliseconds, providing rapid results for improved efficiency""
Input:  Real world crash images
Output:  Delta-V & PDOF","This text describes the use of deep learning in predicting two important parameters, Delta-V and PDOF, for occupant safety research. By analyzing real-world crash images, deep learning models can accurately predict these parameters without the need for WinSmash software or estimations by crash examiners. This not only improves efficiency but also provides rapid results within milliseconds.","This text describes the use of deep learning in predicting two important parameters, Delta-V and PDOF, for occupant safety research. By analyzing real-world crash images, deep learning models can accurately predict these parameters without the need for WinSmash software or estimations by crash examiners. This not only improves efficiency but also provides rapid results within milliseconds.","Yes, the project described potentially poses a safety risk. According to the defined risks, the project falls under category b, which includes the physical movements within various settings, such as transportation or law enforcement. In this case, the use of deep learning models for occupant safety research involves analyzing crash images to predict parameters related to crashes. If these predictions are not accurate or reliable, it could lead to incorrect assessments of safety measures or recommendations, potentially putting occupants at risk in real-world accidents. Therefore, further evaluation and testing are necessary to ensure the safety and reliability of the deep learning models used in this project.","Yes, the project described is potentially a safety risk. The use of deep learning to predict parameters for occupant safety research in real-world crash images may involve the analysis of sensitive data related to accidents and potential injuries to individuals. If the predictions or assessments made by the deep learning models are used in critical decision-making processes such as determining the terms and conditions of employment, insurance processes, or access to government benefits or services, there is a risk that incorrect or biased predictions could lead to negative outcomes for individuals involved. It is important to ensure that the deep learning models are properly validated and regularly updated to minimize potential safety risks and to consider the ethical implications of using such technology in sensitive areas.",True,True
DOE-0052-2023,DOE,National Energy Technology Laboratory,,"Initial case study using regulatory compliance (well integrity testing, fluid compositionali data, geographic, and geologic information from oil and gas wells in the Wattenberg Field, Denver Basin, central Colorado, USA","Researchers will apply artificial intelligence/machine learning (AI/ML) 
techniques to national-scale well characterization and integrity test 
datasets to yield new insights into leakage potential.",,Other,,Department of Energy,"Initial case study using regulatory compliance (well integrity testing, fluid compositionali data, geographic, and geologic information from oil and gas wells in the Wattenberg Field, Denver Basin, central Colorado, USA: 
Researchers will apply artificial intelligence/machine learning (AI/ML) 
techniques to national-scale well characterization and integrity test 
datasets to yield new insights into leakage potential.","Researchers will use AI/ML techniques to analyze well integrity testing, fluid compositional data, and geographical/geological information from oil and gas wells in the Wattenberg Field, Denver Basin, central Colorado, USA. Their goal is to gain new insights into potential leakage issues at a national scale.","Researchers will use AI/ML techniques to analyze well integrity testing, fluid compositional data, and geographical/geological information from oil and gas wells in the Wattenberg Field, Denver Basin, central Colorado, USA. Their goal is to gain new insights into potential leakage issues at a national scale.","Yes, the project potentially poses safety risks. The analysis of well integrity testing and fluid compositional data from oil and gas wells can involve the transportation, safety, design, or development of hazardous chemicals. If not properly managed, this can lead to accidents, leaks, or other safety issues that can harm the environment and human health. Additionally, the project involves the transportation or management of industrial waste, which can also pose risks if not handled appropriately.","Yes, the project is potentially a safety risk. The analysis of well integrity testing and fluid compositional data, along with geographical/geological information, is crucial for identifying potential leakage issues in oil and gas wells. Any leakage in these wells can pose significant safety hazards, including environmental damage, health risks, and potential accidents. Therefore, the project's outcomes and recommendations will directly impact the safety of the oil and gas industry and the surrounding communities.",True,True
DOE-0127-2023,DOE,National Energy Technology Laboratory,,To perform reconstruction of the 3D temperature field using Neural Networks with measured and known propagation paths.,"The sensor will first be tested up to 300 C. For high-temperature tests, 
the Recipient will use Alstom’s Industrial Size Burner Test Facility (ISBF) 
or another appropriate facility. The high-temperature sensor will be first 
tested from room temperature to 1,800 C. The results will be 
compared with data obtained using other methods such as surface 
acoustic wave (SAW), thermocouples, and optical fiber sensors. A 3D 
temperature mapping will be created by fusing the high-temperature 
sensor data. The Recipient will test the system’s survivability in a boiler 
environment. A high-temperature sensing array will be tested to map the 
temperature distribution within an exhaust pipe. The sensor array will be 
tested at one 6’’ port or a similar location. The Recipient will also 
perform reconstruction of the 3D temperature field using Neural 
Networks with measured and known propagation paths.",,Artificial Intelligence Unknown,,Department of Energy,"To perform reconstruction of the 3D temperature field using Neural Networks with measured and known propagation paths.: 
The sensor will first be tested up to 300 C. For high-temperature tests, 
the Recipient will use Alstom’s Industrial Size Burner Test Facility (ISBF) 
or another appropriate facility. The high-temperature sensor will be first 
tested from room temperature to 1,800 C. The results will be 
compared with data obtained using other methods such as surface 
acoustic wave (SAW), thermocouples, and optical fiber sensors. A 3D 
temperature mapping will be created by fusing the high-temperature 
sensor data. The Recipient will test the system’s survivability in a boiler 
environment. A high-temperature sensing array will be tested to map the 
temperature distribution within an exhaust pipe. The sensor array will be 
tested at one 6’’ port or a similar location. The Recipient will also 
perform reconstruction of the 3D temperature field using Neural 
Networks with measured and known propagation paths.","The text describes the process of reconstructing a 3D temperature field using Neural Networks. The sensor used for testing will be subjected to temperatures up to 300C initially, and then up to 1,800C in high-temperature tests. The results will be compared with data from other methods, and a 3D temperature mapping will be created using the sensor data. Additionally, the system's survivability will be tested in a boiler environment, and a high-temperature sensing array will be used to map temperature distribution within an exhaust pipe.","The text describes the process of reconstructing a 3D temperature field using Neural Networks. The sensor used for testing will be subjected to temperatures up to 300C initially, and then up to 1,800C in high-temperature tests. The results will be compared with data from other methods, and a 3D temperature mapping will be created using the sensor data. Additionally, the system's survivability will be tested in a boiler environment, and a high-temperature sensing array will be used to map temperature distribution within an exhaust pipe.","Yes, the project described potentially poses a safety risk. The project involves testing a sensor in high-temperature environments, reaching temperatures up to 1,800°C. This poses a risk of thermal damage or failure of the sensor, which could lead to inaccurate temperature measurements or potential malfunctions. Additionally, testing the system's survivability in a boiler environment raises concerns about potential hazards and risks associated with high temperatures and steam. Therefore, the project should be conducted with appropriate safety measures and protocols to mitigate these risks.","Yes, the project described potentially poses a safety risk. The testing of the sensor at temperatures up to 1,800°C and the survivability testing in a boiler environment involve high temperatures that could lead to equipment failure, malfunction, or potential hazards. Additionally, mapping temperature distribution within an exhaust pipe may involve working in close proximity to hot surfaces and potentially hazardous environments. Therefore, proper safety precautions and protocols should be in place to mitigate the risks associated with this project.",True,True
HHS-0009-2023,HHS,ASPR,BARDA (DRIVe),Digital MCM: Virufy,Using forced cough vocalization (FCV) in a smartphone to detect the presence of COVID-19 using AI.,Operation and Maintenance,,,Department of Health and Human Services,"Digital MCM: Virufy: 
Using forced cough vocalization (FCV) in a smartphone to detect the presence of COVID-19 using AI.",Virufy is a digital MCM that utilizes forced cough vocalization through a smartphone to detect the presence of COVID-19. This innovative technology combines AI to analyze cough sounds and identify potential cases of the virus.,Virufy is a digital MCM that utilizes forced cough vocalization through a smartphone to detect the presence of COVID-19. This innovative technology combines AI to analyze cough sounds and identify potential cases of the virus.,"Yes, the project is potentially a safety risk. The project falls under category b, as it involves the physical movement of individuals within a medical setting. Additionally, there may be concerns related to the delivery of potentially damaging electromagnetic impulses (category c) through the smartphone. As with any medical technology, there is always a risk of false positives or negatives, which could lead to incorrect diagnoses or delayed treatment. Therefore, careful testing, validation, and regulatory oversight are necessary to ensure the safety and effectiveness of the Virufy project.","Yes, the project is potentially a safety risk. This is because it falls under category ""g"" mentioned in the defined risks, which includes decisions regarding medical devices, medical diagnostic tools, and clinical diagnosis and determination of treatment. Virufy is a medical diagnostic tool that aims to detect the presence of COVID-19 through cough sounds. Any technology or system that is used for medical diagnosis carries potential safety risks, as it can have serious consequences if it provides inaccurate or misleading results. Therefore, proper testing, validation, and regulatory oversight are necessary to ensure the safety and effectiveness of such a project.",True,True
DHS-0032-2023,DHS,Immigration and Customs Enforcement,,Facial Recognition Service,"The Facial Recognition Service is used during investigations conducted by HSI agents and analysts for identification of known individuals, as well as extracting faces for further investigations from perpetrators including child exploitation offenses, human rights atrocities, and war criminals.

This is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",Operation and Maintenance,"Machine Learning, Machine Vision",,Department of Homeland Security,"Facial Recognition Service: 
The Facial Recognition Service is used during investigations conducted by HSI agents and analysts for identification of known individuals, as well as extracting faces for further investigations from perpetrators including child exploitation offenses, human rights atrocities, and war criminals.

This is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.","The Facial Recognition Service, developed by the DHS HSI Innovation Lab, is utilized by HSI agents and analysts to identify known individuals and extract faces from perpetrators involved in child exploitation offenses, human rights atrocities, and war crimes. This service is supported by RAVEn, a virtualized environment that enables large analytical projects and helps ICE enforce and investigate violations of U.S. laws. For more details, refer to the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.","The Facial Recognition Service, developed by the DHS HSI Innovation Lab, is utilized by HSI agents and analysts to identify known individuals and extract faces from perpetrators involved in child exploitation offenses, human rights atrocities, and war crimes. This service is supported by RAVEn, a virtualized environment that enables large analytical projects and helps ICE enforce and investigate violations of U.S. laws. For more details, refer to the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.","Yes, the project described above is potentially a safety risk. 

The project involves the use of the Facial Recognition Service for identifying individuals involved in child exploitation offenses, human rights atrocities, and war crimes. This raises concerns about the potential misuse or mishandling of sensitive personal information and potential violations of privacy rights.

Additionally, the project mentions the use of RAVEn, a virtualized environment that supports large analytical projects for ICE to enforce and investigate violations of U.S. laws. This suggests that the project may involve the collection and analysis of a significant amount of data, which could pose risks related to data security and protection.

Overall, the project's focus on law enforcement activities and the potential impact on personal privacy and data security make it a potential safety risk.","Yes, the project described is potentially a safety risk. 

The project involves the use of facial recognition technology by the DHS HSI Innovation Lab to identify individuals involved in child exploitation offenses, human rights atrocities, and war crimes. While the intention behind the project is noble, the use of facial recognition technology for such purposes raises concerns about privacy, civil liberties, and potential misuse of the technology. 

Facial recognition technology has been shown to have accuracy and bias issues, which could result in false identifications or wrongful accusations. Additionally, the project involves the extraction of faces from perpetrators, which raises questions about the consent and privacy rights of individuals whose faces are being extracted.

Furthermore, the project operates within a virtualized environment called RAVEn, which is used by ICE to enforce and investigate violations of U.S. laws. This raises concerns about the potential for misuse or abuse of the technology for purposes beyond its intended use, such as surveillance or targeting individuals based on their ethnicity or political beliefs.

Overall, while the project may have legitimate intentions, the use of facial recognition technology and the potential for misuse make it a potentially significant safety risk.",True,True
DHS-0018-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Critical Infrastructure Anomaly Alerting,"The Cyber Sentry program provides monitoring of critical infrastructure networks. Within the program, threat hunting analysts require advanced anomaly detection and machine learning capabilities to examine multimodal cyber-physical data on IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model provides AI-assistance in processing this information.",Initiation,"Machine Learning, Visualization",,Department of Homeland Security,"Critical Infrastructure Anomaly Alerting: 
The Cyber Sentry program provides monitoring of critical infrastructure networks. Within the program, threat hunting analysts require advanced anomaly detection and machine learning capabilities to examine multimodal cyber-physical data on IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model provides AI-assistance in processing this information.","The Cyber Sentry program monitors critical infrastructure networks and employs threat hunting analysts who need advanced anomaly detection and machine learning capabilities to analyze cyber-physical data on IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model offers AI-assistance to process this information.","The Cyber Sentry program monitors critical infrastructure networks and employs threat hunting analysts who need advanced anomaly detection and machine learning capabilities to analyze cyber-physical data on IT and OT networks, including ICS/SCADA. The Critical Infrastructure Anomaly Alerting model offers AI-assistance to process this information.","Yes, the project is potentially a safety risk. 

The project involves monitoring critical infrastructure networks and analyzing cyber-physical data on IT and OT networks, including ICS/SCADA. This falls under the category of ""a"" - the functioning of infrastructure systems controlling physical transit, such as electrical grids and water and wastewater systems. Any potential failure or compromise of these systems could have serious safety implications.

Furthermore, the project involves the application of advanced anomaly detection and machine learning capabilities to analyze this data. This falls under the category of ""b"" - the physical movements and interactions within various settings, including transportation and law enforcement. If the anomaly detection or machine learning algorithms fail to accurately identify threats or anomalies, it could lead to incorrect responses or actions, posing safety risks.

Therefore, based on the defined risks and the project description, the Cyber Sentry program is potentially a safety risk.","Yes, the project is potentially a safety risk. 

Based on the provided description, the project involves monitoring critical infrastructure networks, including IT and OT networks, which include ICS/SCADA systems. These systems are crucial for the operation of essential services such as power grids, water treatment plants, and transportation systems. Any potential safety risks associated with these systems can have severe consequences, including disruptions to essential services and potential harm to the public.

Additionally, the project mentions employing threat hunting analysts who require advanced anomaly detection and machine learning capabilities to analyze cyber-physical data. While these capabilities can enhance cybersecurity measures, they also introduce potential risks. If the anomaly detection or machine learning algorithms used in the project are not properly designed, implemented, or monitored, they could lead to false positives or false negatives, potentially impacting the reliability and effectiveness of the system.

Overall, the combination of monitoring critical infrastructure networks, utilizing advanced AI capabilities, and the potential for false detections or misinterpretations of data makes this project a potential safety risk. Proper safeguards, testing, and oversight should be in place to mitigate these risks.",True,True
USDA-0025-2023,USDA,USDA,Forest Service,Forest Health Detection Monitoring,"Machine learning models are used to (1) upscale training data, using Sentinel-2, Landsat,  MODIS, and lidar imagery, that was collected from both the field and high-resolution imagery to map and monitor stages of forest mortality and defoliation across the United States, and (2) to post-process raster outputs to vector polygons.",Operation and Management,Machine Learning,,Department of Agriculture,"Forest Health Detection Monitoring: 
Machine learning models are used to (1) upscale training data, using Sentinel-2, Landsat,  MODIS, and lidar imagery, that was collected from both the field and high-resolution imagery to map and monitor stages of forest mortality and defoliation across the United States, and (2) to post-process raster outputs to vector polygons.","Machine learning models are utilized to scale up training data by using various types of imagery, such as Sentinel-2, Landsat, MODIS, and lidar, collected from both field and high-resolution sources. These models are used to map and monitor forest mortality and defoliation stages across the United States and to convert raster outputs into vector polygons.","Machine learning models are utilized to scale up training data by using various types of imagery, such as Sentinel-2, Landsat, MODIS, and lidar, collected from both field and high-resolution sources. These models are used to map and monitor forest mortality and defoliation stages across the United States and to convert raster outputs into vector polygons.","Yes, the project described has the potential to be a safety risk. 

One aspect of the project involves the use of lidar, which uses lasers to measure distances and create detailed maps. If not properly managed, the use of lidar can pose safety risks, such as eye damage or interference with aircraft navigation systems.

Additionally, the project involves mapping and monitoring forest mortality and defoliation stages across the United States. This could potentially involve working in remote or hazardous locations, which can pose risks to the safety of the individuals involved.

Therefore, while the project itself may not directly involve risks to infrastructure or physical safety, certain aspects of it have the potential to pose safety risks if not properly managed.","Yes, the project described potentially poses a safety risk. The project involves the use of machine learning models to map and monitor forest mortality and defoliation stages across the United States. While this aspect of the project itself may not directly pose a safety risk, the use of various types of imagery, including lidar, for data collection and the conversion of raster outputs into vector polygons can have broader implications.

If the lidar data collection involves the use of lasers, there could be safety concerns related to laser exposure. Additionally, the conversion of raster outputs into vector polygons may involve extensive data processing and analysis, which can introduce potential risks related to data security and privacy breaches.

Furthermore, if the project involves the use of drones for data collection or monitoring, there may be safety risks associated with the operation of drones, such as collisions with other aircraft or objects, privacy concerns, or the potential for accidents or injuries.

Therefore, while the project does not directly involve the risks outlined in the provided definition, it does have potential safety risks related to data security, privacy, laser exposure, and the operation of drones.",True,True
DOS-0003-2023,DOS,A,,Supply Chain Fraud and Risk Models,"A/LM plans to expand current risk analytics through development of AI/ML models for detecting anomalous activity within the Integrated Logistics Management System (ILMS) that could be potential fraud or malfeasance. The models will expand upon existing risk models and focus on key supply chain functions such as: Asset Management, Procure-to-Pay, and Fleet Management.",,,,Department of State,"Supply Chain Fraud and Risk Models: 
A/LM plans to expand current risk analytics through development of AI/ML models for detecting anomalous activity within the Integrated Logistics Management System (ILMS) that could be potential fraud or malfeasance. The models will expand upon existing risk models and focus on key supply chain functions such as: Asset Management, Procure-to-Pay, and Fleet Management.","A/LM plans to develop AI/ML models to detect suspicious activity in the Integrated Logistics Management System. These models will focus on key supply chain functions like Asset Management, Procure-to-Pay, and Fleet Management, in order to expand the existing risk analytics and identify potential fraud or malfeasance.","A/LM plans to develop AI/ML models to detect suspicious activity in the Integrated Logistics Management System. These models will focus on key supply chain functions like Asset Management, Procure-to-Pay, and Fleet Management, in order to expand the existing risk analytics and identify potential fraud or malfeasance.","Yes, this project is potentially a safety risk. The project involves the development of AI/ML models to detect suspicious activity in the Integrated Logistics Management System, specifically focusing on key supply chain functions. If the AI/ML models fail to accurately detect fraud or malfeasance, it could pose a risk to the integrity of the supply chain system. This could lead to potential safety issues in terms of compromised assets, procurement processes, and fleet management.","Yes, the project is potentially a safety risk. This is because it involves making decisions related to surveillance, fraud detection, and risk assessments in the supply chain management system. Any errors or biases in these AI/ML models could lead to false accusations, wrongful surveillance, or unfair treatment of individuals and businesses involved in the supply chain. Additionally, if the models are not properly secured or if they are hacked, sensitive data related to logistics and supply chain management could be compromised, leading to potential security and privacy concerns.",True,True
USDA-0038-2023,USDA,USDA,OSSP,Video Surveillance System,"The Video Surveillance System: the VSS system design will include a video management system, NVRs, DVRs, encoders, fixed cameras, Pan and Tilt cameras, network switches, routers, IP cables, equipment racks and mounting hardware. The Video Surveillance System (VSS)- shall control multiple sources of video surveillance subsystems to collect, manage, and present video clearly and concisely. VMS shall integrate the capabilities of each subsystem across single or multiple sites, allowing video management of any compatible analog or digital video device through a unified configuration platform and viewer. Disparate video systems are normalized and funneled through a shared video experience. Drag and drop cameras from the Security Management System hardware tree into VMS views and leverage Security Management System alarm integration and advanced features that help the operator track a target through a set of sequential cameras with a simplified method to select a new central camera and surrounding camera views.",Operation and Management,Visual Analysis,,Department of Agriculture,"Video Surveillance System: 
The Video Surveillance System: the VSS system design will include a video management system, NVRs, DVRs, encoders, fixed cameras, Pan and Tilt cameras, network switches, routers, IP cables, equipment racks and mounting hardware. The Video Surveillance System (VSS)- shall control multiple sources of video surveillance subsystems to collect, manage, and present video clearly and concisely. VMS shall integrate the capabilities of each subsystem across single or multiple sites, allowing video management of any compatible analog or digital video device through a unified configuration platform and viewer. Disparate video systems are normalized and funneled through a shared video experience. Drag and drop cameras from the Security Management System hardware tree into VMS views and leverage Security Management System alarm integration and advanced features that help the operator track a target through a set of sequential cameras with a simplified method to select a new central camera and surrounding camera views.","The Video Surveillance System (VSS) will consist of various components such as cameras, management systems, and network equipment. It will integrate different video surveillance subsystems, allowing for easy management and viewing of video footage from compatible devices. Operators can easily track targets by selecting cameras and accessing advanced features through a unified configuration platform.","The Video Surveillance System (VSS) will consist of various components such as cameras, management systems, and network equipment. It will integrate different video surveillance subsystems, allowing for easy management and viewing of video footage from compatible devices. Operators can easily track targets by selecting cameras and accessing advanced features through a unified configuration platform.","Yes, the project described above has the potential to be a safety risk. 

The Video Surveillance System (VSS) may fall under the category of ""access to or security of government facilities"" (j), as it involves monitoring and surveillance activities. The system's integration with different video surveillance subsystems and the unified configuration platform may provide access to sensitive areas or critical infrastructure, which could pose a risk if not adequately secured.

Additionally, the project may involve the design, construction, or testing of industrial equipment or systems (h), as it requires the installation and setup of cameras, management systems, and network equipment. If any of these components fail, it could affect the overall functionality and reliability of the surveillance system, potentially compromising safety.

Furthermore, the project could also relate to enforcement actions pursuant to controls on exports or shipping (k), as the video surveillance equipment may have export restrictions or require compliance with specific regulations.

Overall, the specific details and implementation of the Video Surveillance System would need to be carefully considered and evaluated to determine the extent of the safety risks involved.","Yes, the project described above is potentially a safety risk. The project involves the implementation of a Video Surveillance System (VSS), which can be used for various purposes including law enforcement, surveillance, and monitoring. These activities can potentially have negative implications on privacy, civil liberties, and the safety of individuals.

The project falls under the category of ""Law enforcement or surveillance-related risk assessments about individuals"" mentioned in the defined risks. The use of surveillance systems, especially when combined with advanced features such as facial matching, iris matching, or social media monitoring, raises concerns about potential abuse or misuse of personal data and infringement of privacy rights.

Additionally, the project's involvement in areas such as determining access to educational resources, determining terms and conditions of employment, or making decisions regarding medical devices and treatments could also have significant implications on individuals' rights, fairness, and well-being.

While video surveillance systems can have legitimate applications for public safety or crime prevention, their implementation and usage should be carefully regulated to ensure that they do not pose unnecessary risks or violate fundamental rights.",True,True
HHS-0045-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),"Center for Program Integrity (CPI) Fraud Prevention System Models (e.g. DMEMBITheftML, HHAProviderML)","These models use Medicare administrative and claims  data to identify potential cases of fraud, waste, and abuse for future investigation using random forest techniques. Outputs are used to alert investigators of the potential fraud scheme and associated providers.",Operation and Maintenance,,,Department of Health and Human Services,"Center for Program Integrity (CPI) Fraud Prevention System Models (e.g. DMEMBITheftML, HHAProviderML): 
These models use Medicare administrative and claims  data to identify potential cases of fraud, waste, and abuse for future investigation using random forest techniques. Outputs are used to alert investigators of the potential fraud scheme and associated providers.","The Center for Program Integrity (CPI) uses data models like DMEMBITheftML and HHAProviderML to detect fraud, waste, and abuse in Medicare. These models analyze administrative and claims data to identify potential cases and alert investigators for further investigation.","The Center for Program Integrity (CPI) uses data models like DMEMBITheftML and HHAProviderML to detect fraud, waste, and abuse in Medicare. These models analyze administrative and claims data to identify potential cases and alert investigators for further investigation.","Yes, the project described is potentially a safety risk. The project involves the analysis of administrative and claims data for Medicare fraud detection. This falls under the category of ""integrity of elections and voting infrastructure"" as it involves the integrity of the healthcare system and the protection of public funds. Any potential failure in detecting or preventing fraud, waste, and abuse in Medicare could have serious consequences for the safety and well-being of individuals relying on the healthcare system.","Yes, the project described above is potentially a safety risk. The project involves the use of data models to detect fraud, waste, and abuse in Medicare. While the goal of the project is to identify potential cases and alert investigators for further investigation, there are potential risks associated with the project.

One major concern is the potential for false positives or false negatives. If the data models incorrectly identify individuals as potential cases of fraud, waste, or abuse, it could lead to unnecessary investigations and potentially harm innocent individuals. On the other hand, if the models fail to identify actual cases of fraud, waste, or abuse, it could result in financial losses and compromised healthcare services.

Additionally, the project involves the analysis of sensitive administrative and claims data. If this data is not properly secured and protected, there is a risk of data breaches and unauthorized access to personal and medical information, which could lead to privacy violations and identity theft.

Overall, the project carries inherent risks and it is important to ensure that proper safeguards are in place to mitigate these risks and protect the privacy and well-being of individuals involved.",True,True
DOS-0007-2023,DOS,A,,Conflict Forecasting,"CSO/AA is developing a suite of conflict and instability forecasting models that use open-source political, social, and economic datasets to predict conflict outcomes including interstate war, mass mobilization, and mass killings. The use of AI is confined to statistical models including machine learning techniques including tree-based methods, neural networks, and clustering approaches.",,,,Department of State,"Conflict Forecasting: 
CSO/AA is developing a suite of conflict and instability forecasting models that use open-source political, social, and economic datasets to predict conflict outcomes including interstate war, mass mobilization, and mass killings. The use of AI is confined to statistical models including machine learning techniques including tree-based methods, neural networks, and clustering approaches.","CSO/AA is creating conflict and instability forecasting models that utilize open-source data to predict outcomes such as interstate war, mass mobilization, and mass killings. AI is employed in statistical models, employing machine learning techniques like tree-based methods, neural networks, and clustering approaches.","CSO/AA is creating conflict and instability forecasting models that utilize open-source data to predict outcomes such as interstate war, mass mobilization, and mass killings. AI is employed in statistical models, employing machine learning techniques like tree-based methods, neural networks, and clustering approaches.","Yes, the project is potentially a safety risk. 

The project involves the use of AI and statistical models to predict outcomes related to conflicts and instability. While the project itself may not directly pose safety risks, the potential consequences of incorrect or biased predictions could lead to significant safety concerns. For example, if the models incorrectly predict the occurrence of interstate war or mass killings, it could lead to unnecessary military interventions or the overlooking of potential threats, both of which could have serious safety implications. Additionally, if the project relies on open-source data that is unreliable or manipulated, it could further compromise the accuracy and reliability of the predictions, increasing the potential safety risks.","Yes, the project described above is potentially a safety risk. The project involves utilizing AI and machine learning techniques to predict outcomes such as interstate war, mass mobilization, and mass killings. These predictions have significant implications for national security and public safety.

By relying on open-source data and statistical models, there is a risk of inaccurate or biased predictions, which could lead to misguided decisions and actions. If the forecasting models are not properly validated or calibrated, they may generate false alarms or fail to identify actual threats, potentially wasting valuable resources or overlooking real dangers.

Additionally, the use of AI in predicting conflict and instability raises ethical concerns, as it involves making decisions that could impact human lives based on machine-generated predictions. The potential for misuse or abuse of such technology in the hands of authoritarian regimes or malicious actors could exacerbate conflicts or lead to unnecessary violence.

Overall, the project's focus on predicting high-risk events and its reliance on AI and machine learning techniques introduce potential safety risks in terms of accuracy, bias, ethical implications, and potential misuse.",True,True
DHS-0001-2023,DHS,Customs and Border Protection,,AI for Autonomous Situational Awareness,"The AI for autonomous situational awareness system is intended to use IoT sensor kits to covertly detect and track illicit cross-border traffic in remote locations. 

The system will leverage a motion image/video system enhanced with Artificial Intelligence that is capable of vehicle detection and direction determination. It will also incorporate a motion sensor that, when triggered, wakes up a high-resolution camera to capture a series of pictures, with additional sensors providing confirmation prior to camera capture. 

Images captured will be processed by Artificial Intelligence models to classify objects, determine vehicle direction at intersections, and provide imagery sufficient for re-identification. Ultimately, the systems is intended to create a low footprint, low cost, low power system to provide situational awareness and covert detection.",Development and Acquisition,Machine Vision,,Department of Homeland Security,"AI for Autonomous Situational Awareness: 
The AI for autonomous situational awareness system is intended to use IoT sensor kits to covertly detect and track illicit cross-border traffic in remote locations. 

The system will leverage a motion image/video system enhanced with Artificial Intelligence that is capable of vehicle detection and direction determination. It will also incorporate a motion sensor that, when triggered, wakes up a high-resolution camera to capture a series of pictures, with additional sensors providing confirmation prior to camera capture. 

Images captured will be processed by Artificial Intelligence models to classify objects, determine vehicle direction at intersections, and provide imagery sufficient for re-identification. Ultimately, the systems is intended to create a low footprint, low cost, low power system to provide situational awareness and covert detection.","The AI for autonomous situational awareness system aims to detect and monitor illegal cross-border traffic in remote areas using IoT sensor kits. It will utilize motion image/video technology enhanced with Artificial Intelligence to detect and determine the direction of vehicles. The system will also incorporate a motion sensor and high-resolution camera to capture images, which will be processed by AI models to classify objects and provide sufficient imagery for re-identification. The goal is to create an efficient, affordable, and covert system for situational awareness and detection.","The AI for autonomous situational awareness system aims to detect and monitor illegal cross-border traffic in remote areas using IoT sensor kits. It will utilize motion image/video technology enhanced with Artificial Intelligence to detect and determine the direction of vehicles. The system will also incorporate a motion sensor and high-resolution camera to capture images, which will be processed by AI models to classify objects and provide sufficient imagery for re-identification. The goal is to create an efficient, affordable, and covert system for situational awareness and detection.","Yes, the project is potentially a safety risk. 

The project involves the monitoring and detection of illegal cross-border traffic, which falls under the category of ""the movements of vehicles,"" as mentioned in the safety risks. Monitoring and controlling physical transit systems, especially in remote areas, can have significant safety implications. 

Additionally, the project incorporates the use of AI, motion sensors, and high-resolution cameras, which are technologies that can potentially pose risks if not properly designed, tested, and regulated. The collection and processing of sensitive data, such as images and vehicle information, also raise concerns regarding privacy and security.

Overall, while the project aims to enhance situational awareness and detection, it involves elements that can potentially pose safety risks if not executed properly.","Yes, the project described is potentially a safety risk. This is because it involves surveillance-related activities, specifically monitoring and detecting illegal cross-border traffic in remote areas. Such activities can raise concerns about privacy invasion and potential misuse of the collected data. Additionally, the use of AI models to classify objects and provide imagery for re-identification may pose risks if the system misidentifies or wrongly targets innocent individuals or vehicles. Therefore, careful consideration and safeguards should be in place to address these safety and ethical concerns.",True,True
HHS-0039-2023,HHS,CDC,NCIPC/DIP,Nowcasting Suicide Trends,"An internal-facing, interactive dashboard incorporating multiple traditional and non-traditional datasets and a multi-stage machine learning pipeline to 'nowcast' suicide death trends nationally on a week-to-week basis. ",Operation and Maintenance,,,Department of Health and Human Services,"Nowcasting Suicide Trends: 
An internal-facing, interactive dashboard incorporating multiple traditional and non-traditional datasets and a multi-stage machine learning pipeline to 'nowcast' suicide death trends nationally on a week-to-week basis. ",The text describes the development of an internal interactive dashboard that utilizes various datasets and a machine learning system to predict suicide death trends on a national level on a weekly basis. The purpose of this system is to provide timely information about suicide rates.,The text describes the development of an internal interactive dashboard that utilizes various datasets and a machine learning system to predict suicide death trends on a national level on a weekly basis. The purpose of this system is to provide timely information about suicide rates.,"Yes, the project is potentially a safety risk. According to the given risks, the project falls under category b, as it involves the use of a machine learning system within a medical setting. The prediction of suicide death trends is a sensitive topic and any inaccuracies or misinterpretations in the system's predictions could have serious consequences for individuals at risk. Therefore, it is crucial to ensure the accuracy and reliability of the machine learning system to prevent potential harm to individuals.","Yes, the project is potentially a safety risk. The project involves the development of a machine learning system to predict suicide death trends on a national level. While the intention of providing timely information about suicide rates is commendable, there are potential safety risks associated with this project.

Firstly, predicting suicide death trends can be a sensitive topic that may have adverse effects on individuals who are already vulnerable. The dissemination of such information without proper context, support, and resources could potentially lead to copycat behaviors or trigger individuals who are already struggling with mental health issues.

Secondly, the project involves handling and analyzing sensitive data related to suicide rates. Any mishandling or unauthorized access to this data could compromise the privacy and confidentiality of individuals affected by suicide. It is crucial to ensure robust data security measures are in place to protect this sensitive information.

Lastly, the project's reliance on machine learning algorithms introduces the potential for biased or inaccurate predictions. If the system is not properly trained or validated, it could result in misleading or incorrect information being provided, which could have serious implications for public health policies and interventions.

Therefore, considering the sensitive nature of the topic, the potential privacy concerns, and the risk of inaccurate predictions, this project should be assessed and implemented with great caution to mitigate safety risks.",True,True
DOI-0009-2023,DOI,BSEE,,Sustained Casing Pressure Identification,"Well casing pressure requests are submitted to BSEE to determine whether a well platform is experiencing a sustained casing pressure (SCP) problem. SCP is usually caused by gas migration from a high-pressured subsurface formation through the leaking cement sheath in one of the well’s casing annuli, but SCP can also be caused by defects in tube connections, downhole accessories, or seals. Because SCP can lead to major safety issues, quickly identifying wells with SCP could greatly mitigate accidents on the well platforms. BSEE entered into an Inter-Agency Agreement with NASA's Advanced Supercomputing Division to help research the use of various AI techniques.",Development (not in production),"Machine learning via deep learning models, such as a Residual Neural Network (ResNet) and Convolutional Neural Networks (CNN)",,Department of Interior,"Sustained Casing Pressure Identification: 
Well casing pressure requests are submitted to BSEE to determine whether a well platform is experiencing a sustained casing pressure (SCP) problem. SCP is usually caused by gas migration from a high-pressured subsurface formation through the leaking cement sheath in one of the well’s casing annuli, but SCP can also be caused by defects in tube connections, downhole accessories, or seals. Because SCP can lead to major safety issues, quickly identifying wells with SCP could greatly mitigate accidents on the well platforms. BSEE entered into an Inter-Agency Agreement with NASA's Advanced Supercomputing Division to help research the use of various AI techniques.","BSEE and NASA's Advanced Supercomputing Division have partnered to research the use of AI techniques in quickly identifying well platforms experiencing sustained casing pressure (SCP) problems. SCP, which can lead to safety issues, is typically caused by gas migration or defects in tube connections, downhole accessories, or seals. The collaboration aims to mitigate accidents by efficiently identifying wells with SCP.","BSEE and NASA's Advanced Supercomputing Division have partnered to research the use of AI techniques in quickly identifying well platforms experiencing sustained casing pressure (SCP) problems. SCP, which can lead to safety issues, is typically caused by gas migration or defects in tube connections, downhole accessories, or seals. The collaboration aims to mitigate accidents by efficiently identifying wells with SCP.","Yes, the project is potentially a safety risk. 

The project involves the use of AI techniques to quickly identify well platforms experiencing sustained casing pressure (SCP) problems. SCP can lead to safety issues and is typically caused by gas migration or defects in tube connections, downhole accessories, or seals. If these issues are not identified and addressed promptly, accidents can occur.

The potential safety risk lies in the fact that the project deals with the functioning of energy systems (well platforms) and the potential for accidents in the oil and gas industry. Failure to accurately and efficiently identify wells with SCP problems could result in safety hazards such as gas leaks, explosions, or other accidents.

Therefore, the project has the potential to pose a safety risk and should be carefully managed to ensure that the AI techniques are effective in identifying and mitigating SCP issues in a timely manner.","Yes, the project described above is potentially a safety risk. The use of AI techniques to quickly identify well platforms experiencing sustained casing pressure (SCP) problems is directly related to mitigating safety issues. SCP can lead to accidents and pose significant risks to the well platforms and surrounding environment. Therefore, the project has the potential to address and improve safety concerns in the oil and gas industry.",True,True
DOE-0160-2023,DOE,"Office of Environment, Health, Safety & Security",,Memorandum of Understanding Between the US DOE and US NRC on Cooperation in the Area of Operating Experience and Applications of Data Analytics (Signed June 2021),"The purpose of the Memorandum of Understanding (MOU) between the 
US DOE and US NRC on cooperation in the area of operating 
experience and applications of data analytics (Signed June 2021) is to 
efficiently use resources and to avoid needless duplication of effort by 
sharing data, technical information, lessons learned, and, in some 
cases, the costs related to the development of approaches and tools, 
whenever such cooperation and cost sharing may be done in a mutually 
beneficial fashion.  The technical areas for collaboration include, those 
related to operating experience and safety data collection and analysis, 
including operational events, occupational injuries, hazardous substance 
releases, nuclear safety, radiation protection, equipment failure, 
accidents and accident precursors, trending analysis, and risk-informed 
decision-making.  Applications of data analytics in the analysis of 
operating experience and safety data, including data visualization and 
analysis, artificial intelligence, machine learning, natural language 
processing, predictive analytics, and other advanced analysis 
techniques, user interface design, and deployment, and decision-
making using data analytics tools.",,,,Department of Energy,"Memorandum of Understanding Between the US DOE and US NRC on Cooperation in the Area of Operating Experience and Applications of Data Analytics (Signed June 2021): 
The purpose of the Memorandum of Understanding (MOU) between the 
US DOE and US NRC on cooperation in the area of operating 
experience and applications of data analytics (Signed June 2021) is to 
efficiently use resources and to avoid needless duplication of effort by 
sharing data, technical information, lessons learned, and, in some 
cases, the costs related to the development of approaches and tools, 
whenever such cooperation and cost sharing may be done in a mutually 
beneficial fashion.  The technical areas for collaboration include, those 
related to operating experience and safety data collection and analysis, 
including operational events, occupational injuries, hazardous substance 
releases, nuclear safety, radiation protection, equipment failure, 
accidents and accident precursors, trending analysis, and risk-informed 
decision-making.  Applications of data analytics in the analysis of 
operating experience and safety data, including data visualization and 
analysis, artificial intelligence, machine learning, natural language 
processing, predictive analytics, and other advanced analysis 
techniques, user interface design, and deployment, and decision-
making using data analytics tools.","The US DOE and US NRC have signed a Memorandum of Understanding (MOU) in June 2021 to collaborate in the areas of operating experience and data analytics. The purpose of this collaboration is to efficiently utilize resources, share data and technical information, and avoid duplication of effort. The collaboration will focus on areas such as safety data collection and analysis, data visualization, artificial intelligence, and predictive analytics.","The US DOE and US NRC have signed a Memorandum of Understanding (MOU) in June 2021 to collaborate in the areas of operating experience and data analytics. The purpose of this collaboration is to efficiently utilize resources, share data and technical information, and avoid duplication of effort. The collaboration will focus on areas such as safety data collection and analysis, data visualization, artificial intelligence, and predictive analytics.","Yes, the project is potentially a safety risk. 

The project involves collaboration between the US Department of Energy (DOE) and the US Nuclear Regulatory Commission (NRC) in the areas of operating experience and data analytics. This collaboration focuses on safety data collection and analysis, data visualization, artificial intelligence, and predictive analytics.

The project falls under several categories of safety risks mentioned in the description. It involves the functioning of nuclear reactors, materials, and waste, which is a critical system that poses potential safety risks. Additionally, the project involves the transport, safety, design, or development of hazardous chemicals or biological entities or pathways, which further adds to the safety risks.

Furthermore, the project deals with data analytics and artificial intelligence, which could have implications for the security of government facilities and the enforcement of controls on exports, investments, or shipping.

Overall, due to its involvement in critical systems and potential impacts on safety, the project is potentially a safety risk.","Yes, the project described above has the potential to be a safety risk. 

The project involves the collaboration between the US Department of Energy (DOE) and the US Nuclear Regulatory Commission (NRC) in the areas of operating experience and data analytics. While the specific risks are not explained in detail, the use of artificial intelligence, predictive analytics, and data visualization in the context of safety data collection and analysis raises concerns.

The potential safety risk comes from the fact that decisions related to safety in the nuclear industry can have significant consequences if not properly handled. If the project involves the use of AI and predictive analytics in making decisions about safety protocols, risk assessments, or operational procedures, there is a potential for errors or biases that may compromise safety.

Making decisions based on algorithms and data analysis alone may overlook important contextual factors or rely on incomplete or biased data, which can lead to incorrect or inadequate safety measures. Additionally, if the project involves the automation of safety-related processes without proper oversight or human intervention, there is a risk of system failures or malfunctions that could pose safety hazards.

Without knowing the specific details of the project and the safeguards in place, it is difficult to make a definitive judgment. However, the combination of advanced technologies like AI and predictive analytics with safety-critical decision-making processes raises concerns about potential safety risks.",True,True
DOJ-0001-2023,DOJ,Federal Bureau of Investigation,,Complaint Lead Value Probability,"Threat Intake Processing System (TIPS) 
database uses artificial intelligence (AI) 
algorithms to accurately identify, 
prioritize, and process actionable tips 
in a timely manner. The AI used in this 
case helps to triage immediate threats 
in order to help FBI field offices and 
law enforcement respond to the most 
serious threats first.  Based on the 
algorithm score, highest priority tips 
are first in the queue for human 
review.",In production: more than 1 year,,,Department of Justice,"Complaint Lead Value Probability: 
Threat Intake Processing System (TIPS) 
database uses artificial intelligence (AI) 
algorithms to accurately identify, 
prioritize, and process actionable tips 
in a timely manner. The AI used in this 
case helps to triage immediate threats 
in order to help FBI field offices and 
law enforcement respond to the most 
serious threats first.  Based on the 
algorithm score, highest priority tips 
are first in the queue for human 
review.","The Threat Intake Processing System (TIPS) database uses artificial intelligence algorithms to quickly and accurately identify, prioritize, and process actionable tips. This AI technology helps the FBI and law enforcement respond to the most urgent threats by triaging immediate threats for immediate attention and human review based on algorithm scores.","The Threat Intake Processing System (TIPS) database uses artificial intelligence algorithms to quickly and accurately identify, prioritize, and process actionable tips. This AI technology helps the FBI and law enforcement respond to the most urgent threats by triaging immediate threats for immediate attention and human review based on algorithm scores.","Yes, the project described is potentially a safety risk. This is because it involves the processing and prioritization of actionable tips for law enforcement and the FBI. These tips could be related to various safety risks, such as insider threats, access to government facilities, and enforcement actions. If the AI algorithms used in the database fail to accurately identify and prioritize these threats, it could result in delayed or inadequate responses, posing a risk to public safety.","Yes, the project described potentially poses a safety risk. The use of artificial intelligence algorithms in the Threat Intake Processing System (TIPS) database involves decision-making processes related to law enforcement and surveillance, which fall under the category of potentially risky projects according to the defined risks. These decisions can have significant consequences on individuals' rights, privacy, and safety. Additionally, the use of AI in determining the urgency and priority of threats may introduce biases or errors that could lead to inappropriate responses or the overlooking of genuine threats. Therefore, careful consideration and oversight are necessary to mitigate any potential safety risks associated with this project.",True,True
DHS-0022-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Malware Reverse Engineering,"Reverse engineering of malware, and software analysis more broadly, will continue to be a critical activity in support of CISA’s cyber defense mission. Threat Focused Reverse Engineering (TFRE) leverages advanced engineering, formal methods, and deep learning techniques for better cyber threat intelligence. Without scalable, automated tools, it is difficult to disrupt sophisticated adversaries’ malware development lifecycle. New, unique, automated techniques are needed to better target adversaries, augment analysts, and create sophisticated tools for end users. Core tools disrupt the adversary’s development lifecycle by exposing tactics, techniques, and procedures (TTPs). Analysts could spend more time and energy to hunt/takedown threats; adversaries can spend less time operating malware and must commit more resources to reorient. TFRE consists of a broader development pipeline providing tool hardening, enhanced computational abilities, understanding of deployment environments, and other important capabilities.",Initiation,Machine Learning,,Department of Homeland Security,"Malware Reverse Engineering: 
Reverse engineering of malware, and software analysis more broadly, will continue to be a critical activity in support of CISA’s cyber defense mission. Threat Focused Reverse Engineering (TFRE) leverages advanced engineering, formal methods, and deep learning techniques for better cyber threat intelligence. Without scalable, automated tools, it is difficult to disrupt sophisticated adversaries’ malware development lifecycle. New, unique, automated techniques are needed to better target adversaries, augment analysts, and create sophisticated tools for end users. Core tools disrupt the adversary’s development lifecycle by exposing tactics, techniques, and procedures (TTPs). Analysts could spend more time and energy to hunt/takedown threats; adversaries can spend less time operating malware and must commit more resources to reorient. TFRE consists of a broader development pipeline providing tool hardening, enhanced computational abilities, understanding of deployment environments, and other important capabilities.","Malware reverse engineering is crucial for CISA's cyber defense mission. Threat Focused Reverse Engineering (TFRE) uses advanced engineering, formal methods, and deep learning techniques to improve cyber threat intelligence. Automated techniques are necessary to disrupt adversaries' malware development and target them more effectively, allowing analysts to focus on hunting and taking down threats. TFRE includes tool hardening, enhanced computational abilities, and understanding of deployment environments to provide important capabilities in the development pipeline.","Malware reverse engineering is crucial for CISA's cyber defense mission. Threat Focused Reverse Engineering (TFRE) uses advanced engineering, formal methods, and deep learning techniques to improve cyber threat intelligence. Automated techniques are necessary to disrupt adversaries' malware development and target them more effectively, allowing analysts to focus on hunting and taking down threats. TFRE includes tool hardening, enhanced computational abilities, and understanding of deployment environments to provide important capabilities in the development pipeline.","Yes, the project is potentially a safety risk. 

The project involves malware reverse engineering, which falls under the category of cyber defense. While the project itself does not directly involve physical systems or movements, it deals with cybersecurity, which can have serious implications for safety.

Cyber threats, including malware, have the potential to compromise critical infrastructure systems such as dams, emergency services, electrical grids, and nuclear reactors (as mentioned in the safety risks definition). If the malware reverse engineering process is not conducted carefully and securely, there is a risk of inadvertently releasing or spreading malware that could cause harm to these systems.

Furthermore, the project mentions the use of advanced engineering, formal methods, and deep learning techniques. If these techniques are not properly implemented or if there are vulnerabilities in the tools used, it could lead to unintended consequences. For example, if a tool used for malware reverse engineering has a flaw or vulnerability, it could be exploited by adversaries to launch cyber attacks or gain unauthorized access to systems.

Therefore, while the project itself may not directly involve physical safety risks, the potential implications and consequences of cyber threats make it a potentially safety risk. It is important to ensure that proper security measures and protocols are in place throughout the project to mitigate these risks.","Yes, the project described potentially poses a safety risk. The project involves malware reverse engineering, which often deals with malicious software and cyber threats. If not handled properly, the reverse engineering process could lead to accidental release or spread of malware, causing harm to computer systems, networks, and potentially compromising sensitive data. Additionally, the use of advanced engineering, formal methods, and deep learning techniques could introduce vulnerabilities or errors that could be exploited by adversaries, leading to further security risks.",True,True
DHS-0000-2023,DHS,Customs and Border Protection,,AI Curated Synthetic Data,"AI Curated Synthetic Data creates synthetic data for computer vision to enable more capable and ethical AI when detecting anomalies in complex environments.

Specifically, it creates an emulated X-ray sensor that can produce visually realistic synthetic X-ray scan images similar to real X-ray scan images, and virtual 3D Assets of vehicles and narcotics containers. These images will be used to enhance the development of Anomaly Detection Algorithms for Non-Intrusive Inspection, incorporating AI/ML for the detection of narcotics and other contraband in conveyances and cargo.",Initiation,Synthetic Image Generation,,Department of Homeland Security,"AI Curated Synthetic Data: 
AI Curated Synthetic Data creates synthetic data for computer vision to enable more capable and ethical AI when detecting anomalies in complex environments.

Specifically, it creates an emulated X-ray sensor that can produce visually realistic synthetic X-ray scan images similar to real X-ray scan images, and virtual 3D Assets of vehicles and narcotics containers. These images will be used to enhance the development of Anomaly Detection Algorithms for Non-Intrusive Inspection, incorporating AI/ML for the detection of narcotics and other contraband in conveyances and cargo.","AI Curated Synthetic Data is a technology that generates realistic synthetic data for computer vision. It produces visually accurate X-ray scan images and virtual 3D assets of vehicles and narcotics containers. This data is used to improve the development of Anomaly Detection Algorithms for Non-Intrusive Inspection, aiding in the detection of contraband in conveyances and cargo using AI/ML technology.","AI Curated Synthetic Data is a technology that generates realistic synthetic data for computer vision. It produces visually accurate X-ray scan images and virtual 3D assets of vehicles and narcotics containers. This data is used to improve the development of Anomaly Detection Algorithms for Non-Intrusive Inspection, aiding in the detection of contraband in conveyances and cargo using AI/ML technology.","Yes, the project is potentially a safety risk. The generation of visually accurate X-ray scan images and virtual 3D assets of vehicles and narcotics containers can have implications for security and safety measures. If this technology falls into the wrong hands or is misused, it could aid in criminal activities such as smuggling contraband. Additionally, the development of anomaly detection algorithms using AI/ML technology for non-intrusive inspection raises concerns about privacy and the potential for false positives or negatives, which could impact the safety and security of individuals and transportation systems.","Yes, the project is potentially a safety risk. The use of AI Curated Synthetic Data in generating realistic synthetic data for computer vision, particularly in producing X-ray scan images and virtual 3D assets of vehicles and narcotics containers, can have several safety implications. 

Firstly, the project involves the development of Anomaly Detection Algorithms for Non-Intrusive Inspection. If these algorithms are not accurate or reliable, there is a risk of false positives or false negatives in detecting contraband in conveyances and cargo. This could lead to potential security breaches or the failure to identify dangerous or illegal items, posing a safety risk.

Secondly, the project's application in the field of law enforcement and surveillance raises concerns. The technology may be used for decisions related to law enforcement tactics, such as identifying individuals or conducting surveillance. If the AI Curated Synthetic Data is not properly validated or calibrated, it could result in wrongful identification or unjust surveillance, potentially violating individuals' rights and privacy.

Lastly, the project's use in medical imaging, such as generating X-ray scan images, requires utmost accuracy. Any inaccuracies or errors in the synthetic data could lead to misdiagnosis or incorrect medical treatment, jeopardizing patient safety.

Therefore, considering the potential risks in terms of security, privacy, and patient safety, the project is potentially a safety risk.",True,True
USAID-0006-2023,USAID,Bureau for Global Health (GH),,Using ML for predicting treatment interruption among PLHIV in Nigeria,"Using data from USAID funded Strengthening Integrated Delivery of HIV/AIDS Services (SIDHAS) project in Nigeria we trained and tested an algorithm that can be used for predicting the probability that someone newly initiated on ART will interrupt treatment. The algorithm has been successfully integrated into the Lafiya Management Information System (LAMIS), the individual-level client level electronic medical record system. Each week the outputs, for each new patient is shared with staff at the health facilities and those at high risk are provided with more intensive follow up support to reduce the risk of treatment interruption. We also conducted a qualitative assessment among to health care workers at the facilities to determine their perception of ML and determine what additional support are required for institutionalizing ML into their routine work.   ",Development and Acquisition,,,U.S. Agency for International Development,"Using ML for predicting treatment interruption among PLHIV in Nigeria: 
Using data from USAID funded Strengthening Integrated Delivery of HIV/AIDS Services (SIDHAS) project in Nigeria we trained and tested an algorithm that can be used for predicting the probability that someone newly initiated on ART will interrupt treatment. The algorithm has been successfully integrated into the Lafiya Management Information System (LAMIS), the individual-level client level electronic medical record system. Each week the outputs, for each new patient is shared with staff at the health facilities and those at high risk are provided with more intensive follow up support to reduce the risk of treatment interruption. We also conducted a qualitative assessment among to health care workers at the facilities to determine their perception of ML and determine what additional support are required for institutionalizing ML into their routine work.   ",An algorithm was developed using data from the SIDHAS project in Nigeria to predict the likelihood of treatment interruption among newly initiated ART patients. The algorithm was successfully integrated into the LAMIS system and the results are shared with healthcare staff to provide more intensive support to high-risk patients. A qualitative assessment was also conducted to gather healthcare workers' perceptions of ML and identify additional support needed to incorporate ML into their routine work.,An algorithm was developed using data from the SIDHAS project in Nigeria to predict the likelihood of treatment interruption among newly initiated ART patients. The algorithm was successfully integrated into the LAMIS system and the results are shared with healthcare staff to provide more intensive support to high-risk patients. A qualitative assessment was also conducted to gather healthcare workers' perceptions of ML and identify additional support needed to incorporate ML into their routine work.,"Yes, the project described is potentially a safety risk. The project involves the use of an algorithm to predict treatment interruption among newly initiated ART patients. If the algorithm fails or provides inaccurate predictions, it could lead to patients not receiving the necessary treatment, which can have serious health consequences and potentially pose a safety risk to the patients. Additionally, if the algorithm is not properly integrated into the LAMIS system or if the results are not effectively communicated to healthcare staff, it may result in inadequate support being provided to high-risk patients, again posing a safety risk.","Yes, the project described above potentially poses a safety risk. 

The project involves using an algorithm to predict the likelihood of treatment interruption among newly initiated ART (Antiretroviral Therapy) patients. This algorithm is integrated into the LAMIS (Laboratory for Advanced Medical Informatics and Systems) system, and the results are shared with healthcare staff to provide more intensive support to high-risk patients.

While the project aims to improve patient care and support, there are potential safety risks associated with it. The use of algorithms and machine learning (ML) in healthcare decision-making can have significant consequences. In this case, the algorithm's predictions could impact the treatment and care of patients.

If the algorithm incorrectly predicts a high likelihood of treatment interruption for a patient, it could result in unnecessary interventions and resources being allocated to that patient. On the other hand, if the algorithm fails to identify a high-risk patient, it could lead to insufficient support and resources being provided, potentially compromising the patient's health.

Additionally, the project raises concerns about data privacy and security. The algorithm uses data from the SIDHAS project in Nigeria, which may contain sensitive and personal health information. If the data is not adequately protected, it could lead to unauthorized access or misuse of patient information, risking their privacy and confidentiality.

Therefore, the project described above is potentially a safety risk due to the potential consequences of incorrect predictions and the associated privacy and security concerns.",True,True
HHS-0058-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Risk Adjustment Payment Integrity Determination System (RAPIDS),RAPIDS AI for Classification| Process Efficiency Improvement,Operation and Maintenance,,,Department of Health and Human Services,"Risk Adjustment Payment Integrity Determination System (RAPIDS): 
RAPIDS AI for Classification| Process Efficiency Improvement",The Risk Adjustment Payment Integrity Determination System (RAPIDS) is an AI system designed to improve the efficiency of classifying and processing risk adjustment payments. It aims to enhance the accuracy and integrity of payment determinations by utilizing advanced technology and automation.,The Risk Adjustment Payment Integrity Determination System (RAPIDS) is an AI system designed to improve the efficiency of classifying and processing risk adjustment payments. It aims to enhance the accuracy and integrity of payment determinations by utilizing advanced technology and automation.,"Yes, the project described potentially poses a safety risk. The project falls under category (a) as it involves the functioning of financial systems, specifically risk adjustment payments. Any error or malfunction in the AI system could result in inaccurate payment determinations, potentially causing financial harm to individuals or organizations involved in the healthcare system.","Yes, the project described above is potentially a safety risk. The project involves making decisions related to various sensitive areas such as law enforcement, surveillance, education, employment, healthcare, finance, government benefits, and child welfare. These decisions have significant consequences for individuals and can potentially impact their rights, privacy, and well-being.

The use of AI in these decision-making processes raises concerns about potential biases, errors, or misuse of data. The project's reliance on advanced technology and automation increases the risk of incorrect or unfair decisions being made, which could result in harm to individuals or communities.

Additionally, the project involves sensitive information and personal data, which raises concerns about data privacy and security. If not properly safeguarded, this information could be vulnerable to unauthorized access or misuse, leading to potential harm to individuals' privacy and security.

Overall, the project's broad scope and potential impact on various aspects of individuals' lives make it a safety risk that requires careful consideration and mitigation of potential harms.",True,True
DHS-0003-2023,DHS,Customs and Border Protection,,Autonomous Aerostat,"Aerostat capability that uses three tethers instead of the traditional single tether, coupled with advanced weather sensors, analytic capabilities, and powerful winches. The AI/ML model is used to detect the need to launch and land based on weather. It also leverages AI and robotics to autonomously launch and recover the aerostat during inclement weather events without the need for on-site staffing, allowing the aerostat to operate autonomously, saving time and manpower.",Development and Acquisition,Automation & Robotics,,Department of Homeland Security,"Autonomous Aerostat: 
Aerostat capability that uses three tethers instead of the traditional single tether, coupled with advanced weather sensors, analytic capabilities, and powerful winches. The AI/ML model is used to detect the need to launch and land based on weather. It also leverages AI and robotics to autonomously launch and recover the aerostat during inclement weather events without the need for on-site staffing, allowing the aerostat to operate autonomously, saving time and manpower.","The Autonomous Aerostat is an advanced system that uses three tethers instead of one, along with weather sensors and analytic capabilities. It employs AI and robotics to launch and recover the aerostat during bad weather without the need for on-site staff, making it able to operate autonomously and saving time and manpower.","The Autonomous Aerostat is an advanced system that uses three tethers instead of one, along with weather sensors and analytic capabilities. It employs AI and robotics to launch and recover the aerostat during bad weather without the need for on-site staff, making it able to operate autonomously and saving time and manpower.","Yes, the project described above is potentially a safety risk. This is because it falls under category a, as it involves the functioning of electrical grids or the generation or movement of energy, and category b, as it involves physical movements within a transportation setting. Any project that involves the use of AI, robotics, and autonomous systems to operate critical infrastructure like electrical grids or transportation systems can pose safety risks if not properly designed, maintained, and monitored.",,False,True
HHS-0148-2023,HHS,NIH,National Institutes of Health (NIH) OD/OER,Internal Referral Module (IRM),The IRM initiative automates a manual process by using Artificial Intelligence & Natural Language Processing capabilities to help predict grant applications to NIH Institutes and Centers (ICs) Program Officers to make informed decisions.,Implementation,,,Department of Health and Human Services,"Internal Referral Module (IRM): 
The IRM initiative automates a manual process by using Artificial Intelligence & Natural Language Processing capabilities to help predict grant applications to NIH Institutes and Centers (ICs) Program Officers to make informed decisions.",The Internal Referral Module (IRM) is a system that uses Artificial Intelligence and Natural Language Processing to automate the prediction of grant applications to NIH Institutes and Centers Program Officers. This technology helps Program Officers make more informed decisions about which applications to consider.,The Internal Referral Module (IRM) is a system that uses Artificial Intelligence and Natural Language Processing to automate the prediction of grant applications to NIH Institutes and Centers Program Officers. This technology helps Program Officers make more informed decisions about which applications to consider.,,"Yes, the project described above is potentially a safety risk. The reason is that it falls under category i mentioned in the risks defined, which involves decisions regarding access to or eligibility for government benefits or services. Any system that determines access to government benefits or services, especially when using artificial intelligence and natural language processing, carries the potential for errors or biases that could negatively impact individuals who rely on those benefits or services. There is a risk of incorrect determinations, denial of access to benefits or services, and potential harm to individuals who may be wrongly excluded. Therefore, further evaluation and safeguards are necessary to mitigate these potential safety risks.",True,False
DOE-0026-2023,DOE,Lawrence Livermore National Laboratory,,Natural and anthropogenic disaster prevention and mitigation,"Leveraging a broad, multimodal data stream to predict and understand 
natural disaster scenarios for the purposes of prevention and mitigation",,,,Department of Energy,"Natural and anthropogenic disaster prevention and mitigation: 
Leveraging a broad, multimodal data stream to predict and understand 
natural disaster scenarios for the purposes of prevention and mitigation","By utilizing a diverse range of data, both natural and human-caused disasters can be predicted and comprehended, aiding in their prevention and reduction. This approach involves gathering various types of information to anticipate and analyze potential natural disaster situations, with the aim of minimizing their impact.","By utilizing a diverse range of data, both natural and human-caused disasters can be predicted and comprehended, aiding in their prevention and reduction. This approach involves gathering various types of information to anticipate and analyze potential natural disaster situations, with the aim of minimizing their impact.","Yes, the project described potentially poses a safety risk. This is because it involves the functioning of emergency services, which are crucial in responding to natural disasters and ensuring the safety of individuals affected. If the project fails to accurately predict or comprehend disasters, it could lead to inadequate preparedness and response, increasing the risk to human lives and property.",,False,True
DOI-0031-2023,DOI,USGS,,Two-Dimensional Detailed Hydraulic Analysis,"The USGS proposes to conduct analysis of detailed hydrology and develop a two-dimensional hydraulic model to assist in decision-making for the protection of life and property and local floodplain management and regulation. The following objectives are identified in the scope of this effort:_x000D_
Data objectives include:_x000D_
1.Topographic surveys in the study reaches to verify or augment existing topography usedin prior analyses._x000D_
a.Transportation routes_x000D_
b.Critical infrastructure_x000D_
c.Various landforms_x000D_
d.Non-structural flood mitigation recommendations at specific asset locations(USACE, 2019)_x000D_
Interpretive objectives include:_x000D_
1.Hydrologic analysis of the main stem of Joachim Creek (fig. 2) to produce discharge- frequency values for the 10%, 4%, 2%, 1%, and 0.2% regulatory flood flows._x000D_
2.Develop a calibrated two-dimensional hydraulic model inclusive of the following studyreaches for the newly developed regulatory flood flows identified in interpretiveobjective (1) above:_x000D_
a.Main stem 3.5-mile reach of Joachim Creek from a location above Highway Edownstream to cross-section AI (fig. 2). The study reach is aligned with theexisting regulatory FIS effective model and FIRM bounded upstream at a mid- point location between cross-section BC and BB and downstream at cross- section AI (fig. 3a, 3b)._x000D_
3.Two-dimensional model simulations of 10%, 4%, 2%, 1%, and 0.2% regulatory floodflows developed in interpretive objective (1) will produce flood profiles for the mainstem of Joachim Creek._x000D_
4.Development of two-dimensional model-derived flood maps for the main stem ofJoachim Creek, will be disseminated for the newly defined 1% and 0.2% regulatory floodflows in interpretive objective (1). Model-derived maps will illustrate inundationextents, water-surface elevation, depth, and velocity, including a published table ofcomparisons with the summarized list of spatially relevant nonstructural floodmitigation assets defined in the preliminary FMP by USACE (USACE, 2019).",Initiation,Doodler: https://github.com/dbuscombe-usgs/dash_doodler,https://github.com/dbuscombe-usgs/dash_doodler,Department of Interior,"Two-Dimensional Detailed Hydraulic Analysis: 
The USGS proposes to conduct analysis of detailed hydrology and develop a two-dimensional hydraulic model to assist in decision-making for the protection of life and property and local floodplain management and regulation. The following objectives are identified in the scope of this effort:_x000D_
Data objectives include:_x000D_
1.Topographic surveys in the study reaches to verify or augment existing topography usedin prior analyses._x000D_
a.Transportation routes_x000D_
b.Critical infrastructure_x000D_
c.Various landforms_x000D_
d.Non-structural flood mitigation recommendations at specific asset locations(USACE, 2019)_x000D_
Interpretive objectives include:_x000D_
1.Hydrologic analysis of the main stem of Joachim Creek (fig. 2) to produce discharge- frequency values for the 10%, 4%, 2%, 1%, and 0.2% regulatory flood flows._x000D_
2.Develop a calibrated two-dimensional hydraulic model inclusive of the following studyreaches for the newly developed regulatory flood flows identified in interpretiveobjective (1) above:_x000D_
a.Main stem 3.5-mile reach of Joachim Creek from a location above Highway Edownstream to cross-section AI (fig. 2). The study reach is aligned with theexisting regulatory FIS effective model and FIRM bounded upstream at a mid- point location between cross-section BC and BB and downstream at cross- section AI (fig. 3a, 3b)._x000D_
3.Two-dimensional model simulations of 10%, 4%, 2%, 1%, and 0.2% regulatory floodflows developed in interpretive objective (1) will produce flood profiles for the mainstem of Joachim Creek._x000D_
4.Development of two-dimensional model-derived flood maps for the main stem ofJoachim Creek, will be disseminated for the newly defined 1% and 0.2% regulatory floodflows in interpretive objective (1). Model-derived maps will illustrate inundationextents, water-surface elevation, depth, and velocity, including a published table ofcomparisons with the summarized list of spatially relevant nonstructural floodmitigation assets defined in the preliminary FMP by USACE (USACE, 2019).","The USGS plans to conduct a detailed hydraulic analysis and develop a two-dimensional hydraulic model to assist in decision-making for floodplain management and protection of life and property. This includes objectives such as conducting topographic surveys, analyzing the hydrology of Joachim Creek, and creating flood maps to show inundation extents and water-surface elevation.","The USGS plans to conduct a detailed hydraulic analysis and develop a two-dimensional hydraulic model to assist in decision-making for floodplain management and protection of life and property. This includes objectives such as conducting topographic surveys, analyzing the hydrology of Joachim Creek, and creating flood maps to show inundation extents and water-surface elevation.","Yes, the project described is potentially a safety risk. It falls under the category of ""water and wastewater systems"" mentioned in the safety risks definition. The analysis and development of a hydraulic model for floodplain management and protection of life and property involves dealing with water systems and potentially hazardous situations caused by flooding. If the project fails to accurately assess and predict flood risks, it could lead to inadequate protection measures, putting lives and properties at risk during flooding events.",,False,True
HHS-0018-2023,HHS,ASPR,"Office of Information Management, Data, and Analytics/Division of Modeling and Simulation",Modeling & Simulation,Create modeling tools and perform analyses in advance of biothreat events and be able to refine them during emergent events,Initiation,,,Department of Health and Human Services,"Modeling & Simulation: 
Create modeling tools and perform analyses in advance of biothreat events and be able to refine them during emergent events",Modeling and simulation are used to develop tools that can predict and analyze biothreat events before they occur. These tools can be continuously improved and adjusted during actual emergencies.,Modeling and simulation are used to develop tools that can predict and analyze biothreat events before they occur. These tools can be continuously improved and adjusted during actual emergencies.,"Yes, the project is potentially a safety risk. 

The project involves the development of tools for predicting and analyzing biothreat events. Biothreat events involve the delivery of biological agents, which fall under the category of physical movements and the delivery of potentially damaging biological agents or chemical agents, as mentioned in the safety risks. These agents have the potential to cause harm to human health and safety.

Additionally, the project involves modeling and simulation, which can be used to continuously improve and adjust the tools during actual emergencies. This suggests that the tools are intended to be used in real-life situations, such as during emergencies. If these tools fail or provide inaccurate predictions, it could pose a meaningful risk to safety, especially in situations where the response to biothreat events relies on the accuracy of the tools.

Therefore, the project has the potential to pose safety risks, particularly in terms of the delivery of biological agents and the potential failure of the tools during emergencies.",,False,True
DOE-0088-2023,DOE,National Energy Technology Laboratory,,To develop 5G integrated edge computing platform for efficient component monitoring in coal-fired power plants,"Develop an on-demand distributed edge computing platform to gather, 
process, and efficiently analyze the component health data in coal-fired 
power plants. Given that edge computing servers are closer to the field 
devices in modernized power plants, the efficiency of edge computing 
service with respect to dynamic orchestration, resource data collection, 
and health information monitoring will be investigated for timely detection 
of remote faults and to perform diagnosis.",,Big Data,,Department of Energy,"To develop 5G integrated edge computing platform for efficient component monitoring in coal-fired power plants: 
Develop an on-demand distributed edge computing platform to gather, 
process, and efficiently analyze the component health data in coal-fired 
power plants. Given that edge computing servers are closer to the field 
devices in modernized power plants, the efficiency of edge computing 
service with respect to dynamic orchestration, resource data collection, 
and health information monitoring will be investigated for timely detection 
of remote faults and to perform diagnosis.","A 5G integrated edge computing platform will be developed to monitor components in coal-fired power plants. This platform will gather and analyze component health data efficiently using on-demand distributed edge computing. The focus will be on investigating the efficiency of edge computing service in terms of dynamic orchestration, resource data collection, and health information monitoring, in order to detect remote faults and perform timely diagnosis.","A 5G integrated edge computing platform will be developed to monitor components in coal-fired power plants. This platform will gather and analyze component health data efficiently using on-demand distributed edge computing. The focus will be on investigating the efficiency of edge computing service in terms of dynamic orchestration, resource data collection, and health information monitoring, in order to detect remote faults and perform timely diagnosis.","Yes, the project is potentially a safety risk. This is because it falls under category a, as it involves the functioning of electrical grids and the generation of energy. Any project that involves monitoring and analyzing components in power plants carries the risk of potential failures or malfunctions in the power generation process, which can lead to safety hazards such as electrical accidents or power outages.",,False,True
VA-0005-2023,VA,,,Automated eye movement analysis and diagnostic prediction of neurological disease,"Artificial intelligence  recursively analyzes previously collected data to both improve the quality and accuracy of automated algorithms, as well as to screen for markers of neurological disease (e.g. traumatic brain injury, Parkinson's, stroke, etc).",,,,Department of Veterans Affairs,"Automated eye movement analysis and diagnostic prediction of neurological disease: 
Artificial intelligence  recursively analyzes previously collected data to both improve the quality and accuracy of automated algorithms, as well as to screen for markers of neurological disease (e.g. traumatic brain injury, Parkinson's, stroke, etc).","Artificial intelligence is used to analyze eye movements and predict neurological diseases by continuously improving automated algorithms and identifying markers of conditions like traumatic brain injury, Parkinson's, and stroke. This automated analysis enhances the quality and accuracy of diagnostic predictions.","Artificial intelligence is used to analyze eye movements and predict neurological diseases by continuously improving automated algorithms and identifying markers of conditions like traumatic brain injury, Parkinson's, and stroke. This automated analysis enhances the quality and accuracy of diagnostic predictions.","Yes, the project described potentially poses safety risks. 

Although the project does not directly involve any of the listed safety risks, it falls under category 'b' which includes physical movements within medical settings. The use of artificial intelligence to analyze eye movements and predict neurological diseases involves interaction with individuals in medical settings, which could potentially pose safety risks. 

For example, if the automated algorithms or predictions are inaccurate or unreliable, it could lead to misdiagnosis or inappropriate treatment, potentially jeopardizing the safety and well-being of patients. Additionally, if the technology is not properly implemented or monitored, there could be issues with data privacy and security, which could have negative consequences for individuals involved in the project.

Therefore, although the risks are not explicitly mentioned in the project description, the nature of the project and its potential impact on medical diagnosis and treatment make it potentially a safety risk.",,False,True
SSA-0005-2023,SSA,"Office of Analytics, Review, and Oversight",,SSI Redetermination Model,This model uses machine learning to identify supplemental security income cases with highest expected overpayments due to changes in financial eligibility and flag them for technician review.  ,,,,Social Security Administration,"SSI Redetermination Model: 
This model uses machine learning to identify supplemental security income cases with highest expected overpayments due to changes in financial eligibility and flag them for technician review.  ","The SSI Redetermination Model utilizes machine learning to pinpoint supplemental security income cases that are likely to have significant overpayments due to changes in financial eligibility. These cases are then flagged for technician review, allowing for appropriate action to be taken.","The SSI Redetermination Model utilizes machine learning to pinpoint supplemental security income cases that are likely to have significant overpayments due to changes in financial eligibility. These cases are then flagged for technician review, allowing for appropriate action to be taken.",,"Yes, the project described above is potentially a safety risk. The project involves making decisions regarding access to government benefits or services, specifically determining cases with significant overpayments. This decision-making process is being automated through machine learning, which introduces the potential for errors or biases in the algorithm.

If the algorithm incorrectly flags cases for technician review or fails to identify cases with significant overpayments, individuals may be wrongly denied benefits or may receive insufficient financial assistance. This can have serious consequences for vulnerable individuals who rely on supplemental security income.

Additionally, if the algorithm is biased or discriminatory in its decision-making, certain individuals or communities may be disproportionately affected by incorrect or unfair determinations. This could lead to widespread injustice and social inequality.

Therefore, the project raises safety concerns related to the potential harm caused by improper benefit allocation and the potential for bias or discrimination in the decision-making process.",True,False
DOE-0070-2023,DOE,National Energy Technology Laboratory,,"To drive insights on the power system reliability, cost, and operations during the energy transition with and without FECM technologies","Commercially available models will be used to generate predictive 
scenarios",,Big Data,,Department of Energy,"To drive insights on the power system reliability, cost, and operations during the energy transition with and without FECM technologies: 
Commercially available models will be used to generate predictive 
scenarios","Commercially available models will be utilized to create predictive scenarios in order to understand the impact of FECM technologies on power system reliability, cost, and operations during the energy transition. These scenarios will provide valuable insights into the potential benefits and challenges of implementing FECM technologies in the power sector.","Commercially available models will be utilized to create predictive scenarios in order to understand the impact of FECM technologies on power system reliability, cost, and operations during the energy transition. These scenarios will provide valuable insights into the potential benefits and challenges of implementing FECM technologies in the power sector.","Yes, the project described potentially poses safety risks. The project involves the use of FECM technologies in the power sector, which falls under the category of ""the functioning of electrical grids or the generation or movement of energy"" mentioned in the safety risks. The project aims to understand the impact of FECM technologies on power system reliability, cost, and operations, which could have implications for the safe functioning of electrical grids and energy generation. Therefore, there is a potential safety risk associated with this project.",,False,True
DOC-0029-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,"The VOLcanic Cloud Analysis Toolkit (VOLCAT): An application system for detecting, tracking, characterizing, and forecasting hazardous volcanic events","Volcanic ash is a major aviation hazard. The VOLcanic Cloud Analysis Toolkit (VOLCAT) 
consists of several AI powered satellite applications including: eruption detection, 
alerting, and volcanic cloud tracking. These applications are routinely utilized by Volcanic 
Ash Advisory Centers to issue volcanic ash advisories. Under this project, the VOLCAT 
products will be further developed, and subsequently transitioned to the NESDIS Common 
Cloud Framework, to help ensure adherence to new International Civil Aviation 
Organization requirements.",,,,Department of Commerce,"The VOLcanic Cloud Analysis Toolkit (VOLCAT): An application system for detecting, tracking, characterizing, and forecasting hazardous volcanic events: 
Volcanic ash is a major aviation hazard. The VOLcanic Cloud Analysis Toolkit (VOLCAT) 
consists of several AI powered satellite applications including: eruption detection, 
alerting, and volcanic cloud tracking. These applications are routinely utilized by Volcanic 
Ash Advisory Centers to issue volcanic ash advisories. Under this project, the VOLCAT 
products will be further developed, and subsequently transitioned to the NESDIS Common 
Cloud Framework, to help ensure adherence to new International Civil Aviation 
Organization requirements.","The VOLcanic Cloud Analysis Toolkit (VOLCAT) is an application system that uses artificial intelligence and satellite technology to detect, track, characterize, and forecast hazardous volcanic events, particularly volcanic ash. It includes several applications that are used by Volcanic Ash Advisory Centers to issue volcanic ash advisories. The project aims to further develop the VOLCAT products and integrate them into the NESDIS Common Cloud Framework to meet the new International Civil Aviation Organization requirements.","The VOLcanic Cloud Analysis Toolkit (VOLCAT) is an application system that uses artificial intelligence and satellite technology to detect, track, characterize, and forecast hazardous volcanic events, particularly volcanic ash. It includes several applications that are used by Volcanic Ash Advisory Centers to issue volcanic ash advisories. The project aims to further develop the VOLCAT products and integrate them into the NESDIS Common Cloud Framework to meet the new International Civil Aviation Organization requirements.","Yes, the project is potentially a safety risk. This is because it falls under the category of ""Industrial emissions and environmental impact control processes"" (risk f) and ""The design, construction, or testing of industrial equipment, systems, or structures that, if they failed, would pose a meaningful risk to safety"" (risk h). 

The VOLcanic Cloud Analysis Toolkit (VOLCAT) involves the analysis and tracking of hazardous volcanic events, particularly volcanic ash. If the system fails or provides inaccurate information, it could potentially lead to incorrect advisories being issued by Volcanic Ash Advisory Centers. This could pose a safety risk to aviation as aircraft could potentially fly into volcanic ash clouds, resulting in engine damage or failure.

Additionally, the project involves the integration of the VOLCAT products into the NESDIS Common Cloud Framework to meet new International Civil Aviation Organization requirements. If there are any failures or vulnerabilities in the integration process, it could potentially compromise the accuracy and effectiveness of the volcanic ash advisories, leading to safety risks for aviation.

Therefore, due to the potential consequences of system failure or inaccuracies in the volcanic ash advisories, the project is considered a safety risk.",,False,True
DOE-0010-2023,DOE,Fermi National Accelerator,,Machine Learning for Linac Improved Performance,"In Linacs at FNAL and J-PARC, the current emittance optimization 
procedure is limited to manual adjustments of a few parameters; using 
a larger number is not practically feasible for a human operator. Using 
machine learning (ML) techniques allows lifting this restriction and 
expanding this set. Our goal is to integrate ML into linac operation - and 
in particular RF control to achieve a more optimal longitudinal emittance 
and lower overall losses.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"Machine Learning for Linac Improved Performance: 
In Linacs at FNAL and J-PARC, the current emittance optimization 
procedure is limited to manual adjustments of a few parameters; using 
a larger number is not practically feasible for a human operator. Using 
machine learning (ML) techniques allows lifting this restriction and 
expanding this set. Our goal is to integrate ML into linac operation - and 
in particular RF control to achieve a more optimal longitudinal emittance 
and lower overall losses.","The current emittance optimization procedure in Linacs at FNAL and J-PARC is limited to manual adjustments of a few parameters, which is not feasible for a human operator to handle a larger number of parameters. By incorporating machine learning techniques, this limitation can be overcome, allowing for a greater number of parameters to be adjusted. The objective is to integrate machine learning into linac operation, specifically RF control, in order to achieve improved longitudinal emittance and reduce overall losses.","The current emittance optimization procedure in Linacs at FNAL and J-PARC is limited to manual adjustments of a few parameters, which is not feasible for a human operator to handle a larger number of parameters. By incorporating machine learning techniques, this limitation can be overcome, allowing for a greater number of parameters to be adjusted. The objective is to integrate machine learning into linac operation, specifically RF control, in order to achieve improved longitudinal emittance and reduce overall losses.",,"Yes, the project described potentially poses a safety risk. The use of machine learning in linac operation, specifically RF control, introduces the possibility of errors or malfunctions in the system. If the machine learning algorithms are not properly trained or calibrated, they may make incorrect adjustments to the parameters, leading to unintended consequences. In a linac, any errors or malfunctions can have serious safety implications, such as radiation hazards or damage to the equipment. Therefore, careful testing, validation, and monitoring of the machine learning system would be necessary to mitigate these risks.",True,False
DOE-0134-2023,DOE,National Energy Technology Laboratory,,To research and develop physics- aware and AI-enabled cyber- physical intrusion response for the power grid.,"Responding to anomalous cyber and physical events in a timely manner 
requires fusing data from both cyber and physical sensors into 
actionable information. Thus, cyber-physical intrusion response research 
will be conducted that leverages cyber and physical side data and 
models with artificial intelligence (AI) as a scalable approach to maintain 
or regain power system resilience under anomalous incidents such as 
cyber threats.",,Artificial Intelligence Unknown,,Department of Energy,"To research and develop physics- aware and AI-enabled cyber- physical intrusion response for the power grid.: 
Responding to anomalous cyber and physical events in a timely manner 
requires fusing data from both cyber and physical sensors into 
actionable information. Thus, cyber-physical intrusion response research 
will be conducted that leverages cyber and physical side data and 
models with artificial intelligence (AI) as a scalable approach to maintain 
or regain power system resilience under anomalous incidents such as 
cyber threats.","The goal of the research is to develop a response system for the power grid that can effectively address both cyber and physical threats. This will involve using data from various sensors and models, combined with artificial intelligence, to quickly and efficiently respond to anomalous incidents and maintain the resilience of the power system.","The goal of the research is to develop a response system for the power grid that can effectively address both cyber and physical threats. This will involve using data from various sensors and models, combined with artificial intelligence, to quickly and efficiently respond to anomalous incidents and maintain the resilience of the power system.","Yes, the project is potentially a safety risk. The project involves the functioning of electrical grids, which falls under the category of safety risks mentioned in the question. Any potential failures or malfunctions in the response system for the power grid could pose a meaningful risk to safety. Additionally, the use of artificial intelligence and the integration of various sensors and models could introduce vulnerabilities and potential threats to the power system, making it susceptible to cyber threats.",,False,True
DOE-0153-2023,DOE,National Energy Technology Laboratory,,Using recursive neural networks and using fiber optic cables to recognize strain patterns and warn operators a fracture is coming.,"This project will develop an ML algorithm to predict the time when a 
growing fracture will reach the monitored well. The ML workflow will be 
trained on the distinctive tensile strain signature that precedes the 
growing fracture. The new workflow will be designed to work in 
conjunction with the fracture warning ML workflow developed in EY21. 
Together, these workflows will: (1) provide an early warning of well-to-
well communication, (2) predict the measured depths where the 
communication will happen, and (3) provide an estimated time until the 
beginning of well-to-well communication.",,"Neural Networks, Other",,Department of Energy,"Using recursive neural networks and using fiber optic cables to recognize strain patterns and warn operators a fracture is coming.: 
This project will develop an ML algorithm to predict the time when a 
growing fracture will reach the monitored well. The ML workflow will be 
trained on the distinctive tensile strain signature that precedes the 
growing fracture. The new workflow will be designed to work in 
conjunction with the fracture warning ML workflow developed in EY21. 
Together, these workflows will: (1) provide an early warning of well-to-
well communication, (2) predict the measured depths where the 
communication will happen, and (3) provide an estimated time until the 
beginning of well-to-well communication.","This project aims to develop a machine learning algorithm that can predict the timing of a growing fracture reaching a monitored well. The algorithm will be trained on the unique tensile strain pattern that occurs before a fracture. When used in conjunction with an existing fracture warning algorithm, this new workflow will provide early warning of well-to-well communication, predict the depths where the communication will occur, and estimate the time until the communication begins.","This project aims to develop a machine learning algorithm that can predict the timing of a growing fracture reaching a monitored well. The algorithm will be trained on the unique tensile strain pattern that occurs before a fracture. When used in conjunction with an existing fracture warning algorithm, this new workflow will provide early warning of well-to-well communication, predict the depths where the communication will occur, and estimate the time until the communication begins.","Yes, this project is potentially a safety risk. 

The project falls under category b, as it involves physical movements within a workplace setting. In this case, the movement of a growing fracture could potentially cause damage or compromise the integrity of the monitored well, leading to safety hazards for workers or the environment.

Additionally, the project could also fall under category h, as the design and construction of the machine learning algorithm and the existing fracture warning algorithm are crucial for ensuring the safety of the well. If these algorithms fail or provide incorrect predictions, it could lead to miscommunication or inadequate warning of well-to-well communication, which could have safety implications.

Therefore, considering the potential risks associated with the physical movements and the design of the algorithms, this project is potentially a safety risk.",,False,True
SSA-0001-2023,SSA,"Office of Analytics, Review, and Oversight",,Anomalous iClaim Predictive Model,The anomalous iClaim predictive model is a machine learning model that identifies high-risk iClaims. These claims are then sent to Operations for further review before additional action is taken to adjudicate the claims. ,,,,Social Security Administration,"Anomalous iClaim Predictive Model: 
The anomalous iClaim predictive model is a machine learning model that identifies high-risk iClaims. These claims are then sent to Operations for further review before additional action is taken to adjudicate the claims. ","The anomalous iClaim predictive model is a machine learning model that detects high-risk iClaims. Once identified, these claims are forwarded to Operations for further evaluation before any further action is taken to process them.","The anomalous iClaim predictive model is a machine learning model that detects high-risk iClaims. Once identified, these claims are forwarded to Operations for further evaluation before any further action is taken to process them.",,"Yes, the project described above is potentially a safety risk. The project involves the use of a predictive model to detect high-risk iClaims, which are then forwarded to Operations for further evaluation before any further action is taken. 

The potential safety risk lies in the fact that the project does not provide details on how the high-risk iClaims are identified or what criteria are used to classify them as high-risk. Without proper transparency and accountability, there is a risk of false positives or biased decision-making, which can have serious consequences for individuals involved. 

Furthermore, the project's lack of clarity on the nature of the iClaims and the actions taken after they are forwarded to Operations raises concerns about potential violations of privacy and civil liberties. The project's involvement in decisions related to law enforcement, surveillance, or determining access to government benefits or services can have significant implications for individuals' rights and freedoms. 

Overall, the lack of transparency, potential for biased decision-making, and involvement in sensitive areas make this project a potential safety risk.",True,False
DOE-0125-2023,DOE,National Energy Technology Laboratory,,To leverage machine learning and predictive analytics to advance the state of the art in pipline infrastructure integrity management.,"The purpose of this project is to leverage advances in machine learning 
and predictive analytics to advance the state of the art in pipeline 
infrastructure integrity management using forecasted (predicted) 
pipeline condition, using large sets of pipeline integrity data (periodic 
nondestructive inspection, NDI) and continuous operational data (e.g., 
sensor data used to monitor flow rate and temperature) generated by oil 
and gas (O&G) transmission pipeline operators.",,Artificial Intelligence Unknown,,Department of Energy,"To leverage machine learning and predictive analytics to advance the state of the art in pipline infrastructure integrity management.: 
The purpose of this project is to leverage advances in machine learning 
and predictive analytics to advance the state of the art in pipeline 
infrastructure integrity management using forecasted (predicted) 
pipeline condition, using large sets of pipeline integrity data (periodic 
nondestructive inspection, NDI) and continuous operational data (e.g., 
sensor data used to monitor flow rate and temperature) generated by oil 
and gas (O&G) transmission pipeline operators.",The project aims to improve pipeline infrastructure integrity management by using machine learning and predictive analytics. This will be achieved by utilizing forecasted pipeline conditions based on large sets of pipeline integrity data and continuous operational data collected by oil and gas transmission pipeline operators.,The project aims to improve pipeline infrastructure integrity management by using machine learning and predictive analytics. This will be achieved by utilizing forecasted pipeline conditions based on large sets of pipeline integrity data and continuous operational data collected by oil and gas transmission pipeline operators.,"Yes, the project is potentially a safety risk. This is because it falls under category (a) of safety risks mentioned, specifically the functioning of energy systems. The project involves improving pipeline infrastructure, which is closely related to the generation and movement of energy in the form of oil and gas transmission. Any failures or issues with the pipeline infrastructure could potentially lead to safety hazards such as leaks, explosions, or environmental damage. Therefore, careful consideration and implementation of safety measures are necessary to mitigate the risks associated with this project.",,False,True
HHS-0142-2023,HHS,NIH,National Institutes of Health (NIH) OD/DPCPSI/OPA,Identification of emerging areas,Developed an AI/ML-based approach that computes the age and rate of progress of topics in NIH portfolios. This information can identify emerging areas of research at scale and help accelerate scientific progress.,Implementation,,,Department of Health and Human Services,"Identification of emerging areas: 
Developed an AI/ML-based approach that computes the age and rate of progress of topics in NIH portfolios. This information can identify emerging areas of research at scale and help accelerate scientific progress.",An AI/ML-based approach has been developed to determine the age and rate of progress of topics in NIH portfolios. This method can effectively identify emerging areas of research and contribute to speeding up scientific progress.,An AI/ML-based approach has been developed to determine the age and rate of progress of topics in NIH portfolios. This method can effectively identify emerging areas of research and contribute to speeding up scientific progress.,,"Yes, the project described potentially poses a safety risk. 

The project involves the use of AI/ML to determine the age and rate of progress of topics in NIH portfolios. While this may seem like a harmless application, it falls under the category of decision-making processes that can have significant implications. Specifically, it falls under the category of determining access to educational resources or programs, which is listed as a potentially risky area.

The potential safety risk arises from the fact that the project involves influencing admissions processes and projecting student progress or outcomes. These decisions can have a direct impact on individuals' educational opportunities and future prospects. If the AI/ML system used in this project is not accurate or fair in its assessments, it could lead to biased or discriminatory outcomes, potentially denying deserving students access to resources or programs.

Furthermore, the project's goal of identifying emerging areas of research and speeding up scientific progress may also have unintended consequences. If the AI/ML system is not properly designed or trained, it could lead to incorrect conclusions and misguided allocation of resources in research and development. This could hamper scientific progress and result in the misdirection of funding and efforts.

Therefore, while the project's intention is to contribute to scientific progress, it involves decision-making processes in education and research that have the potential to negatively impact individuals and the scientific community if not implemented carefully and ethically.",True,False
DOE-0065-2023,DOE,National Energy Technology Laboratory,,Prediction of gasification gas yield and compositions using machine learning,"A machine learning (ML) model will be developed to aid in investigating 
and optimizing of gasification with various feedstocks like waste plastic, 
waste coal, biomass and MSW. Database on the gasification will be 
built from main resources of literature, prior experiments in NETL, and 
new generating experiments in NETL. Al/ML will be a part of the project. 
It combines with experimental study to accelerate development of 
gasification applying to variour feedstocks including waste plastics, 
waste coal, MSW and its mixture. The ML will have more impact as the 
big database will be built.",,"Big Data, Other",,Department of Energy,"Prediction of gasification gas yield and compositions using machine learning: 
A machine learning (ML) model will be developed to aid in investigating 
and optimizing of gasification with various feedstocks like waste plastic, 
waste coal, biomass and MSW. Database on the gasification will be 
built from main resources of literature, prior experiments in NETL, and 
new generating experiments in NETL. Al/ML will be a part of the project. 
It combines with experimental study to accelerate development of 
gasification applying to variour feedstocks including waste plastics, 
waste coal, MSW and its mixture. The ML will have more impact as the 
big database will be built.","A machine learning model will be created to analyze and improve the gasification process using different types of feedstocks such as waste plastic, waste coal, biomass, and municipal solid waste (MSW). The model will be developed using a database compiled from literature, previous experiments, and new experiments conducted at NETL. This project aims to accelerate the development of gasification technology by combining machine learning with experimental studies, particularly as the size of the database grows.","A machine learning model will be created to analyze and improve the gasification process using different types of feedstocks such as waste plastic, waste coal, biomass, and municipal solid waste (MSW). The model will be developed using a database compiled from literature, previous experiments, and new experiments conducted at NETL. This project aims to accelerate the development of gasification technology by combining machine learning with experimental studies, particularly as the size of the database grows.","Yes, the project described potentially poses safety risks. 

Firstly, the project involves the design and development of industrial equipment and systems for the gasification process. If these systems were to fail, it could pose a meaningful risk to safety (as stated in risk category h).

Secondly, the project involves the use of different types of feedstocks, including waste plastic, waste coal, biomass, and municipal solid waste. These materials can be hazardous and may require careful handling and disposal to prevent environmental and health risks (as stated in risk category k).

Although the project primarily focuses on the application of machine learning and experimental studies, the potential safety risks associated with the gasification process and the handling of hazardous materials make it a potentially risky project.",,False,True
VA-0019-2023,VA,,,Seizure detection from EEG and video,Machine learning algorithms use EEG and video data from a VHA epilepsy monitoring unit in order to automatically identify seizures without human intervention.,,,,Department of Veterans Affairs,"Seizure detection from EEG and video: 
Machine learning algorithms use EEG and video data from a VHA epilepsy monitoring unit in order to automatically identify seizures without human intervention.",Machine learning algorithms analyze EEG and video data to detect seizures in a VHA epilepsy monitoring unit. This automated process eliminates the need for human intervention in identifying seizures.,Machine learning algorithms analyze EEG and video data to detect seizures in a VHA epilepsy monitoring unit. This automated process eliminates the need for human intervention in identifying seizures.,"Yes, the project is potentially a safety risk. According to the provided definition, the project involves the movement and actions of medical equipment and systems within a medical setting, which falls under category b. It also deals with the monitoring and detection of seizures, which are critical medical events that require immediate attention and intervention. If the machine learning algorithms fail to accurately detect seizures or if there are any errors in the automated process, it could lead to delayed or incorrect treatment, posing a risk to the safety and well-being of the patients in the VHA epilepsy monitoring unit.",,False,True
DOJ-0000-2023,DOJ,Drug Enforcement Administration,,Drug Signature Program Algorithms,"DEA's Special Testing and Research 
Laboratory utilizes AI/ML techniques and 
has developed a robust statistical 
methodology including multi-variate 
statistical analysis tools to automatically 
classify the geographical region of origin 
of samples selected for DEA's Heroin and 
Cocaine signature programs. The system 
provides for detection of anomalies and 
low confidence results.",In production: more than 1 year,,,Department of Justice,"Drug Signature Program Algorithms: 
DEA's Special Testing and Research 
Laboratory utilizes AI/ML techniques and 
has developed a robust statistical 
methodology including multi-variate 
statistical analysis tools to automatically 
classify the geographical region of origin 
of samples selected for DEA's Heroin and 
Cocaine signature programs. The system 
provides for detection of anomalies and 
low confidence results.","The DEA's Special Testing and Research Laboratory uses AI/ML techniques to create algorithms for their Drug Signature Program. These algorithms use statistical analysis tools to automatically determine the geographical region where samples of heroin and cocaine originated, and can also identify anomalies and results with low confidence.","The DEA's Special Testing and Research Laboratory uses AI/ML techniques to create algorithms for their Drug Signature Program. These algorithms use statistical analysis tools to automatically determine the geographical region where samples of heroin and cocaine originated, and can also identify anomalies and results with low confidence.",,"Yes, the project described above is potentially a safety risk. This is because it falls under category b, specifically the ""forensic analysis"" aspect. The use of AI/ML techniques to determine the geographical region of drug samples and identify anomalies and low-confidence results can have significant implications in law enforcement and criminal justice processes. The accuracy and reliability of these algorithms play a crucial role in decisions related to investigations, arrests, and potentially sentencing. Any errors or biases in the algorithms can lead to wrongful accusations or the overlooking of important evidence, which could result in serious consequences for individuals involved in criminal cases. Therefore, there is a potential safety risk associated with the project.",True,False
HHS-0063-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Artificial Intelligence (AI) Explorers Program Pilot - Section 508 accessibility Testing,90 day Pilot is to better inform CMS technical leads and Application Development Organizations (ADOs) to conduct a comprehensive analysis on the data from the test result documents in support of the CMS Section 508 Program.,Development and Acquisition,,,Department of Health and Human Services,"Artificial Intelligence (AI) Explorers Program Pilot - Section 508 accessibility Testing: 
90 day Pilot is to better inform CMS technical leads and Application Development Organizations (ADOs) to conduct a comprehensive analysis on the data from the test result documents in support of the CMS Section 508 Program.",The Artificial Intelligence Explorers Program Pilot for Section 508 accessibility testing aims to help CMS technical leads and ADOs analyze test result documents more effectively. This 90-day pilot program aims to improve the CMS Section 508 Program.,The Artificial Intelligence Explorers Program Pilot for Section 508 accessibility testing aims to help CMS technical leads and ADOs analyze test result documents more effectively. This 90-day pilot program aims to improve the CMS Section 508 Program.,,"Yes, the project potentially poses a safety risk. The project involves the use of artificial intelligence in analyzing test result documents for the CMS Section 508 Program. While the project itself does not directly involve any of the defined risks, the use of artificial intelligence in decision-making processes, even for accessibility testing, can potentially have unintended consequences or biases that could impact individuals' access to government benefits or services. Therefore, there is a potential risk involved in the project.",True,False
DOE-0164-2023,DOE,Pacific Northwest National Laboratory,,Adaptive Cyber-Physical Resilience for Building Control Systems,"Deep learning models are used for predicting the operation of building 
energy systems, and detecting and diagnosing the health state or cyber 
attack presence, and for optimizing the building energy system 
response to provide resilient operation and sustained energy efficiency.",,,,Department of Energy,"Adaptive Cyber-Physical Resilience for Building Control Systems: 
Deep learning models are used for predicting the operation of building 
energy systems, and detecting and diagnosing the health state or cyber 
attack presence, and for optimizing the building energy system 
response to provide resilient operation and sustained energy efficiency.",Deep learning models are utilized to forecast the performance of building energy systems and identify any potential cyber attacks or health issues. These models also optimize the response of the building energy system to ensure resilient operation and long-term energy efficiency.,Deep learning models are utilized to forecast the performance of building energy systems and identify any potential cyber attacks or health issues. These models also optimize the response of the building energy system to ensure resilient operation and long-term energy efficiency.,"Yes, the project described potentially poses a safety risk. This is because it involves the functioning of energy systems, which falls under the category of ""The functioning of dams, emergency services, electrical grids or the generation or movement of energy."" If the deep learning models used to forecast building energy systems fail or give inaccurate results, it could lead to issues in the operation of the building energy system, potentially compromising the safety and efficiency of the system. Additionally, the identification of cyber attacks is also a safety concern as it involves the security of the system against potential threats.",,False,True
DHS-0014-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Advanced Network Anomaly Alerting,"Threat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of data from the National Cybersecurity Protection System's (NCPS) Einstein sensors. Manually developed detection alerts and automatic correlation via off the shelf tooling are common, but not comprehensive. Many network attacks can be probabilistically determined given sufficient training data and time. Analysts use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and backed in subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",Initiation,Machine Learning,,Department of Homeland Security,"Advanced Network Anomaly Alerting: 
Threat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of data from the National Cybersecurity Protection System's (NCPS) Einstein sensors. Manually developed detection alerts and automatic correlation via off the shelf tooling are common, but not comprehensive. Many network attacks can be probabilistically determined given sufficient training data and time. Analysts use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and backed in subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ","Advanced Network Anomaly Alerting enables SOC analysts to receive large amounts of data from NCPS's Einstein sensors. By using automated tooling and mathematically-based models, analysts can refine and produce accurate alerts based on aggregated information, ensuring timely detection of high fidelity anomalies.","Advanced Network Anomaly Alerting enables SOC analysts to receive large amounts of data from NCPS's Einstein sensors. By using automated tooling and mathematically-based models, analysts can refine and produce accurate alerts based on aggregated information, ensuring timely detection of high fidelity anomalies.",,"Yes, the project described above has the potential to be a safety risk. The project involves the use of advanced network anomaly alerting to detect anomalies in data received from Einstein sensors. While the project description does not provide specific details about the potential safety risks, it falls under the category of ""physical location-monitoring devices"" and ""conduct of cyber intrusions"" mentioned in the definition of safety risks.

The use of automated tooling and mathematically-based models for anomaly detection can raise concerns related to privacy, surveillance, and potential misuse of personal data. The project's ability to monitor and analyze large amounts of data collected from Einstein sensors could have significant implications for individuals' privacy and civil liberties.

Additionally, the project's involvement in detecting cyber intrusions raises concerns about potential breaches in cybersecurity and the possibility of unauthorized access to sensitive information. If the project's alerting system is not robust and secure, it could lead to false positives or false negatives, impacting the effectiveness of the security operations center (SOC) and potentially putting sensitive systems and data at risk.

Overall, the project's focus on network anomaly detection and its potential to collect and analyze large amounts of data make it potentially risky in terms of privacy, cybersecurity, and the potential for misuse or unauthorized access to personal or sensitive information.",True,False
HHS-0015-2023,HHS,ASPR,Office of Critical Infrastructure,Cyber Threat Detection/ Predictive analytics,Use AI and ML tools for processing of extremely large threat data,Initiation,,,Department of Health and Human Services,"Cyber Threat Detection/ Predictive analytics: 
Use AI and ML tools for processing of extremely large threat data","AI and ML tools are utilized for the processing of vast amounts of threat data in order to detect and predict cyber threats effectively. This approach, known as cyber threat detection or predictive analytics, enables advanced analysis and identification of potential cyber attacks.","AI and ML tools are utilized for the processing of vast amounts of threat data in order to detect and predict cyber threats effectively. This approach, known as cyber threat detection or predictive analytics, enables advanced analysis and identification of potential cyber attacks.","Yes, the project potentially poses a safety risk. This is because the project involves the processing and analysis of vast amounts of threat data, which can have implications on the safety and security of various systems and infrastructure mentioned in the safety risks definition. Cyber attacks can target critical systems such as dams, emergency services, electrical grids, and voting infrastructure, potentially causing significant harm or disruption. Therefore, the application of AI and ML tools for cyber threat detection should be carefully managed to ensure the safety and integrity of these systems.",,False,True
DOE-0143-2023,DOE,National Energy Technology Laboratory,,Use AI to process large sensor datasets for identification and classification of NG pipeline conditions and methane leaks,"Focused on development of advanced data analytic techniques and 
methods for distributed OFS technology, including AI and ML, for 
identification of signatures and patterns representative of hazards, 
defects, and operational parameters of the natural gas pipeline network.",,"Big Data, Other",,Department of Energy,"Use AI to process large sensor datasets for identification and classification of NG pipeline conditions and methane leaks: 
Focused on development of advanced data analytic techniques and 
methods for distributed OFS technology, including AI and ML, for 
identification of signatures and patterns representative of hazards, 
defects, and operational parameters of the natural gas pipeline network.","This text highlights the use of artificial intelligence (AI) to analyze vast sensor datasets and identify and classify conditions and methane leaks in natural gas pipelines. The focus is on developing advanced data analytic techniques, including AI and machine learning (ML), to identify patterns and signatures that represent hazards, defects, and operational parameters of the pipeline network.","This text highlights the use of artificial intelligence (AI) to analyze vast sensor datasets and identify and classify conditions and methane leaks in natural gas pipelines. The focus is on developing advanced data analytic techniques, including AI and machine learning (ML), to identify patterns and signatures that represent hazards, defects, and operational parameters of the pipeline network.","Yes, the project described above has the potential to be a safety risk. The project involves the use of artificial intelligence (AI) to analyze sensor datasets and identify and classify conditions and methane leaks in natural gas pipelines. The potential safety risks associated with this project fall under several categories mentioned in the provided list.

Firstly, the project involves the functioning of energy systems, specifically natural gas pipelines. Any failure or malfunction in these systems can pose significant safety risks, including explosions, fires, and environmental damage.

Secondly, the project involves the transportation and management of hazardous substances, such as methane. Leaks or improper handling of these substances can have severe safety implications, including the risk of explosions, health hazards, and environmental pollution.

Furthermore, the project involves the design and development of industrial equipment and systems. If there are any failures or defects in the design or construction of these systems, it could pose meaningful risks to safety, such as pipeline ruptures or equipment malfunctions.

In conclusion, due to its involvement with critical energy systems, transportation of hazardous substances, and the design and development of industrial equipment, the project described above has the potential to be a safety risk.",,False,True
SSA-0004-2023,SSA,"Office of Analytics, Review, and Oversight",,CDR Model,This model uses machine learning techniques to identify disability cases with the greatest likelihood of medical improvement and flag them for a coninuing disability review.,,,,Social Security Administration,"CDR Model: 
This model uses machine learning techniques to identify disability cases with the greatest likelihood of medical improvement and flag them for a coninuing disability review.","The CDR Model utilizes machine learning to pinpoint disability cases that are more likely to show medical improvement and highlights them for a continuing disability review. By applying advanced techniques, this model helps identify cases that may no longer require disability benefits.","The CDR Model utilizes machine learning to pinpoint disability cases that are more likely to show medical improvement and highlights them for a continuing disability review. By applying advanced techniques, this model helps identify cases that may no longer require disability benefits.",,"Yes, the project described above has the potential to be a safety risk. 

The project involves using machine learning to identify disability cases that may no longer require disability benefits. This means that the project has the potential to impact individuals' access to government benefits or services, which falls under the category of decisions regarding access to or eligibility for government benefits or services. 

Making decisions about whether individuals should continue to receive disability benefits can have significant consequences for their well-being and livelihood. If the model incorrectly identifies cases that no longer require disability benefits, it could result in individuals losing their benefits and facing financial hardship.

Additionally, the project involves the use of advanced techniques and machine learning, which can introduce biases and inaccuracies in the decision-making process. If the model disproportionately targets certain groups or fails to accurately assess an individual's disability status, it could lead to unfair outcomes and negatively impact vulnerable populations.

Therefore, due to the potential risks involved in making decisions about individuals' access to government benefits, this project should be carefully evaluated and monitored to ensure that it does not result in unjust or harmful outcomes.",True,False
HHS-0080-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Onboarding of EHR data partners,"In the currently proposed project (DI6), structured fields from EHRs and linked claims data from two identified commercial data partners will be converted to the Sentinel Common Data Model (SCDM). The SCDM is an organizing CDM that preserves the original information from a data source and has been successfully used in the Sentinel system for over a decade. While originally built for claims data, SCDM was expanded in 2015 to accommodate some information commonly found in EHRs in separate clinical data tables to capture laboratory test results of interest and vital signs. We selected the SCDM over other CDMs because data formatted in the SCDM enables analyses that can leverage the standardized active risk identification and analysis (ARIA) tools. Operationally, both Data Partners will share SCDM transformed patient-level linked EHR-claims data with the IC after quality assessments are passed. This is a substantial advantage in this early stage of understanding how to optimally analyze such data. It will allow Sentinel investigators to directly work with the data, adapt existing analytic programs, and test algorithms. In sum, transformation of structured data from the proposed sources to SCDM format will be a key first step for potential future incorporation of these Data Partners into Sentinel to provide access to EHR-claims linked data for >10 million patients, which will be critical to meet the need identified in the 5-year Sentinel System strategic plan of 2019.",Initiation,,,Department of Health and Human Services,"Onboarding of EHR data partners: 
In the currently proposed project (DI6), structured fields from EHRs and linked claims data from two identified commercial data partners will be converted to the Sentinel Common Data Model (SCDM). The SCDM is an organizing CDM that preserves the original information from a data source and has been successfully used in the Sentinel system for over a decade. While originally built for claims data, SCDM was expanded in 2015 to accommodate some information commonly found in EHRs in separate clinical data tables to capture laboratory test results of interest and vital signs. We selected the SCDM over other CDMs because data formatted in the SCDM enables analyses that can leverage the standardized active risk identification and analysis (ARIA) tools. Operationally, both Data Partners will share SCDM transformed patient-level linked EHR-claims data with the IC after quality assessments are passed. This is a substantial advantage in this early stage of understanding how to optimally analyze such data. It will allow Sentinel investigators to directly work with the data, adapt existing analytic programs, and test algorithms. In sum, transformation of structured data from the proposed sources to SCDM format will be a key first step for potential future incorporation of these Data Partners into Sentinel to provide access to EHR-claims linked data for >10 million patients, which will be critical to meet the need identified in the 5-year Sentinel System strategic plan of 2019.","In the DI6 project, structured data from electronic health records (EHRs) and linked claims data from two commercial data partners will be converted to the Sentinel Common Data Model (SCDM), which has been successfully used in the Sentinel system for over a decade. This conversion will allow Sentinel investigators to directly work with the data, adapt existing analytic programs, and test algorithms, which is crucial for meeting the goals of the 5-year Sentinel System strategic plan of 2019.","In the DI6 project, structured data from electronic health records (EHRs) and linked claims data from two commercial data partners will be converted to the Sentinel Common Data Model (SCDM), which has been successfully used in the Sentinel system for over a decade. This conversion will allow Sentinel investigators to directly work with the data, adapt existing analytic programs, and test algorithms, which is crucial for meeting the goals of the 5-year Sentinel System strategic plan of 2019.",,"Yes, the project described potentially poses a safety risk. The project involves handling sensitive health data from electronic health records (EHRs) and claims data. This data may contain personally identifiable information (PII) and sensitive medical information, making it susceptible to privacy breaches and unauthorized access. If proper security measures are not in place, there is a risk of data breaches, identity theft, or unauthorized use of the information. Additionally, the project may involve making decisions regarding medical diagnosis, treatment, and health-risk assessments, which can have significant implications for patient safety and well-being if inaccurate or flawed algorithms are used. Therefore, the project needs to prioritize data security and accuracy to mitigate potential safety risks.",True,False
DOI-0014-2023,DOI,USGS,,DO NOT USE (21st Century IMT Applicaitons Analysis AIML),Activity: Implement artificial intelligence (AI) and machine learning (ML) cloud services including SageMaker and Rekognition . Outcome/Value:  Provide Cloud-based tools and services that present options to pursue investigations using machine learning or artificial intelligence-based approaches.  These are critical capabilities to support predictive science and enabling the movement toward actionable intelligence.  ,Development and Acquisition,Convolutional Neural Networks,,Department of Interior,"DO NOT USE (21st Century IMT Applicaitons Analysis AIML): 
Activity: Implement artificial intelligence (AI) and machine learning (ML) cloud services including SageMaker and Rekognition . Outcome/Value:  Provide Cloud-based tools and services that present options to pursue investigations using machine learning or artificial intelligence-based approaches.  These are critical capabilities to support predictive science and enabling the movement toward actionable intelligence.  ","The text discusses the implementation of AI and ML cloud services, such as SageMaker and Rekognition, to provide cloud-based tools and services for investigations using machine learning or artificial intelligence approaches. These capabilities are important for predictive science and facilitating the transition towards actionable intelligence.","The text discusses the implementation of AI and ML cloud services, such as SageMaker and Rekognition, to provide cloud-based tools and services for investigations using machine learning or artificial intelligence approaches. These capabilities are important for predictive science and facilitating the transition towards actionable intelligence.",,"Yes, the project described is potentially a safety risk. The project involves the use of AI and ML cloud services for investigations using machine learning or artificial intelligence approaches. This could potentially lead to risks related to privacy, security, and potential bias in decision-making processes.

For example, the use of facial matching, facial sketching, and genetic facial reconstruction for law enforcement or surveillance purposes may raise concerns about privacy and potential misuse of personal information. Additionally, the use of AI in determining access to educational resources or programs, employment decisions, or government benefits could introduce biases and unfair practices.

Furthermore, the project's focus on predictive science and actionable intelligence raises concerns about the accuracy and reliability of the AI and ML algorithms used. If these algorithms are not properly validated and tested, they may lead to incorrect predictions or decisions with potentially harmful consequences.

Overall, the project's involvement in various areas with significant impact on individuals' lives, combined with the use of AI and ML technologies, increases the potential safety risks associated with the project.",True,False
DOC-0010-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Fast tracking the use of VIAME for automated identification of reef fish,"We've been compiling image libraries for use in creating automated detection and 
classification models for use in automating the annotation process for the SEAMAP Reef 
Fish Video survey of the Gulf of Mexico. This work is being conducted in VIAME but we're 
looking at several other paths forward in the project to identify best performing models. 
Current status is that models are performing well enough that we will incorporate 
automated analysis in video reads this spring as part of a supervised annotation-qa/qc 
process.",,,,Department of Commerce,"Fast tracking the use of VIAME for automated identification of reef fish: 
We've been compiling image libraries for use in creating automated detection and 
classification models for use in automating the annotation process for the SEAMAP Reef 
Fish Video survey of the Gulf of Mexico. This work is being conducted in VIAME but we're 
looking at several other paths forward in the project to identify best performing models. 
Current status is that models are performing well enough that we will incorporate 
automated analysis in video reads this spring as part of a supervised annotation-qa/qc 
process.","Researchers are using VIAME to develop automated detection and classification models for the SEAMAP Reef Fish Video survey in the Gulf of Mexico. These models are performing well enough that they will be incorporated into the annotation process for video reads this spring, as part of a supervised quality control process.","Researchers are using VIAME to develop automated detection and classification models for the SEAMAP Reef Fish Video survey in the Gulf of Mexico. These models are performing well enough that they will be incorporated into the annotation process for video reads this spring, as part of a supervised quality control process.",,"Yes, the project described potentially poses a safety risk. This is because it involves the use of automated detection and classification models for video surveys in the Gulf of Mexico. While the project description does not directly mention any of the defined risks, it is possible that the project may indirectly impact areas such as environmental monitoring, resource management, or ecological conservation. These aspects can have safety implications for marine life, habitats, and the overall ecosystem. Therefore, further evaluation and assessment would be necessary to determine the specific safety risks associated with this project.",True,False
HHS-0121-2023,HHS,NIH,National Institutes of Health (NIH) NIEHS,Splunk IT System Monitoring Software,Utilizes machine learning to aggregate system logs from on-premises IT infrastructure systems and endpoints for auditing and cybersecurity monitoring purposes.,Operation and Maintenance,,,Department of Health and Human Services,"Splunk IT System Monitoring Software: 
Utilizes machine learning to aggregate system logs from on-premises IT infrastructure systems and endpoints for auditing and cybersecurity monitoring purposes.","Splunk IT System Monitoring Software is a powerful tool that utilizes machine learning to gather system logs from on-premises IT infrastructure systems and endpoints. It is specifically designed for auditing and cybersecurity monitoring purposes, providing comprehensive monitoring and analysis capabilities.","Splunk IT System Monitoring Software is a powerful tool that utilizes machine learning to gather system logs from on-premises IT infrastructure systems and endpoints. It is specifically designed for auditing and cybersecurity monitoring purposes, providing comprehensive monitoring and analysis capabilities.",,"Yes, the project described has the potential to be a safety risk. This is because it involves the collection and analysis of sensitive data related to individuals, such as surveillance, monitoring, and decision-making processes. These activities can potentially infringe on privacy rights, lead to biased decision-making, and have negative impacts on individuals' well-being. Additionally, the use of machine learning and AI technologies in such contexts may introduce errors, biases, or vulnerabilities that can further exacerbate safety risks. Therefore, careful consideration and safeguards should be implemented to mitigate these potential risks.",True,False
GSA-0006-2023,GSA,GSA IT (IC),,Document Workflow / Intelligent Data Capture and Extraction,"GSA is driving towards a more accurate and scalable document workflow platform. GSA seeks to intelligently capture, classify, and transfer critical data from unstructured and structured documents, namely PDF files, to the right process, workflow, or decision engine.",Operation and Maintenance,Intelligent Document Recognition (IDR); Optical Character Recognition (OCR); Intelligent Character Recognition (ICR); Optical Mark Reading (OMR); Barcode Recognition; Robotic Process Automation (RPA); API Automation; Machine Learning;,,U.S. General Services Administration,"Document Workflow / Intelligent Data Capture and Extraction: 
GSA is driving towards a more accurate and scalable document workflow platform. GSA seeks to intelligently capture, classify, and transfer critical data from unstructured and structured documents, namely PDF files, to the right process, workflow, or decision engine.","GSA aims to improve its document workflow platform by implementing intelligent data capture and extraction. This involves capturing and transferring important data from both structured and unstructured documents, such as PDF files, to the appropriate process, workflow, or decision engine.","GSA aims to improve its document workflow platform by implementing intelligent data capture and extraction. This involves capturing and transferring important data from both structured and unstructured documents, such as PDF files, to the appropriate process, workflow, or decision engine.",,"Yes, the project described has the potential to be a safety risk. The implementation of intelligent data capture and extraction in the document workflow platform could involve the processing and analysis of sensitive information across various domains, such as law enforcement, education, healthcare, and financial systems. This raises concerns about privacy, data security, and potential misuse of the captured information.

For example, if the project involves processing documents related to law enforcement or surveillance, there could be risks associated with decisions made based on the extracted data, such as determining parole, probation, or pretrial detention. Similarly, if the project involves processing medical or mental health-related documents, there could be risks associated with clinical diagnosis, treatment determination, or mental health status detection.

Additionally, the project may involve the use of biometrics or other means to access IT systems for government services, which raises concerns about privacy and potential misuse of personal information.

Overall, the project's potential impact on sensitive domains and the processing of personal data make it a potential safety risk that needs careful consideration and safeguards to mitigate any potential negative consequences.",True,False
HHS-0007-2023,HHS,ASPR,BARDA (CBRN),Burn & Blast MCMs: Philips,AI-based algorithms on Lumify handheld ultrasound system to detect traumatic injuries,Development and Acquisition,,,Department of Health and Human Services,"Burn & Blast MCMs: Philips: 
AI-based algorithms on Lumify handheld ultrasound system to detect traumatic injuries","Philips has developed AI-based algorithms for its Lumify handheld ultrasound system to detect traumatic injuries caused by burns and blasts. These algorithms utilize artificial intelligence to enhance the accuracy and efficiency of diagnosis, enabling healthcare professionals to quickly identify and treat these types of injuries.","Philips has developed AI-based algorithms for its Lumify handheld ultrasound system to detect traumatic injuries caused by burns and blasts. These algorithms utilize artificial intelligence to enhance the accuracy and efficiency of diagnosis, enabling healthcare professionals to quickly identify and treat these types of injuries.","Yes, the project described potentially poses a safety risk. The use of AI-based algorithms for diagnosing traumatic injuries caused by burns and blasts in healthcare settings involves the movement and application of physical force within a medical setting, which falls under the category of physical movements with potential safety risks. Additionally, the accuracy and efficiency of diagnosis are crucial in ensuring the prompt and appropriate treatment of these injuries, which further emphasizes the importance of safety in this project.",,False,True
HHS-0047-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),"Priority Score Timeliness - forecast the time needed to work on an alert produced by Fraud Prevention System (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression)","Inputs - Medicare Claims data, TPE Data, Jurisdiction information
Output -  forecast the time needed to work on an alert produced by FPS (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression)",Operation and Maintenance,,,Department of Health and Human Services,"Priority Score Timeliness - forecast the time needed to work on an alert produced by Fraud Prevention System (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression): 
Inputs - Medicare Claims data, TPE Data, Jurisdiction information
Output -  forecast the time needed to work on an alert produced by FPS (Random Forest, Decision Tree, Gradient Boost, Generalized Linear Regression)","The Priority Score Timeliness tool predicts the amount of time required to address alerts generated by the Fraud Prevention System, using various algorithms such as Random Forest, Decision Tree, Gradient Boost, and Generalized Linear Regression. The tool takes inputs such as Medicare Claims data, TPE Data, and Jurisdiction information, and outputs a forecasted time estimate for each alert.","The Priority Score Timeliness tool predicts the amount of time required to address alerts generated by the Fraud Prevention System, using various algorithms such as Random Forest, Decision Tree, Gradient Boost, and Generalized Linear Regression. The tool takes inputs such as Medicare Claims data, TPE Data, and Jurisdiction information, and outputs a forecasted time estimate for each alert.",,"Yes, the project described above is potentially a safety risk. The project involves the use of algorithms to predict the amount of time required to address alerts generated by the Fraud Prevention System. While the description does not explicitly mention any specific safety risks, the nature of the project suggests that it involves decision-making processes that could have significant consequences for individuals.

The project falls under category h, which includes loan-allocation processes, financial-system access determinations, credit scoring, and determining who is subject to a financial audit. These processes can have a direct impact on individuals' financial well-being and can potentially lead to financial hardship or discrimination if not implemented properly.

Additionally, the use of algorithms and data inputs such as Medicare Claims data raises concerns about privacy and data security. If the project mishandles sensitive personal information or makes inaccurate predictions, it could result in negative outcomes for individuals and potentially compromise their privacy and security.

Overall, the project's potential to make decisions that directly affect individuals' financial well-being and the potential risks associated with data privacy and accuracy make it a safety risk.",True,False
DHS-0033-2023,DHS,United States Citizenship and Immigration Services,,I-485 Family Matching,"I-485 Family Matching is designed to create models to match family members to underlying I-485 petitions. The underlying immigrant petition defines if the I-485 is employment-based or family-based. It also has information about the visa classification and priority date which, when compared against the Department of State’s monthly Visa Bulletin, helps predict visa usage. It is difficult to match an I-485 to its underlying immigrant petition, because the only available field on which to match is the A-number. This number is not always present on the immigrant petition, and name/date of birth matching is not as reliable. The goal of I-485 Family Matching is to leverage AI to more confidently create connections between petitioners and their families based on limited data.

Additionally, it will be able to help identify and group I485s filed by family members, as well as gather up the many ancillary forms they may have pending (such as I765, I131). Similar to immigrant petition matching, it can be difficult to match up I485s filed by family members. In these cases the only similar fields are a common address. Efforts have been made in the past to identify family members by address, but it is effective only to a point. The AI model will help make working with this data more reliable, as well as group individual petitioners, their families, and other helpful associated data together for faster and more accurate processing.",Development and Acquisition,"Machine Learning, Clustering, Regression",,Department of Homeland Security,"I-485 Family Matching: 
I-485 Family Matching is designed to create models to match family members to underlying I-485 petitions. The underlying immigrant petition defines if the I-485 is employment-based or family-based. It also has information about the visa classification and priority date which, when compared against the Department of State’s monthly Visa Bulletin, helps predict visa usage. It is difficult to match an I-485 to its underlying immigrant petition, because the only available field on which to match is the A-number. This number is not always present on the immigrant petition, and name/date of birth matching is not as reliable. The goal of I-485 Family Matching is to leverage AI to more confidently create connections between petitioners and their families based on limited data.

Additionally, it will be able to help identify and group I485s filed by family members, as well as gather up the many ancillary forms they may have pending (such as I765, I131). Similar to immigrant petition matching, it can be difficult to match up I485s filed by family members. In these cases the only similar fields are a common address. Efforts have been made in the past to identify family members by address, but it is effective only to a point. The AI model will help make working with this data more reliable, as well as group individual petitioners, their families, and other helpful associated data together for faster and more accurate processing.","The I-485 Family Matching system uses AI to create connections between family members and their underlying I-485 petitions, which determine if the petition is employment-based or family-based. This system helps predict visa usage by comparing the petition's visa classification and priority date with the Department of State's Visa Bulletin. It also aids in identifying and grouping I-485s filed by family members, even when the only available matching field is a common address. Overall, the goal is to improve the reliability and efficiency of processing this data.","The I-485 Family Matching system uses AI to create connections between family members and their underlying I-485 petitions, which determine if the petition is employment-based or family-based. This system helps predict visa usage by comparing the petition's visa classification and priority date with the Department of State's Visa Bulletin. It also aids in identifying and grouping I-485s filed by family members, even when the only available matching field is a common address. Overall, the goal is to improve the reliability and efficiency of processing this data.",,"Yes, the project described is potentially a safety risk. The project involves making decisions related to immigration processes, which can have significant consequences for individuals and their families. The use of AI in determining visa usage and grouping I-485s filed by family members raises concerns about potential errors, biases, or discriminatory outcomes. Any inaccuracies or biases in the system could result in unfair treatment, separation of families, or denial of visa applications. Therefore, there is a potential safety risk in terms of the impact on individuals' lives and well-being.",True,False
VA-0007-2023,VA,,,CuraPatient,"CuraPatient is a remote tool that allows patients to better manage their conditions without having to see a provider.  Driven by artificial intelligence, it allows patients to create a profile to track their health, enroll in programs, manage insurance, and schedule appointments.",,,,Department of Veterans Affairs,"CuraPatient: 
CuraPatient is a remote tool that allows patients to better manage their conditions without having to see a provider.  Driven by artificial intelligence, it allows patients to create a profile to track their health, enroll in programs, manage insurance, and schedule appointments.","CuraPatient is an AI-powered remote tool that enables patients to effectively manage their health conditions without the need for in-person medical appointments. It offers features like health tracking, program enrollment, insurance management, and appointment scheduling through a personalized patient profile.","CuraPatient is an AI-powered remote tool that enables patients to effectively manage their health conditions without the need for in-person medical appointments. It offers features like health tracking, program enrollment, insurance management, and appointment scheduling through a personalized patient profile.",,"Yes, the project described (CuraPatient) is potentially a safety risk. 

According to the defined risks, the project falls under category (g) which involves decisions regarding medical devices, clinical diagnosis, treatment, and health-risk assessments. As the AI-powered remote tool is responsible for managing patients' health conditions, it is involved in clinical diagnosis and determination of treatment. This introduces the potential risk of incorrect diagnoses or ineffective treatments, which could have serious consequences for patients' health and well-being. Additionally, if the tool is used to assess health-risk or flag patients for interventions, there is a risk of false positives or negatives, leading to inadequate or unnecessary interventions. These risks make the project potentially unsafe, as it directly impacts patients' health and medical decisions.",True,False
VA-0035-2023,VA,,,Extraction of family medical history from patient records,This pilot project uses TIU documentation on African American Veterans aged 45-50 to extract family medical history data and identify Veterans who are are at risk of prostate cancer but have not undergone prostate cancer screening.,,,,Department of Veterans Affairs,"Extraction of family medical history from patient records: 
This pilot project uses TIU documentation on African American Veterans aged 45-50 to extract family medical history data and identify Veterans who are are at risk of prostate cancer but have not undergone prostate cancer screening.",A pilot project is being conducted to extract family medical history data and identify African American Veterans aged 45-50 who are at risk of prostate cancer but have not undergone screening. This is done by analyzing TIU documentation from patient records.,A pilot project is being conducted to extract family medical history data and identify African American Veterans aged 45-50 who are at risk of prostate cancer but have not undergone screening. This is done by analyzing TIU documentation from patient records.,,"Yes, the project is potentially a safety risk. 

The project involves data extraction and analysis from patient records to identify individuals at risk of prostate cancer. While the intention behind the project may be to improve healthcare outcomes for African American Veterans, there are several potential safety risks involved.

Firstly, the project involves accessing and analyzing sensitive medical records. Any mishandling or unauthorized access of this data could lead to privacy breaches and potential harm to the individuals involved.

Secondly, the project focuses on identifying individuals who have not undergone screening for prostate cancer. It is essential to consider the potential psychological and emotional impact on these individuals if they are identified as being at risk. The project should have appropriate measures in place to ensure proper counseling and support are available to those affected.

Lastly, the project targets a specific racial group (African American Veterans) and age range (45-50). This targeted approach raises concerns about potential discrimination and bias in healthcare decision-making. It is crucial to ensure that the project does not perpetuate inequalities or lead to unequal access to healthcare services.

Overall, while the project aims to address a specific health concern, it must carefully consider and mitigate the potential risks involved to safeguard the privacy, mental well-being, and equitable treatment of the individuals involved.",True,False
DOE-0084-2023,DOE,National Energy Technology Laboratory,,To deploy dynamic neural network optimization to minimize heat rate during ramping for coal.,"The primary objective of the proposed work is to 1) deploy dynamic 
neural network optimization (D-NNO) to minimize heat rate during all 
phases of operation (ramping, low load, and high load) at a coal power 
plant. The project will build a high-fidelity, systems-level, dynamic model 
of the plant for a rapid prototyping environment for the D-NNO and to 
allow researchers to better understand the dynamic phenomena that 
occur during ramping and at various plant loads, and  Commercialize D-
NNO as a readily-available software application by working with an 
industry-proven software platform. The plant will be perturbed over time 
to allow machine learning (ML) models to be fitted to the plant’s 
response data.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To deploy dynamic neural network optimization to minimize heat rate during ramping for coal.: 
The primary objective of the proposed work is to 1) deploy dynamic 
neural network optimization (D-NNO) to minimize heat rate during all 
phases of operation (ramping, low load, and high load) at a coal power 
plant. The project will build a high-fidelity, systems-level, dynamic model 
of the plant for a rapid prototyping environment for the D-NNO and to 
allow researchers to better understand the dynamic phenomena that 
occur during ramping and at various plant loads, and  Commercialize D-
NNO as a readily-available software application by working with an 
industry-proven software platform. The plant will be perturbed over time 
to allow machine learning (ML) models to be fitted to the plant’s 
response data.","The proposed work aims to use dynamic neural network optimization (D-NNO) to minimize heat rate during all phases of operation at a coal power plant. This will be achieved by developing a dynamic model of the plant to better understand its behavior during ramping and different load conditions, and then using machine learning to fit models to the plant's response data. The ultimate goal is to commercialize D-NNO as a readily-available software application by collaborating with an industry-proven software platform.","The proposed work aims to use dynamic neural network optimization (D-NNO) to minimize heat rate during all phases of operation at a coal power plant. This will be achieved by developing a dynamic model of the plant to better understand its behavior during ramping and different load conditions, and then using machine learning to fit models to the plant's response data. The ultimate goal is to commercialize D-NNO as a readily-available software application by collaborating with an industry-proven software platform.","Yes, the project is potentially a safety risk. 
The project involves the design, construction, and testing of industrial equipment and systems, specifically in a coal power plant. If the project fails or if there are any issues with the dynamic neural network optimization, it could pose a meaningful risk to safety. Coal power plants have inherent risks related to fire safety systems, emissions, and environmental impact control processes. The project's focus on minimizing heat rate during all phases of operation also suggests potential risks in the management of industrial waste or pollutants. Therefore, the project falls under category h (design, construction, or testing of industrial equipment posing a risk to safety) and f (industrial emissions and environmental impact control processes), making it potentially a safety risk.",,False,True
DOI-0032-2023,DOI,USGS,,GEMSC Geospatial Modernization and Machine Learning Integration,"The USGS Director's office laid out a vision for the USGS for the next decade in the blog post “21st Century Science—Preparing for the Future”. A key component of this vision was outlined by stating “Over the next decade, we will take advantage of advances in sensor technologies, integrated modeling, artificial intelligence (AI), machine learning (ML), and high-performance computing to observe, understand, and project change across spatial and temporal scales in real-time and over the long term.” For GEMSC to play a role in this initiative, a multi-year project is proposed to integrate these technologies in GEMSC project workflows and data services. The overarching objective for this project is development of a strategic framework for integrating ERP science with traditional information technology related platforms.",Initiation,"Active learning, transfer learning, deep learing, convolutional neural networks (Fastern-RCNN, YOLOv5)",,Department of Interior,"GEMSC Geospatial Modernization and Machine Learning Integration: 
The USGS Director's office laid out a vision for the USGS for the next decade in the blog post “21st Century Science—Preparing for the Future”. A key component of this vision was outlined by stating “Over the next decade, we will take advantage of advances in sensor technologies, integrated modeling, artificial intelligence (AI), machine learning (ML), and high-performance computing to observe, understand, and project change across spatial and temporal scales in real-time and over the long term.” For GEMSC to play a role in this initiative, a multi-year project is proposed to integrate these technologies in GEMSC project workflows and data services. The overarching objective for this project is development of a strategic framework for integrating ERP science with traditional information technology related platforms.","The USGS has a vision for the next decade that includes using advanced technologies like sensor technologies, AI, ML, and high-performance computing to observe and understand change in real-time. The proposed GEMSC project aims to integrate these technologies into their workflows and data services to develop a strategic framework for combining science with IT platforms.","The USGS has a vision for the next decade that includes using advanced technologies like sensor technologies, AI, ML, and high-performance computing to observe and understand change in real-time. The proposed GEMSC project aims to integrate these technologies into their workflows and data services to develop a strategic framework for combining science with IT platforms.",,"Yes, the project described is potentially a safety risk. The project involves the use of advanced technologies like sensor technologies, AI, ML, and high-performance computing in the field of geosciences. While the project description does not explicitly mention any of the defined risks, it is possible that the integration of these technologies into the workflows and data services of the USGS could lead to unintended consequences.

For example, the use of AI and ML algorithms in analyzing geoscience data could result in inaccurate predictions or assessments, which may have implications for public safety. Additionally, the use of advanced technologies in real-time monitoring of geological changes could potentially lead to false alarms or missed warnings, impacting emergency response and public safety measures.

It is important for the project to have proper risk assessment and mitigation strategies in place to address these potential safety risks and ensure that the integration of advanced technologies does not compromise the well-being of individuals or communities.",True,False
HHS-0091-2023,HHS,FDA,CFSAN/OFAS,Emerging Chemical Hazard Intelligence Platform (ECHIP - completed),"This is an AI solution designed to identify emerging, potential chemical hazards or emerging stakeholder concerns regarding potential hazards associated with substances of interest to CFSAN. Implementation of this solution will enable CFSAN to take proactive measures to protect and/or address concerns from our stakeholders. ECHIP uses data from the news and social media, and the scientific literature to identify potential issues that may require CFSAN's attention. Real world examples without the ECHIP AI solution have taken 2-4 weeks for signal identification and verification depending on the number of scientists dedicated to reviewing the open literature, news and social media.  Results from pilot studies indicate that ECHIP could reduce the overall signal detection and validation process to about 2 hours. ECHIP accomplishes this reduction by automatically ingesting, reviewing, analyzing and presenting data from multiple sources to scientists in such a way that signal detection and verification can be done an a very short time period.",Operation and Maintenance,,,Department of Health and Human Services,"Emerging Chemical Hazard Intelligence Platform (ECHIP - completed): 
This is an AI solution designed to identify emerging, potential chemical hazards or emerging stakeholder concerns regarding potential hazards associated with substances of interest to CFSAN. Implementation of this solution will enable CFSAN to take proactive measures to protect and/or address concerns from our stakeholders. ECHIP uses data from the news and social media, and the scientific literature to identify potential issues that may require CFSAN's attention. Real world examples without the ECHIP AI solution have taken 2-4 weeks for signal identification and verification depending on the number of scientists dedicated to reviewing the open literature, news and social media.  Results from pilot studies indicate that ECHIP could reduce the overall signal detection and validation process to about 2 hours. ECHIP accomplishes this reduction by automatically ingesting, reviewing, analyzing and presenting data from multiple sources to scientists in such a way that signal detection and verification can be done an a very short time period.","The Emerging Chemical Hazard Intelligence Platform (ECHIP) is an AI solution that uses data from news, social media, and scientific literature to identify potential chemical hazards and stakeholder concerns. By automatically reviewing and analyzing data, ECHIP can significantly reduce the time it takes for signal detection and validation from weeks to just a few hours.","The Emerging Chemical Hazard Intelligence Platform (ECHIP) is an AI solution that uses data from news, social media, and scientific literature to identify potential chemical hazards and stakeholder concerns. By automatically reviewing and analyzing data, ECHIP can significantly reduce the time it takes for signal detection and validation from weeks to just a few hours.","Yes, the project is potentially a safety risk. According to the defined risks, the project falls under risk category f, which includes industrial emissions and environmental impact control processes. As the project involves the analysis of potential chemical hazards, there is a risk of mishandling hazardous chemicals or materials, which could lead to environmental pollution or harm to human health. Therefore, proper safety measures and protocols should be in place to mitigate these risks.",,False,True
DHS-0023-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Operational Activities Explorer,"Duty officers and analysts in CISA's Operations Center use a dashboard powered by artificial intelligence to enable sensemaking of ongoing operational activities. Artificial intelligence uses new near-real-time event data (from open source reporting, partner reporting, CISA regional staff, and cybersecurity sensors) coupled with historical cybersecurity and infrastructure security information and previous operational response activity to recommend courses-of-action and engagement strategies with other government entities and critical infrastructure owners and operators based on potential impacts to the National Critical Functions.",Initiation,"Natural Language Processing (NLP), Machine Learning, Visualization",,Department of Homeland Security,"Operational Activities Explorer: 
Duty officers and analysts in CISA's Operations Center use a dashboard powered by artificial intelligence to enable sensemaking of ongoing operational activities. Artificial intelligence uses new near-real-time event data (from open source reporting, partner reporting, CISA regional staff, and cybersecurity sensors) coupled with historical cybersecurity and infrastructure security information and previous operational response activity to recommend courses-of-action and engagement strategies with other government entities and critical infrastructure owners and operators based on potential impacts to the National Critical Functions.","The Operations Center at CISA utilizes a dashboard powered by artificial intelligence to make sense of ongoing operational activities. This AI system leverages real-time event data, historical cybersecurity information, and previous operational responses to suggest appropriate actions and engagement strategies with government entities and critical infrastructure owners and operators, considering the potential impact on National Critical Functions.","The Operations Center at CISA utilizes a dashboard powered by artificial intelligence to make sense of ongoing operational activities. This AI system leverages real-time event data, historical cybersecurity information, and previous operational responses to suggest appropriate actions and engagement strategies with government entities and critical infrastructure owners and operators, considering the potential impact on National Critical Functions.",,"Yes, the project described above has the potential to be a safety risk. This is because it involves decision-making processes that could impact various critical areas, such as law enforcement, surveillance, education, employment, healthcare, finance, government services, and child welfare. These decisions, which are influenced by artificial intelligence, have significant implications for individual rights, privacy, and potential biases. If not properly regulated and monitored, the AI system could lead to unfair or discriminatory outcomes, violation of civil liberties, or inaccurate assessments. Therefore, careful consideration and oversight are necessary to ensure the project does not pose safety risks.",True,False
DOE-0071-2023,DOE,National Energy Technology Laboratory,,To accelerate discovery of protection system and laser processing of protective coatings on CMC for hydrogen turbines.,"The objectives of this project are to design, process, and validate a 
laser-manufactured, integrated, and graded bond coat-environmental 
barrier coat-thermal barrier coat (BC-EBC-TBC) system that can 
effectively protect and lead to the use of Silicon Carbide fiber/Silicon 
Carbide (SiCf/SiC) matrix CMCs in next-generation hydrogen-fueled 
turbines.",,Artificial Intelligence Unknown,,Department of Energy,"To accelerate discovery of protection system and laser processing of protective coatings on CMC for hydrogen turbines.: 
The objectives of this project are to design, process, and validate a 
laser-manufactured, integrated, and graded bond coat-environmental 
barrier coat-thermal barrier coat (BC-EBC-TBC) system that can 
effectively protect and lead to the use of Silicon Carbide fiber/Silicon 
Carbide (SiCf/SiC) matrix CMCs in next-generation hydrogen-fueled 
turbines.",The goal of this project is to create a laser-manufactured protection system for hydrogen turbines that will allow for the use of Silicon Carbide fiber/Silicon Carbide (SiCf/SiC) matrix CMCs. This system will consist of a bond coat-environmental barrier coat-thermal barrier coat (BC-EBC-TBC) that effectively protects the CMCs.,The goal of this project is to create a laser-manufactured protection system for hydrogen turbines that will allow for the use of Silicon Carbide fiber/Silicon Carbide (SiCf/SiC) matrix CMCs. This system will consist of a bond coat-environmental barrier coat-thermal barrier coat (BC-EBC-TBC) that effectively protects the CMCs.,"Yes, this project potentially poses a safety risk. The project involves the design and development of a protection system for hydrogen turbines using laser-manufactured technology. Given that hydrogen turbines are involved, there is a potential risk of fire and explosion, which falls under the category of ""the functioning of dams, emergency services, electrical grids or the generation or movement of energy, fire safety systems."" Additionally, the project deals with hazardous chemicals and materials like Silicon Carbide fiber/Silicon Carbide (SiCf/SiC) matrix CMCs, which fall under the category of ""the transport, safety, design, or development of hazardous chemicals or biological entities or pathways."" Therefore, this project has the potential to be a safety risk.",,False,True
DHS-0017-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Automated Indicator Sharing (AIS) Automated PII Detection,"The Automated PII Detection and Human Review Process incorporates descriptive, predictive, and prescriptive analytics. Automated PII Detection leverages natural language processing (NLP) tasks including named entity recognition (NER) coupled with Privacy guidance thresholds to automatically detect potential PII from within AIS submissions. If submissions are flagged for possible PII, the submission will be queued for human review where the analysts will be provided with the submission and AI-assisted guidance to the specific PII concerns. Within Human Review, analysts are able to confirm/deny proper identification of PII and redact the information (if needed). Privacy experts are also able to review the actions of the system and analysts to ensure proper performance of the entire process along with providing feedback to the system and analysts for process improvements (if needed). The system learns from feedback from the analysts and Privacy experts. Through the incorporation of the automated PII detection, CISA fully compliances with Privacy, Civil Rights and Civil Liberties requirements of CISA 2015 and scaled analyst review of submissions by removing false positives and providing guidance to submission to be reviewed. Through continual audits CISA will maintain integrity and trust in system and human processes.",Operation and Maintenance,Natural Language Processing (NLP),,Department of Homeland Security,"Automated Indicator Sharing (AIS) Automated PII Detection: 
The Automated PII Detection and Human Review Process incorporates descriptive, predictive, and prescriptive analytics. Automated PII Detection leverages natural language processing (NLP) tasks including named entity recognition (NER) coupled with Privacy guidance thresholds to automatically detect potential PII from within AIS submissions. If submissions are flagged for possible PII, the submission will be queued for human review where the analysts will be provided with the submission and AI-assisted guidance to the specific PII concerns. Within Human Review, analysts are able to confirm/deny proper identification of PII and redact the information (if needed). Privacy experts are also able to review the actions of the system and analysts to ensure proper performance of the entire process along with providing feedback to the system and analysts for process improvements (if needed). The system learns from feedback from the analysts and Privacy experts. Through the incorporation of the automated PII detection, CISA fully compliances with Privacy, Civil Rights and Civil Liberties requirements of CISA 2015 and scaled analyst review of submissions by removing false positives and providing guidance to submission to be reviewed. Through continual audits CISA will maintain integrity and trust in system and human processes.","The Automated PII Detection and Human Review Process uses analytics and natural language processing to automatically detect potential personally identifiable information (PII) in submissions to Automated Indicator Sharing (AIS). If potential PII is detected, the submission is reviewed by analysts who can confirm or deny the identification of PII and redact the information if necessary. Privacy experts oversee the process and provide feedback for improvement, ensuring compliance with privacy requirements and maintaining the integrity and trust in the system.","The Automated PII Detection and Human Review Process uses analytics and natural language processing to automatically detect potential personally identifiable information (PII) in submissions to Automated Indicator Sharing (AIS). If potential PII is detected, the submission is reviewed by analysts who can confirm or deny the identification of PII and redact the information if necessary. Privacy experts oversee the process and provide feedback for improvement, ensuring compliance with privacy requirements and maintaining the integrity and trust in the system.",,"Yes, the project is potentially a safety risk. This is because it involves the detection and handling of personally identifiable information (PII), which is sensitive and can pose risks to individuals if mishandled or exposed. If the project fails to adequately detect and protect PII, it can lead to privacy breaches, identity theft, or other harmful consequences for individuals whose information is involved. Additionally, the project's use of analytics and natural language processing may introduce errors or biases in the identification and handling of PII, further increasing the safety risk.",True,False
DOE-0072-2023,DOE,National Energy Technology Laboratory,,To accurately predict alloy & component performance extrapolated to conditions where experimental results to do not exist.,"AI/ML will be used to  interrogate databases comprised of  experimental 
data,  literature data,  and  synthetic data generated improved physics 
based models  to generate reduced order models to accurate predict 
materials the performance of materials and components under extreme 
environments (temperature, atmosphere) and complex loading (cyclical, 
triaxial) for long service life durations.",,"Big Data, Other",,Department of Energy,"To accurately predict alloy & component performance extrapolated to conditions where experimental results to do not exist.: 
AI/ML will be used to  interrogate databases comprised of  experimental 
data,  literature data,  and  synthetic data generated improved physics 
based models  to generate reduced order models to accurate predict 
materials the performance of materials and components under extreme 
environments (temperature, atmosphere) and complex loading (cyclical, 
triaxial) for long service life durations.",AI/ML will use various databases and improved physics-based models to accurately predict the performance of alloys and components under extreme conditions and complex loading. This will be done by generating reduced order models and extrapolating results to conditions where experimental data is lacking.,AI/ML will use various databases and improved physics-based models to accurately predict the performance of alloys and components under extreme conditions and complex loading. This will be done by generating reduced order models and extrapolating results to conditions where experimental data is lacking.,"Yes, the project described potentially poses a safety risk. 

The project involves the design and development of materials and components, which could be used in various safety-critical applications such as dams, transportation systems, medical equipment, etc. If the predictions of the AI/ML models are inaccurate or unreliable, it could lead to the failure of these components under extreme conditions, posing a risk to safety. 

Furthermore, if the project involves the use or transportation of hazardous chemicals or materials, there could be safety risks associated with their handling, transport, and potential environmental impact. 

Therefore, the project's focus on accurately predicting the performance of alloys and components under extreme conditions and complex loading has the potential to impact safety, making it a potential safety risk.",,False,True
HHS-0140-2023,HHS,NIH,National Institutes of Health (NIH) OD/DPCPSI/OAR,HIV-related grant classifier tool,"A front-end application for scientific staff to input grant information which then runs an automated algorithm to classify HIV-related grants.  Additional features and technologies used include an interactive data visualization, such as a heat map, using Plotly Python library to display the confidence level of predicted grants. ",Implementation,,,Department of Health and Human Services,"HIV-related grant classifier tool: 
A front-end application for scientific staff to input grant information which then runs an automated algorithm to classify HIV-related grants.  Additional features and technologies used include an interactive data visualization, such as a heat map, using Plotly Python library to display the confidence level of predicted grants. ","The HIV-related grant classifier tool is a front-end application that allows scientific staff to input grant information and automatically classifies them using an algorithm. It also includes interactive data visualization, such as a heat map, to display the confidence level of predicted grants using the Plotly Python library.","The HIV-related grant classifier tool is a front-end application that allows scientific staff to input grant information and automatically classifies them using an algorithm. It also includes interactive data visualization, such as a heat map, to display the confidence level of predicted grants using the Plotly Python library.",,"Yes, the project described is potentially a safety risk. While the project itself does not involve any directly harmful activities, it falls under the category of ""determining access to or eligibility for government benefits or services"" (j) which can have significant implications for individuals. If the algorithm used in the grant classifier tool is flawed or biased, it could lead to unfair distribution of resources or discrimination against certain individuals or communities. This could have negative impacts on the welfare and well-being of people affected by HIV. Therefore, careful consideration and assessment of the algorithm's accuracy and fairness is necessary to mitigate potential safety risks.",True,False
NARA-0004-2023,NARA,NGC FOIA Office,,Freedom of Information Act (FOIA) Discovery AI Pilot,"NARA would like to utilize various AI techniques to respond to FOIA requests. The AI system will do two things. First, the AI system would offer an NLP based search technique based on the content similarity between the query and the content of the records. The second main AI application would be to redact based on the nature of the FOIA request. Most of the time, the personal information is redacted, but additional information would also need to be redacted based on the requester.  ",Planned (not in production),AI based Vector search or Content similarity search.,,National Archives and Records Administration,"Freedom of Information Act (FOIA) Discovery AI Pilot: 
NARA would like to utilize various AI techniques to respond to FOIA requests. The AI system will do two things. First, the AI system would offer an NLP based search technique based on the content similarity between the query and the content of the records. The second main AI application would be to redact based on the nature of the FOIA request. Most of the time, the personal information is redacted, but additional information would also need to be redacted based on the requester.  ",The Freedom of Information Act (FOIA) Discovery AI Pilot aims to use AI techniques to improve the response to FOIA requests. The AI system will provide a search technique based on content similarity and redact personal information and additional details based on the nature of the request and the requester.,The Freedom of Information Act (FOIA) Discovery AI Pilot aims to use AI techniques to improve the response to FOIA requests. The AI system will provide a search technique based on content similarity and redact personal information and additional details based on the nature of the request and the requester.,,"Yes, the project is potentially a safety risk. The project involves making decisions about the redaction and disclosure of information based on AI techniques. These decisions can have significant implications for individual privacy and potentially infringe on protected speech. Additionally, the project involves handling personal information and determining what information should be redacted, which can also raise concerns about data protection and potential misuse of personal information. Therefore, careful consideration should be given to ensure that the AI system does not violate privacy rights or discriminate against certain individuals or groups.",True,False
HHS-0077-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Augmenting date and cause of death ascertainment in observational data sources,"The objective of this project is to develop a set of algorithms to augment assessment of mortality through probabilistic linkage of alternative data sources with EHRs. Development of generalizable approaches to improve death ascertainment is critical to improve validity of Sentinel investigations using mortality as an endpoint, and these algorithms may also be usable in supplementing death ascertainment in claims data as well. Specifically, we propose the following Aims.
Specific Aim 1: We propose to leverage online publicly available data to detect date of death for patients seen at two healthcare systems.
Specific Aim 2: We propose to augment cause of death data using healthcare system narrative text and administrative codes to develop probabilistic estimates for common causes of death",Implementation,,,Department of Health and Human Services,"Augmenting date and cause of death ascertainment in observational data sources: 
The objective of this project is to develop a set of algorithms to augment assessment of mortality through probabilistic linkage of alternative data sources with EHRs. Development of generalizable approaches to improve death ascertainment is critical to improve validity of Sentinel investigations using mortality as an endpoint, and these algorithms may also be usable in supplementing death ascertainment in claims data as well. Specifically, we propose the following Aims.
Specific Aim 1: We propose to leverage online publicly available data to detect date of death for patients seen at two healthcare systems.
Specific Aim 2: We propose to augment cause of death data using healthcare system narrative text and administrative codes to develop probabilistic estimates for common causes of death",The objective of this project is to develop algorithms that can improve the assessment of mortality in observational data sources by linking them with electronic health records (EHRs). This is important for ensuring the accuracy of investigations using mortality as an endpoint. The algorithms developed can also be used to supplement death ascertainment in claims data and can detect the date of death and estimate the cause of death using publicly available data and healthcare system information.,The objective of this project is to develop algorithms that can improve the assessment of mortality in observational data sources by linking them with electronic health records (EHRs). This is important for ensuring the accuracy of investigations using mortality as an endpoint. The algorithms developed can also be used to supplement death ascertainment in claims data and can detect the date of death and estimate the cause of death using publicly available data and healthcare system information.,,"Yes, the project described above potentially poses a safety risk. The project involves developing algorithms to assess mortality in observational data sources by linking them with electronic health records (EHRs). While the objective of improving mortality assessment is important for accurate investigations, the potential risks arise from the use of publicly available data and healthcare system information to detect the date and cause of death.

This project could potentially infringe on privacy and confidentiality concerns as it involves accessing and analyzing personal health information. The use of such data without proper safeguards or consent could lead to unauthorized access, misuse, or disclosure of sensitive medical information.

Additionally, if the algorithms used in this project are not accurate or reliable, there is a risk of incorrect determinations of mortality and cause of death. This could have serious implications for individuals and their families, leading to incorrect medical diagnoses, treatment plans, or even potentially impacting insurance coverage.

Therefore, due to the potential privacy concerns and the risk of incorrect determinations, this project should be considered a safety risk and appropriate measures should be implemented to mitigate these risks.",True,False
HHS-0052-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Federally Facilitated Marketplaces (FFM),FFM AI for Anomaly Detection and Correction| Classification| Forecasting and Predicting Time Series,Initiation,,,Department of Health and Human Services,"Federally Facilitated Marketplaces (FFM): 
FFM AI for Anomaly Detection and Correction| Classification| Forecasting and Predicting Time Series","The Federally Facilitated Marketplaces (FFM) utilize artificial intelligence (AI) for various tasks including anomaly detection and correction, classification, and forecasting and predicting time series data. This technology helps improve the efficiency and accuracy of the FFM operations and decision-making processes.","The Federally Facilitated Marketplaces (FFM) utilize artificial intelligence (AI) for various tasks including anomaly detection and correction, classification, and forecasting and predicting time series data. This technology helps improve the efficiency and accuracy of the FFM operations and decision-making processes.",,"Yes, the project described above is potentially a safety risk. The inclusion of artificial intelligence (AI) in the Federally Facilitated Marketplaces (FFM) introduces several potential risks.

First, the use of AI for decision-making processes, such as anomaly detection and correction, classification, and forecasting, can lead to biased or unfair outcomes. If the AI algorithms are not properly trained or if there is inherent bias in the data used for training, it can result in discriminatory decisions that may negatively impact individuals.

Second, the project involves the handling of sensitive personal data, such as medical and financial information, which raises concerns about data privacy and security. If the AI systems are not adequately protected from cyber threats or if there are vulnerabilities in the technology, it could lead to unauthorized access or misuse of personal information.

Additionally, the reliance on AI for critical tasks in the FFM operations introduces the risk of technical failures or errors. If the AI algorithms are not properly calibrated or if there are bugs in the system, it can result in incorrect decisions or inaccurate predictions, potentially leading to financial losses or harm to individuals.

Overall, the combination of decision-making power, handling of sensitive data, and potential technical failures makes the project a safety risk that requires careful consideration and mitigation strategies to ensure the protection of individuals and their rights.",True,False
DOE-0132-2023,DOE,National Energy Technology Laboratory,,To provide natural gas leak detection and quality control,"Employing machine learning techniques to train sensing systems to 
quantify the concentration of natural gas species, distinguish between 
natural gas at different parts of the processing pipeline, and distinguish 
natural gas from natural and man-made interfering sources such as 
wetlands and agriculture.",,Artificial Intelligence Unknown,,Department of Energy,"To provide natural gas leak detection and quality control: 
Employing machine learning techniques to train sensing systems to 
quantify the concentration of natural gas species, distinguish between 
natural gas at different parts of the processing pipeline, and distinguish 
natural gas from natural and man-made interfering sources such as 
wetlands and agriculture.",Machine learning techniques are being used to train sensing systems in order to detect and measure the concentration of natural gas species. These systems can also differentiate between natural gas at various stages of the processing pipeline and distinguish it from other sources such as wetlands and agriculture.,Machine learning techniques are being used to train sensing systems in order to detect and measure the concentration of natural gas species. These systems can also differentiate between natural gas at various stages of the processing pipeline and distinguish it from other sources such as wetlands and agriculture.,"Yes, the project is potentially a safety risk. The project involves the use of machine learning techniques to train sensing systems for detecting and measuring the concentration of natural gas species. Natural gas is a hazardous substance that can pose risks such as leaks, explosions, and asphyxiation. If the sensing systems fail to accurately detect or measure the concentration of natural gas, it could lead to safety hazards and potential accidents. Therefore, the project falls under the category of ""the design, construction, or testing of industrial equipment, systems, or structures that, if they failed, would pose a meaningful risk to safety"" (risk category h).",,False,True
VA-0004-2023,VA,,,Assessing lung function in health and disease,Health professionals can use this artificial intelligence to determine predictors of normal and abnormal lung function and sleep parameters.,,,,Department of Veterans Affairs,"Assessing lung function in health and disease: 
Health professionals can use this artificial intelligence to determine predictors of normal and abnormal lung function and sleep parameters.","Artificial intelligence can assist health professionals in evaluating lung function and sleep parameters, enabling them to identify factors that indicate normal or abnormal lung function. This technology aids in assessing respiratory health and can provide valuable insights for diagnosing and monitoring lung diseases.","Artificial intelligence can assist health professionals in evaluating lung function and sleep parameters, enabling them to identify factors that indicate normal or abnormal lung function. This technology aids in assessing respiratory health and can provide valuable insights for diagnosing and monitoring lung diseases.",,"Yes, the project described potentially poses a safety risk. 

The project involves the use of artificial intelligence to evaluate lung function and sleep parameters. While this technology can provide valuable insights for diagnosing and monitoring lung diseases, it falls under the category of ""decisions regarding medical devices, medical diagnostic tools, clinical diagnosis and determination of treatment, medical or insurance health-risk assessments."" 

Any decision or recommendation related to medical diagnosis and treatment carries inherent safety risks. If the artificial intelligence system provides inaccurate or misleading assessments, it could lead to incorrect diagnoses or inappropriate treatments, potentially endangering the health and well-being of patients. Therefore, careful validation and oversight are necessary to mitigate these safety risks.",True,False
VA-0020-2023,VA,,,SoKat Suicidial Ideation Detection Engine,The SoKat Suicide Ideation Engine (SSIE) uses natural language processing (NLP) to improve identification of Veteran suicide ideation (SI) from survey data collected by the Office of Mental Health (OMH) Veteran Crisis Line (VCL) support team (VSignals).,,,,Department of Veterans Affairs,"SoKat Suicidial Ideation Detection Engine: 
The SoKat Suicide Ideation Engine (SSIE) uses natural language processing (NLP) to improve identification of Veteran suicide ideation (SI) from survey data collected by the Office of Mental Health (OMH) Veteran Crisis Line (VCL) support team (VSignals).",The SoKat Suicide Ideation Engine (SSIE) utilizes natural language processing (NLP) to enhance the identification of suicide ideation among veterans. It analyzes survey data gathered by the Office of Mental Health (OMH) Veteran Crisis Line (VCL) support team called VSignals.,The SoKat Suicide Ideation Engine (SSIE) utilizes natural language processing (NLP) to enhance the identification of suicide ideation among veterans. It analyzes survey data gathered by the Office of Mental Health (OMH) Veteran Crisis Line (VCL) support team called VSignals.,,"Yes, the project is potentially a safety risk. The project involves the use of personal data and analysis of mental health information of veterans. This can be considered a safety risk because it involves making decisions related to mental health status detection or prevention, which falls under the category of potentially impacting individuals' well-being and access to mental health services. There is a risk of misinterpretation or mishandling of the data, leading to incorrect assessments or inappropriate interventions. Additionally, if the project is not implemented with proper privacy and security measures, there is a risk of unauthorized access to sensitive information, potentially causing harm to the individuals involved.",True,False
NASA-0014-2023,NASA,Jet Propulsion Laboratory,,Mexec Onboard Planning and Execution,"MEXEC is a lightweight, multi-mission software for activity scheduling and execution developed to increase the
autonomy and efficiency of a robotic explorer. MEXEC was first created as a prototype demonstration for the
Europa Clipper project as a potential solution to fail-operational requirements. Specifically, the Europa project is
concerned with the radiation environment around Jupiter which can trigger on-board computer resets at critical
times of the mission (e.g. during Europa flybys). If a CPU reset occurs, flight software must bring the spacecraft back
to a safe state and resume science operations as quickly as possible to minimize science loss. The MEXEC prototype
flight software was developed to provide such a capability using proven AI planning, scheduling, and execution
technologies. Instead of command sequences, MEXEC works with task networks, which include abstract
representations of command behavior, constraints on timing, and resources required and/or consumed by the
behavior. Using this knowledge on-board, MEXEC can monitor command behavior and react to off-nominal
outcomes (e.g. CPU reset), reconstructing command sequences to continue spacecraft operations without
jeopardizing spacecraft safety.",In-use,,,National Aeronautics and Space Administration,"Mexec Onboard Planning and Execution: 
MEXEC is a lightweight, multi-mission software for activity scheduling and execution developed to increase the
autonomy and efficiency of a robotic explorer. MEXEC was first created as a prototype demonstration for the
Europa Clipper project as a potential solution to fail-operational requirements. Specifically, the Europa project is
concerned with the radiation environment around Jupiter which can trigger on-board computer resets at critical
times of the mission (e.g. during Europa flybys). If a CPU reset occurs, flight software must bring the spacecraft back
to a safe state and resume science operations as quickly as possible to minimize science loss. The MEXEC prototype
flight software was developed to provide such a capability using proven AI planning, scheduling, and execution
technologies. Instead of command sequences, MEXEC works with task networks, which include abstract
representations of command behavior, constraints on timing, and resources required and/or consumed by the
behavior. Using this knowledge on-board, MEXEC can monitor command behavior and react to off-nominal
outcomes (e.g. CPU reset), reconstructing command sequences to continue spacecraft operations without
jeopardizing spacecraft safety.","MEXEC is a software designed to enhance the autonomy and efficiency of robotic explorers by scheduling and executing activities. It was developed as a solution to the fail-operational requirements of the Europa Clipper project, specifically addressing issues caused by the radiation environment around Jupiter. The software uses AI planning, scheduling, and execution technologies to monitor and react to unexpected events, reconstructing command sequences to ensure the safety of the spacecraft while minimizing science loss.","MEXEC is a software designed to enhance the autonomy and efficiency of robotic explorers by scheduling and executing activities. It was developed as a solution to the fail-operational requirements of the Europa Clipper project, specifically addressing issues caused by the radiation environment around Jupiter. The software uses AI planning, scheduling, and execution technologies to monitor and react to unexpected events, reconstructing command sequences to ensure the safety of the spacecraft while minimizing science loss.","Yes, the project described potentially poses a safety risk. This is because it involves the functioning and movement of robotic explorers in a radiation environment around Jupiter. The project's goal is to enhance the autonomy and efficiency of these explorers, which implies that they will be operating without direct human control. If there are any unexpected events or failures in the software, it could lead to the spacecraft's safety being compromised, potentially resulting in damage or loss of the spacecraft. Therefore, due to the potential risks associated with the movement and operation of the robotic explorers, this project is considered a safety risk.",,False,True
HHS-0042-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Feedback Analysis Solution (FAS),"The Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to review public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural Language Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review process. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted dataset.  ",Operation and Maintenance,,,Department of Health and Human Services,"Feedback Analysis Solution (FAS): 
The Feedback Analysis Solution is a system that uses CMS or other publicly available data (such as Regulations.Gov) to review public comments and/or analyze other information from internal and external stakeholders. The FAS uses Natural Language Processing (NLP) tools to aggregate, sort and identify duplicates to create efficiencies in the comment review process. FAS also uses machine learning (ML) tools to identify topics, themes and sentiment outputs for the targeted dataset.  ","The Feedback Analysis Solution (FAS) is a system that uses publicly available data to analyze public comments and other information from stakeholders. It utilizes Natural Language Processing (NLP) and machine learning (ML) tools to aggregate, sort, identify duplicates, and extract topics, themes, and sentiment from the dataset, streamlining the comment review process.","The Feedback Analysis Solution (FAS) is a system that uses publicly available data to analyze public comments and other information from stakeholders. It utilizes Natural Language Processing (NLP) and machine learning (ML) tools to aggregate, sort, identify duplicates, and extract topics, themes, and sentiment from the dataset, streamlining the comment review process.",,"Yes, the project described above is potentially a safety risk. This is because it falls under the category of ""social media monitoring"" and involves analyzing public comments and other information from stakeholders. Social media monitoring can potentially violate privacy rights and lead to the misuse of personal data. Additionally, the use of Natural Language Processing (NLP) and machine learning (ML) tools to extract topics, themes, and sentiment from the dataset can result in biased or inaccurate analysis, which could have negative consequences for individuals or groups. Therefore, the project poses potential safety risks in terms of privacy infringement and the potential for biased or inaccurate analysis.",True,False
DOE-0094-2023,DOE,National Energy Technology Laboratory,,To develop an Artificial intelligence- based model for rotating detonation engine designs,"An artificial intelligence-based model will be used to develop low-loss 
rotating detonation engine (RDE) designs for use in power generation 
using natural gas/syngas mixtures. The model formulation will enable full-
scale RDE calculations over 100-1000 detonation cycles.",,Artificial Intelligence Unknown,,Department of Energy,"To develop an Artificial intelligence- based model for rotating detonation engine designs: 
An artificial intelligence-based model will be used to develop low-loss 
rotating detonation engine (RDE) designs for use in power generation 
using natural gas/syngas mixtures. The model formulation will enable full-
scale RDE calculations over 100-1000 detonation cycles.",An artificial intelligence model will be created to design low-loss rotating detonation engines for power generation using natural gas/syngas mixtures. This model will allow for full-scale calculations of the engine over 100-1000 detonation cycles.,An artificial intelligence model will be created to design low-loss rotating detonation engines for power generation using natural gas/syngas mixtures. This model will allow for full-scale calculations of the engine over 100-1000 detonation cycles.,"Yes, the project described potentially poses safety risks. 

The project involves the design of low-loss rotating detonation engines for power generation using natural gas/syngas mixtures. This falls under the category of ""The functioning of dams, emergency services, electrical grids or the generation or movement of energy"" mentioned in the safety risks. 

The project involves the development and testing of industrial equipment and systems which, if they were to fail, could pose a meaningful risk to safety. Additionally, the design, construction, and testing of engines that use potentially hazardous materials like natural gas and syngas also adds to the safety concerns. 

Therefore, due to the potential risks associated with the development and testing of the engine, this project is potentially a safety risk.",,False,True
VA-0014-2023,VA,,,Precision medicine PTSD and suicidality diagnostic and predictive tool,"This model interprets various real time inputs in a diagnostic and predictive capacity in order to forewarn episodes of PTSD and suicidality, support early and accurate diagnosis of the same, and gain a better understanding of the short and long term effects of stress, especially in extreme situations, as it relates to the onset of PTSD.",,,,Department of Veterans Affairs,"Precision medicine PTSD and suicidality diagnostic and predictive tool: 
This model interprets various real time inputs in a diagnostic and predictive capacity in order to forewarn episodes of PTSD and suicidality, support early and accurate diagnosis of the same, and gain a better understanding of the short and long term effects of stress, especially in extreme situations, as it relates to the onset of PTSD.","The Precision Medicine PTSD and Suicidality Diagnostic and Predictive Tool uses real-time data to analyze and predict episodes of PTSD and suicidality. It helps diagnose these conditions early and accurately, while also providing insights into the effects of stress on the development of PTSD, particularly in extreme situations.","The Precision Medicine PTSD and Suicidality Diagnostic and Predictive Tool uses real-time data to analyze and predict episodes of PTSD and suicidality. It helps diagnose these conditions early and accurately, while also providing insights into the effects of stress on the development of PTSD, particularly in extreme situations.",,"Yes, the project is potentially a safety risk. The project involves making decisions related to mental health status detection or prevention, which falls under category g. These decisions can have significant consequences on an individual's well-being and may involve interventions or treatments. If the predictive tool is not accurate or reliable, it could lead to misdiagnosis or inappropriate interventions, potentially putting individuals at risk. Therefore, careful consideration and validation of the tool's effectiveness and safety measures are necessary to minimize potential harm.",True,False
DOE-0158-2023,DOE,"Office of Environment, Health, Safety & Security",,"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data: Classification, Robotic Process Automation and Data Visualization","""The EHSS Data Analytics Machine Learning (DAMaL) tools, 
classification, robotic process automation and data visualization tool, 
uses natural language processing (NLP) and classification algorithms 
(i.e., random forests) to automate the classification of records, visually 
provide insights in the trends and provide an indication of importance 
and risk.   The tool leverages artificial intelligence (AI) to analyze the text 
of the DOE environment, safety, and health (ES&H) and operating 
experience dataset records (e.g., occurrence reporting and processing 
system, fire protection, lessons learned, accident and injury reporting 
system, contractor assurance system CAS) and identifies important 
topics that can be used by an analyst to drill down and further explore 
potential safety issues in the DOE operations.
As of October 2021, the tool has been deployed in the DAMaL tools 
website.  Expected to continue to maintain, develop documentation 
(e.g., users analysis guides), improve and enhance, and increase data 
sources.",,,,Department of Energy,"Data Analytics and Machine Learning (DAMaL) Tools to enhance the analysis of Environment, Safety and Health (ES&H) data: Classification, Robotic Process Automation and Data Visualization: 
""The EHSS Data Analytics Machine Learning (DAMaL) tools, 
classification, robotic process automation and data visualization tool, 
uses natural language processing (NLP) and classification algorithms 
(i.e., random forests) to automate the classification of records, visually 
provide insights in the trends and provide an indication of importance 
and risk.   The tool leverages artificial intelligence (AI) to analyze the text 
of the DOE environment, safety, and health (ES&H) and operating 
experience dataset records (e.g., occurrence reporting and processing 
system, fire protection, lessons learned, accident and injury reporting 
system, contractor assurance system CAS) and identifies important 
topics that can be used by an analyst to drill down and further explore 
potential safety issues in the DOE operations.
As of October 2021, the tool has been deployed in the DAMaL tools 
website.  Expected to continue to maintain, develop documentation 
(e.g., users analysis guides), improve and enhance, and increase data 
sources.","The EHSS DAMaL tools use classification, robotic process automation, and data visualization to automate the analysis of ES&H data. By leveraging AI and NLP, the tools analyze DOE records and identify important topics for further exploration, helping analysts uncover potential safety issues in DOE operations. The tools have been deployed on the DAMaL website and are expected to be continuously maintained, documented, improved, and expanded with more data sources.","The EHSS DAMaL tools use classification, robotic process automation, and data visualization to automate the analysis of ES&H data. By leveraging AI and NLP, the tools analyze DOE records and identify important topics for further exploration, helping analysts uncover potential safety issues in DOE operations. The tools have been deployed on the DAMaL website and are expected to be continuously maintained, documented, improved, and expanded with more data sources.","Yes, the project described potentially has safety risks. The project involves the analysis of ES&H (Environment, Safety, and Health) data from the Department of Energy (DOE) operations. The functioning and safety of energy generation, movement, and storage systems are included in the list of safety risks provided. Therefore, the potential safety risks associated with the project include the functioning of electrical grids, the generation or movement of energy, and the integrity of nuclear reactors, materials, and waste.

Additionally, the project involves the use of robotics and automation within various settings such as workplaces, schools, transportation, and law enforcement. This falls under the category of physical movements and human-robot teaming, which is also listed as a safety risk. Therefore, the potential safety risks associated with the project also include the movements of robotic appendages or bodies within these settings.

Overall, the project's involvement with energy systems, robotics, and automation in various settings makes it potentially a safety risk.",,False,True
DOE-0075-2023,DOE,National Energy Technology Laboratory,,To apply machine learning and data analytics techniques to integrated subsurface datasets to predict key reservoir properties and compare various fields across the area of study and to correlate vintage data with new data and address the distribution of fractures and vugs.,"Laboratory experiments will be used to optimize a CO2 flood 
composition specific to HTD rock properties, and subsequently design 
and simulate injection scenarios that offer wettability alteration, foaming, 
and reduced surface tension. This work will improve oil recovery from 
matrix porosity and mitigate the impact of fracture zones. The optimized 
design will be implemented and tested in a Trenton/Black River field. 
The results will provide strategies to improve oil recovery in complex 
carbonate formations in the Michigan Basin as well as in other 
carbonate plays.",,"Artificial Intelligence, Big Data",,Department of Energy,"To apply machine learning and data analytics techniques to integrated subsurface datasets to predict key reservoir properties and compare various fields across the area of study and to correlate vintage data with new data and address the distribution of fractures and vugs.: 
Laboratory experiments will be used to optimize a CO2 flood 
composition specific to HTD rock properties, and subsequently design 
and simulate injection scenarios that offer wettability alteration, foaming, 
and reduced surface tension. This work will improve oil recovery from 
matrix porosity and mitigate the impact of fracture zones. The optimized 
design will be implemented and tested in a Trenton/Black River field. 
The results will provide strategies to improve oil recovery in complex 
carbonate formations in the Michigan Basin as well as in other 
carbonate plays.","The text describes a project that aims to use machine learning and data analytics to predict reservoir properties and compare different fields in a study area. Additionally, laboratory experiments will be conducted to optimize a CO2 flood composition for specific rock properties and improve oil recovery in carbonate formations. The results of the project will provide strategies for improving oil recovery in the Michigan Basin and other carbonate plays.","The text describes a project that aims to use machine learning and data analytics to predict reservoir properties and compare different fields in a study area. Additionally, laboratory experiments will be conducted to optimize a CO2 flood composition for specific rock properties and improve oil recovery in carbonate formations. The results of the project will provide strategies for improving oil recovery in the Michigan Basin and other carbonate plays.","Yes, the project is potentially a safety risk. 

The project involves conducting laboratory experiments to optimize a CO2 flood composition for specific rock properties and improve oil recovery in carbonate formations. This process may involve the transport, safety, design, or development of hazardous chemicals or biological entities or pathways, which falls under the category of safety risks listed. If not properly managed, the handling and transportation of hazardous chemicals can pose risks to the environment and human health. Additionally, the project's aim to improve oil recovery in the Michigan Basin and other carbonate plays may have environmental impact control processes, which also falls under the safety risks category. Therefore, the project has the potential to pose safety risks if not carefully managed.",,False,True
DOE-0175-2023,DOE,Pacific Northwest National Laboratory,,Surrogate models for probabilistic Bayesian inference,"We are using AI/ML to build surrogate models of the observable 
response of complex physical systems. These surrogate models will be 
used for probabilistic model inversion of these systems with the goal of 
estimating unknown model parameters from indirect observations.",,,,Department of Energy,"Surrogate models for probabilistic Bayesian inference: 
We are using AI/ML to build surrogate models of the observable 
response of complex physical systems. These surrogate models will be 
used for probabilistic model inversion of these systems with the goal of 
estimating unknown model parameters from indirect observations.",The text explains that AI/ML technologies are being employed to create surrogate models of complex physical systems. These surrogate models will enable the estimation of unknown model parameters by utilizing probabilistic model inversion based on indirect observations.,The text explains that AI/ML technologies are being employed to create surrogate models of complex physical systems. These surrogate models will enable the estimation of unknown model parameters by utilizing probabilistic model inversion based on indirect observations.,"Yes, the project could potentially be a safety risk. According to the defined risks, the project falls under category a, which includes the functioning of electrical grids or the generation of energy. If the surrogate models created by AI/ML technologies are used to estimate unknown model parameters for such systems and the estimations are incorrect or lead to faulty functioning, it could pose a meaningful risk to safety.",,False,True
USAID-0002-2023,USAID,"Bureau for Development, Democracy, and Innovation (DDI)",,Machine Learning for Peace,"Objective 1 under the Illuminating New Solutions and Programmatic Innovations for Resilient Spaces’ (INSPIRES). Includes program activities
and website - https://web.sas.upenn.edu/mlp-devlab/",Development and Acquisition,,,U.S. Agency for International Development,"Machine Learning for Peace: 
Objective 1 under the Illuminating New Solutions and Programmatic Innovations for Resilient Spaces’ (INSPIRES). Includes program activities
and website - https://web.sas.upenn.edu/mlp-devlab/",Machine Learning for Peace is an initiative that falls under the INSPIRES program. It aims to develop new solutions and programmatic innovations for creating resilient spaces. More information about the program and its activities can be found on its website at https://web.sas.upenn.edu/mlp-devlab/.,Machine Learning for Peace is an initiative that falls under the INSPIRES program. It aims to develop new solutions and programmatic innovations for creating resilient spaces. More information about the program and its activities can be found on its website at https://web.sas.upenn.edu/mlp-devlab/.,,"Yes, the project described potentially poses a safety risk. This is because the project involves the use of machine learning in various domains that have the potential to impact individuals' rights, privacy, and well-being. For example, the project mentions activities such as law enforcement or surveillance-related risk assessments, facial recognition, social media monitoring, and determining access to government benefits or services.

These applications can raise concerns about the misuse of personal data, violation of privacy rights, and potential biases or discrimination in decision-making processes. Without adequate safeguards and ethical considerations, the use of machine learning in these areas can lead to unintended consequences and harm to individuals or communities.

Therefore, it is important to carefully assess and address the potential safety risks associated with the project, ensuring that appropriate measures are in place to protect individuals' rights and well-being.",True,False
HHS-0038-2023,HHS,CDC,NCHS,Named Entity Recognition for Opioid Use in Free Text Clinical Notes from Electronic Health Records,A team of scientists participating in CDC's Data Science Upskilling Program are developing an NLP Named Entity Recognition model to detect the assertion or negation of opioid use in electronic medical records from the National Hospital Care Survey,Development and Acquisition,,,Department of Health and Human Services,"Named Entity Recognition for Opioid Use in Free Text Clinical Notes from Electronic Health Records: 
A team of scientists participating in CDC's Data Science Upskilling Program are developing an NLP Named Entity Recognition model to detect the assertion or negation of opioid use in electronic medical records from the National Hospital Care Survey",A team of scientists is working on a Named Entity Recognition model to identify the presence or absence of opioid use in electronic medical records. This model is being developed as part of the CDC's Data Science Upskilling Program and aims to improve the detection of opioid use in the National Hospital Care Survey.,A team of scientists is working on a Named Entity Recognition model to identify the presence or absence of opioid use in electronic medical records. This model is being developed as part of the CDC's Data Science Upskilling Program and aims to improve the detection of opioid use in the National Hospital Care Survey.,,"Yes, the project is potentially a safety risk. This is because it falls under the category of ""Decisions regarding medical devices, medical diagnostic tools, clinical diagnosis and determination of treatment, medical or insurance health-risk assessments, drug-addiction risk assessments and associated access systems, suicide or other violence risk assessment, or mental-health status detection or prevention, systems that flag patients for interventions, public insurance care-allocation systems, or health-insurance cost and underwriting processes"" as mentioned in the defined risks.

The use of the Named Entity Recognition model to identify opioid use in electronic medical records has implications for patient privacy, data security, and potential biases in the detection and treatment of opioid use. If the model is not properly developed and implemented, it could lead to incorrect identification of opioid use, resulting in misdiagnosis or inappropriate treatment decisions. Additionally, the use of such technology raises concerns about the ethical use of patient data and potential misuse of information.

Therefore, further evaluation and careful consideration of safety measures and ethical implications are necessary to minimize the risks associated with this project.",True,False
DOE-0121-2023,DOE,National Energy Technology Laboratory,,To implement sensor-driven deep learning/artificial intelligence for power plant monitoring,"Sensor-driven deep learning/artificial intelligence for intelligent health 
monitoring capabilities that occur at the sensor (embedded computing) 
or base station (edge computing). Will give power plant operators more 
prediction tools about scheduling maintenance. Focus is on a high-
priority in-situ boiler temperature measurement system that relies on 
chipless RFID technology and much-needed temperature, pressure, 
environmental, and water quality industrial sensors.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To implement sensor-driven deep learning/artificial intelligence for power plant monitoring: 
Sensor-driven deep learning/artificial intelligence for intelligent health 
monitoring capabilities that occur at the sensor (embedded computing) 
or base station (edge computing). Will give power plant operators more 
prediction tools about scheduling maintenance. Focus is on a high-
priority in-situ boiler temperature measurement system that relies on 
chipless RFID technology and much-needed temperature, pressure, 
environmental, and water quality industrial sensors.","Implementing sensor-driven deep learning/artificial intelligence in power plant monitoring enables intelligent health monitoring at the sensor or base station level. This provides power plant operators with enhanced prediction tools for maintenance scheduling. The focus is on utilizing chipless RFID technology and various industrial sensors to measure in-situ boiler temperature, as well as monitor temperature, pressure, environmental conditions, and water quality.","Implementing sensor-driven deep learning/artificial intelligence in power plant monitoring enables intelligent health monitoring at the sensor or base station level. This provides power plant operators with enhanced prediction tools for maintenance scheduling. The focus is on utilizing chipless RFID technology and various industrial sensors to measure in-situ boiler temperature, as well as monitor temperature, pressure, environmental conditions, and water quality.","Yes, the project described above has the potential to be a safety risk. 

The project involves implementing sensor-driven deep learning/artificial intelligence in power plant monitoring. Power plants are included in the list of safety risks provided, specifically under the category of ""the functioning of... electrical grids or the generation or movement of energy."" Any project related to power plants and their monitoring has the potential to impact the safety and functioning of the electrical grid, which could have serious consequences.

Additionally, the project involves the use of industrial sensors to measure various parameters such as temperature, pressure, and water quality. These measurements are crucial for the safe and efficient operation of a power plant. If the sensors provide inaccurate or unreliable data, it could lead to faulty maintenance scheduling and potential failures in the power plant, posing a safety risk.

Therefore, considering the involvement of power plant monitoring and the potential for inaccurate data from industrial sensors, this project is potentially a safety risk.",,False,True
DOE-0003-2023,DOE,Fermi National Accelerator,,AI Denoising,"This program aims to develop generative models for quickly simulating 
showers of particles in calorimeters for LHC experiments",,"Artificial Intelligence, Big Data, Neural Networks, Hierarchical Generative Model",,Department of Energy,"AI Denoising: 
This program aims to develop generative models for quickly simulating 
showers of particles in calorimeters for LHC experiments",The AI Denoising program focuses on creating generative models that can efficiently simulate particle showers in calorimeters used for LHC experiments. Its objective is to provide a faster and more accurate method for simulating these showers using artificial intelligence technology.,The AI Denoising program focuses on creating generative models that can efficiently simulate particle showers in calorimeters used for LHC experiments. Its objective is to provide a faster and more accurate method for simulating these showers using artificial intelligence technology.,"Yes, the project is potentially a safety risk because it involves the design and development of industrial equipment and systems. If the AI Denoising program fails, it could pose a meaningful risk to safety in the context of LHC experiments.",,False,True
DOE-0163-2023,DOE,Office of the Chief Information Officer,,AI-Based Chat Bot,"The OCIO EITS Service Desk is exploring the ability to use AI chat bots 
to interact with end-users. We are looking to have a single bot 
architecture that is highly tuned to IT system languages to properly 
handle the terms that may be used in an enterprise environment. The 
primary benefit would be to make knowledge more available to the end-
users in a consumable manner. Additionally, it would connect to ITSM 
workflows that could automate basic functions such as request an 
account, provide permissions, or create an MS Teams site as 
examples. Additionally, the technology needs to provide a significant 
amount of feedback to the EITS Service Desk on unanswered 
questions, questions dropped, ineffective responses, incorrect 
responses, etc.",,,,Department of Energy,"AI-Based Chat Bot: 
The OCIO EITS Service Desk is exploring the ability to use AI chat bots 
to interact with end-users. We are looking to have a single bot 
architecture that is highly tuned to IT system languages to properly 
handle the terms that may be used in an enterprise environment. The 
primary benefit would be to make knowledge more available to the end-
users in a consumable manner. Additionally, it would connect to ITSM 
workflows that could automate basic functions such as request an 
account, provide permissions, or create an MS Teams site as 
examples. Additionally, the technology needs to provide a significant 
amount of feedback to the EITS Service Desk on unanswered 
questions, questions dropped, ineffective responses, incorrect 
responses, etc.",The OCIO EITS Service Desk is exploring the use of AI chat bots to improve interactions with end-users. The chat bot would have a specialized architecture to handle IT system languages and provide knowledge and assistance in an accessible way. It would also automate basic functions and provide feedback to the service desk on its performance.,The OCIO EITS Service Desk is exploring the use of AI chat bots to improve interactions with end-users. The chat bot would have a specialized architecture to handle IT system languages and provide knowledge and assistance in an accessible way. It would also automate basic functions and provide feedback to the service desk on its performance.,,"Yes, the project is potentially a safety risk. This is because it falls under the category of ""f. Determining the terms and conditions of employment, including pre-employment screening, pay or promotion, performance management, hiring or termination, time-on-task tracking, virtual or augmented reality workplace training programs, or electronic workplace surveillance and management systems."" The use of AI chat bots in this context raises concerns about privacy, surveillance, and potential bias in decision-making processes related to employment. These risks could potentially harm individuals' rights and well-being.",True,False
DOS-0017-2023,DOS,GPA,,Machine-Learning Assisted Measurement and Evaluation of Public Outreach,"GPA’s production system for collecting, analyzing, and summarizing the global digital content footprint of the Department.",,,,Department of State,"Machine-Learning Assisted Measurement and Evaluation of Public Outreach: 
GPA’s production system for collecting, analyzing, and summarizing the global digital content footprint of the Department.","GPA has developed a machine-learning assisted system to collect, analyze, and summarize the digital content footprint of the Department for public outreach purposes. This system helps in measuring and evaluating the effectiveness of their outreach efforts on a global scale.","GPA has developed a machine-learning assisted system to collect, analyze, and summarize the digital content footprint of the Department for public outreach purposes. This system helps in measuring and evaluating the effectiveness of their outreach efforts on a global scale.",,"Yes, the project described potentially poses a safety risk. This is because it involves the collection, analysis, and summarization of digital content, which could potentially infringe on individuals' privacy and freedom of speech rights. Additionally, the project's aim to measure and evaluate the effectiveness of the Department's outreach efforts on a global scale could lead to decisions that impact protected speech, potentially limiting the reach of certain content. These factors align with the risks mentioned in the definition, particularly in relation to social media monitoring and decision-making processes that may have implications on public welfare and government benefits.",True,False
DOE-0067-2023,DOE,National Energy Technology Laboratory,,Rokbase Geologic Core Data Tool,"This project will develop the platform through which the DOE OGFL data 
are easily accessible, searchable, and described, enabling future R&D, 
sustainable resource planning, and responsible stewardship of the 
team’s national resources. NETL’s expertise in developing geo-data 
science, ML, visualization, online data mining and integration, and 
advanced analytics through scientific computing (including high 
performance computing and big data computing methods) and 
virtualized environments can be leveraged to support further intelligent 
analytics for offshore systems.",,"Neural Networks, Other",,Department of Energy,"Rokbase Geologic Core Data Tool: 
This project will develop the platform through which the DOE OGFL data 
are easily accessible, searchable, and described, enabling future R&D, 
sustainable resource planning, and responsible stewardship of the 
team’s national resources. NETL’s expertise in developing geo-data 
science, ML, visualization, online data mining and integration, and 
advanced analytics through scientific computing (including high 
performance computing and big data computing methods) and 
virtualized environments can be leveraged to support further intelligent 
analytics for offshore systems.","The Rokbase Geologic Core Data Tool aims to create a platform that allows for easy access, searchability, and description of DOE OGFL data. This will enable future research and development, sustainable resource planning, and responsible management of national resources. NETL's expertise in geo-data science, machine learning, visualization, online data mining, and advanced analytics can be utilized to enhance intelligent analytics for offshore systems.","The Rokbase Geologic Core Data Tool aims to create a platform that allows for easy access, searchability, and description of DOE OGFL data. This will enable future research and development, sustainable resource planning, and responsible management of national resources. NETL's expertise in geo-data science, machine learning, visualization, online data mining, and advanced analytics can be utilized to enhance intelligent analytics for offshore systems.","Based on the provided information, it is not possible to determine if the project is potentially a safety risk. The project description does not provide any details or actions that directly relate to the safety risks mentioned.",,False,True
DHS-0010-2023,DHS,Customs and Border Protection,,RVSS Legacy Overhauled System Project (INVNT),"Video Computer Aided Detection (VCAD) (also known as Matroid AI) is software that enables CBP end users to create and share vision detectors. 

VCAD detectors are trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. 

Users can view detection information via a variety of reports and alert notifications to process and identify important events and trends. Detection data is also available through VCAD's powerful developer Application Programming Interface (API) and language specific clients, so CBP applications can be integrated with the power of computer vision.",Deployment,"The Matroid software currently processes and annotates images using proprietary software to determine if any of the images contain human subjects. Future use cases include the potential to detect additional items of interest such as vehicles, subjects with long-arm rifles or large backpacks and to exclude items of little or no interest such as animals.",,Department of Homeland Security,"RVSS Legacy Overhauled System Project (INVNT): 
Video Computer Aided Detection (VCAD) (also known as Matroid AI) is software that enables CBP end users to create and share vision detectors. 

VCAD detectors are trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. 

Users can view detection information via a variety of reports and alert notifications to process and identify important events and trends. Detection data is also available through VCAD's powerful developer Application Programming Interface (API) and language specific clients, so CBP applications can be integrated with the power of computer vision.","The RVSS Legacy Overhauled System Project (INVNT) introduces the Video Computer Aided Detection (VCAD) software, also known as Matroid AI. This software allows CBP end users to create and share vision detectors, which are trained computer vision models that can recognize objects, people, and events in images or videos. Users can monitor streaming video in real time or search through pre-recorded data to identify objects, people, and events of interest, and access detection information through reports, alerts, and an API for integration with CBP applications.","The RVSS Legacy Overhauled System Project (INVNT) introduces the Video Computer Aided Detection (VCAD) software, also known as Matroid AI. This software allows CBP end users to create and share vision detectors, which are trained computer vision models that can recognize objects, people, and events in images or videos. Users can monitor streaming video in real time or search through pre-recorded data to identify objects, people, and events of interest, and access detection information through reports, alerts, and an API for integration with CBP applications.",,"Yes, the project described above is potentially a safety risk. The reason is that the project involves the use of artificial intelligence (AI) software, specifically the Video Computer Aided Detection (VCAD) software, which can be used for surveillance and monitoring activities. These activities can potentially infringe on individuals' privacy rights and can be misused for various purposes, including law enforcement, surveillance, and decision-making processes.

Additionally, the project involves the collection, analysis, and storage of sensitive data, such as facial recognition, genetic information, and personal information. If this data is mishandled or falls into the wrong hands, it can pose a significant privacy and security risk to individuals.

Furthermore, the project's scope includes decision-making processes in various domains, such as law enforcement, education, employment, healthcare, and government benefits. These decisions can have significant implications for individuals' rights, freedoms, and opportunities. If the AI algorithms used in the project are biased or flawed, it can lead to unfair or discriminatory outcomes, potentially harming individuals and communities.

Overall, the combination of surveillance capabilities, sensitive data handling, and decision-making processes in various domains makes this project a potential safety risk. It is crucial to carefully consider and mitigate the ethical, privacy, and security implications associated with the deployment of such AI systems.",True,False
USAID-0001-2023,USAID,"Bureau for Development, Democracy, and Innovation (DDI)",,Gender differentiated credit scoring,"University of California, Berkeley, is building a machine learning model to conduct gender differentiated credit scoring for customers of Rappicard in Mexico. They will compare this ML model to Rappi's ""status quo"" model to determine whether a gender differentiated model leads to greater access to credit for women.",Initiation,XGBoost algorithm with parameters tuned via random hyperparameter search using 5-fold cross validation on the training dataset for 60 iterations (resulting in at least a 95% chance of finding a hyperparameter combination in the best 5% of combinations). The scores resulting from the XGBoost are calibrated via Platt scaling so that model scores can be interpreted as default probabilities. These is standard method for training credit scoring algorithms in the industry.,,U.S. Agency for International Development,"Gender differentiated credit scoring: 
University of California, Berkeley, is building a machine learning model to conduct gender differentiated credit scoring for customers of Rappicard in Mexico. They will compare this ML model to Rappi's ""status quo"" model to determine whether a gender differentiated model leads to greater access to credit for women.","The University of California, Berkeley is creating a machine learning model to evaluate gender differentiated credit scoring for Rappicard customers in Mexico. By comparing this model to Rappi's current approach, they aim to assess if a gender-based model improves women's access to credit.","The University of California, Berkeley is creating a machine learning model to evaluate gender differentiated credit scoring for Rappicard customers in Mexico. By comparing this model to Rappi's current approach, they aim to assess if a gender-based model improves women's access to credit.",,"Yes, the project described above has the potential to be a safety risk. 

The project involves using machine learning to evaluate gender differentiated credit scoring for Rappicard customers in Mexico. While the intention behind the project is to assess if a gender-based model improves women's access to credit, it falls under the category of determining access to financial services and credit scoring, which is listed as a potential safety risk in the defined risks.

Gender-based models can perpetuate bias and discrimination, leading to unequal treatment and opportunities for individuals. If the machine learning model used in this project is not properly designed and validated, it could result in unfair and discriminatory practices in credit allocation, which can have significant social and economic implications.

Therefore, it is crucial to carefully consider the potential risks and ensure that appropriate measures are in place to mitigate any bias and discrimination that may arise from the use of gender-based credit scoring models.",True,False
SSA-0007-2023,SSA,"Office of Analytics, Review, and Oversight",,PATH Model,This model uses machine learning to identify cases likely to receive an allowance at the hearing level and refer them to administrative law judges or senior adjudicators for prioritized review.,,,,Social Security Administration,"PATH Model: 
This model uses machine learning to identify cases likely to receive an allowance at the hearing level and refer them to administrative law judges or senior adjudicators for prioritized review.",The PATH Model is a machine learning-based approach that predicts which cases are more likely to receive an allowance at the hearing level. It uses this prediction to refer those cases to administrative law judges or senior adjudicators for a prioritized review.,The PATH Model is a machine learning-based approach that predicts which cases are more likely to receive an allowance at the hearing level. It uses this prediction to refer those cases to administrative law judges or senior adjudicators for a prioritized review.,,"Yes, the project described above is potentially a safety risk. This is because it falls under category h, which involves determining loan-allocation processes, financial-system access determinations, credit scoring, and other financial systems that apply penalties. These decisions can have significant impacts on individuals' financial well-being and can potentially lead to financial hardship or unfair treatment. Therefore, there is a risk of negative consequences and potential harm to individuals involved in the project.",True,False
GSA-0009-2023,GSA,OGP,,Solicitation Review Tool (SRT),"The SRT intakes SAM.gov data for all Information and Communications Technology (ICT) solicitations. The system then compiles the data into a database to be used by machine learning algorithms. The first of these is a Natural Language Processing model that determines if a solicitation contains compliance language. If a solicitation does not have compliance language, then it is marked as non-compliant. Each agency is asked to review their data and validate the SRT predictions.  GSA also conducts random manual reviews monthly.",Operation and Maintenance,Natural Language Processing (NLP); Intelligent Document Recognition (IDR); Optical Character Recognition (OCR); Intelligent Character Recognition (ICR); Robotic Process Automation (RPA); Machine Learning,https://github.com/GSA/srt-api,U.S. General Services Administration,"Solicitation Review Tool (SRT): 
The SRT intakes SAM.gov data for all Information and Communications Technology (ICT) solicitations. The system then compiles the data into a database to be used by machine learning algorithms. The first of these is a Natural Language Processing model that determines if a solicitation contains compliance language. If a solicitation does not have compliance language, then it is marked as non-compliant. Each agency is asked to review their data and validate the SRT predictions.  GSA also conducts random manual reviews monthly.","The Solicitation Review Tool (SRT) collects SAM.gov data on ICT solicitations and uses machine learning algorithms to determine compliance. A Natural Language Processing model is used to identify solicitation containing compliance language. Agencies are required to review and validate the SRT predictions, and random manual reviews are conducted by the GSA on a monthly basis.","The Solicitation Review Tool (SRT) collects SAM.gov data on ICT solicitations and uses machine learning algorithms to determine compliance. A Natural Language Processing model is used to identify solicitation containing compliance language. Agencies are required to review and validate the SRT predictions, and random manual reviews are conducted by the GSA on a monthly basis.",,"Yes, the project described above is potentially a safety risk. The project involves the use of machine learning algorithms and Natural Language Processing to determine compliance in ICT solicitations. While the project itself may not pose a direct physical safety risk, it does raise concerns regarding data privacy and potential biases in the decision-making process.

The collection and analysis of sensitive data, such as personal information, can pose a risk if adequate security measures are not in place to protect the data from unauthorized access or misuse. Additionally, the use of machine learning algorithms introduces the possibility of bias in decision-making, which can result in unfair treatment or discrimination.

Furthermore, the project involves decisions and assessments related to government contracts, which have financial implications. If the algorithms used in the project are not reliable or accurate, it could lead to incorrect determinations of compliance and potentially result in financial losses or legal issues for both the government agencies and the contractors involved.

Overall, the project raises safety concerns related to data privacy, potential biases, and financial risks, making it potentially a safety risk.",True,False
DOE-0014-2023,DOE,Fermi National Accelerator,,SONIC: AI acceleration as a service,"This project focuses on integration of AI hardware for at-scale inference 
acceleration for particle physics experiments.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"SONIC: AI acceleration as a service: 
This project focuses on integration of AI hardware for at-scale inference 
acceleration for particle physics experiments.","The SONIC project aims to integrate AI hardware to accelerate the inference process for particle physics experiments. It aims to provide AI acceleration as a service, focusing on at-scale implementation for efficient and faster results.","The SONIC project aims to integrate AI hardware to accelerate the inference process for particle physics experiments. It aims to provide AI acceleration as a service, focusing on at-scale implementation for efficient and faster results.","Yes, the SONIC project is potentially a safety risk because it falls under category f: industrial emissions and environmental impact control processes. The integration of AI hardware and acceleration of the inference process for particle physics experiments may result in increased industrial emissions and potential environmental impacts. These emissions and impacts need to be carefully managed and controlled to ensure the safety of the environment and individuals involved in the project.",,False,True
DOE-0157-2023,DOE,"Office of Environment, Health, Safety & Security",,"Data Analytics and Machine Learning (DAMaL) Tools for Analysis of Environment, Safety and Health (ES&H) data: Similarity Based Information Retrieval","""The EHSS Data Analytics Machine Learning (DAMaL) tools, similarity-
based information retrieval tool, uses natural language processing 
(NLP) and cosine similarity to leverage artificial intelligence (AI) to 
increase the efficiency of a user to find important records in the DOE 
environment, safety, and health (ES&H) datasets (e.g., occurrence 
reporting and processing system, fire protection, lessons learned, 
accident and injury reporting system, contractor assurance system 
CAS).  The tool has no restriction on the text query, provides NLP 
options to the user (e.g., stemming or lemmatization) and could be used 
to improve decision-making in job planning activities, identifying hazards, 
and obtaining insights from operating experience and lessons learned 
data discovery and analysis, accident investigations among other areas.
As of October 2021, Tool developed and deployed in the DAMaL tools 
website.  Expected to continue to maintain, develop documentation 
(e.g., users analysis guides), improve and enhance, and increase data 
sources.",,,,Department of Energy,"Data Analytics and Machine Learning (DAMaL) Tools for Analysis of Environment, Safety and Health (ES&H) data: Similarity Based Information Retrieval: 
""The EHSS Data Analytics Machine Learning (DAMaL) tools, similarity-
based information retrieval tool, uses natural language processing 
(NLP) and cosine similarity to leverage artificial intelligence (AI) to 
increase the efficiency of a user to find important records in the DOE 
environment, safety, and health (ES&H) datasets (e.g., occurrence 
reporting and processing system, fire protection, lessons learned, 
accident and injury reporting system, contractor assurance system 
CAS).  The tool has no restriction on the text query, provides NLP 
options to the user (e.g., stemming or lemmatization) and could be used 
to improve decision-making in job planning activities, identifying hazards, 
and obtaining insights from operating experience and lessons learned 
data discovery and analysis, accident investigations among other areas.
As of October 2021, Tool developed and deployed in the DAMaL tools 
website.  Expected to continue to maintain, develop documentation 
(e.g., users analysis guides), improve and enhance, and increase data 
sources.","The EHSS DAMaL tools use natural language processing and cosine similarity to efficiently retrieve important records from DOE ES&H datasets. The tools have no text query restrictions, offer NLP options, and can be used to improve decision-making in various areas such as job planning, hazard identification, and accident investigations. The tool is currently available on the DAMaL tools website and is expected to be continuously maintained, enhanced, and expanded with more data sources.","The EHSS DAMaL tools use natural language processing and cosine similarity to efficiently retrieve important records from DOE ES&H datasets. The tools have no text query restrictions, offer NLP options, and can be used to improve decision-making in various areas such as job planning, hazard identification, and accident investigations. The tool is currently available on the DAMaL tools website and is expected to be continuously maintained, enhanced, and expanded with more data sources.","Yes, the project is potentially a safety risk. 

The project falls under risk category a, as it involves the functioning of data retrieval tools for DOE ES&H datasets. These datasets likely contain important information related to the safety of dams, emergency services, electrical grids, and other systems controlling physical transit. If the retrieval tools fail to provide accurate or timely information, it could potentially lead to safety issues in these systems.

Furthermore, the project also falls under risk category h, as it involves the design, construction, or testing of industrial equipment or systems. If the EHSS DAMaL tools are not properly designed or tested, and they fail to retrieve important safety records, it could pose a meaningful risk to safety.

Therefore, considering the potential impact on safety-related systems and equipment, the project is a safety risk.",,False,True
DOE-0089-2023,DOE,National Energy Technology Laboratory,,To develop a deep-learning Artificial Intelligence model for analysis of fundamental combustion characteristics,"A deep-learning Artificial Intelligence model will be pursued for rapid 
analysis of detailed fundamental combustion characteristics that support 
the design and troubleshooting process of H2-containing fuel combustor 
development.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To develop a deep-learning Artificial Intelligence model for analysis of fundamental combustion characteristics: 
A deep-learning Artificial Intelligence model will be pursued for rapid 
analysis of detailed fundamental combustion characteristics that support 
the design and troubleshooting process of H2-containing fuel combustor 
development.",A deep-learning AI model will be created to quickly analyze the fundamental combustion characteristics required for the development and troubleshooting of H2-containing fuel combustors. This model aims to support the design process by providing rapid and detailed analysis.,A deep-learning AI model will be created to quickly analyze the fundamental combustion characteristics required for the development and troubleshooting of H2-containing fuel combustors. This model aims to support the design process by providing rapid and detailed analysis.,"Yes, the project is potentially a safety risk. The project involves the design and development of combustors for H2-containing fuel. Combustion processes can be highly volatile and can pose safety risks, especially when dealing with hydrogen. Hydrogen is highly flammable and can lead to explosions if not handled properly. Therefore, the project's focus on developing and troubleshooting combustors for H2-containing fuel carries inherent safety risks.",,False,True
USAID-0000-2023,USAID,"Bureau for Development, Democracy, and Innovation (DDI)",,Media Early Warning System (MEWS),To detect narratives and trends in social media alterations of images and video in order to find and counteract malign narratives,Initiation,,,U.S. Agency for International Development,"Media Early Warning System (MEWS): 
To detect narratives and trends in social media alterations of images and video in order to find and counteract malign narratives",The Media Early Warning System (MEWS) is designed to identify and address malicious narratives by monitoring social media for changes in images and videos and analyzing trends. Its purpose is to detect and counteract any harmful narratives that may be spreading through these mediums.,The Media Early Warning System (MEWS) is designed to identify and address malicious narratives by monitoring social media for changes in images and videos and analyzing trends. Its purpose is to detect and counteract any harmful narratives that may be spreading through these mediums.,,"Yes, the project described above is potentially a safety risk. The project involves monitoring social media for changes in images and videos and analyzing trends to identify and address malicious narratives. This can potentially involve decisions related to blocking, removing, or limiting the reach of protected speech, as well as social media monitoring and surveillance. Such activities can raise concerns about freedom of speech and privacy rights. Additionally, there is a risk of misinterpretation or bias in identifying harmful narratives, which could lead to the suppression of legitimate speech or the targeting of individuals unfairly.",True,False
HHS-0089-2023,HHS,FDA,CFSAN /OFAS,Data Infrastructure Backbone for AI applications,"OFAS is creating a data lake (WILEE knowledgebase) that ingests and integrates data from a variety of data sources to assist our use of advance analytics in driving risked based decision making. The sources of data include, internal stakeholder submission data, data generated by OFAS staff, scientific information from PubMed, NIH and other scientific publications, CFSAN generated data such as the total diet study, news articles and blog posts, publications from sister agencies, food ingredient and packaging data, food sales data etc. The design of this data store allows for the automated ingestion of new data while allowing for manual curation where necessary. It is also designed to enable the identification, acquisition and integration of new data sources as they become available. The design of the data lake centralizes information about CFSAN regulated products, food additives, color additives, GRAS substances and food contact substance and integrates the different sources of information with stakeholder submission information contained in FARM and cheminformatics information in CERES enabling greater insights and a more efficient knowledge discovery during review of premarket submissions and post market monitoring of the U.S food supply. ",Operation and Maintenance,,,Department of Health and Human Services,"Data Infrastructure Backbone for AI applications: 
OFAS is creating a data lake (WILEE knowledgebase) that ingests and integrates data from a variety of data sources to assist our use of advance analytics in driving risked based decision making. The sources of data include, internal stakeholder submission data, data generated by OFAS staff, scientific information from PubMed, NIH and other scientific publications, CFSAN generated data such as the total diet study, news articles and blog posts, publications from sister agencies, food ingredient and packaging data, food sales data etc. The design of this data store allows for the automated ingestion of new data while allowing for manual curation where necessary. It is also designed to enable the identification, acquisition and integration of new data sources as they become available. The design of the data lake centralizes information about CFSAN regulated products, food additives, color additives, GRAS substances and food contact substance and integrates the different sources of information with stakeholder submission information contained in FARM and cheminformatics information in CERES enabling greater insights and a more efficient knowledge discovery during review of premarket submissions and post market monitoring of the U.S food supply. ","OFAS is creating a data lake called WILEE knowledgebase to integrate data from various sources for advanced analytics in risk-based decision making. This data store allows for automated ingestion of new data and manual curation when needed, and can also incorporate new data sources as they become available. The data lake centralizes information on CFSAN regulated products, food additives, color additives, GRAS substances, and food contact substances, integrating them with stakeholder submission information and cheminformatics data for more efficient knowledge discovery in reviewing premarket submissions and monitoring the US food supply.","OFAS is creating a data lake called WILEE knowledgebase to integrate data from various sources for advanced analytics in risk-based decision making. This data store allows for automated ingestion of new data and manual curation when needed, and can also incorporate new data sources as they become available. The data lake centralizes information on CFSAN regulated products, food additives, color additives, GRAS substances, and food contact substances, integrating them with stakeholder submission information and cheminformatics data for more efficient knowledge discovery in reviewing premarket submissions and monitoring the US food supply.",,"Yes, the project described above has the potential to be a safety risk. The project involves the creation of a data lake called WILEE knowledgebase that integrates data from various sources for advanced analytics in risk-based decision making. This data store centralizes information on regulated products, additives, and substances related to the US food supply.

Although the project itself does not directly involve actions that pose safety risks, it can have indirect implications for safety. The integration and analysis of data related to food supply and regulatory decisions can impact public health and safety. Any errors, inaccuracies, or biases in the data or the algorithms used for analysis can lead to incorrect risk assessments, potentially jeopardizing the safety of food products and the well-being of consumers.

Additionally, the project's use of automated ingestion of new data and manual curation introduces the possibility of human errors or oversight, which can further increase the safety risks associated with the project.

Therefore, while the project may not pose an immediate safety risk, the potential indirect implications for food safety make it important to carefully evaluate and monitor the accuracy, integrity, and reliability of the data and analysis processes involved.",True,False
NARA-0002-2023,NARA,Information Service,,Automated Data Discovery and Classification Pilot,"NARA is planning to conduct a future pilot to test AI/ML based automated data discovery and classification using public/mock-up datasets. In this pilot we will also test both supervised and un-supervised AI/ML techniques.

We’re planning to use vendor’s COTS solution/ML algorithms ""document classifier"" which allows the customer to search and discover full documents rather than individual sensitive data elements such as SSN or credit card numbers.  This technique allows for the ""finding"" of discovery to be a document.  Our customers can search for and discover all their RFPs, purchase orders, NDAs, financial statements, budget documents, resumes, etc.  In cases where NARA has a document type in mind that vendor’s COTS solution does not already understand, we should be able to assemble a learning set of documents (typically 20 - 100 examples) and train the vendor algorithm to find all documents of that type.",Planned (not in production),"Document/File Classification: Document/file classification is a supervised ML algorithm that classifies whole documents according to their type. The algorithm works by converting each document to a term frequency–inverse document frequency (tf-idf) numerical representation and passing these vectors through a multi-layer neural network to finally get the document’s type/class. Document/File Clustering: Document/file clustering is an unsupervised ML algorithm that groups similar files together according to their content. For example, non-disclosure agreements will cluster together while product presentation files will be assigned to a different cluster.",,National Archives and Records Administration,"Automated Data Discovery and Classification Pilot: 
NARA is planning to conduct a future pilot to test AI/ML based automated data discovery and classification using public/mock-up datasets. In this pilot we will also test both supervised and un-supervised AI/ML techniques.

We’re planning to use vendor’s COTS solution/ML algorithms ""document classifier"" which allows the customer to search and discover full documents rather than individual sensitive data elements such as SSN or credit card numbers.  This technique allows for the ""finding"" of discovery to be a document.  Our customers can search for and discover all their RFPs, purchase orders, NDAs, financial statements, budget documents, resumes, etc.  In cases where NARA has a document type in mind that vendor’s COTS solution does not already understand, we should be able to assemble a learning set of documents (typically 20 - 100 examples) and train the vendor algorithm to find all documents of that type.","NARA is planning to conduct a pilot to test automated data discovery and classification using AI/ML techniques. They will use a vendor's COTS solution that allows customers to search and discover full documents, rather than individual sensitive data elements. If the vendor's solution does not understand a specific document type, NARA can train the algorithm to find all documents of that type by providing a learning set of examples.","NARA is planning to conduct a pilot to test automated data discovery and classification using AI/ML techniques. They will use a vendor's COTS solution that allows customers to search and discover full documents, rather than individual sensitive data elements. If the vendor's solution does not understand a specific document type, NARA can train the algorithm to find all documents of that type by providing a learning set of examples.",,"Yes, the project described above has the potential to be a safety risk. The project involves the use of automated data discovery and classification using AI/ML techniques, which can have implications for privacy and security.

The project could potentially involve the processing and analysis of sensitive and protected speech, as well as personal and confidential information related to law enforcement, surveillance, education, employment, healthcare, finance, government benefits, and child welfare. These areas involve highly sensitive and critical decision-making processes that can significantly impact individuals' rights, well-being, and privacy.

If the AI/ML algorithms used in the project are not properly trained, tested, and validated, there is a risk of erroneous or biased decision-making. This can lead to false positives or negatives in identifying sensitive documents, which could result in privacy breaches, wrongful actions, or discrimination.

Additionally, the use of AI/ML techniques in such critical areas raises concerns about the transparency, explainability, and accountability of the decision-making processes. If the algorithms used are black-box models that cannot provide clear explanations for their decisions, it becomes challenging to ensure fairness, ethics, and accountability in the system.

Overall, the project described has the potential to be a safety risk due to the sensitivity and impact of the data involved, as well as the potential for biased or erroneous decision-making. Proper safeguards, oversight, and accountability mechanisms should be in place to mitigate these risks and protect individuals' rights and well-being.",True,False
HHS-0005-2023,HHS,ASPR,BARDA (CBRN),Burn & Blast MCMs: Rivanna,AI Based algorithms on Accuro XV to detect and highlight fractures and soft tissue injuries,Development and Acquisition,,,Department of Health and Human Services,"Burn & Blast MCMs: Rivanna: 
AI Based algorithms on Accuro XV to detect and highlight fractures and soft tissue injuries","The Rivanna Accuro XV utilizes AI algorithms to effectively identify and emphasize fractures and soft tissue injuries in Burn & Blast MCMs. This advanced technology aids in the detection and highlighting of such injuries, improving the accuracy and efficiency of medical assessments.","The Rivanna Accuro XV utilizes AI algorithms to effectively identify and emphasize fractures and soft tissue injuries in Burn & Blast MCMs. This advanced technology aids in the detection and highlighting of such injuries, improving the accuracy and efficiency of medical assessments.","Yes, the project is potentially a safety risk. The use of AI algorithms in medical assessments involves the application of kinetic force, as well as the delivery of potentially damaging electromagnetic impulses. Additionally, the project involves the detection and highlighting of fractures and soft tissue injuries, which are physical movements within a medical setting. Therefore, there is a potential risk to the safety of individuals involved in the project or receiving medical assessments.",,False,True
DOS-0026-2023,DOS,R,,SentiBERTIQ,"GEC A&R uses deep contextual AI of text to identify and extract subjective information within the source material. This sentiment model was trained by fine-tuning a multilingual, BERT model leveraging word embeddings across 2.2 million labeled tweets spanning English, Spanish, Arabic, and traditional and simplified Chinese. The tool will assign a sentiment to each text document and output a CSV containing the sentiment and confidence interval for user review.",,,,Department of State,"SentiBERTIQ: 
GEC A&R uses deep contextual AI of text to identify and extract subjective information within the source material. This sentiment model was trained by fine-tuning a multilingual, BERT model leveraging word embeddings across 2.2 million labeled tweets spanning English, Spanish, Arabic, and traditional and simplified Chinese. The tool will assign a sentiment to each text document and output a CSV containing the sentiment and confidence interval for user review.","SentiBERTIQ is a tool that uses deep contextual AI to analyze text and extract subjective information. It was trained using a multilingual BERT model on 2.2 million labeled tweets in multiple languages, and it can assign a sentiment to each text document and provide a confidence interval in a CSV format for user review.","SentiBERTIQ is a tool that uses deep contextual AI to analyze text and extract subjective information. It was trained using a multilingual BERT model on 2.2 million labeled tweets in multiple languages, and it can assign a sentiment to each text document and provide a confidence interval in a CSV format for user review.",,"Yes, the project described is potentially a safety risk. 

The project involves the use of AI to analyze text and extract subjective information. This can have implications in various domains such as law enforcement, education, employment, healthcare, and government services. The potential risks arise from the fact that the tool can make decisions or recommendations in these areas based on its analysis of text data.

For example, in law enforcement, if the tool is used for risk assessments about individuals or for decisions related to sentencing, parole, or bail, there is a risk of biased or unfair outcomes. Similarly, in education, if the tool is used for detecting student cheating or plagiarism, recommending disciplinary interventions, or determining access to educational resources, there is a risk of privacy invasion and unfair treatment of students.

In healthcare, if the tool is used for clinical diagnosis, treatment determination, or mental health status detection, there is a risk of incorrect or harmful decisions being made. Additionally, in government services, if the tool is used for determining access to benefits or assigning penalties, there is a risk of unfair treatment and potential denial of essential services.

The potential safety risks arise from the fact that AI systems are not infallible and can be biased or flawed in their analysis and decision-making. The use of such a tool without proper oversight, accountability, and transparency can lead to negative consequences for individuals and society as a whole. Therefore, it is important to carefully evaluate and regulate the use of such AI tools to mitigate potential safety risks.",True,False
HHS-0087-2023,HHS,FDA,CDER/Office of Translational Sciences/Office of Biostatistics,CluePoints CRADA,"This project uses unsupervised machine learning to detect and identify data anomalies in clinical trial data at the site, country and subject levels.  This project will consider multiple use cases with the goals of improving data quality and data integrity, assist site selection for inspection, and assist reviewers by identifying potentially problematic sites for sensitivity analyses. ",Development and Acquisition,,,Department of Health and Human Services,"CluePoints CRADA: 
This project uses unsupervised machine learning to detect and identify data anomalies in clinical trial data at the site, country and subject levels.  This project will consider multiple use cases with the goals of improving data quality and data integrity, assist site selection for inspection, and assist reviewers by identifying potentially problematic sites for sensitivity analyses. ","The CluePoints CRADA project aims to detect and identify data anomalies in clinical trial data using unsupervised machine learning. It will focus on improving data quality and integrity, aiding site selection for inspection, and helping reviewers identify potentially problematic sites for sensitivity analyses.","The CluePoints CRADA project aims to detect and identify data anomalies in clinical trial data using unsupervised machine learning. It will focus on improving data quality and integrity, aiding site selection for inspection, and helping reviewers identify potentially problematic sites for sensitivity analyses.",,"Yes, the project described above has the potential to be a safety risk. This is because it involves the use of machine learning algorithms to detect and identify data anomalies in clinical trial data. Clinical trials are crucial for evaluating the safety and efficacy of new drugs or treatments. Any anomalies or errors in the data could potentially lead to incorrect conclusions about the safety and effectiveness of the interventions being tested. Therefore, if the machine learning algorithms used in this project are not properly validated and fail to accurately detect data anomalies, it could result in incorrect decisions being made regarding the safety and effectiveness of medical interventions, potentially putting patients at risk.",True,False
DOE-0103-2023,DOE,National Energy Technology Laboratory,,To develop low cost conversion of coal to graphene,"Demonstrate the techno-economical feasibility of a 250 ton/day 
manufacturing facility to convert coal to high-quality graphene. The core 
technology is based on flash joule heating (FJH) to convert various 
coals to graphene. Machine learning algorithms will map out the 
correlation of processing parameters with the final product (graphene 
yield, quality, dimensions).",,"Natural Language Processing, Neural Networks",,Department of Energy,"To develop low cost conversion of coal to graphene: 
Demonstrate the techno-economical feasibility of a 250 ton/day 
manufacturing facility to convert coal to high-quality graphene. The core 
technology is based on flash joule heating (FJH) to convert various 
coals to graphene. Machine learning algorithms will map out the 
correlation of processing parameters with the final product (graphene 
yield, quality, dimensions).","This text discusses the goal of developing a cost-effective method for converting coal into high-quality graphene. The plan is to build a manufacturing facility that can process 250 tons of coal per day using flash joule heating technology. Additionally, machine learning algorithms will be used to analyze the relationship between processing parameters and the quality, yield, and dimensions of the graphene produced.","This text discusses the goal of developing a cost-effective method for converting coal into high-quality graphene. The plan is to build a manufacturing facility that can process 250 tons of coal per day using flash joule heating technology. Additionally, machine learning algorithms will be used to analyze the relationship between processing parameters and the quality, yield, and dimensions of the graphene produced.","Yes, this project is potentially a safety risk. 

According to the defined safety risks, this project falls under category f, which involves industrial emissions and environmental impact control processes. The conversion of coal into graphene involves the use of flash joule heating technology, which can potentially emit harmful industrial emissions. These emissions can have adverse effects on the environment and pose a risk to the health and safety of workers and nearby communities.

Furthermore, the project may also fall under category h, as the design and construction of the manufacturing facility, if not done properly, could pose a meaningful risk to safety. Any failures or malfunctions of the equipment or structures involved in the process could lead to accidents or hazardous situations.

Therefore, considering the potential environmental and safety risks associated with industrial emissions and equipment failures, this project is potentially a safety risk.",,False,True
HHS-0011-2023,HHS,ASPR,BARDA (DRIVe),Digital MCM: Raisonance,Using forced cough vocalization (FCV) in a smartphone to detect the presence of COVID-19 and Influenza using AI.,Development and Acquisition,,,Department of Health and Human Services,"Digital MCM: Raisonance: 
Using forced cough vocalization (FCV) in a smartphone to detect the presence of COVID-19 and Influenza using AI.",Raisonance has developed a digital MCM (Mobile Cough Monitor) that uses forced cough vocalization (FCV) in smartphones to identify the existence of COVID-19 and Influenza. This technology incorporates artificial intelligence (AI) to analyze the cough sounds and provide accurate detection of these respiratory illnesses.,Raisonance has developed a digital MCM (Mobile Cough Monitor) that uses forced cough vocalization (FCV) in smartphones to identify the existence of COVID-19 and Influenza. This technology incorporates artificial intelligence (AI) to analyze the cough sounds and provide accurate detection of these respiratory illnesses.,"Yes, the project is potentially a safety risk. 

The project involves the use of smartphones and artificial intelligence to detect COVID-19 and Influenza through cough sounds. While the intention is to provide accurate detection of respiratory illnesses, there are potential safety risks involved.

Firstly, the project involves the collection and analysis of personal health data, which raises concerns about privacy and data security. There is a risk of unauthorized access or misuse of this sensitive information.

Secondly, the project relies on the accuracy of the AI algorithms in analyzing cough sounds. If the AI fails to accurately detect respiratory illnesses, there is a risk of false negatives or false positives, which could lead to incorrect diagnoses and subsequent health risks.

Lastly, the project involves the use of smartphones, which are often used in various settings such as workplaces, schools, transportation, and medical facilities. If the technology is not properly regulated or controlled, there is a risk of false alarms or unnecessary panic among individuals who may be falsely identified as having COVID-19 or Influenza.

Therefore, while the project has the potential to be beneficial in detecting respiratory illnesses, it also poses safety risks that need to be carefully addressed and mitigated.",,False,True
DOT-0007-2023,DOT,NSR Human Injury Research Division,,Machine Learning for Occupant Safety Research,"Description: Utilize deep learning models for predicting head kinematics directly from crash videos. The utilization of deep learning techniques enables the extraction of 3D kinematics from 2D views, offering a viable alternative for calculating head kinematics in the absence of sensors or when sensor availability is inadequate, and when high-quality sensor data is absent
Input:  Vehicle crash videos
Output: Angular velocity - injury prediction",Proof of Concept completed and published,"Deep learning models - Convolutional Neural Networks, Long-Short Term Memory based Recurrent Neural Networks",,Department of Transportation,"Machine Learning for Occupant Safety Research: 
Description: Utilize deep learning models for predicting head kinematics directly from crash videos. The utilization of deep learning techniques enables the extraction of 3D kinematics from 2D views, offering a viable alternative for calculating head kinematics in the absence of sensors or when sensor availability is inadequate, and when high-quality sensor data is absent
Input:  Vehicle crash videos
Output: Angular velocity - injury prediction","Machine learning models can be used to predict head kinematics in vehicle crashes using deep learning techniques. These models can extract 3D kinematics from 2D crash videos, providing a reliable method for calculating head kinematics when sensors are not available or when sensor data is of low quality. The output of these models is the angular velocity, which can be used to predict the likelihood of injury.","Machine learning models can be used to predict head kinematics in vehicle crashes using deep learning techniques. These models can extract 3D kinematics from 2D crash videos, providing a reliable method for calculating head kinematics when sensors are not available or when sensor data is of low quality. The output of these models is the angular velocity, which can be used to predict the likelihood of injury.","Yes, the project is potentially a safety risk. According to the provided definition, it falls under category (d) as it involves the movements of vehicles, specifically in the context of vehicle crashes. The project aims to predict head kinematics in vehicle crashes, which directly relates to the safety of individuals involved in accidents. If the predictions are inaccurate or unreliable, it could potentially lead to incorrect assessments of injury likelihood and inadequate safety measures being implemented.",,False,True
VA-0018-2023,VA,,,Provider directory data accuracy and system of record alignment,"AI is used to add value as a transactor for intelligent identity resolution and linking.  AI also has a domain cache function that can be used for both Clinical Decision Support and for intelligent state reconstruction over time and real-time discrepancy detection.  As a synchronizer, AI can perform intelligent propagation and semi-automated discrepancy resolution.  AI adapters can be used for inference via OWL and logic programming.  Lastly, AI has long term storage (“black box flight recorder”) for virtually limitless machine learning and BI applications.",,,,Department of Veterans Affairs,"Provider directory data accuracy and system of record alignment: 
AI is used to add value as a transactor for intelligent identity resolution and linking.  AI also has a domain cache function that can be used for both Clinical Decision Support and for intelligent state reconstruction over time and real-time discrepancy detection.  As a synchronizer, AI can perform intelligent propagation and semi-automated discrepancy resolution.  AI adapters can be used for inference via OWL and logic programming.  Lastly, AI has long term storage (“black box flight recorder”) for virtually limitless machine learning and BI applications.","AI is utilized in provider directories to enhance accuracy and align with the system of record. It serves as a transactor for intelligent identity resolution and linking, with additional functions such as domain cache for Clinical Decision Support and state reconstruction, as well as discrepancy detection. AI acts as a synchronizer, performing intelligent propagation and semi-automated discrepancy resolution, while adapters enable inference through OWL and logic programming. Lastly, AI offers long-term storage for extensive machine learning and business intelligence applications.","AI is utilized in provider directories to enhance accuracy and align with the system of record. It serves as a transactor for intelligent identity resolution and linking, with additional functions such as domain cache for Clinical Decision Support and state reconstruction, as well as discrepancy detection. AI acts as a synchronizer, performing intelligent propagation and semi-automated discrepancy resolution, while adapters enable inference through OWL and logic programming. Lastly, AI offers long-term storage for extensive machine learning and business intelligence applications.",,"Yes, the project described above is potentially a safety risk. 

The project involves the use of artificial intelligence (AI) in various areas such as law enforcement, surveillance, education, employment, medical diagnosis and treatment, financial systems, government benefits, and child welfare. These are all sensitive domains where the decisions made based on AI can have significant consequences for individuals.

If the AI algorithms used in these areas are not properly designed, trained, or validated, they can lead to biased or inaccurate results. This can result in unfair treatment, discrimination, or harm to individuals involved. For example, if AI is used in law enforcement to predict criminal recidivism or make decisions related to sentencing, it could perpetuate existing biases or result in unjust outcomes.

Additionally, the use of AI in healthcare, such as in clinical diagnosis and treatment, carries the risk of incorrect or inadequate recommendations, potentially leading to patient harm or incorrect medical decisions.

Furthermore, the project involves the use of AI in financial systems, determining access to government benefits, and making recommendations or decisions about child welfare. Errors or biases in these areas can have severe consequences for individuals' financial stability, access to essential services, and even child custody.

Overall, the wide range of sensitive areas involved in the project and the potential for biased or inaccurate AI algorithms make it a potential safety risk. Proper precautions, such as rigorous testing, validation, and ongoing monitoring, should be taken to mitigate these risks and ensure the fair and safe implementation of AI in these domains.",True,False
DHS-0036-2023,DHS,United States Citizenship and Immigration Services,,Person-Centric Identity Services A-Number Management Model,"The vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The A-Number Management model ingests person-centric datasets from various source systems for model training and evaluation purposes. The dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. 

The A-Number Management identifies which records from within our identity database best match search criteria. The model uses machine learning to ensure that search results presented to authorized external partners for external integrations and servicing have a high degree of confidence with the search criteria so that trust in the PCIS entity resolution remains high.

The A-Number Management model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The machine learning models are more capable of resolving ""fuzzy"" matches, and deal with the reality of different data quality.",Operation and Maintenance,"Ensemble Learning, Machine Learning",,Department of Homeland Security,"Person-Centric Identity Services A-Number Management Model: 
The vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The A-Number Management model ingests person-centric datasets from various source systems for model training and evaluation purposes. The dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. 

The A-Number Management identifies which records from within our identity database best match search criteria. The model uses machine learning to ensure that search results presented to authorized external partners for external integrations and servicing have a high degree of confidence with the search criteria so that trust in the PCIS entity resolution remains high.

The A-Number Management model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The machine learning models are more capable of resolving ""fuzzy"" matches, and deal with the reality of different data quality.","The Person-Centric Identity Services (PCIS) aims to be the trusted source of comprehensive immigration history and status information, using biographical and biometric data. The A-Number Management model is responsible for training and evaluating the PCIS system by ingesting various datasets and using machine learning to ensure accurate search results and high confidence in entity resolution. This model is critical in surfacing and resolving a person's records, even when dealing with fuzzy matches and varying data quality.","The Person-Centric Identity Services (PCIS) aims to be the trusted source of comprehensive immigration history and status information, using biographical and biometric data. The A-Number Management model is responsible for training and evaluating the PCIS system by ingesting various datasets and using machine learning to ensure accurate search results and high confidence in entity resolution. This model is critical in surfacing and resolving a person's records, even when dealing with fuzzy matches and varying data quality.",,"Yes, the project described potentially poses a safety risk. The project involves the use of biographical and biometric data for the purpose of immigration history and status information. This falls under the category of ""decisions regarding access to or eligibility for government benefits or services"" as mentioned in the defined risks. Any project that involves decision-making processes related to immigration status can have significant implications on individuals' lives and their access to essential services. Therefore, it is crucial to ensure that the project is conducted with a high level of accuracy and security to mitigate any potential safety risks.",True,False
HHS-0064-2023,HHS,FDA,CBER/OBPV/DABRA,Process Large Amount of Submitted Docket Comments,"Provide an automated process to transfer, deduplicate, summarize and cluster docket comments using AI/ML",Implementation,,,Department of Health and Human Services,"Process Large Amount of Submitted Docket Comments: 
Provide an automated process to transfer, deduplicate, summarize and cluster docket comments using AI/ML","A system is needed to automate the handling of a high volume of docket comments by utilizing AI/ML technology. This system will transfer the comments, remove duplicates, provide summaries, and group similar comments together.","A system is needed to automate the handling of a high volume of docket comments by utilizing AI/ML technology. This system will transfer the comments, remove duplicates, provide summaries, and group similar comments together.",,"Yes, the project has the potential to be a safety risk. While the project itself does not directly involve any of the specific risks mentioned, the use of AI/ML technology in handling a high volume of docket comments can lead to unintended consequences. If the AI/ML system is not properly trained or monitored, there is a risk of misinterpretation or misclassification of comments, which could have serious consequences in legal proceedings. Additionally, if the system is not designed to handle sensitive or confidential information appropriately, there could be privacy and security risks associated with the automated handling of these comments. Therefore, it is important to carefully evaluate and mitigate these potential risks before implementing the project.",True,False
HHS-0050-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),CMS Connect (CCN),CCN AI for Global Search ,Operation and Maintenance,,,Department of Health and Human Services,"CMS Connect (CCN): 
CCN AI for Global Search ",CMS Connect (CCN) is an artificial intelligence system designed for global search purposes. It utilizes advanced technology to provide efficient and effective search results on a global scale.,CMS Connect (CCN) is an artificial intelligence system designed for global search purposes. It utilizes advanced technology to provide efficient and effective search results on a global scale.,,"Yes, the project described above is potentially a safety risk. 

The risks associated with the project include decisions related to surveillance, monitoring, and profiling of individuals, which can infringe upon privacy rights. Additionally, the use of artificial intelligence in determining access to educational resources, employment opportunities, medical care, financial services, government benefits, and child welfare can introduce biases and potentially discriminate against certain individuals or groups. These decisions should be made with human oversight and ethical considerations, as relying solely on AI systems may lead to unjust outcomes.",True,False
DOT-0002-2023,DOT,ATO,,Surface Report Classifiier (SCM/Auto-Class),"SCM classifies surface incident reports by event type, such as Runway Incursion, Runway Excursion, Taxiway Incursion/Excursion and categorizes runway incursions further by severity type (Category A, B, C, D, E)",Refinments planned for future release,"Support Vector Machines, Gradient boosting, neural networks, natural language processing",,Department of Transportation,"Surface Report Classifiier (SCM/Auto-Class): 
SCM classifies surface incident reports by event type, such as Runway Incursion, Runway Excursion, Taxiway Incursion/Excursion and categorizes runway incursions further by severity type (Category A, B, C, D, E)","The Surface Report Classifier (SCM/Auto-Class) is a system that categorizes surface incident reports based on the type of event, such as runway incursion or taxiway excursion. It also further classifies runway incursions based on severity, using categories A, B, C, D, and E.","The Surface Report Classifier (SCM/Auto-Class) is a system that categorizes surface incident reports based on the type of event, such as runway incursion or taxiway excursion. It also further classifies runway incursions based on severity, using categories A, B, C, D, and E.",,"Yes, the project described above has the potential to be a safety risk. 

The project involves the use of an automated system, the Surface Report Classifier, to categorize surface incident reports in aviation. This classification includes categorizing events such as runway incursions or taxiway excursions and further classifying runway incursions based on severity.

Aviation safety is of utmost importance, and any system or technology that influences decisions or assessments related to safety carries inherent risks. If the Surface Report Classifier has inaccuracies or flaws in its classification algorithms, it could potentially misclassify or misinterpret surface incidents. This could lead to incorrect assessments of the severity of runway incursions, which in turn may impact the implementation of appropriate safety measures or corrective actions.

Furthermore, if the system is relied upon as the sole basis for decision-making without human oversight or verification, there is a risk of overlooking critical incidents or failing to address safety concerns adequately.

Therefore, while the project may have positive intentions of improving incident reporting and classification, its potential impact on aviation safety warrants careful consideration and thorough evaluation to mitigate any potential safety risks.",True,False
DOE-0092-2023,DOE,National Energy Technology Laboratory,,"To develop a wireless, distributed data acquisition and interpretation system foe seismic monitoring and carbon storage characterization.","Resensys plans to develop a wireless, distributed data acquisition and 
interpretation system tailored for monitoring and characterization of 
seismic activity at carbon storage sites.  The seismicity data collected in 
real time during the CO2 storage site characterization and sequestration 
processes combined with advanced signal processing and Artificial 
Intelligence and Machine Learning (AI/ML) methodologies provide an 
understanding of natural seismicity risks prior to any CO2 injection, prior 
to making large investments in developing the storage project.",,Artificial Intelligence Unknown,,Department of Energy,"To develop a wireless, distributed data acquisition and interpretation system foe seismic monitoring and carbon storage characterization.: 
Resensys plans to develop a wireless, distributed data acquisition and 
interpretation system tailored for monitoring and characterization of 
seismic activity at carbon storage sites.  The seismicity data collected in 
real time during the CO2 storage site characterization and sequestration 
processes combined with advanced signal processing and Artificial 
Intelligence and Machine Learning (AI/ML) methodologies provide an 
understanding of natural seismicity risks prior to any CO2 injection, prior 
to making large investments in developing the storage project.","Resensys is working on a wireless data system that will monitor and interpret seismic activity at carbon storage sites in real time. By using advanced signal processing and AI/ML techniques, this system will help assess the risks of natural seismicity before any CO2 injection, saving time and money in developing the storage project.","Resensys is working on a wireless data system that will monitor and interpret seismic activity at carbon storage sites in real time. By using advanced signal processing and AI/ML techniques, this system will help assess the risks of natural seismicity before any CO2 injection, saving time and money in developing the storage project.","Yes, the project described above is potentially a safety risk. The project involves the monitoring and interpretation of seismic activity at carbon storage sites. If the system fails or provides inaccurate information, it could lead to the injection of CO2 in an unsafe manner, potentially resulting in leaks or other hazards. Additionally, the use of advanced signal processing and AI/ML techniques introduces the possibility of technical failures or errors in the interpretation of data, which could also pose risks to safety.",,False,True
VA-0012-2023,VA,,,Machine learning tools to predict outcomes of hospitalized VA patients,"This is an IRB-approved study which aims to examine machine learning approaches to predict health outcomes of VA patients.  It will focus on the prediction of Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.",,,,Department of Veterans Affairs,"Machine learning tools to predict outcomes of hospitalized VA patients: 
This is an IRB-approved study which aims to examine machine learning approaches to predict health outcomes of VA patients.  It will focus on the prediction of Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.","A study has been approved to use machine learning tools to predict health outcomes of VA patients. The study will specifically focus on predicting Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.","A study has been approved to use machine learning tools to predict health outcomes of VA patients. The study will specifically focus on predicting Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection.",,"Yes, the project described above potentially poses a safety risk. According to the defined risks, the project falls under the category of ""Decisions regarding medical devices, medical diagnostic tools, clinical diagnosis and determination of treatment, medical or insurance health-risk assessments, drug-addiction risk assessments and associated access systems, suicide or other violence risk assessment, or mental-health status detection or prevention, systems that flag patients for interventions, public insurance care-allocation systems, or health-insurance cost and underwriting processes.""

Using machine learning tools to predict health outcomes for patients, including Alzheimer's disease, rehospitalization, and Chlostridioides difficile infection, involves making decisions related to clinical diagnosis and treatment. These predictions could potentially influence medical decisions, treatment plans, and allocation of healthcare resources. If the predictions are inaccurate or unreliable, it could lead to inappropriate or harmful interventions, inadequate care, or misallocation of resources, all of which could pose safety risks to the patients involved.

Furthermore, the use of machine learning tools in healthcare introduces the possibility of biases, errors, or unintended consequences in the prediction models. If the algorithms are not properly validated or if they are trained on biased or incomplete data, it could lead to discriminatory or unfair treatment, compromising patient safety and well-being.

Therefore, while the project has the potential to contribute to medical advancements and improve patient care, it must be implemented with caution and rigorous evaluation to mitigate the safety risks associated with making critical decisions based on the predictions generated by machine learning tools.",True,False
DHS-0030-2023,DHS,Immigration and Customs Enforcement,,Mobile Device Analytics,"Mobile Device Analytics (MDA) has been developed to meet the demand on investigators to view and analyze massive amounts of data resulting from court ordered mobile device extractions.  The overarching goal of MDA is to improve the efficacy of agents and analysts in identifying pertinent evidence, relationships, and criminal networks from data extracted from cellular phones. Machine Learning is being developed for object detection (such as firearms, drugs, money, etc.) in photos and videos contained in the data.

This is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",Development and Acquisition,"Machine Learning, Object Detection, Natural Language Processing (NLP)",,Department of Homeland Security,"Mobile Device Analytics: 
Mobile Device Analytics (MDA) has been developed to meet the demand on investigators to view and analyze massive amounts of data resulting from court ordered mobile device extractions.  The overarching goal of MDA is to improve the efficacy of agents and analysts in identifying pertinent evidence, relationships, and criminal networks from data extracted from cellular phones. Machine Learning is being developed for object detection (such as firearms, drugs, money, etc.) in photos and videos contained in the data.

This is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.","Mobile Device Analytics (MDA) has been developed to help investigators analyze large amounts of data extracted from mobile devices following court orders. The goal of MDA is to improve the efficiency of agents and analysts in identifying relevant evidence, relationships, and criminal networks. The project involves developing machine learning for object detection in photos and videos, and is part of the DHS HSI Innovation Lab / RAVEn project, which supports ICE's mission to enforce and investigate violations of U.S. laws.","Mobile Device Analytics (MDA) has been developed to help investigators analyze large amounts of data extracted from mobile devices following court orders. The goal of MDA is to improve the efficiency of agents and analysts in identifying relevant evidence, relationships, and criminal networks. The project involves developing machine learning for object detection in photos and videos, and is part of the DHS HSI Innovation Lab / RAVEn project, which supports ICE's mission to enforce and investigate violations of U.S. laws.",,"Yes, the project is potentially a safety risk. The project involves developing machine learning for object detection in photos and videos, which can be used for law enforcement or surveillance-related purposes. This falls under the category b mentioned in the defined risks, which includes potential risks associated with law enforcement or surveillance-related activities. These activities can have implications on privacy and civil liberties, and if not properly regulated or monitored, can pose a safety risk to individuals.",True,False
HHS-0056-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Performance Metrics Database and Analytics (PMDA),PMDA AI for Anomaly Detection and Correction| Language Interpretation and Translation| Knowledge Management,Initiation,,,Department of Health and Human Services,"Performance Metrics Database and Analytics (PMDA): 
PMDA AI for Anomaly Detection and Correction| Language Interpretation and Translation| Knowledge Management","The Performance Metrics Database and Analytics (PMDA) is an AI system that is capable of detecting and correcting anomalies. It also has features for language interpretation and translation, as well as knowledge management.","The Performance Metrics Database and Analytics (PMDA) is an AI system that is capable of detecting and correcting anomalies. It also has features for language interpretation and translation, as well as knowledge management.",,"Yes, the project described has the potential to be a safety risk. The project involves an AI system that has capabilities for detecting and correcting anomalies, language interpretation and translation, and knowledge management. Although the project description does not explicitly mention any specific risks, the inclusion of AI systems in various domains such as law enforcement, education, healthcare, finance, and government services can introduce safety concerns.

The use of AI for decision-making in areas like law enforcement, education, and government benefits can have significant implications for individuals' rights and privacy. The potential for biases, errors, or misuse of AI algorithms can lead to unfair outcomes, discrimination, or violations of individual rights. For example, if the AI system used in law enforcement or criminal justice decisions is not properly designed or trained, it could result in unjust arrests, biased sentencing, or the denial of fair trial rights.

Similarly, in healthcare, the use of AI systems for clinical diagnosis and treatment decisions raises concerns about accuracy, privacy, and potential harm to patients. If the AI system makes incorrect diagnoses or recommends inappropriate treatments, it could have serious consequences for patient safety and well-being.

Additionally, the project's involvement in language interpretation and translation can introduce risks related to accuracy and potential miscommunication. In critical situations, such as emergency response or legal proceedings, relying solely on AI systems without human verification or oversight could lead to misinterpretation or misunderstanding, potentially endangering individuals involved.

Overall, the project's involvement in various domains and its potential impact on individuals' rights, privacy, and safety indicate that it has the potential to be a safety risk. Proper safeguards, regulations, and oversight should be in place to mitigate these risks and ensure the responsible and ethical use of AI systems.",True,False
DOE-0044-2023,DOE,National Energy Technology Laboratory,,Develop and demonstrate reinforcement learning approach for time-varying control for flexible hydrogen and power production.,"Efforts on IES control will include the development of a dynamic 
optimization-based nonlinear model predictive control (NMPC) 
framework. NMPC approaches for optimizing cell thermal management 
and maximizing IES efficiency under set-point transition will be 
developed for flexible operation. Reinforcement learning (RL) 
approaches will also be developed for optimal control policy selection 
and learning-based adaptive control. There are opportunities for 
improved learning through interaction with the electrolyzer in addition to 
learning from the MPC action. Multi-policy approaches will be developed 
for control, independently by RL or in concert with MPC, or even for 
scheduling the operating policy.  The ultimate goal is to develop 
operational strategies and an NMPC and RL control framework for 
optimizing IES performance under flexible hydrogen and power 
production scenarios, while minimizing physical and chemical 
degradation over long-term operation.",,Other,,Department of Energy,"Develop and demonstrate reinforcement learning approach for time-varying control for flexible hydrogen and power production.: 
Efforts on IES control will include the development of a dynamic 
optimization-based nonlinear model predictive control (NMPC) 
framework. NMPC approaches for optimizing cell thermal management 
and maximizing IES efficiency under set-point transition will be 
developed for flexible operation. Reinforcement learning (RL) 
approaches will also be developed for optimal control policy selection 
and learning-based adaptive control. There are opportunities for 
improved learning through interaction with the electrolyzer in addition to 
learning from the MPC action. Multi-policy approaches will be developed 
for control, independently by RL or in concert with MPC, or even for 
scheduling the operating policy.  The ultimate goal is to develop 
operational strategies and an NMPC and RL control framework for 
optimizing IES performance under flexible hydrogen and power 
production scenarios, while minimizing physical and chemical 
degradation over long-term operation.",The text discusses the development and demonstration of a reinforcement learning approach for time-varying control in flexible hydrogen and power production. This includes the development of a nonlinear model predictive control framework and reinforcement learning approaches for optimal control policy selection and adaptive control. The goal is to optimize the performance of the system while minimizing degradation over long-term operation.,The text discusses the development and demonstration of a reinforcement learning approach for time-varying control in flexible hydrogen and power production. This includes the development of a nonlinear model predictive control framework and reinforcement learning approaches for optimal control policy selection and adaptive control. The goal is to optimize the performance of the system while minimizing degradation over long-term operation.,"Yes, the project is potentially a safety risk. The project involves the development and demonstration of a reinforcement learning approach for time-varying control in flexible hydrogen and power production. This falls under the category of ""the functioning of dams, emergency services, electrical grids or the generation or movement of energy."" Any project related to the control and management of energy systems can pose safety risks if not properly executed. There is a potential for accidents, malfunctions, or failures that could lead to safety hazards, such as fires, explosions, or power outages. Therefore, this project should be carefully monitored and implemented with appropriate safety measures in place.",,False,True
USDA-0037-2023,USDA,USDA,OCIO,Predictive Maintenance Impacts,"Predict impacts of DISC maintenance on infrastructure items.  Utilizes: einblick, mysql, python, linux, tableau",Operation and Management,Machine Learning,,Department of Agriculture,"Predictive Maintenance Impacts: 
Predict impacts of DISC maintenance on infrastructure items.  Utilizes: einblick, mysql, python, linux, tableau","Predictive maintenance is used to forecast the effects of DISC maintenance on infrastructure items. This is done by utilizing various tools such as einblick, mysql, python, linux, and tableau.","Predictive maintenance is used to forecast the effects of DISC maintenance on infrastructure items. This is done by utilizing various tools such as einblick, mysql, python, linux, and tableau.",,"Yes, the project described above is potentially a safety risk. 

The project falls under category h, which includes financial-system access determinations and credit scoring. If the predictive maintenance system is used to determine access to or eligibility for government benefits or services, it could have serious consequences for individuals who are wrongly denied access to essential services.

Additionally, if the infrastructure items being maintained are critical to public safety, such as bridges or power plants, any errors or failures in the predictive maintenance system could result in accidents, injuries, or even loss of life.

Therefore, it is important to carefully evaluate and ensure the accuracy and reliability of the predictive maintenance system to mitigate potential safety risks.",True,False
DOE-0087-2023,DOE,National Energy Technology Laboratory,,To detect leaks and creaks.,"The relevant research has been focused on demonstrating applicability 
of novel machine learning based approaches to two major challenges 
associated with safe management of large-scale geologic CO2 storage 
operations, early detection of leaks (i.e., by detecting small leaks) and 
early detection of induced seismicity (i.e. by detecting small seismic 
signals).",,Artificial Intelligence Unknown,,Department of Energy,"To detect leaks and creaks.: 
The relevant research has been focused on demonstrating applicability 
of novel machine learning based approaches to two major challenges 
associated with safe management of large-scale geologic CO2 storage 
operations, early detection of leaks (i.e., by detecting small leaks) and 
early detection of induced seismicity (i.e. by detecting small seismic 
signals).",Researchers have been studying new machine learning methods to address the two main challenges in managing large-scale geologic CO2 storage operations: detecting small leaks and detecting small seismic signals that may indicate induced seismicity. The research aims to demonstrate the effectiveness of these approaches in ensuring the safe management of such operations.,Researchers have been studying new machine learning methods to address the two main challenges in managing large-scale geologic CO2 storage operations: detecting small leaks and detecting small seismic signals that may indicate induced seismicity. The research aims to demonstrate the effectiveness of these approaches in ensuring the safe management of such operations.,"Yes, the project is potentially a safety risk. The research involves managing large-scale geologic CO2 storage operations, which falls under the category of industrial emissions and environmental impact control processes (category f). If the machine learning methods being studied are not effective in detecting small leaks or small seismic signals, it could pose a risk to the safe management of these operations. Leakage of CO2 can have detrimental effects on the environment and potentially harm human health. Additionally, induced seismicity can lead to earthquakes, which can cause damage to infrastructure and pose a threat to safety. Therefore, the project has the potential to pose safety risks if the research methods are not successful in ensuring the safe management of these operations.",,False,True
HHS-0027-2023,HHS,CDC,NCCDPHP/DNPAO,"Identify walking and bicycling trips in location-based data, including global-positioning system data from smartphone applications","The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is developing machine learning techniques to identify walking and bicycling trips in GPS-based data sources. Inputs would include commercially-available location-based data similar to those used to track community mobility during the COVID-19 pandemic. Outputs could include geocoded data tables, GIS layers, and maps.",Initiation,,,Department of Health and Human Services,"Identify walking and bicycling trips in location-based data, including global-positioning system data from smartphone applications: 
The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is developing machine learning techniques to identify walking and bicycling trips in GPS-based data sources. Inputs would include commercially-available location-based data similar to those used to track community mobility during the COVID-19 pandemic. Outputs could include geocoded data tables, GIS layers, and maps.","The Division of Nutrition, Physical Activity, and Obesity is using machine learning to identify walking and bicycling trips in GPS data, such as smartphone applications. They aim to produce geocoded data tables, GIS layers, and maps from commercially-available location-based data sources.","The Division of Nutrition, Physical Activity, and Obesity is using machine learning to identify walking and bicycling trips in GPS data, such as smartphone applications. They aim to produce geocoded data tables, GIS layers, and maps from commercially-available location-based data sources.",,"Yes, the project is potentially a safety risk. The project involves the use of machine learning to identify walking and bicycling trips in GPS data, which can potentially invade individuals' privacy by monitoring their movements and activities. This can raise concerns about surveillance and the potential for misuse of personal information. Additionally, the project involves the collection and analysis of location-based data, which can pose a risk of data breaches and unauthorized access to sensitive information. Therefore, the project has the potential to compromise individual privacy and safety.",True,False
DOE-0129-2023,DOE,National Energy Technology Laboratory,,To provide combustion performance and emissions optimization through integration of a miniaturized high- temperature multi process monitoring system,"Project will develop control logic for automated control of lignite coal-
fired boiler. Plant operational data will be compared against monitoring 
data to determine when different sensor output from a miniaturized high 
temperature multi-process, high-spatial-resolution monitoring system 
signifies damaging conditions in that region of the boiler, and what 
operational changes can be made to eliminate the damaging condition. 
The control logic will be developed for automated control of soot-blowing 
and other boiler operations",,,,Department of Energy,"To provide combustion performance and emissions optimization through integration of a miniaturized high- temperature multi process monitoring system: 
Project will develop control logic for automated control of lignite coal-
fired boiler. Plant operational data will be compared against monitoring 
data to determine when different sensor output from a miniaturized high 
temperature multi-process, high-spatial-resolution monitoring system 
signifies damaging conditions in that region of the boiler, and what 
operational changes can be made to eliminate the damaging condition. 
The control logic will be developed for automated control of soot-blowing 
and other boiler operations","The project aims to improve combustion performance and reduce emissions by integrating a small, high-temperature multi-process monitoring system. The control logic will be developed to automatically adjust boiler operations based on the data collected, such as initiating soot-blowing to eliminate damaging conditions.","The project aims to improve combustion performance and reduce emissions by integrating a small, high-temperature multi-process monitoring system. The control logic will be developed to automatically adjust boiler operations based on the data collected, such as initiating soot-blowing to eliminate damaging conditions.","Yes, the project is potentially a safety risk. This is because it involves the design, construction, and testing of industrial equipment (the high-temperature multi-process monitoring system) that, if it were to fail, could pose a meaningful risk to safety. Additionally, the project deals with the improvement of combustion performance and reduction of emissions, which may involve the transportation or management of industrial waste or controlled pollutants. Therefore, there is a potential for environmental impact and the transportation of hazardous substances.",,False,True
SSA-0009-2023,SSA,"Office of Disability Determinations, Office of Disability Information Systems",,Intelligent Medical Language Analysis Generation (IMAGEN),"IMAGEN is an IT Modernization Disability Analytics & Disability Decision Support (ADDS) Product that will provide new tools and services to visualize, search and more easily identify relevant clinical content in medical records.  These tools and services will improve the efficiency and consistency of disability determinations and decisions and provide a foundation for machine-based decisional guidance. IMAGEN will transform text to data and enable disability adjudicators to leverage various machine learning technologies like Natural Language Processing (NLP) and predictive analytics and will support other high-priority agency initiatives such as fraud prevention and detection.",,,,Social Security Administration,"Intelligent Medical Language Analysis Generation (IMAGEN): 
IMAGEN is an IT Modernization Disability Analytics & Disability Decision Support (ADDS) Product that will provide new tools and services to visualize, search and more easily identify relevant clinical content in medical records.  These tools and services will improve the efficiency and consistency of disability determinations and decisions and provide a foundation for machine-based decisional guidance. IMAGEN will transform text to data and enable disability adjudicators to leverage various machine learning technologies like Natural Language Processing (NLP) and predictive analytics and will support other high-priority agency initiatives such as fraud prevention and detection.",IMAGEN is an IT Modernization Disability Analytics & Disability Decision Support (ADDS) Product that will enhance the analysis of medical records to improve disability determinations and decisions. It will utilize machine learning technologies like Natural Language Processing (NLP) and predictive analytics to transform text into data and support fraud prevention and detection efforts.,IMAGEN is an IT Modernization Disability Analytics & Disability Decision Support (ADDS) Product that will enhance the analysis of medical records to improve disability determinations and decisions. It will utilize machine learning technologies like Natural Language Processing (NLP) and predictive analytics to transform text into data and support fraud prevention and detection efforts.,,"Yes, the project described above has the potential to be a safety risk. The use of machine learning technologies like Natural Language Processing (NLP) and predictive analytics to analyze medical records and make disability determinations raises concerns about privacy, accuracy, and potential biases. If the algorithms used in the project are not properly trained or validated, they may lead to incorrect disability determinations, resulting in individuals being denied the benefits they are entitled to or receiving benefits they do not qualify for. This can have significant consequences for the well-being and livelihood of the individuals involved. Additionally, the project's focus on fraud prevention and detection raises concerns about the potential for false accusations or the misuse of personal data. Overall, the project's reliance on automated decision-making in a sensitive domain like disability determinations poses safety risks that need to be carefully addressed and mitigated.",True,False
SSA-0003-2023,SSA,"Office of Analytics, Review, and Oversight",,Rep Payee Misuse Model,This model uses machine learning to estimate the probability of resource misuse by representative payees and flag the cases for a technician to examine.,,,,Social Security Administration,"Rep Payee Misuse Model: 
This model uses machine learning to estimate the probability of resource misuse by representative payees and flag the cases for a technician to examine.",The Rep Payee Misuse Model employs machine learning to predict the likelihood of representative payees misusing resources. It then alerts technicians to investigate those specific cases.,The Rep Payee Misuse Model employs machine learning to predict the likelihood of representative payees misusing resources. It then alerts technicians to investigate those specific cases.,,"Yes, the project is potentially a safety risk. The project description falls under category h, which involves decisions regarding loan-allocation processes, financial-system access determinations, credit scoring, determining who is subject to a financial audit, or insurance processes including risk assessments, interest rate determinations, or financial systems that apply penalties. Predicting the likelihood of representative payees misusing resources could potentially lead to incorrect accusations and penalties, affecting the financial well-being of individuals. This could result in harm or injustice if the predictions are not accurate or if the investigation is biased. Therefore, it is important to carefully assess and mitigate the potential safety risks associated with such a project.",True,False
DOE-0005-2023,DOE,Fermi National Accelerator,,High-Velocity AI: Generative Models,"This project has two parts: 1. generating adversarial examples and then 
using domain adaptation and other techniques to improve the 
robustness of AI classification algorithms against those attacks 
(focusing on astrophysics/cosmology applications); 2. using AI 
algorithms to improve the output of low-quality classical simulation 
engines to deliver a high-quality result at high speed.",,"Artificial Intelligence, Big Data, Neural Networks, Hierarchical Generative Model",,Department of Energy,"High-Velocity AI: Generative Models: 
This project has two parts: 1. generating adversarial examples and then 
using domain adaptation and other techniques to improve the 
robustness of AI classification algorithms against those attacks 
(focusing on astrophysics/cosmology applications); 2. using AI 
algorithms to improve the output of low-quality classical simulation 
engines to deliver a high-quality result at high speed.","This project aims to enhance the robustness of AI classification algorithms in astrophysics/cosmology applications by generating adversarial examples and implementing domain adaptation techniques. Additionally, it aims to utilize AI algorithms to enhance the output of low-quality classical simulation engines, enabling high-quality results at a fast pace.","This project aims to enhance the robustness of AI classification algorithms in astrophysics/cosmology applications by generating adversarial examples and implementing domain adaptation techniques. Additionally, it aims to utilize AI algorithms to enhance the output of low-quality classical simulation engines, enabling high-quality results at a fast pace.","Yes, the project has the potential to be a safety risk. According to the given definition of safety risks, the project involves the development and testing of AI algorithms, which fall under the category of industrial equipment, systems, or structures that, if they failed, could pose a meaningful risk to safety (h). Additionally, the project aims to enhance the output of classical simulation engines, which could fall under the category of industrial emissions and environmental impact control processes (f). Therefore, the project has the potential to pose safety risks and should be carefully assessed and managed.",,False,True
HHS-0010-2023,HHS,ASPR,BARDA (DRIVe),Current Health,Continuous monitoring platform and AI algorithm for COVID severity,Operation and Maintenance,,,Department of Health and Human Services,"Current Health: 
Continuous monitoring platform and AI algorithm for COVID severity",Current Health is a platform that provides continuous monitoring and an AI algorithm specifically designed to assess the severity of COVID-19. This platform allows for constant surveillance of patients' health and utilizes artificial intelligence to accurately evaluate the seriousness of their condition related to the virus.,Current Health is a platform that provides continuous monitoring and an AI algorithm specifically designed to assess the severity of COVID-19. This platform allows for constant surveillance of patients' health and utilizes artificial intelligence to accurately evaluate the seriousness of their condition related to the virus.,"Yes, the project is potentially a safety risk. This is because it involves the monitoring and assessment of patients' health related to COVID-19, which falls under the category of healthcare and medical systems. Healthcare systems have the potential to impact the safety and well-being of individuals, and any failure or malfunction in the monitoring or assessment process could have serious consequences for patients' health.",,False,True
DHS-0037-2023,DHS,United States Citizenship and Immigration Services,,Person-Centric Identity Services Deduplication Model,"The vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The de-duplication model, ingests person-centric datasets from various source systems for model training and evaluation purposes. Our dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. 

Critical to the success of PCIS is the entity resolution/deduplication of individual records from various systems of records to create a complete picture of a person. Using machine learning, it is able to identify which case management records belong to the same unique individual with a high degree of confidence. This allows PCIS to pull together a full immigration history for an individual without time-consuming research across multiple disparate systems.

The Deduplication model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The ML models are more resilient to fuzzy matches, and deals with the reality of different data fill rates more reliably.",Operation and Maintenance,Machine Learning,,Department of Homeland Security,"Person-Centric Identity Services Deduplication Model: 
The vision of Person-Centric Identity Services (PCIS) is to be the authoritative source of trusted biographical and biometric information that provides real-time, two-way visibility between services into an individual's comprehensive immigration history and status. The de-duplication model, ingests person-centric datasets from various source systems for model training and evaluation purposes. Our dataset includes biographic information (name, date of birth, Alien #, Social Security #, passport #, etc.) as well as biographic information (fingerprint IDs, eye color, hair color, height, weight, etc.) for model training and matching purposes. 

Critical to the success of PCIS is the entity resolution/deduplication of individual records from various systems of records to create a complete picture of a person. Using machine learning, it is able to identify which case management records belong to the same unique individual with a high degree of confidence. This allows PCIS to pull together a full immigration history for an individual without time-consuming research across multiple disparate systems.

The Deduplication model plays a critical role in the entity resolution and surfacing of a person and all their associated records. The ML models are more resilient to fuzzy matches, and deals with the reality of different data fill rates more reliably.","The Person-Centric Identity Services (PCIS) aims to be the trusted source of biographical and biometric information, allowing real-time access to an individual's immigration history and status. The Deduplication model is crucial in identifying and combining records from various systems, using machine learning to accurately match and consolidate data for a comprehensive view of a person's immigration history.","The Person-Centric Identity Services (PCIS) aims to be the trusted source of biographical and biometric information, allowing real-time access to an individual's immigration history and status. The Deduplication model is crucial in identifying and combining records from various systems, using machine learning to accurately match and consolidate data for a comprehensive view of a person's immigration history.",,"Yes, the project described above is potentially a safety risk. 

The project involves the use of biographical and biometric information for real-time access to an individual's immigration history and status. This raises concerns about privacy and potential misuse of personal data. The project also mentions the use of machine learning for data matching and consolidation, which can introduce the risk of algorithmic bias and discrimination.

Additionally, the project involves making decisions regarding access to government benefits or services based on biometrics or other means. This raises concerns about fairness and potential errors in the decision-making process.

Overall, the project has the potential to impact individuals' privacy, rights, and access to services, making it a safety risk.",True,False
HHS-0104-2023,HHS,FDA,NCTR,Informing selection of drugs for COVID-19 treatment by big data analytics and artificial intelligence,"The pandemic of COVID-19 is the biggest global health concern currently. As of July 11, 2020, more than 12 million people have been tested positive of SARS-COV-2 virus infection and more than half million deaths have been caused by COVID-19 in the world. Currently, no vaccines and/or drugs have been proved to be effective to treat COVID-19. Therefore, many drug products on the market are being repurposed for the treatment of COVID-19. However, sufficient evidence is needed to determine that the repurposed drugs are safe and effective. Therefore, safety information on the drugs  selected for repurposing purpose is important. The proposed project aims to mine adverse drug events using artificial intelligence and big data analytics in the public domain including the agency's database, public databases, and social media data for the drugs to be repurposed for the treatment of COVID-19. The ultimate goal of this project is to provide detailed adverse event information that can be used to facilitate safety evaluation for drugs repurposed for the treatment COVID-19. The detailed adverse event information will be used to develop recommendations for selecting the right drugs for repurposing efforts and for help select the appropriate COVID-19 patients and thus better to combat the pandemic.",Implementation,,,Department of Health and Human Services,"Informing selection of drugs for COVID-19 treatment by big data analytics and artificial intelligence: 
The pandemic of COVID-19 is the biggest global health concern currently. As of July 11, 2020, more than 12 million people have been tested positive of SARS-COV-2 virus infection and more than half million deaths have been caused by COVID-19 in the world. Currently, no vaccines and/or drugs have been proved to be effective to treat COVID-19. Therefore, many drug products on the market are being repurposed for the treatment of COVID-19. However, sufficient evidence is needed to determine that the repurposed drugs are safe and effective. Therefore, safety information on the drugs  selected for repurposing purpose is important. The proposed project aims to mine adverse drug events using artificial intelligence and big data analytics in the public domain including the agency's database, public databases, and social media data for the drugs to be repurposed for the treatment of COVID-19. The ultimate goal of this project is to provide detailed adverse event information that can be used to facilitate safety evaluation for drugs repurposed for the treatment COVID-19. The detailed adverse event information will be used to develop recommendations for selecting the right drugs for repurposing efforts and for help select the appropriate COVID-19 patients and thus better to combat the pandemic.","This text discusses the need to find safe and effective drugs for the treatment of COVID-19. Currently, many drugs are being repurposed, but more evidence is needed to determine their safety and efficacy. The proposed project aims to use artificial intelligence and big data analytics to mine adverse drug events and provide detailed information that can be used to evaluate the safety of repurposed drugs and select the right drugs for COVID-19 treatment.","This text discusses the need to find safe and effective drugs for the treatment of COVID-19. Currently, many drugs are being repurposed, but more evidence is needed to determine their safety and efficacy. The proposed project aims to use artificial intelligence and big data analytics to mine adverse drug events and provide detailed information that can be used to evaluate the safety of repurposed drugs and select the right drugs for COVID-19 treatment.",,"Yes, the project is potentially a safety risk. The project involves using artificial intelligence and big data analytics to mine adverse drug events and evaluate the safety of repurposed drugs for COVID-19 treatment. This falls under the category of medical diagnostic tools, clinical diagnosis, and determination of treatment, which is mentioned as a potential safety risk in the given list of risks. The use of artificial intelligence and big data analytics in this context can have implications for patient safety and the effectiveness of treatment. Therefore, a thorough evaluation and consideration of potential risks and ethical concerns should be undertaken before implementing such a project.",True,False
DOE-0168-2023,DOE,Pacific Northwest National Laboratory,,APT Analytics,Development of AI/ML for automated analysis of APT data.,,,,Department of Energy,"APT Analytics: 
Development of AI/ML for automated analysis of APT data.",APT Analytics is focused on creating artificial intelligence and machine learning technology to automate the analysis of advanced persistent threat (APT) data. Their goal is to develop innovative solutions that can efficiently process and interpret APT data without human intervention.,APT Analytics is focused on creating artificial intelligence and machine learning technology to automate the analysis of advanced persistent threat (APT) data. Their goal is to develop innovative solutions that can efficiently process and interpret APT data without human intervention.,,"Yes, the project is potentially a safety risk. The project involves the development of artificial intelligence and machine learning technology to automate the analysis of advanced persistent threat (APT) data without human intervention. This could lead to decisions being made based solely on the algorithms and models developed, without proper human oversight or intervention.

The potential risks are present in several areas defined in the project description. For example, in the area of law enforcement or surveillance-related risk assessments, if decisions regarding individuals and criminal recidivism prediction are solely made by the AI system, there is a risk of biased or incorrect assessments that could impact the rights and freedoms of individuals.

Additionally, in the area of medical diagnosis and treatment, if the AI system is solely responsible for determining diagnosis and treatment options, there is a risk of incorrect or inadequate decisions that could potentially harm patients.

Furthermore, in the area of financial systems and access determinations, if the AI system is solely responsible for making decisions regarding loan allocations, credit scoring, or insurance processes, there is a risk of unfair or biased decisions that could have significant financial and personal consequences for individuals.

Overall, the lack of human intervention and oversight in the project's goal of automating the analysis of APT data raises concerns about the potential safety risks associated with relying solely on artificial intelligence and machine learning technologies for critical decision-making processes.",True,False
DHS-0002-2023,DHS,Customs and Border Protection,,Automated Item of Interest Detection - ICAD,"The software analyzes photographs that are taken by field imaging equipment, which are then fed into the ICAD system for review by USBP agents and personnel. The Matroid software currently processes and annotates images using proprietary software to determine if any of the images contain human subjects.

Matroid is the name of the Video Computer Aided Detection system used by CBP. It uses trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. 

The intent for the ICAD system is to expand the models used to vehicles, and subjects with long-arm rifles, while excluding items of little or no interest such as animals.",Operation and Maintenance,Machine Learning,,Department of Homeland Security,"Automated Item of Interest Detection - ICAD: 
The software analyzes photographs that are taken by field imaging equipment, which are then fed into the ICAD system for review by USBP agents and personnel. The Matroid software currently processes and annotates images using proprietary software to determine if any of the images contain human subjects.

Matroid is the name of the Video Computer Aided Detection system used by CBP. It uses trained computer vision models that recognize objects, people, and events in any image or video stream. Once a detector is trained, it can monitor streaming video in real time, or efficiently search through pre-recorded video data or images to identify objects, people, and events of interest. 

The intent for the ICAD system is to expand the models used to vehicles, and subjects with long-arm rifles, while excluding items of little or no interest such as animals.","The ICAD system is a software used by USBP agents to analyze photographs taken by field imaging equipment. It uses the Matroid software to determine if any of the images contain human subjects. The goal is to expand the system's models to include vehicles and subjects with long-arm rifles, while excluding animals or items of little interest.","The ICAD system is a software used by USBP agents to analyze photographs taken by field imaging equipment. It uses the Matroid software to determine if any of the images contain human subjects. The goal is to expand the system's models to include vehicles and subjects with long-arm rifles, while excluding animals or items of little interest.",,"Yes, the project below is potentially a safety risk. 

The project involves the use of the ICAD system, which is a software used by USBP (United States Border Patrol) agents to analyze photographs taken by field imaging equipment. The software uses the Matroid software to determine if any of the images contain human subjects. The goal of the project is to expand the system's models to include vehicles and subjects with long-arm rifles, while excluding animals or items of little interest.

The potential safety risk arises from the fact that the project falls under the category of ""Law enforcement or surveillance-related risk assessments about individuals"" mentioned in the defined risks. These risk assessments can have significant implications on individuals' rights, privacy, and potentially even their safety. The use of such technology for decision-making, especially in the context of law enforcement, can result in biased or unjust outcomes, infringing on civil liberties and potentially causing harm.

Additionally, the use of facial matching and the detection of emotions, thoughts, or deception in humans (mentioned in the defined risks) raises concerns about privacy invasion and the potential for misuse or abuse of such data. If the ICAD system is used to make decisions regarding law enforcement actions or interventions, there is a risk of unfair targeting or profiling based on the analysis results.

Therefore, considering the potential risks to individual rights, privacy, and the potential for biased outcomes, the project can be considered a safety risk.",True,False
DOE-0167-2023,DOE,Pacific Northwest National Laboratory,,AI used for predictive modeling and real time control of traffic systems,"Domain aware deep learning models are used for predictive modeling of 
traffic. Deep learning based predictive controllers are trained from 
simulated data to optimize the traffic signaling and coordination for 
improved traffic flow and reduced energy consumption and GHG 
emissions",,,,Department of Energy,"AI used for predictive modeling and real time control of traffic systems: 
Domain aware deep learning models are used for predictive modeling of 
traffic. Deep learning based predictive controllers are trained from 
simulated data to optimize the traffic signaling and coordination for 
improved traffic flow and reduced energy consumption and GHG 
emissions","AI is being utilized to predict traffic patterns and control traffic systems in real-time. Deep learning models are employed to make accurate predictions about traffic and optimize traffic signaling and coordination, leading to better traffic flow and reduced energy consumption and greenhouse gas emissions.","AI is being utilized to predict traffic patterns and control traffic systems in real-time. Deep learning models are employed to make accurate predictions about traffic and optimize traffic signaling and coordination, leading to better traffic flow and reduced energy consumption and greenhouse gas emissions.","Yes, the project described above is potentially a safety risk. 

The project falls under the category of ""systems controlling physical transit"" mentioned in the safety risks. Any project that involves controlling traffic systems, especially in real-time, has the potential to impact the safety of the people using the transportation infrastructure.

If the AI system controlling traffic signals and coordination malfunctions or makes incorrect predictions, it can lead to traffic accidents, congestion, and potential harm to individuals. For example, if the AI system fails to accurately predict traffic patterns or coordinate traffic signals, it may cause collisions or create dangerous situations on the roads.

Additionally, if the project involves physical movements within transportation systems, such as controlling autonomous vehicles, there is an added risk of accidents or malfunctions that can result in harm to passengers, pedestrians, or other vehicles on the road.

Therefore, due to the potential safety risks associated with controlling traffic systems and physical movements, this project should be carefully monitored and tested to ensure the safety of the public.",,False,True
DOT-0000-2023,DOT,ANG,,Remote Oceanic Meteorological Information Operations (ROMIO),"ROMIO is an operational demonstration to evaluate the feasibility to uplink convective weather information to aircraft operating over the ocean and remote regions. Capability converted weather satellite data, lightning and weather prediction model data into areas of thunderstorm activity and cloud top heights. AI is used to improve the accuracy of the output based on previous activity compared to ground truth data.",Technical transfer of capability to industry planned this summer.,"AI, ML via a Convolutional Neural Network",,Department of Transportation,"Remote Oceanic Meteorological Information Operations (ROMIO): 
ROMIO is an operational demonstration to evaluate the feasibility to uplink convective weather information to aircraft operating over the ocean and remote regions. Capability converted weather satellite data, lightning and weather prediction model data into areas of thunderstorm activity and cloud top heights. AI is used to improve the accuracy of the output based on previous activity compared to ground truth data.","ROMIO is an operational demonstration that assesses the possibility of sending convective weather information to aircraft in remote oceanic regions. It utilizes converted weather satellite data, lightning, and weather prediction model data to identify areas of thunderstorm activity and cloud top heights. Additionally, AI is employed to enhance the accuracy of the output by comparing past activity with ground truth data.","ROMIO is an operational demonstration that assesses the possibility of sending convective weather information to aircraft in remote oceanic regions. It utilizes converted weather satellite data, lightning, and weather prediction model data to identify areas of thunderstorm activity and cloud top heights. Additionally, AI is employed to enhance the accuracy of the output by comparing past activity with ground truth data.","Yes, the project described above is potentially a safety risk. 

The project involves the transmission of weather information to aircraft in remote oceanic regions. This falls under the category of ""physical movements"" within the transportation setting (b). If the weather information transmitted is inaccurate or unreliable, it can pose a safety risk to the aircraft and its passengers.

Furthermore, the project utilizes data from weather satellites, lightning, and weather prediction models (a). If there are errors or malfunctions in these data sources, it can lead to incorrect weather information being provided to the aircraft, potentially endangering their safety.

Overall, while the project aims to enhance the accuracy of weather information using AI, any flaws or failures in the system can result in safety risks for the aircraft and its occupants. Therefore, it is important to carefully assess and mitigate these risks to ensure the safety of the project.",,False,True
DOE-0133-2023,DOE,National Energy Technology Laboratory,,To realize next generation solid-state power substation.,"The objective of the proposed project is to realize next generation solid-
state power substation (SSPS) incorporating machine learning, cyber-
physical anomaly detection, and multi-agent distributed networked 
control. The project will have the following capabilities: distributed control 
and coordination coupled with localized intelligence and sensing, 
autonomous control for plug-and-play, automatic reconfiguration, 
recovery, and restoration enabling decoupled, asynchronous, and fractal 
systems.",,Artificial Intelligence Unknown,,Department of Energy,"To realize next generation solid-state power substation.: 
The objective of the proposed project is to realize next generation solid-
state power substation (SSPS) incorporating machine learning, cyber-
physical anomaly detection, and multi-agent distributed networked 
control. The project will have the following capabilities: distributed control 
and coordination coupled with localized intelligence and sensing, 
autonomous control for plug-and-play, automatic reconfiguration, 
recovery, and restoration enabling decoupled, asynchronous, and fractal 
systems.","The proposed project aims to create a next generation solid-state power substation that incorporates machine learning, cyber-physical anomaly detection, and multi-agent distributed networked control. The project will enable distributed control and coordination, autonomous control for plug-and-play, automatic reconfiguration, recovery, and restoration, allowing for decoupled, asynchronous, and fractal systems.","The proposed project aims to create a next generation solid-state power substation that incorporates machine learning, cyber-physical anomaly detection, and multi-agent distributed networked control. The project will enable distributed control and coordination, autonomous control for plug-and-play, automatic reconfiguration, recovery, and restoration, allowing for decoupled, asynchronous, and fractal systems.","Yes, the project described potentially poses a safety risk. This is because it involves the design, construction, and testing of industrial equipment (the solid-state power substation) that, if it were to fail, could pose a meaningful risk to safety (as stated in risk category h). Additionally, the incorporation of machine learning, cyber-physical anomaly detection, and multi-agent distributed networked control introduces complexities and potential vulnerabilities in the control and coordination of the power substation, which could further increase the safety risks.",,False,True
DOC-0012-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,FathomNet,"FathomNet provides much-needed training data (e.g., annotated, and localized imagery) 
for developing machine learning algorithms that will enable fast, sophisticated analysis of 
visual data. We've utilized interns and college class curriculums to localize annotations on 
NOAA video data for inclusion in FathomNet and to begin training our own algorithms.",,,,Department of Commerce,"FathomNet: 
FathomNet provides much-needed training data (e.g., annotated, and localized imagery) 
for developing machine learning algorithms that will enable fast, sophisticated analysis of 
visual data. We've utilized interns and college class curriculums to localize annotations on 
NOAA video data for inclusion in FathomNet and to begin training our own algorithms.","FathomNet offers training data, including annotated and localized imagery, for the development of machine learning algorithms. They have employed interns and incorporated college class curriculums to localize annotations on NOAA video data and train their own algorithms.","FathomNet offers training data, including annotated and localized imagery, for the development of machine learning algorithms. They have employed interns and incorporated college class curriculums to localize annotations on NOAA video data and train their own algorithms.",,"Yes, the project described has the potential to be a safety risk. The project involves the development of machine learning algorithms using annotated and localized imagery. While the project description itself does not explicitly mention any risks, the nature of the project suggests that it could be used in various applications, some of which fall within the defined risks.

For example, if the developed algorithms are utilized in surveillance systems, law enforcement, or facial recognition technology, they could potentially infringe on privacy rights and be subject to misuse or abuse. Additionally, if the algorithms are used in medical diagnosis or mental health assessment, there is a risk of incorrect or biased outcomes which could lead to incorrect treatments or interventions.

Without more specific information about how the trained algorithms will be used and implemented, it is difficult to assess the full extent of the safety risks associated with this project. However, based on the defined risks and the potential applications of the machine learning algorithms, it is reasonable to consider the project as potentially a safety risk.",True,False
DOE-0102-2023,DOE,National Energy Technology Laboratory,,To develop innovative biomonitoring and remediation of heavy metals using phytotechnologies.,"The objective of the work is to utilize algal- and cyanobacterial-based 
phycotechnologies to address pervasive heavy metal contamination 
from coal combustion product (CCP) impoundments at the Savannah 
River Site. Novel bioindicators will be developed to gauge the potential 
for phytoremediation to restore legacy impoundment sites.",,Artificial Intelligence Unknown,,Department of Energy,"To develop innovative biomonitoring and remediation of heavy metals using phytotechnologies.: 
The objective of the work is to utilize algal- and cyanobacterial-based 
phycotechnologies to address pervasive heavy metal contamination 
from coal combustion product (CCP) impoundments at the Savannah 
River Site. Novel bioindicators will be developed to gauge the potential 
for phytoremediation to restore legacy impoundment sites.",The goal of this project is to use algal and cyanobacterial phycotechnologies to tackle heavy metal pollution caused by coal combustion. The project aims to develop new bioindicators that can assess the potential of phytoremediation to restore contaminated sites.,The goal of this project is to use algal and cyanobacterial phycotechnologies to tackle heavy metal pollution caused by coal combustion. The project aims to develop new bioindicators that can assess the potential of phytoremediation to restore contaminated sites.,"Yes, the project is potentially a safety risk. 

The project involves the transport, safety, design, and development of hazardous chemicals or biological entities, which falls under the defined safety risks. The use of algal and cyanobacterial phycotechnologies to tackle heavy metal pollution caused by coal combustion could potentially involve the handling and transportation of hazardous materials. There is a risk of exposure to these hazardous chemicals, which could pose a threat to the safety of individuals involved in the project or those living in the surrounding areas.

Additionally, the project aims to develop new bioindicators that can assess the potential of phytoremediation to restore contaminated sites. The testing and evaluation of these bioindicators could involve the design, construction, or testing of industrial equipment or systems. If any of these components fail, it could pose a meaningful risk to safety.

Therefore, due to the involvement of hazardous chemicals and potential risks in the design and testing phases, the project is potentially a safety risk.",,False,True
TREAS-0007-2023,TREAS,,,Inventory Item Replenishment MLR Modeling Pilot - Phase 1b,"The Bureau of Engraving and Printing wanted to establish a proof of 
concept (POC) for Predictive Analytics at the BEP. This POC consisted of 
developing a Logistic Regression model for the Office of Supply Chain 
Management (OSCM), to predict whether an item would be delivered by 
the specified ""Need by Date"". This is the date that the BEP needs the 
material in its facility and is set automatically to 128 days when a purchase 
order (PO) is approved in the system. The model utilizes historical 
requisition, vendor, and item specific data to come up with binary (0 or 1) 
predictions, which are then used to determine whether an item will be 
delivered on-time or if the OSCM should expect a delay. If the model 
outputs a 1, we expect that the item will be delayed and the OSCM can be 
proactive in their decision making to prepare for a potential inventory 
shortage.",Development and Acquisition,,,Department of Treasury,"Inventory Item Replenishment MLR Modeling Pilot - Phase 1b: 
The Bureau of Engraving and Printing wanted to establish a proof of 
concept (POC) for Predictive Analytics at the BEP. This POC consisted of 
developing a Logistic Regression model for the Office of Supply Chain 
Management (OSCM), to predict whether an item would be delivered by 
the specified ""Need by Date"". This is the date that the BEP needs the 
material in its facility and is set automatically to 128 days when a purchase 
order (PO) is approved in the system. The model utilizes historical 
requisition, vendor, and item specific data to come up with binary (0 or 1) 
predictions, which are then used to determine whether an item will be 
delivered on-time or if the OSCM should expect a delay. If the model 
outputs a 1, we expect that the item will be delayed and the OSCM can be 
proactive in their decision making to prepare for a potential inventory 
shortage.","In order to demonstrate the effectiveness of predictive analytics, the Bureau of Engraving and Printing developed a Logistic Regression model to predict whether items would be delivered by the specified ""Need by Date"". By analyzing historical data, the model provides binary predictions that determine whether an item will be delivered on-time or if there will be a delay, allowing the Office of Supply Chain Management to make proactive decisions to prevent inventory shortages.","In order to demonstrate the effectiveness of predictive analytics, the Bureau of Engraving and Printing developed a Logistic Regression model to predict whether items would be delivered by the specified ""Need by Date"". By analyzing historical data, the model provides binary predictions that determine whether an item will be delivered on-time or if there will be a delay, allowing the Office of Supply Chain Management to make proactive decisions to prevent inventory shortages.",,"Yes, the project described potentially poses a safety risk. The project involves using predictive analytics to determine whether items will be delivered on time or if there will be a delay. While this may seem like a harmless application, it falls under the category of ""determining access to educational resources or programs"" as mentioned in the defined risks.

If the Office of Supply Chain Management relies solely on this predictive model to make proactive decisions, there is a risk of inventory shortages if the model inaccurately predicts delays. Inventory shortages can have serious consequences, especially in critical sectors such as healthcare or emergency supplies.

Therefore, the project has the potential to impact the availability of essential resources, which could indirectly affect the safety and well-being of individuals who rely on those resources.",True,False
HHS-0044-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Fraud Prevention System Alert Summary Report Priority Score,"This model will use Medicare administrative, claims, and fraud alert and investigations data to predict the likelihood of an investigation leading to an administrative action (positive outcome), supporting CMS in prioritizing their use of investigations resources. This analysis is still in development and the final model type has not been determined yet.",Development and Acquisition,,,Department of Health and Human Services,"Fraud Prevention System Alert Summary Report Priority Score: 
This model will use Medicare administrative, claims, and fraud alert and investigations data to predict the likelihood of an investigation leading to an administrative action (positive outcome), supporting CMS in prioritizing their use of investigations resources. This analysis is still in development and the final model type has not been determined yet.","The Fraud Prevention System Alert Summary Report Priority Score is a model that utilizes various data sources to predict the probability of an investigation resulting in an administrative action. Its purpose is to assist CMS in effectively allocating investigation resources. However, the final model type is still under development and has not been finalized.","The Fraud Prevention System Alert Summary Report Priority Score is a model that utilizes various data sources to predict the probability of an investigation resulting in an administrative action. Its purpose is to assist CMS in effectively allocating investigation resources. However, the final model type is still under development and has not been finalized.",,"Yes, the project is potentially a safety risk. 

The project involves making decisions regarding access to government benefits or services, detecting fraud, and assigning penalties in the context of federal benefits. These decisions can have significant consequences for individuals, including loss of access to benefits or penalties being applied. If the model used to make these decisions is not accurately predicting the probability of an investigation resulting in an administrative action, it could lead to unfair or incorrect allocation of resources and unjust outcomes for individuals. This has the potential to harm individuals who are wrongly denied benefits or unfairly penalized. Therefore, there is a safety risk associated with this project.",True,False
DOE-0119-2023,DOE,National Energy Technology Laboratory,,To implement machine learning to predict aerodynamic and combustion characteristics in hydrogen turbine,"Design rules and reduced models will be formulated by combining high 
fidelity simulations of chemically reacting flow, stochastic modeling 
techniques, reduced modeling through machine learning and testing of 
injector configurations. These can be used in an industrial setting to 
predict the aerodynamic and combustion characteristics in hydrogen 
turbine combustors based upon which design decisions are made.",,Artificial Intelligence Unknown,,Department of Energy,"To implement machine learning to predict aerodynamic and combustion characteristics in hydrogen turbine: 
Design rules and reduced models will be formulated by combining high 
fidelity simulations of chemically reacting flow, stochastic modeling 
techniques, reduced modeling through machine learning and testing of 
injector configurations. These can be used in an industrial setting to 
predict the aerodynamic and combustion characteristics in hydrogen 
turbine combustors based upon which design decisions are made.","The text states that machine learning will be used to predict aerodynamic and combustion characteristics in hydrogen turbines. This will be achieved by combining high fidelity simulations, stochastic modeling, reduced modeling through machine learning, and testing of injector configurations. These predictions can then be used in an industrial setting to make design decisions for hydrogen turbine combustors.","The text states that machine learning will be used to predict aerodynamic and combustion characteristics in hydrogen turbines. This will be achieved by combining high fidelity simulations, stochastic modeling, reduced modeling through machine learning, and testing of injector configurations. These predictions can then be used in an industrial setting to make design decisions for hydrogen turbine combustors.","Yes, this project is potentially a safety risk. 

According to the defined risks, this project falls under risk category f: Industrial emissions and environmental impact control processes. The use of hydrogen in turbines raises concerns regarding emissions and environmental impact, as hydrogen combustion can produce harmful byproducts and contribute to air pollution.

In addition, the project involves testing of injector configurations, which can potentially lead to physical movements and interactions within an industrial setting (risk category b). These movements and interactions can pose safety risks to workers and equipment.

Therefore, considering the potential environmental impact and safety risks involved in the project, it can be classified as a potential safety risk.",,False,True
DHS-0027-2023,DHS,Immigration and Customs Enforcement,,Normalization Services,"HSI uses Artificial Intelligence to verify, validate, correct, and normalize addresses, phone numbers, names, and ID numbers to streamline the process of correcting data entry errors, point out purposeful misidentification, connect information about a person across HSI datasets, and cut down the number of resource hours needed for investigations. 

Examples of the normalization services provided include: normalizing less well-defined addresses into usable addresses for analysis- (such as those using mile markers instead of a street number); inferring ID type based on user-provided ID value (such as distinguishing a SSN from a DL number without additional context); categorizing name parts while taking into account additional factors (including generational suffixes and multi-part family names); and validating and normalizing phone numbers to the E164 standard, including their identified county of origin.

These services are provided as part of the Repository for Analytics in a Virtualized Environment (RAVEn).  RAVEn is a DHS HSI Innovation Lab project that facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",Operation and Maintenance,Machine Learning,,Department of Homeland Security,"Normalization Services: 
HSI uses Artificial Intelligence to verify, validate, correct, and normalize addresses, phone numbers, names, and ID numbers to streamline the process of correcting data entry errors, point out purposeful misidentification, connect information about a person across HSI datasets, and cut down the number of resource hours needed for investigations. 

Examples of the normalization services provided include: normalizing less well-defined addresses into usable addresses for analysis- (such as those using mile markers instead of a street number); inferring ID type based on user-provided ID value (such as distinguishing a SSN from a DL number without additional context); categorizing name parts while taking into account additional factors (including generational suffixes and multi-part family names); and validating and normalizing phone numbers to the E164 standard, including their identified county of origin.

These services are provided as part of the Repository for Analytics in a Virtualized Environment (RAVEn).  RAVEn is a DHS HSI Innovation Lab project that facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.","HSI uses Artificial Intelligence to normalize and validate addresses, phone numbers, names, and ID numbers. This helps to correct data entry errors, identify purposeful misidentification, connect information across datasets, and reduce the time and resources needed for investigations. These services are provided through RAVEn, a project that supports ICE's mission to enforce and investigate violations of U.S. laws and analyze trends and criminal patterns.","HSI uses Artificial Intelligence to normalize and validate addresses, phone numbers, names, and ID numbers. This helps to correct data entry errors, identify purposeful misidentification, connect information across datasets, and reduce the time and resources needed for investigations. These services are provided through RAVEn, a project that supports ICE's mission to enforce and investigate violations of U.S. laws and analyze trends and criminal patterns.",,"Yes, the project described is potentially a safety risk. The project involves using Artificial Intelligence to normalize and validate personal information such as addresses, phone numbers, names, and ID numbers. This can raise concerns about privacy and data security. The use of this technology by law enforcement agencies like ICE may infringe on individuals' rights and lead to potential abuses of power. Additionally, the project's focus on enforcing and investigating violations of U.S. laws and analyzing criminal patterns raises concerns about the potential for biased or discriminatory practices. Overall, the project poses safety risks related to privacy, data security, and potential misuse of personal information.",True,False
DOE-0078-2023,DOE,National Energy Technology Laboratory,,"To automate RDE image analysis, machine learning for RDE image analysis is being employed.","The expected outcome of this project will be extensive experimental 
data that can provide valuable insight in RDC design, coupling RDC with 
turbomachinery, model validation, and next generation combustion 
sensors that use artificial intelligence and computer vision.         Design 
of an optimized inlet to maximize pressure gain in an RDE relies on an 
understanding of the coupling between the inlet plenums (fuel and air), 
the combustor annular channel, and the exhaust diffusor. This creates a 
challenge for CFD as the models are significant and computationally 
expensive. NETL is continuing a collaboration with the University of 
Michigan to accelerate reacting flow CFD modeling using machine 
learning (ML).",,Other,,Department of Energy,"To automate RDE image analysis, machine learning for RDE image analysis is being employed.: 
The expected outcome of this project will be extensive experimental 
data that can provide valuable insight in RDC design, coupling RDC with 
turbomachinery, model validation, and next generation combustion 
sensors that use artificial intelligence and computer vision.         Design 
of an optimized inlet to maximize pressure gain in an RDE relies on an 
understanding of the coupling between the inlet plenums (fuel and air), 
the combustor annular channel, and the exhaust diffusor. This creates a 
challenge for CFD as the models are significant and computationally 
expensive. NETL is continuing a collaboration with the University of 
Michigan to accelerate reacting flow CFD modeling using machine 
learning (ML).","The project aims to use machine learning for RDE image analysis, which will generate experimental data for insights in RDC design, turbomachinery coupling, model validation, and combustion sensors. NETL is collaborating with the University of Michigan to utilize machine learning in order to accelerate reacting flow CFD modeling and overcome the computational challenges posed by the complex coupling in RDE design.","The project aims to use machine learning for RDE image analysis, which will generate experimental data for insights in RDC design, turbomachinery coupling, model validation, and combustion sensors. NETL is collaborating with the University of Michigan to utilize machine learning in order to accelerate reacting flow CFD modeling and overcome the computational challenges posed by the complex coupling in RDE design.","Yes, the project described potentially involves safety risks. The project focuses on using machine learning for RDE (Rotating Detonation Engine) image analysis, which involves the design and development of combustion engines. Combustion engines have inherent safety risks, including the potential for explosions, fires, and release of hazardous chemicals. Additionally, the project mentions the need for model validation and combustion sensors, which are key components in ensuring the safe operation of combustion systems. Therefore, the project's involvement in the design and development of combustion engines and the potential risks associated with it make it potentially a safety risk.",,False,True
USDA-0017-2023,USDA,USDA,Federal CDO Council,OCIO/CDO Council Comment Analysis Tool,"The Comment Analysis pilot has shown that a toolset leveraging recent advances in Natural Language Processing (NLP) can aid the regulatory comment analysis process. We developed tools that help comment reviewers identify the topics and themes of comments, as well as group comments that are semantically similar. Tools like these offer significant value by creating efficiencies through novel insights and streamlined processing of comments, reducing duplicative, upfront development efforts across government, and ultimately realizing cost savings for agencies and the USG. 
",Development and Acquisition,Natural Language Processing,https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fkenambrose-GSA%2FCDO-Council-Public-Comment-Analysis-Project.git&data=04%7C01%7C%7Cae1c2e505f5f4cb50f0e08d9453f6ede%7Ced5b36e701ee4ebc867ee03cfa0d4697%7C0%7C0%7C637616961007063,Department of Agriculture,"OCIO/CDO Council Comment Analysis Tool: 
The Comment Analysis pilot has shown that a toolset leveraging recent advances in Natural Language Processing (NLP) can aid the regulatory comment analysis process. We developed tools that help comment reviewers identify the topics and themes of comments, as well as group comments that are semantically similar. Tools like these offer significant value by creating efficiencies through novel insights and streamlined processing of comments, reducing duplicative, upfront development efforts across government, and ultimately realizing cost savings for agencies and the USG. 
","The Comment Analysis Tool, developed by the OCIO/CDO Council, utilizes Natural Language Processing (NLP) to assist in regulatory comment analysis. This toolset helps reviewers identify comment topics and themes, as well as group similar comments together. By providing novel insights and streamlining the comment processing process, these tools offer significant value by reducing duplicate efforts and ultimately saving costs for government agencies and the USG.","The Comment Analysis Tool, developed by the OCIO/CDO Council, utilizes Natural Language Processing (NLP) to assist in regulatory comment analysis. This toolset helps reviewers identify comment topics and themes, as well as group similar comments together. By providing novel insights and streamlining the comment processing process, these tools offer significant value by reducing duplicate efforts and ultimately saving costs for government agencies and the USG.",,"Yes, the project described is potentially a safety risk. This is because the project involves the use of Natural Language Processing (NLP) to analyze comments and potentially make decisions or recommendations in various domains, including law enforcement, education, employment, healthcare, and government benefits. These decisions and recommendations have the potential to impact individuals' rights, liberties, and access to resources and services.

The use of NLP algorithms to analyze and process comments raises concerns about privacy, accuracy, fairness, and potential biases. There is a risk of misinterpretation or misclassification of comments, leading to incorrect decisions or recommendations. Additionally, the use of such tools in critical areas like law enforcement, healthcare, and child welfare raises ethical and legal concerns.

Moreover, the project's broad scope and potential impact on various aspects of individuals' lives make it crucial to ensure transparency, accountability, and robust safeguards to prevent potential misuse or abuse. Without adequate oversight and safeguards, the project may pose a safety risk by infringing on individuals' rights, perpetuating discrimination, or compromising privacy and security.",True,False
DOE-0104-2023,DOE,National Energy Technology Laboratory,,"To drive insights on emissions from natural gas production, storage, and transmission to determine how best to reduce emissions","AI/ML will be used to recognice patterns in well integrity records that 
could predict failure events",,"Big Data, Other",,Department of Energy,"To drive insights on emissions from natural gas production, storage, and transmission to determine how best to reduce emissions: 
AI/ML will be used to recognice patterns in well integrity records that 
could predict failure events","Artificial intelligence and machine learning techniques will be utilized to analyze well integrity records in order to identify patterns that can predict potential failure events in natural gas production, storage, and transmission. This approach aims to provide valuable insights and guidance on reducing emissions in these processes.","Artificial intelligence and machine learning techniques will be utilized to analyze well integrity records in order to identify patterns that can predict potential failure events in natural gas production, storage, and transmission. This approach aims to provide valuable insights and guidance on reducing emissions in these processes.","Yes, the project described above is potentially a safety risk. This falls under category (f) - industrial emissions and environmental impact control processes. The utilization of artificial intelligence and machine learning techniques to analyze well integrity records and predict potential failure events in natural gas production, storage, and transmission can have safety implications.

If the analysis fails to accurately predict potential failure events or if the guidance provided is not followed, it could result in gas leaks, explosions, or other safety hazards. These incidents can harm workers, nearby communities, and the environment.

Therefore, proper safety protocols and measures should be implemented to minimize the risks associated with this project.",,False,True
DOE-0085-2023,DOE,National Energy Technology Laboratory,,"To design, develop, and demonstrate an AI-integrated physics-based attack resilient proactive system.","Enable ""defense-in-depth"" cyber-physical system (CPS) security and 
resiliency for the distribution grid. The recipient will design, develop, and 
demonstrate a vendor-agonistic scalable Artificial Intelligence Integrated 
Attack-Resilient Proactive System (AI-ARPS) for utility distribution grid 
systems including advanced distribution management system (ADMS) 
and DER management system (DERMS) applications.",,Artificial Intelligence Unknown,,Department of Energy,"To design, develop, and demonstrate an AI-integrated physics-based attack resilient proactive system.: 
Enable ""defense-in-depth"" cyber-physical system (CPS) security and 
resiliency for the distribution grid. The recipient will design, develop, and 
demonstrate a vendor-agonistic scalable Artificial Intelligence Integrated 
Attack-Resilient Proactive System (AI-ARPS) for utility distribution grid 
systems including advanced distribution management system (ADMS) 
and DER management system (DERMS) applications.",The goal of the project is to create a proactive system that uses artificial intelligence to enhance the security and resiliency of cyber-physical systems in the distribution grid. This system will be designed to work with various vendors and will be able to manage and protect advanced distribution management and DER management systems.,The goal of the project is to create a proactive system that uses artificial intelligence to enhance the security and resiliency of cyber-physical systems in the distribution grid. This system will be designed to work with various vendors and will be able to manage and protect advanced distribution management and DER management systems.,"Yes, the project is potentially a safety risk. 

The project involves the design and implementation of a proactive system using artificial intelligence to enhance the security and resiliency of cyber-physical systems in the distribution grid. This falls under the category of ""electrical grids or the generation or movement of energy"" mentioned in the safety risks. 

If the system fails or malfunctions, it could potentially lead to disruptions in the distribution grid, affecting the functioning of the electrical system and posing a safety risk to the users and stakeholders involved. Additionally, the project deals with the management and protection of advanced distribution management and DER management systems, which are critical components of the energy infrastructure. Any failures or vulnerabilities in these systems could have significant safety implications.",,False,True
DHS-0031-2023,DHS,Immigration and Customs Enforcement,,Barcode Scanner,"The Barcode Scanner has been developed to scan and populate detected information into corresponding text fields within the RAVEn GO's Encounter Card. The barcode scanner currently supports MRZ and PDF417 barcode types, frequently found on travel documents (Passport and Passport cards) and US Driver's Licenses. 

This is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",Operation and Maintenance,"Machine Learning, Machine Vision",,Department of Homeland Security,"Barcode Scanner: 
The Barcode Scanner has been developed to scan and populate detected information into corresponding text fields within the RAVEn GO's Encounter Card. The barcode scanner currently supports MRZ and PDF417 barcode types, frequently found on travel documents (Passport and Passport cards) and US Driver's Licenses. 

This is a DHS HSI Innovation Lab / RAVEn project. The Repository for Analytics in a Virtualized Environment (RAVEn) facilitates large, complex analytical projects to support ICE’s mission to enforce and investigate violations of U.S. criminal, civil, and administrative laws. RAVEn also enables tools used to analyze trends and isolate criminal patterns as HSI mission needs arise. For more information, please read the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.","The Barcode Scanner is a tool developed for the RAVEn GO's Encounter Card that can scan and input information from MRZ and PDF417 barcodes found on travel documents and US Driver's Licenses. This project is a part of the DHS HSI Innovation Lab and RAVEn, which supports ICE's mission to enforce and investigate violations of US laws and provides tools for analyzing trends and identifying criminal patterns. For more information, refer to the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.","The Barcode Scanner is a tool developed for the RAVEn GO's Encounter Card that can scan and input information from MRZ and PDF417 barcodes found on travel documents and US Driver's Licenses. This project is a part of the DHS HSI Innovation Lab and RAVEn, which supports ICE's mission to enforce and investigate violations of US laws and provides tools for analyzing trends and identifying criminal patterns. For more information, refer to the DHS/ICE/PIA-055 - Privacy Impact Assessment 055 for RAVEn.",,"Yes, the project described is potentially a safety risk. This is because it involves law enforcement and surveillance-related activities, which can have significant implications for privacy and civil liberties. It includes scanning and inputting information from travel documents and driver's licenses, which raises concerns about the collection and use of personal data. Additionally, the project is associated with ICE's mission to enforce and investigate violations of US laws, which can involve sensitive and controversial issues. Therefore, careful consideration should be given to the potential risks and safeguards in place to protect individuals' rights and privacy.",True,False
DOE-0113-2023,DOE,National Energy Technology Laboratory,,To expore and analtze hydrogen- fueled rotating detonation engines using advanced turbulent combustion modeling and high- fidelity simultion tools.,"(1) analysis of injector design effects on RDE parasitic combustion; (2) 
understanding the impact of RDE ignition mechanism and initial 
transients on the ensuing detonation wave behavior; (3) deployment and 
assessment of machine learning assisted turbulent combustion models 
for predictive and computationally-efficient RDE CFD simulations; and 
(4) development of a highly scalable high-order CFD modeling 
framework for scale-resolving simulations of full-scale RDEs and 
investigation of TCI and wall boundary layer effects.(1) analysis of 
injector design effects on RDE parasitic combustion; (2) understanding 
the impact of RDE ignition mechanism and initial transients on the 
ensuing detonation wave behavior; (3) deployment and assessment of 
machine learning assisted turbulent combustion models for predictive 
and computationally-efficient RDE CFD simulations; and (4) 
development of a highly scalable high-order CFD modeling framework 
for scale-resolving simulations of full-scale RDEs and investigation of 
TCI and wall boundary layer effects.",,Artificial Intelligence Unknown,,Department of Energy,"To expore and analtze hydrogen- fueled rotating detonation engines using advanced turbulent combustion modeling and high- fidelity simultion tools.: 
(1) analysis of injector design effects on RDE parasitic combustion; (2) 
understanding the impact of RDE ignition mechanism and initial 
transients on the ensuing detonation wave behavior; (3) deployment and 
assessment of machine learning assisted turbulent combustion models 
for predictive and computationally-efficient RDE CFD simulations; and 
(4) development of a highly scalable high-order CFD modeling 
framework for scale-resolving simulations of full-scale RDEs and 
investigation of TCI and wall boundary layer effects.(1) analysis of 
injector design effects on RDE parasitic combustion; (2) understanding 
the impact of RDE ignition mechanism and initial transients on the 
ensuing detonation wave behavior; (3) deployment and assessment of 
machine learning assisted turbulent combustion models for predictive 
and computationally-efficient RDE CFD simulations; and (4) 
development of a highly scalable high-order CFD modeling framework 
for scale-resolving simulations of full-scale RDEs and investigation of 
TCI and wall boundary layer effects.","This text outlines four main objectives: analyzing the effects of injector design on parasitic combustion in hydrogen-fueled rotating detonation engines (RDEs), understanding the impact of RDE ignition mechanisms and initial transients on the behavior of detonation waves, deploying and assessing machine learning assisted turbulent combustion models for predictive and efficient RDE simulations, and developing a scalable high-order computational fluid dynamics (CFD) modeling framework for simulating full-scale RDEs and investigating the effects of turbulence, combustion, and wall boundary layers.","This text outlines four main objectives: analyzing the effects of injector design on parasitic combustion in hydrogen-fueled rotating detonation engines (RDEs), understanding the impact of RDE ignition mechanisms and initial transients on the behavior of detonation waves, deploying and assessing machine learning assisted turbulent combustion models for predictive and efficient RDE simulations, and developing a scalable high-order computational fluid dynamics (CFD) modeling framework for simulating full-scale RDEs and investigating the effects of turbulence, combustion, and wall boundary layers.","Yes, the project potentially poses a safety risk. The project involves the analysis and development of hydrogen-fueled rotating detonation engines (RDEs), which are systems controlling the generation and movement of energy. The project also includes the development of computational fluid dynamics (CFD) modeling framework for simulating full-scale RDEs, which may involve the design, construction, or testing of industrial equipment. If any failures occur in the design or development of these RDEs or the computational models, it could pose a meaningful risk to safety.",,False,True
DHS-0021-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Cyber Vulnerability Reporting,"Vulnerability analysts require advanced automation tools to process data received through various  vulnerability reporting channels, as well as aggregate the information for automated sharing. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data in the KEV and CVE databases.",Initiation,"Natural Language Processing, Visualization",,Department of Homeland Security,"Cyber Vulnerability Reporting: 
Vulnerability analysts require advanced automation tools to process data received through various  vulnerability reporting channels, as well as aggregate the information for automated sharing. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data in the KEV and CVE databases.",Advanced automation tools are needed by vulnerability analysts to process data from multiple reporting channels and share it automatically. These tools utilize Machine Learning and Natural Language Processing to improve the accuracy and relevance of filtered data for human analysts and decision-makers. Machine Learning techniques are also used to aggregate information from databases like KEV and CVE for further analysis and presentation.,Advanced automation tools are needed by vulnerability analysts to process data from multiple reporting channels and share it automatically. These tools utilize Machine Learning and Natural Language Processing to improve the accuracy and relevance of filtered data for human analysts and decision-makers. Machine Learning techniques are also used to aggregate information from databases like KEV and CVE for further analysis and presentation.,"Yes, the project described potentially poses a safety risk. This is because it involves the use of advanced automation tools that utilize Machine Learning and Natural Language Processing to process and analyze data from multiple reporting channels. These tools are used by vulnerability analysts to improve the accuracy and relevance of filtered data for human analysts and decision-makers.

While the project itself may not directly involve the risks mentioned in the safety risks definition, it indirectly contributes to the safety risks by potentially impacting the functioning of critical systems and infrastructure. The accuracy and relevance of the filtered data generated by the automation tools are crucial for making informed decisions in various sectors, including emergency services, transportation, and industrial equipment.

If the automation tools fail to accurately process and analyze the data, it could lead to incorrect or delayed decisions being made, which can have detrimental effects on safety. For example, if vulnerabilities or threats are not properly identified or communicated due to errors in the automation tools, it could increase the risk of system failures, compromises in security, or even physical harm.

Therefore, while the project may not directly involve the specific safety risks mentioned, its role in providing accurate and reliable information for decision-making in critical sectors makes it potentially a safety risk if the automation tools fail to perform as intended.",,False,True
OPM-0001-2023,OPM,HRS/USAJOBS,,Skills matching on Open Opportunities,"The website uses Skills engine, a third party vendor, to provide personalized recommendations to users based on user input text and opportunity descriptions",Operation and Maintenance,Natural Language Processing,,U.S. Office of Personnel Management,"Skills matching on Open Opportunities: 
The website uses Skills engine, a third party vendor, to provide personalized recommendations to users based on user input text and opportunity descriptions",The website Open Opportunities utilizes a third-party vendor called Skills engine to match users with suitable opportunities. This is done by analyzing user input text and opportunity descriptions to generate personalized recommendations.,The website Open Opportunities utilizes a third-party vendor called Skills engine to match users with suitable opportunities. This is done by analyzing user input text and opportunity descriptions to generate personalized recommendations.,,"Yes, the project described above potentially poses a safety risk. The project involves analyzing user input text and opportunity descriptions to generate personalized recommendations. While the description of the project does not explicitly mention any safety risks, it falls under the category of decision-making processes that can have significant implications in various domains, such as education, employment, and government benefits.

The potential safety risk arises from the fact that the project utilizes algorithms to make decisions or recommendations that can have a direct impact on individuals. These decisions could include determining access to educational resources or programs, influencing employment terms and conditions, or even recommending child welfare decisions. If the algorithms used by the project are not properly designed, tested, or monitored, they can result in biased or discriminatory outcomes, leading to unfair treatment or harm to individuals.

Furthermore, the project involves analyzing user input text, which may involve personal information or sensitive data. If the security measures in place to protect this data are inadequate, it could lead to privacy breaches or unauthorized access to personal information, resulting in potential safety risks for the users.

Therefore, it is important for this project to have robust safeguards in place to address potential biases, ensure data privacy and security, and mitigate the risks associated with decision-making processes that can significantly impact individuals' lives.",True,False
DHS-0004-2023,DHS,Customs and Border Protection,,Autonomous Maritime Awareness,"The Autonomous Maritime Awareness system combines surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to autonomously detect, identify, and track items of interest in a maritime environment.

The towers are low-cost, customizable, and relocatable surveillance systems. They are equipped with a suite of radars and day/night camera sensors. The ASVs have been ruggedized for the open ocean and are powered by wind, solar, and/or onboard engine as required, allowing them to operate in an area of responsibility (AOR) for up to 12 months. Their sensor suite includes cameras and radar. 

Both systems use AI/ML to detect and identify objects, determine items of interest (IoI) and autonomously track those items using their sensor suites. Once identified, these systems can send alerts to monitoring agencies for at-sea interdictions of potential targets and/or intel collections.",Development and Acquisition,Machine Learning Automation & Robotics,,Department of Homeland Security,"Autonomous Maritime Awareness: 
The Autonomous Maritime Awareness system combines surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI to autonomously detect, identify, and track items of interest in a maritime environment.

The towers are low-cost, customizable, and relocatable surveillance systems. They are equipped with a suite of radars and day/night camera sensors. The ASVs have been ruggedized for the open ocean and are powered by wind, solar, and/or onboard engine as required, allowing them to operate in an area of responsibility (AOR) for up to 12 months. Their sensor suite includes cameras and radar. 

Both systems use AI/ML to detect and identify objects, determine items of interest (IoI) and autonomously track those items using their sensor suites. Once identified, these systems can send alerts to monitoring agencies for at-sea interdictions of potential targets and/or intel collections.","The Autonomous Maritime Awareness system is a combination of surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI. The system can autonomously detect, identify, and track items of interest in a maritime environment using radars, cameras, and sensor suites. It can send alerts to monitoring agencies for potential interdictions or intel collections.","The Autonomous Maritime Awareness system is a combination of surveillance towers, ocean data solutions, unmanned autonomous surface vehicles (ASV), and AI. The system can autonomously detect, identify, and track items of interest in a maritime environment using radars, cameras, and sensor suites. It can send alerts to monitoring agencies for potential interdictions or intel collections.",,"Yes, the project described potentially poses a safety risk. The use of surveillance towers, unmanned autonomous surface vehicles (ASV), and AI for detecting and tracking items in a maritime environment raises concerns about privacy invasion and the potential for misuse or abuse of the collected data. Additionally, the use of AI in making decisions related to potential interdictions or intelligence collections could lead to errors or biases, which could have serious consequences in maritime security operations.",True,False
TREAS-0010-2023,TREAS,,,NRP Redesign,"Deploy state-of-the-art AI machine learning methods to provide a lower 
opportunity cost method of estimating a compliance baseline to support 
tax gap estimation, improper payments reporting, development and 
validation of workload identification and selection models, and inform 
policy analysis.  System inputs require existing NRP data which provide an 
acceptable level of precision and quality for an acceptable level of data 
quality output.",In production: less than one year,,,Department of Treasury,"NRP Redesign: 
Deploy state-of-the-art AI machine learning methods to provide a lower 
opportunity cost method of estimating a compliance baseline to support 
tax gap estimation, improper payments reporting, development and 
validation of workload identification and selection models, and inform 
policy analysis.  System inputs require existing NRP data which provide an 
acceptable level of precision and quality for an acceptable level of data 
quality output.","The NRP Redesign aims to use advanced AI machine learning techniques to accurately estimate compliance baselines for tax gap estimation, improper payments reporting, workload identification and selection models, and policy analysis. The system will rely on existing NRP data that meets acceptable precision and quality standards to ensure reliable output.","The NRP Redesign aims to use advanced AI machine learning techniques to accurately estimate compliance baselines for tax gap estimation, improper payments reporting, workload identification and selection models, and policy analysis. The system will rely on existing NRP data that meets acceptable precision and quality standards to ensure reliable output.",,"Yes, the project described above is potentially a safety risk. This is because it involves making decisions related to financial systems, government benefits, and tax compliance using advanced AI machine learning techniques. Any errors or biases in the AI algorithms used could lead to inaccurate estimations, improper payment reporting, and unfair decisions regarding access to benefits or penalties. These decisions can have significant impacts on individuals and society as a whole. Therefore, there is a potential for harm or injustice if the AI system is not designed, implemented, and monitored properly.",True,False
DOS-0018-2023,DOS,GPA,,GPATools and GPAIX,GPA’s production system for testing potential messages at scale across segmented foreign sub-audiences to determine effective outreach to target audiences.,,,,Department of State,"GPATools and GPAIX: 
GPA’s production system for testing potential messages at scale across segmented foreign sub-audiences to determine effective outreach to target audiences.",GPATools and GPAIX are production systems developed by GPA that are used to test potential messages on a large scale. These systems help determine the most effective way to reach and engage specific target audiences by conducting tests across segmented foreign sub-audiences.,GPATools and GPAIX are production systems developed by GPA that are used to test potential messages on a large scale. These systems help determine the most effective way to reach and engage specific target audiences by conducting tests across segmented foreign sub-audiences.,,"Yes, the project described is potentially a safety risk. The project involves the use of GPATools and GPAIX systems to test potential messages on a large scale and determine the most effective way to reach and engage specific target audiences. While the project description does not explicitly mention any safety risks, the nature of the project raises concerns related to privacy, surveillance, and potential manipulation of individuals.

The project involves conducting tests across segmented foreign sub-audiences, which could potentially involve the collection and analysis of personal data, including sensitive information. This raises concerns about privacy and the potential misuse of personal information.

Additionally, the project may involve the use of algorithms and artificial intelligence to make decisions regarding the targeting and engagement of specific audiences. These automated decision-making processes can be prone to biases and errors, leading to potential discrimination or unfair treatment of individuals.

Furthermore, the project's focus on influencing and engaging specific target audiences raises ethical concerns about the potential manipulation of individuals' thoughts, opinions, and behaviors. This can have broader societal implications and can undermine democratic processes and individual autonomy.

Overall, the project's involvement in data collection, algorithmic decision-making, and potential manipulation of individuals raises significant safety and ethical concerns.",True,False
DOE-0156-2023,DOE,"Office of Environment, Health, Safety & Security",,Applications of Natural Language Processing and Similarity Measures for Similarity Ranking,"""EHSS has been developing applications of natural language 
processing (NLP) and similarity measures for advanced information 
retrieval and searching of datasets (e.g., SQL databases, CSV files, 
reports) as well as estimating similarities between records within a 
dataset or records between different datasets.  Similarity search has 
been successfully applied to efficiently search DOE COVID-19 Hotline 
questions and answer database, searching DOE annual site 
environmental reports, similarity between DOE occurrence reporting and 
processing system and lessons learned, and AIX data.  Similarity 
measures can also be used to identify opportunities for resource 
prioritization and prediction.
As of October 2021, the tool runs locally by the principal investigator on 
project based, as requested or as a desktop application.  Initial 
developments were initiated to move to a web-based application but not 
completed due to lack of user need and resources.""",,,,Department of Energy,"Applications of Natural Language Processing and Similarity Measures for Similarity Ranking: 
""EHSS has been developing applications of natural language 
processing (NLP) and similarity measures for advanced information 
retrieval and searching of datasets (e.g., SQL databases, CSV files, 
reports) as well as estimating similarities between records within a 
dataset or records between different datasets.  Similarity search has 
been successfully applied to efficiently search DOE COVID-19 Hotline 
questions and answer database, searching DOE annual site 
environmental reports, similarity between DOE occurrence reporting and 
processing system and lessons learned, and AIX data.  Similarity 
measures can also be used to identify opportunities for resource 
prioritization and prediction.
As of October 2021, the tool runs locally by the principal investigator on 
project based, as requested or as a desktop application.  Initial 
developments were initiated to move to a web-based application but not 
completed due to lack of user need and resources.""","EHSS has developed applications of natural language processing and similarity measures to improve information retrieval and searching of datasets. These applications have been successfully used for tasks such as searching databases, estimating similarities between records, and identifying opportunities for resource prioritization. Currently, the tool is run locally by the principal investigator, but plans to transition to a web-based application were halted due to lack of demand and resources.","EHSS has developed applications of natural language processing and similarity measures to improve information retrieval and searching of datasets. These applications have been successfully used for tasks such as searching databases, estimating similarities between records, and identifying opportunities for resource prioritization. Currently, the tool is run locally by the principal investigator, but plans to transition to a web-based application were halted due to lack of demand and resources.",,"Yes, the project described potentially poses a safety risk. The project involves developing applications of natural language processing and similarity measures for information retrieval and searching of datasets. While this description does not directly mention any specific risks, it falls under the category of ""Right impacting"" as defined earlier. This category includes decisions related to surveillance, monitoring, and profiling individuals. If the tool is used for purposes such as monitoring individuals' online activities, conducting surveillance, or making decisions related to employment, education, or government benefits, it could potentially infringe upon privacy rights and individual liberties, leading to safety risks. Additionally, if the tool is used to make critical decisions in areas such as law enforcement, healthcare, or child welfare, any errors or biases in the tool's algorithms or data could have serious consequences and negatively impact individuals' lives.",True,False
USDA-0008-2023,USDA,USDA,APHIS,Artificial Intelligence for correlative statistical analysis,"AI-type statistical techniques are used to model predictive relationships between variables. We routinely use modeling approaches such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines, for statistical prediction. ",Operation and Management,"Neural networks,Clustering",,Department of Agriculture,"Artificial Intelligence for correlative statistical analysis: 
AI-type statistical techniques are used to model predictive relationships between variables. We routinely use modeling approaches such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines, for statistical prediction. ","Artificial Intelligence is employed to perform correlative statistical analysis by employing various modeling techniques such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines. These techniques enable the prediction of relationships between variables.","Artificial Intelligence is employed to perform correlative statistical analysis by employing various modeling techniques such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines. These techniques enable the prediction of relationships between variables.",,"Yes, this project is potentially a safety risk. The project involves using Artificial Intelligence to perform correlative statistical analysis and predict relationships between variables. Although the specific risks are not explicitly mentioned in the project description, the techniques mentioned such as random forest, artificial neural networks, k-nearest neighbor clustering, and support vector machines can have significant implications in various domains.

For example, if these techniques are used in law enforcement or surveillance-related risk assessments, decisions related to sentencing or parole, or determining access to government benefits, there is a potential for biased or unfair outcomes. AI models are trained on historical data, and if the training data contains biases or discriminatory patterns, the predictions made by the AI system can perpetuate and amplify those biases.

Furthermore, if AI is used to make decisions regarding medical treatment, determining financial system access, or child welfare, there is a risk of incorrect or harmful decisions being made. AI models are not perfect and can make errors, and relying solely on AI predictions without human oversight or intervention can have serious consequences.

Therefore, without further information on how the AI models are trained, validated, and deployed, it is prudent to consider this project as potentially a safety risk. Safeguards and ethical considerations should be in place to ensure fairness, transparency, and accountability in the decision-making processes.",True,False
DHS-0013-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Advanced Analytic Enabled Forensic Investigation,"CISA deploys forensic specialists to analyze cyber events at Federal Civilian Executive Branch (FCEB) departments and agencies, as well as other State, Local, Tribal, Territorial, and Critical Infrastructure partners. Forensic analysts can utilize advanced analytic tooling, in the form of Artificial Intelligence implementations to better understand anomalies and potential threats. This tooling allows forensic specialists the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",Initiation,Machine Learning,,Department of Homeland Security,"Advanced Analytic Enabled Forensic Investigation: 
CISA deploys forensic specialists to analyze cyber events at Federal Civilian Executive Branch (FCEB) departments and agencies, as well as other State, Local, Tribal, Territorial, and Critical Infrastructure partners. Forensic analysts can utilize advanced analytic tooling, in the form of Artificial Intelligence implementations to better understand anomalies and potential threats. This tooling allows forensic specialists the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ","CISA uses forensic specialists to investigate cyber events in various government and critical infrastructure organizations. These specialists utilize advanced analytic tools, including Artificial Intelligence, to analyze data and identify anomalies and potential threats efficiently. This automated process ensures timely detection of high-quality anomalies using mathematical and probabilistic models.","CISA uses forensic specialists to investigate cyber events in various government and critical infrastructure organizations. These specialists utilize advanced analytic tools, including Artificial Intelligence, to analyze data and identify anomalies and potential threats efficiently. This automated process ensures timely detection of high-quality anomalies using mathematical and probabilistic models.",,"Yes, the project described above is potentially a safety risk. The project involves using Artificial Intelligence and advanced analytic tools to investigate cyber events in government and critical infrastructure organizations. The use of AI and automated processes to analyze data and identify anomalies can lead to potential risks in several areas.

Firstly, in the context of law enforcement or surveillance-related risk assessments, the project may involve the use of facial matching, iris matching, or social media monitoring. These techniques raise concerns about privacy and civil liberties, as there is a risk of misidentifications or false positives, which could lead to wrongful targeting or profiling of individuals.

Secondly, the project's involvement in determining access to educational resources or programs, or recommending disciplinary interventions, can have significant implications for students. The use of automated systems to detect cheating or plagiarism, project student progress, or recommend interventions may not take into account individual circumstances or provide a fair assessment, potentially leading to unjust consequences for students.

Thirdly, the project's role in determining the terms and conditions of employment, including pre-employment screening and performance management, raises concerns about fairness and bias. Automated systems may not accurately assess an individual's qualifications or potential, leading to discriminatory practices or unjust treatment.

Additionally, the project's involvement in decisions regarding medical devices, clinical diagnosis, or mental health status detection raises concerns about the accuracy and reliability of AI algorithms. Incorrect or biased determinations in these areas can have severe consequences for individuals' health and well-being.

Overall, the project's use of AI and automated processes in various sensitive areas poses potential safety risks related to privacy, fairness, discrimination, and individual rights. Proper safeguards, transparency, and ongoing evaluation of the system's performance are necessary to mitigate these risks.",True,False
NASA-0011-2023,NASA,Jet Propulsion Laboratory,,"Autonomous Marine Vehicles (Single, Multiple)","Due to the communication paradigm associated with operating an underwater submersible on an Ocean World, the
vehicle must be able to act autonomously when achieving scientific goals. One such goal is the study of
hydrothermal venting. Evidence for hydrothermal activity has been found on one Ocean World, Enceladus. On
Earth, these geological phenomena harbor unique ecosystems and are potentially critical to the origin of life. Similar
vents on Ocean Worlds could be the best chance at extra-terrestrial life in our Solar System. We focus on performing
autonomous science, specifically the localization of features of interest - such as hydrothermal venting - with limited
to no human interaction. A field program to Karasik Seamount in the Arctic Ocean was completed in Fall 2016 to
study and understand the human-in-the-loop approach to the localizing hydrothermal venting. In 2017/2018 an
autonomous nested search method for hydrothermal venting was developed and tested in simulation using a
hydrothermal plume dispersion model developed by Woods Hole Oceanographic Institution. Numerous
deployments have been executed including to Monterey Bar (multiple), Chesapeake Bay.",In mission,constraint-based heuristic Search,,National Aeronautics and Space Administration,"Autonomous Marine Vehicles (Single, Multiple): 
Due to the communication paradigm associated with operating an underwater submersible on an Ocean World, the
vehicle must be able to act autonomously when achieving scientific goals. One such goal is the study of
hydrothermal venting. Evidence for hydrothermal activity has been found on one Ocean World, Enceladus. On
Earth, these geological phenomena harbor unique ecosystems and are potentially critical to the origin of life. Similar
vents on Ocean Worlds could be the best chance at extra-terrestrial life in our Solar System. We focus on performing
autonomous science, specifically the localization of features of interest - such as hydrothermal venting - with limited
to no human interaction. A field program to Karasik Seamount in the Arctic Ocean was completed in Fall 2016 to
study and understand the human-in-the-loop approach to the localizing hydrothermal venting. In 2017/2018 an
autonomous nested search method for hydrothermal venting was developed and tested in simulation using a
hydrothermal plume dispersion model developed by Woods Hole Oceanographic Institution. Numerous
deployments have been executed including to Monterey Bar (multiple), Chesapeake Bay.","Autonomous Marine Vehicles are necessary for studying hydrothermal venting on Ocean Worlds, such as Enceladus, which may hold potential for extraterrestrial life. The focus is on achieving scientific goals autonomously, specifically the localization of features like hydrothermal venting, with limited human interaction. Field programs and simulations have been conducted to develop and test methods for locating these vents.","Autonomous Marine Vehicles are necessary for studying hydrothermal venting on Ocean Worlds, such as Enceladus, which may hold potential for extraterrestrial life. The focus is on achieving scientific goals autonomously, specifically the localization of features like hydrothermal venting, with limited human interaction. Field programs and simulations have been conducted to develop and test methods for locating these vents.","Yes, the project described is potentially a safety risk. 

The project involves the use of Autonomous Marine Vehicles for studying hydrothermal venting on Ocean Worlds. These vehicles would be operating in potentially hazardous environments and may encounter various safety risks. 

Firstly, the project falls under the category of ""movements of vehicles"" (point d) and involves the transportation of vehicles in the sea. Any transportation or movement of vehicles, especially in challenging environments like the ocean, carries inherent safety risks.

Secondly, the project involves the study of hydrothermal venting, which involves the transport and management of potentially hazardous chemicals or biological entities (point e). Dealing with such substances can pose safety risks if not handled properly.

Additionally, as the project focuses on achieving scientific goals autonomously, with limited human interaction, there could be risks associated with the lack of human oversight and control (point b). If the autonomous vehicles encounter any issues or malfunctions, it could lead to safety concerns.

Overall, due to the nature of the project involving the movement of vehicles, potential exposure to hazardous substances, and limited human interaction, it can be considered a safety risk.",,False,True
DOE-0031-2023,DOE,National Energy Technology Laboratory,,AI used to interpret sensor data.,"AI is being used to classify sensor data.  An AI algorithm was written 
and trained with a wide range of known sensor conditions to enable 
automatic classification of sensor data into likely constituent gas 
concentrations.",,Other,,Department of Energy,"AI used to interpret sensor data.: 
AI is being used to classify sensor data.  An AI algorithm was written 
and trained with a wide range of known sensor conditions to enable 
automatic classification of sensor data into likely constituent gas 
concentrations.",AI is currently being utilized to interpret sensor data by employing an algorithm trained with various known sensor conditions. This allows for the automatic classification of sensor data into probable gas concentrations.,AI is currently being utilized to interpret sensor data by employing an algorithm trained with various known sensor conditions. This allows for the automatic classification of sensor data into probable gas concentrations.,"Yes, the project described is potentially a safety risk. This is because it falls under the category of ""f. Industrial emissions and environmental impact control processes."" The use of AI to interpret sensor data for classifying gas concentrations is directly related to monitoring and controlling industrial emissions, which can have environmental and health impacts. If the algorithm used for classification fails or provides inaccurate results, it could lead to incorrect assessments of gas concentrations and inadequate environmental impact control measures, potentially posing a risk to safety.",,False,True
DOE-0130-2023,DOE,National Energy Technology Laboratory,,To provide insights into opportunities to beneficiate and use hydrocarbon infrastructure for alternative uses such as offshore carbon storage.,"Multiple big data-driven AI/ML models will be used to evaluate geologic, 
geospatial, and infrastructure related information to inform predictions 
using natural language processing, Artificial Neural Networks, and 
possibly bayesian networks as well.",,"Big Data, Other",,Department of Energy,"To provide insights into opportunities to beneficiate and use hydrocarbon infrastructure for alternative uses such as offshore carbon storage.: 
Multiple big data-driven AI/ML models will be used to evaluate geologic, 
geospatial, and infrastructure related information to inform predictions 
using natural language processing, Artificial Neural Networks, and 
possibly bayesian networks as well.","This text describes the use of AI and big data models to analyze various types of information related to hydrocarbon infrastructure, with the goal of identifying opportunities for alternative uses such as offshore carbon storage. The models will use techniques such as natural language processing, Artificial Neural Networks, and potentially bayesian networks to make predictions based on the data.","This text describes the use of AI and big data models to analyze various types of information related to hydrocarbon infrastructure, with the goal of identifying opportunities for alternative uses such as offshore carbon storage. The models will use techniques such as natural language processing, Artificial Neural Networks, and potentially bayesian networks to make predictions based on the data.","Yes, the project is potentially a safety risk.

Explanation:
The project involves the analysis of hydrocarbon infrastructure, which falls under the category of industrial emissions and environmental impact control processes (risk f). The use of AI and big data models to analyze this information could potentially have an impact on the transportation or management of industrial waste or other controlled pollutants (risk g). Additionally, the project aims to identify opportunities for offshore carbon storage, which involves the transport, safety, design, or development of hazardous chemicals or biological entities or pathways (risk e).

Therefore, due to its potential impact on industrial emissions, environmental impact control, transportation, management of waste, and hazardous chemicals, the project is potentially a safety risk.",,False,True
HHS-0046-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Priority Score Model - ranks providers within the Fraud Prevention System using logistic regression based on program integrity guidelines.,"Inputs - Medicare Claims data, Targeted Probe and Educate (TPE) Data, Jurisdiction information
Output -  ranks providers within the FPS system using logistic regression based on program integrity guidelines.",Operation and Maintenance,,,Department of Health and Human Services,"Priority Score Model - ranks providers within the Fraud Prevention System using logistic regression based on program integrity guidelines.: 
Inputs - Medicare Claims data, Targeted Probe and Educate (TPE) Data, Jurisdiction information
Output -  ranks providers within the FPS system using logistic regression based on program integrity guidelines.","The Priority Score Model uses logistic regression to rank providers within the Fraud Prevention System. It takes inputs such as Medicare Claims data, Targeted Probe and Educate (TPE) Data, and Jurisdiction information to determine the rankings based on program integrity guidelines.","The Priority Score Model uses logistic regression to rank providers within the Fraud Prevention System. It takes inputs such as Medicare Claims data, Targeted Probe and Educate (TPE) Data, and Jurisdiction information to determine the rankings based on program integrity guidelines.",,"Yes, the project described above is potentially a safety risk. 

This is because it involves making decisions about access to government benefits or services, detecting fraud, and assigning penalties in the context of federal benefits. These decisions can have a significant impact on individuals' lives and livelihoods. If the model is not accurate or if it is biased, it may lead to incorrect determinations, unjust penalties, or the denial of benefits to eligible individuals. This can result in harm, inequality, and potential safety risks for those affected by these decisions.",True,False
DOE-0056-2023,DOE,National Energy Technology Laboratory,,Machine learning to process multi- model data and information to aid in the identification of undocumented orphaned wells,"Use of machine learning to process and analyze trends and patterns in 
known well data to predict undocuemnted orphaned wells, as well as 
machine learning approached to process different imagery based data 
to further classify and characterize additional undocuemented orphaned 
wells within the Appalachain Basin",,"Big Data, Other",,Department of Energy,"Machine learning to process multi- model data and information to aid in the identification of undocumented orphaned wells: 
Use of machine learning to process and analyze trends and patterns in 
known well data to predict undocuemnted orphaned wells, as well as 
machine learning approached to process different imagery based data 
to further classify and characterize additional undocuemented orphaned 
wells within the Appalachain Basin","Machine learning is being used to analyze various types of data and information in order to identify undocumented orphaned wells. By analyzing trends and patterns in known well data, machine learning can predict the existence of undocumented wells. Additionally, machine learning is used to process different types of imagery-based data to classify and characterize additional undocumented orphaned wells in the Appalachain Basin.","Machine learning is being used to analyze various types of data and information in order to identify undocumented orphaned wells. By analyzing trends and patterns in known well data, machine learning can predict the existence of undocumented wells. Additionally, machine learning is used to process different types of imagery-based data to classify and characterize additional undocumented orphaned wells in the Appalachain Basin.","Based on the given risks and project description, the project is not potentially a safety risk. The project involves using machine learning to analyze data and identify undocumented orphaned wells. It does not involve any of the safety risks listed in the definition, such as functioning of dams, emergency services, electrical grids, etc. Therefore, the project does not pose a safety risk.",,False,True
HHS-0030-2023,HHS,CDC,NCEZID,Use of Natural Language Processing for Topic Modeling to Automate Review of Public Comments to Notice of Proposed Rulemaking,Development of a Natural Language Processing Topic Modeling tool to improve efficiency for the process of clustering public comments to a 'notice of proposed rulemaking' ,Development and Acquisition,,,Department of Health and Human Services,"Use of Natural Language Processing for Topic Modeling to Automate Review of Public Comments to Notice of Proposed Rulemaking: 
Development of a Natural Language Processing Topic Modeling tool to improve efficiency for the process of clustering public comments to a 'notice of proposed rulemaking' ","A Natural Language Processing (NLP) tool has been developed to automate the review of public comments for a 'notice of proposed rulemaking' (NPRM). This tool utilizes NLP for topic modeling, improving the efficiency of clustering the comments and streamlining the process.","A Natural Language Processing (NLP) tool has been developed to automate the review of public comments for a 'notice of proposed rulemaking' (NPRM). This tool utilizes NLP for topic modeling, improving the efficiency of clustering the comments and streamlining the process.",,"Yes, the project described above is potentially a safety risk. 

The project involves the use of Natural Language Processing (NLP) to automate the review of public comments for a 'notice of proposed rulemaking' (NPRM). While this may seem like a harmless application of NLP, it falls under the category of ""decisions to block, remove, hide, or limit the reach of protected speech"" as defined in the risks. 

Automating the review of public comments can potentially lead to the suppression or censorship of certain viewpoints, which can infringe on individuals' freedom of speech. It is crucial to ensure that any decisions related to blocking or limiting the reach of protected speech are made with careful consideration and human oversight to avoid bias or potential harm.

Therefore, considering the potential risks involved in the project, it is classified as a safety risk.",True,False
DOE-0118-2023,DOE,National Energy Technology Laboratory,,To implement boiler health monitoring using a hybrid first principles-artificial intelligence model,"Develop methodologies and algorithms to yield (1) a hybrid first-
principles artificial intelligence (AI) model of a PC boiler, (2) a physics-
based approach to material damage informed by ex-service component 
evaluation, and (3) an online health-monitoring framework that 
synergistically leverages the hybrid models and plant measurements to 
provide the spatial and temporal profile of key transport variables and 
characteristic measures for plant health.",,Artificial Intelligence Unknown,,Department of Energy,"To implement boiler health monitoring using a hybrid first principles-artificial intelligence model: 
Develop methodologies and algorithms to yield (1) a hybrid first-
principles artificial intelligence (AI) model of a PC boiler, (2) a physics-
based approach to material damage informed by ex-service component 
evaluation, and (3) an online health-monitoring framework that 
synergistically leverages the hybrid models and plant measurements to 
provide the spatial and temporal profile of key transport variables and 
characteristic measures for plant health.","The text outlines the steps needed to implement a hybrid first principles-artificial intelligence model for monitoring the health of a boiler. This includes developing algorithms and methodologies for creating the model, using a physics-based approach to assess material damage, and creating an online health-monitoring framework that combines the hybrid models and plant measurements to track key variables and measures for the boiler's health.","The text outlines the steps needed to implement a hybrid first principles-artificial intelligence model for monitoring the health of a boiler. This includes developing algorithms and methodologies for creating the model, using a physics-based approach to assess material damage, and creating an online health-monitoring framework that combines the hybrid models and plant measurements to track key variables and measures for the boiler's health.","Yes, the project is potentially a safety risk. 

The project involves the design, construction, and testing of industrial equipment, specifically a boiler. If the implementation of the hybrid first principles-artificial intelligence model fails, it could pose a meaningful risk to safety. A malfunctioning boiler can lead to various safety hazards such as explosions, fires, and release of hazardous chemicals or substances.

Additionally, the project involves the transport, safety, design, or development of potentially hazardous chemicals or biological entities, as the boiler's health is monitored through plant measurements and assessment of material damage. Mishandling or improper management of these hazardous substances can result in safety risks to workers, the environment, and potentially the surrounding community.

Therefore, due to the involvement of industrial equipment, potential risks associated with material damage assessment, and the management of hazardous substances, this project is potentially a safety risk.",,False,True
USDA-0034-2023,USDA,USDA,OASCR,Artificial Intelligence SPAM Mitigation Project,"The AI Solution invoves Robotic Process Automation + AI/ML model solution to automatically classify and remove spam and marketing emails that appear in civil rights complaints email channels. A significant portion of incoming OASCR emails are spam, marketing and phishing emails. 
",Development and Acquisition,"Machine Learning,Machine Language Learning",,Department of Agriculture,"Artificial Intelligence SPAM Mitigation Project: 
The AI Solution invoves Robotic Process Automation + AI/ML model solution to automatically classify and remove spam and marketing emails that appear in civil rights complaints email channels. A significant portion of incoming OASCR emails are spam, marketing and phishing emails. 
","The Artificial Intelligence SPAM Mitigation Project aims to tackle the issue of spam and marketing emails in civil rights complaints email channels. By combining Robotic Process Automation with AI/ML models, the project automatically identifies and eliminates these unwanted emails, which make up a significant proportion of incoming OASCR emails.","The Artificial Intelligence SPAM Mitigation Project aims to tackle the issue of spam and marketing emails in civil rights complaints email channels. By combining Robotic Process Automation with AI/ML models, the project automatically identifies and eliminates these unwanted emails, which make up a significant proportion of incoming OASCR emails.",,"Yes, the project described has the potential to be a safety risk. The risks outlined in the project description fall under category (a) of the defined risks, which involves decisions to block, remove, hide, or limit the reach of protected speech. By automatically identifying and eliminating unwanted emails, there is a possibility that legitimate emails containing protected speech could be mistakenly classified as spam and blocked or removed. This could infringe on individuals' freedom of speech and potentially have legal implications. Therefore, the project should carefully consider the potential safety risks and ensure that proper safeguards are in place to prevent any undue limitations on protected speech.",True,False
HHS-0107-2023,HHS,FDA,NCTR,NCTR/DBB-CDER/OCS collaboration on A SafetAI Initiative to Enhance IND Review Process,"The development of animal-free models has been actively investigated and successfully demonstrated as an alternative to animal-based approaches for toxicity assessments.  Artificial Intelligence (AI) and Machine learning (ML) have been the central engine in this paradigm shift to identify safety biomarkers from non-animal assays or to predict safety outcomes solely based on chemical structure data. AI is a computer system or algorithm that has the ability to learn from existing data to foresee the future outcome. ML, a subset of AI, has been specifically studied to make predictions for adverse drug reactions. Deep Learning (DL) is arguably the most advanced approach in ML which frequently outperforms other types of ML approaches (or conventional ML approaches) for the study of drug safety and efficacy. DL usually consists of multiple layers of neural networks to mimic the cognitive behaviors associated with the human brain learning and problem-solving process to solve data intensive problems. Among many studies using AI/ML, DL has become a default algorithm to consider due to its superior performance. This proposal will apply DL to flag safety concerns regarding drug-induced liver injury (DILI) and carcinogenicity during the IND review process.",Initiation,,,Department of Health and Human Services,"NCTR/DBB-CDER/OCS collaboration on A SafetAI Initiative to Enhance IND Review Process: 
The development of animal-free models has been actively investigated and successfully demonstrated as an alternative to animal-based approaches for toxicity assessments.  Artificial Intelligence (AI) and Machine learning (ML) have been the central engine in this paradigm shift to identify safety biomarkers from non-animal assays or to predict safety outcomes solely based on chemical structure data. AI is a computer system or algorithm that has the ability to learn from existing data to foresee the future outcome. ML, a subset of AI, has been specifically studied to make predictions for adverse drug reactions. Deep Learning (DL) is arguably the most advanced approach in ML which frequently outperforms other types of ML approaches (or conventional ML approaches) for the study of drug safety and efficacy. DL usually consists of multiple layers of neural networks to mimic the cognitive behaviors associated with the human brain learning and problem-solving process to solve data intensive problems. Among many studies using AI/ML, DL has become a default algorithm to consider due to its superior performance. This proposal will apply DL to flag safety concerns regarding drug-induced liver injury (DILI) and carcinogenicity during the IND review process.","The NCTR/DBB-CDER/OCS collaboration is working on a project called A SafetAI Initiative to improve the IND review process. They are using artificial intelligence (AI) and machine learning (ML) to develop animal-free models for toxicity assessments and to predict safety outcomes based on chemical structure data. Specifically, they will be using deep learning (DL), which is a highly advanced form of ML, to identify safety concerns related to drug-induced liver injury (DILI) and carcinogenicity.","The NCTR/DBB-CDER/OCS collaboration is working on a project called A SafetAI Initiative to improve the IND review process. They are using artificial intelligence (AI) and machine learning (ML) to develop animal-free models for toxicity assessments and to predict safety outcomes based on chemical structure data. Specifically, they will be using deep learning (DL), which is a highly advanced form of ML, to identify safety concerns related to drug-induced liver injury (DILI) and carcinogenicity.","Yes, the project is potentially a safety risk. 

The project involves the development of animal-free models for toxicity assessments and prediction of safety outcomes based on chemical structure data using artificial intelligence (AI) and machine learning (ML). Although this project may have numerous benefits, there are potential safety risks associated with it.

One of the safety risks mentioned in the provided definition is the ""transport, safety, design, or development of hazardous chemicals or biological entities or pathways."" In this project, the use of AI and ML to predict safety outcomes based on chemical structure data implies that there may be involvement with hazardous chemicals. If these chemicals are not handled properly or if there are errors in the prediction models, it could lead to potential safety risks.

Additionally, the project involves the use of deep learning (DL), which is a highly advanced form of ML. Deep learning algorithms are complex and can be prone to making errors or biases in their predictions. In the context of safety assessments for drug-induced liver injury (DILI) and carcinogenicity, inaccurate or biased predictions could lead to harmful or unsafe drugs being approved, posing a safety risk to patients.

Therefore, considering the potential involvement with hazardous chemicals and the risks associated with the complexity of deep learning algorithms, the project is potentially a safety risk.",,False,True
HHS-0075-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Information Visualization Platform (InfoViP) to support analysis of individual case safety reports,"Developed the Information Visualization Platform (InfoViP) for post market safety surveillance, to improve the efficiency and scientific rigor of Individual Case Study Reports (ICSRs) review and evaluation process. InfoViP incorporates artificial intelligence and advanced visualizations to detect duplicate ICSRs, create temporal data visualization, and classify ICSRs for useability. ",Development and Acquisition,,,Department of Health and Human Services,"Information Visualization Platform (InfoViP) to support analysis of individual case safety reports: 
Developed the Information Visualization Platform (InfoViP) for post market safety surveillance, to improve the efficiency and scientific rigor of Individual Case Study Reports (ICSRs) review and evaluation process. InfoViP incorporates artificial intelligence and advanced visualizations to detect duplicate ICSRs, create temporal data visualization, and classify ICSRs for useability. ","The Information Visualization Platform (InfoViP) has been created to enhance the analysis of individual case safety reports (ICSRs). InfoViP utilizes artificial intelligence and advanced visualizations to identify duplicate ICSRs, generate temporal data visualizations, and categorize ICSRs for improved usability, thereby streamlining the review and evaluation process.","The Information Visualization Platform (InfoViP) has been created to enhance the analysis of individual case safety reports (ICSRs). InfoViP utilizes artificial intelligence and advanced visualizations to identify duplicate ICSRs, generate temporal data visualizations, and categorize ICSRs for improved usability, thereby streamlining the review and evaluation process.",,"Yes, the project is potentially a safety risk. 

The project involves the use of artificial intelligence and advanced visualizations to analyze individual case safety reports (ICSRs). These reports likely contain sensitive and confidential information related to safety incidents, adverse events, and potential risks associated with medical devices, clinical diagnosis, and treatments.

If the project fails to properly handle and protect this sensitive information, it could lead to privacy breaches, unauthorized access to personal medical data, and potential harm to individuals. Additionally, if the artificial intelligence algorithms used in the project are not accurately identifying duplicate ICSRs or categorizing them correctly, it could result in incorrect evaluations and recommendations, potentially compromising patient safety.

Therefore, due to the nature of the information being analyzed and the potential consequences of errors or breaches, the project presents a safety risk.",True,False
HHS-0021-2023,HHS,ASPR,"Office of Information Management, Data, and Analytics/ODA",Highly Infectious Patient Movement optimization,"Given a limited number of highly infectious patient transport containers, optimize US location based on various factors like distance, population, etc. Use as a planning tool for decision-making.",Initiation,,,Department of Health and Human Services,"Highly Infectious Patient Movement optimization: 
Given a limited number of highly infectious patient transport containers, optimize US location based on various factors like distance, population, etc. Use as a planning tool for decision-making.",The goal is to optimize the location of highly infectious patient transport containers in the US by considering factors such as distance and population. This planning tool will help in making informed decisions regarding the movement of these patients.,The goal is to optimize the location of highly infectious patient transport containers in the US by considering factors such as distance and population. This planning tool will help in making informed decisions regarding the movement of these patients.,"Yes, the project is potentially a safety risk. 

The project involves the transport of highly infectious patients, which falls under the category of ""physical movements"" in a medical setting. This type of movement carries the risk of spreading infectious diseases and potentially endangering the health and safety of individuals involved in the transportation process. 

While the goal of optimizing the location of patient transport containers is important for efficient and effective healthcare response, it also involves the risk of mishandling or improper containment of infectious materials. If the containers are not properly designed, constructed, or managed, there is a potential for the release of hazardous biological agents and the spread of diseases.

Therefore, the project needs to consider and implement appropriate safety measures, such as secure containment, proper training of personnel, adherence to strict protocols, and the use of appropriate protective equipment, to mitigate the potential risks associated with transporting highly infectious patients.",,False,True
DOC-0027-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Automated detection of hazardous low clouds in support of safe and efficient transportation,"This is a maintenance and sustainment project for the operational GOES-R fog/low stratus 
(FLS) products. The FLS products are derived from the combination of GOES-R satellite 
imagery and NWP data using machine learning. The FLS products, which are available in 
AWIPS, are routinely used by the NWS Aviation Weather Center and Weather Forecast 
Offices.",,,,Department of Commerce,"Automated detection of hazardous low clouds in support of safe and efficient transportation: 
This is a maintenance and sustainment project for the operational GOES-R fog/low stratus 
(FLS) products. The FLS products are derived from the combination of GOES-R satellite 
imagery and NWP data using machine learning. The FLS products, which are available in 
AWIPS, are routinely used by the NWS Aviation Weather Center and Weather Forecast 
Offices.",This project aims to maintain and improve the automated detection of dangerous low clouds to ensure safe and efficient transportation. It involves using machine learning to combine satellite imagery and NWP data to create FLS products that are regularly used by NWS Aviation Weather Center and Weather Forecast Offices.,This project aims to maintain and improve the automated detection of dangerous low clouds to ensure safe and efficient transportation. It involves using machine learning to combine satellite imagery and NWP data to create FLS products that are regularly used by NWS Aviation Weather Center and Weather Forecast Offices.,"Yes, this project is potentially a safety risk. According to the defined risks, it falls under category (b) as it involves the physical movement within a transportation setting. The automated detection of dangerous low clouds is crucial for ensuring safe transportation, especially in the aviation industry. If the system fails to accurately detect these clouds or if there are errors in the machine learning algorithms, it could lead to potential accidents or hazards for aircraft and passengers. Therefore, there is a potential safety risk associated with this project.",,False,True
NASA-0021-2023,NASA,Langley Research Center,,Pedestrian Safety Corridors for Drone Test Range,"NASA Langley Research Center (LaRC) is actively experimenting with Unmanned Aerial Systems (UAS - Drones and
surrounding systems) to include command, control, coordination and safety mechanisms. LaRC is expanding an on-
site UAS test range, to include areas where people walk, drive, etc. This project leverages the parking advisor image
recognition project and applies it to detecting pedestrian traffic to supplement statistical assessment of human-
heavy and human lite traffic areas with near-real time human-presence-detection. Inputs include camera signals
and hand labelled training data. Outputs include maps indicating density of human pedestrian traffic. The results
have been embedded into the GRASP flight risk simulation tool.",In-use,,https://gitlab.grc.nasa.gov/dmtrent/wahldo-1,National Aeronautics and Space Administration,"Pedestrian Safety Corridors for Drone Test Range: 
NASA Langley Research Center (LaRC) is actively experimenting with Unmanned Aerial Systems (UAS - Drones and
surrounding systems) to include command, control, coordination and safety mechanisms. LaRC is expanding an on-
site UAS test range, to include areas where people walk, drive, etc. This project leverages the parking advisor image
recognition project and applies it to detecting pedestrian traffic to supplement statistical assessment of human-
heavy and human lite traffic areas with near-real time human-presence-detection. Inputs include camera signals
and hand labelled training data. Outputs include maps indicating density of human pedestrian traffic. The results
have been embedded into the GRASP flight risk simulation tool.","The NASA Langley Research Center is conducting experiments with drones and their safety mechanisms. They are expanding their test range to include areas where people walk and drive, and are using image recognition technology to detect pedestrian traffic in real time. The data collected is used to create maps showing the density of human pedestrian traffic, which is then integrated into the GRASP flight risk simulation tool.","The NASA Langley Research Center is conducting experiments with drones and their safety mechanisms. They are expanding their test range to include areas where people walk and drive, and are using image recognition technology to detect pedestrian traffic in real time. The data collected is used to create maps showing the density of human pedestrian traffic, which is then integrated into the GRASP flight risk simulation tool.","Yes, the project described above is potentially a safety risk. 

The project involves the use of drones in areas where people walk and drive, which presents a potential risk of collisions and accidents. Additionally, the use of image recognition technology to detect pedestrian traffic in real time may have limitations and could result in errors or false detections, leading to unsafe situations. 

Furthermore, the integration of the collected data into the GRASP flight risk simulation tool implies that the drones will be flying in areas with human pedestrian traffic. This raises concerns about the potential for accidents or injuries if the drones malfunction or lose control.

Overall, the project involves the movement of drones in areas with human activity and relies on technology that may have limitations, increasing the potential safety risks.",,False,True
DOE-0030-2023,DOE,National Energy Technology Laboratory,,Advanced model to forecast offshore landslide risks and marine geohazards,"This research will use data and models from the Offshore Risk Modeling 
(ORM) with intelligent databases, artificial intelligence (AI)/ML, big data, 
and other advanced computing technologies to address offshore 
subsurface natural-engineered system challenges, such as 
characterization and mapping of geologic hazards, safe operations, 
equipment reliability, and environmental assessments.",,"Big Data, Natural Language Processing, Other",,Department of Energy,"Advanced model to forecast offshore landslide risks and marine geohazards: 
This research will use data and models from the Offshore Risk Modeling 
(ORM) with intelligent databases, artificial intelligence (AI)/ML, big data, 
and other advanced computing technologies to address offshore 
subsurface natural-engineered system challenges, such as 
characterization and mapping of geologic hazards, safe operations, 
equipment reliability, and environmental assessments.","The research aims to develop an advanced model that can accurately predict offshore landslide risks and other marine geohazards. This will be achieved by utilizing intelligent databases, artificial intelligence, big data, and other advanced computing technologies to address various challenges related to subsurface natural-engineered systems in offshore environments.","The research aims to develop an advanced model that can accurately predict offshore landslide risks and other marine geohazards. This will be achieved by utilizing intelligent databases, artificial intelligence, big data, and other advanced computing technologies to address various challenges related to subsurface natural-engineered systems in offshore environments.","Yes, this project potentially poses a safety risk. The project involves the research and development of an advanced model to predict offshore landslide risks and other marine geohazards. These geohazards can have significant safety implications for activities such as offshore drilling, construction of offshore structures, and navigation of vessels in the affected areas. Failure to accurately predict and mitigate these risks could lead to accidents, injuries, or even loss of life. Therefore, the project falls under the category of ""The design, construction, or testing of industrial equipment, systems, or structures that, if they failed, would pose a meaningful risk to safety"" (risk category h).",,False,True
DOE-0099-2023,DOE,National Energy Technology Laboratory,,To develop artificial intelligence- enabled tools (ArtIT) for cyber hardening of power grids.,"To develop a novel resiliency framework for power grids by integrating 
different theories, such as closed-loop controls, security, agility, formal 
reasoning and synthesis, machine learning, and laboratory setup 
demonstration. The framework will provide enhanced resiliency to wide-
area control operations in cyberattacks.",,Artificial Intelligence Unknown,,Department of Energy,"To develop artificial intelligence- enabled tools (ArtIT) for cyber hardening of power grids.: 
To develop a novel resiliency framework for power grids by integrating 
different theories, such as closed-loop controls, security, agility, formal 
reasoning and synthesis, machine learning, and laboratory setup 
demonstration. The framework will provide enhanced resiliency to wide-
area control operations in cyberattacks.","The goal is to create artificial intelligence tools that can strengthen power grids against cyberattacks. This will be achieved by combining various theories and technologies, such as closed-loop controls, security measures, machine learning, and laboratory demonstrations, to develop a resilient framework for wide-area control operations.","The goal is to create artificial intelligence tools that can strengthen power grids against cyberattacks. This will be achieved by combining various theories and technologies, such as closed-loop controls, security measures, machine learning, and laboratory demonstrations, to develop a resilient framework for wide-area control operations.","Yes, the project described above is potentially a safety risk. This is because it involves the functioning of electrical grids, which falls under the category of safety risks mentioned in the definition. The project aims to strengthen power grids against cyberattacks, and any failure in the implementation or functioning of the artificial intelligence tools could potentially lead to disruptions or vulnerabilities in the power grid system.",,False,True
HHS-0072-2023,HHS,FDA,CDER/Office of Pharmaceutical Quality (OPQ),Centers of Excellence in Regulatory Science and Innovation (CERSI) project - Leveraging AI for improving remote interactions.,"This project aims to improve four major areas identified by FDA, including transcription, translation, document and evidence management, and co-working space. Automatic speech recognition has been widely used in many applications. Its cutting-edge technology is transformer-based sequence to sequence (seq2seq) model, which is trained to generate transcripts autoregressively and has been fine-tuned on certain datasets. Using pre-trained language models directly may not be suitable because they might not work properly with different accents and specialized regulatory and scientific terminologies. This is because the models were trained on a specific type of data and may not be able to handle data that is significantly different from what they were trained on. To address this, researchers plan to manually read a set of video/audio to obtain their true transcripts, upon which they fine-tune the model to make it adapt to this new domain. Machine translation converts a sequence of text from one language to another. Researchers usually use a method called ""seq2seq,"" where original text is codified into a language that a computer can understand. Then, we use this code to generate the translated version of the text. It's like a translator who listens to someone speak in one language and then repeats what they said in another language. Similarly, it is not appropriate to directly apply the existing pre-trained seq2seq models, because (a) some languages used in the FDA context might not exist in existing models. (b) domain specific terms used in FDA are very different from general human languages. To tackle these challenges, models are trained for some unusual languages and fine-tune pre-trained models for major languages. For both situations, researchers prepare high-quality training set labeled by experts. University of Maryland CERSI (M-CERSI) plans to build a system to manage different documents and evidence, by implementing three sub-systems: (a) document classifier, (b) video/audio classifier, and (c) an interactive middleware that connects the trained model at the backend and the input at the frontend. With this, all documents created during co-working can be shared and accessed by all participants.",Initiation,,,Department of Health and Human Services,"Centers of Excellence in Regulatory Science and Innovation (CERSI) project - Leveraging AI for improving remote interactions.: 
This project aims to improve four major areas identified by FDA, including transcription, translation, document and evidence management, and co-working space. Automatic speech recognition has been widely used in many applications. Its cutting-edge technology is transformer-based sequence to sequence (seq2seq) model, which is trained to generate transcripts autoregressively and has been fine-tuned on certain datasets. Using pre-trained language models directly may not be suitable because they might not work properly with different accents and specialized regulatory and scientific terminologies. This is because the models were trained on a specific type of data and may not be able to handle data that is significantly different from what they were trained on. To address this, researchers plan to manually read a set of video/audio to obtain their true transcripts, upon which they fine-tune the model to make it adapt to this new domain. Machine translation converts a sequence of text from one language to another. Researchers usually use a method called ""seq2seq,"" where original text is codified into a language that a computer can understand. Then, we use this code to generate the translated version of the text. It's like a translator who listens to someone speak in one language and then repeats what they said in another language. Similarly, it is not appropriate to directly apply the existing pre-trained seq2seq models, because (a) some languages used in the FDA context might not exist in existing models. (b) domain specific terms used in FDA are very different from general human languages. To tackle these challenges, models are trained for some unusual languages and fine-tune pre-trained models for major languages. For both situations, researchers prepare high-quality training set labeled by experts. University of Maryland CERSI (M-CERSI) plans to build a system to manage different documents and evidence, by implementing three sub-systems: (a) document classifier, (b) video/audio classifier, and (c) an interactive middleware that connects the trained model at the backend and the input at the frontend. With this, all documents created during co-working can be shared and accessed by all participants.","The Centers of Excellence in Regulatory Science and Innovation (CERSI) project aims to improve transcription, translation, document and evidence management, and co-working space in the FDA. They plan to use transformer-based sequence to sequence (seq2seq) models for automatic speech recognition and machine translation. To ensure accuracy and adaptability, the models will be manually trained and fine-tuned on specific datasets, including those with different accents and specialized regulatory and scientific terminologies. Additionally, the project includes the implementation of a system to manage documents and evidence, allowing for easy sharing and access among participants.","The Centers of Excellence in Regulatory Science and Innovation (CERSI) project aims to improve transcription, translation, document and evidence management, and co-working space in the FDA. They plan to use transformer-based sequence to sequence (seq2seq) models for automatic speech recognition and machine translation. To ensure accuracy and adaptability, the models will be manually trained and fine-tuned on specific datasets, including those with different accents and specialized regulatory and scientific terminologies. Additionally, the project includes the implementation of a system to manage documents and evidence, allowing for easy sharing and access among participants.",,"Yes, the project described potentially poses safety risks. 

The project involves the use of transformer-based sequence to sequence (seq2seq) models for automatic speech recognition and machine translation. While this technology can be beneficial in improving transcription and translation, it also raises concerns regarding the potential for bias, misinformation, or misinterpretation of speech and documents. If the models are not properly trained and fine-tuned, they may produce inaccurate or misleading results, which could have serious consequences in regulatory science and innovation.

Furthermore, the implementation of a system to manage documents and evidence raises security and privacy concerns. If not adequately protected, sensitive information and data could be exposed or manipulated, compromising the integrity and security of the regulatory processes.

Therefore, the project has the potential to be a safety risk and should be carefully monitored and managed to mitigate any potential harm or adverse effects.",True,False
DOT-0006-2023,DOT,Aviation Safety (AVS),,Course Deviation Identification for Multiple Airport Route Separation (MARS),"The Multiple Airport Route Separation (MARS) program is developing a safety case for reduced separation standards between Performance Based Navigation (PBN) routes in terminal airspace. These new standards may enable deconfliction of airports in high-demand metropolitan areas, including the Northeast Corridor (NEC), North Texas, and Southern California. To build necessary collision risk models for the safety case, several models are needed, including one that describes the behavior of aircraft that fail to navigate the procedure correctly. These events are very rare and difficult to identify with standard data sources. Prior work has used Machine Learning to filter incident data to identify similar events on departure procedures.",,"Python in Jupyter Labs, ML, NLP",,Department of Transportation,"Course Deviation Identification for Multiple Airport Route Separation (MARS): 
The Multiple Airport Route Separation (MARS) program is developing a safety case for reduced separation standards between Performance Based Navigation (PBN) routes in terminal airspace. These new standards may enable deconfliction of airports in high-demand metropolitan areas, including the Northeast Corridor (NEC), North Texas, and Southern California. To build necessary collision risk models for the safety case, several models are needed, including one that describes the behavior of aircraft that fail to navigate the procedure correctly. These events are very rare and difficult to identify with standard data sources. Prior work has used Machine Learning to filter incident data to identify similar events on departure procedures.","The MARS program aims to establish reduced separation standards between PBN routes in terminal airspace, potentially allowing for more airports in busy metropolitan areas. To build a safety case, collision risk models are needed, including one that analyzes the behavior of aircraft that deviate from the correct navigation procedure. Previous research has utilized Machine Learning to identify similar events during departure procedures by filtering incident data.","The MARS program aims to establish reduced separation standards between PBN routes in terminal airspace, potentially allowing for more airports in busy metropolitan areas. To build a safety case, collision risk models are needed, including one that analyzes the behavior of aircraft that deviate from the correct navigation procedure. Previous research has utilized Machine Learning to identify similar events during departure procedures by filtering incident data.","Yes, the project described potentially poses a safety risk. 

The project involves the establishment of reduced separation standards between PBN (Performance-Based Navigation) routes in terminal airspace, which could lead to more airports in busy metropolitan areas. The use of Machine Learning to analyze the behavior of aircraft that deviate from the correct navigation procedure is also mentioned.

Given the safety risks defined, this project falls under the category of ""The movements of vehicles, whether on land, underground, at sea, in the air, or in space."" Any changes in the separation standards between aircraft in terminal airspace can potentially increase the risk of collisions or accidents.

To mitigate this risk, the project mentions the need for collision risk models and analyzing the behavior of aircraft deviating from the correct procedure. However, without proper testing, simulation, and evaluation, implementing reduced separation standards without comprehensive safety measures could pose a meaningful risk to safety.

Therefore, this project is potentially a safety risk and requires careful consideration and evaluation of the proposed changes to ensure the safe operation of aircraft in terminal airspace.",,False,True
DOE-0106-2023,DOE,National Energy Technology Laboratory,,To drive insights on pipeline maintenance and repair strategies to reduce incidents of pipeline leakage; support evaluation of use and reuse strategies,"ML will be used to develop a pipeline risk assessment geospatial model 
and support evaluation of use and reuse opportunities.",,"Big Data, Other",,Department of Energy,"To drive insights on pipeline maintenance and repair strategies to reduce incidents of pipeline leakage; support evaluation of use and reuse strategies: 
ML will be used to develop a pipeline risk assessment geospatial model 
and support evaluation of use and reuse opportunities.","A geospatial model powered by machine learning will be developed to assess the risks associated with pipeline maintenance and repair, aiming to minimize incidents of leakage. Additionally, the model will aid in evaluating the potential for using and reusing pipelines as part of sustainability strategies.","A geospatial model powered by machine learning will be developed to assess the risks associated with pipeline maintenance and repair, aiming to minimize incidents of leakage. Additionally, the model will aid in evaluating the potential for using and reusing pipelines as part of sustainability strategies.","Yes, the project is potentially a safety risk. 

The project involves the design, construction, and testing of a geospatial model powered by machine learning to assess the risks associated with pipeline maintenance and repair. If this model fails or provides inaccurate assessments, it could pose a meaningful risk to safety. Pipeline leakage can have severe consequences, including environmental damage, health risks, and even explosions in some cases. Therefore, the project's failure to accurately assess these risks could lead to incidents of leakage and potential safety hazards.

Furthermore, the project aims to evaluate the potential for using and reusing pipelines as part of sustainability strategies. The transportation or management of industrial waste or other controlled pollutants, such as pipeline contents, is listed as a safety risk. If the project does not adequately address the transportation and management of hazardous substances within the pipelines, it could lead to safety hazards and environmental impacts.

Overall, the project's involvement in the design, construction, and testing of industrial equipment (geospatial model) and the transportation and management of industrial waste (pipeline contents) make it potentially a safety risk.",,False,True
HHS-0108-2023,HHS,NIH,National Institutes of Health (NIH) CC,individual Functional Activity Composite Tool (inFACT),inFACT is being developed for use in the Social Security Administration (SSA) disability determination process to assist adjudicators in identifying evidence on function from case records that might be hundreds or thousands of pages long. inFACT displays information on whole person function as extracted from an individual's free text medical records and aligned with key business elements.,Development and Acquisition,,,Department of Health and Human Services,"individual Functional Activity Composite Tool (inFACT): 
inFACT is being developed for use in the Social Security Administration (SSA) disability determination process to assist adjudicators in identifying evidence on function from case records that might be hundreds or thousands of pages long. inFACT displays information on whole person function as extracted from an individual's free text medical records and aligned with key business elements.","The individual Functional Activity Composite Tool (inFACT) is being created to help Social Security Administration adjudicators review extensive case records and find evidence on an individual's functional abilities. inFACT presents a summary of a person's overall functioning, extracted from their medical records and linked to important business factors.","The individual Functional Activity Composite Tool (inFACT) is being created to help Social Security Administration adjudicators review extensive case records and find evidence on an individual's functional abilities. inFACT presents a summary of a person's overall functioning, extracted from their medical records and linked to important business factors.",,"Yes, the project described above is potentially a safety risk. 

The project involves the creation of the individual Functional Activity Composite Tool (inFACT), which aims to assist Social Security Administration adjudicators in reviewing extensive case records and finding evidence on an individual's functional abilities. While the specific details of the project's implementation are not provided, it falls under the category of determining eligibility for government benefits or services, as mentioned in the defined risks.

This can be considered a safety risk because the use of inFACT could potentially impact individuals' access to government benefits or services. The tool's ability to extract information from medical records and link it to important business factors raises concerns about privacy, data security, and the potential for biased decision-making. If the tool fails to accurately assess an individual's functional abilities or if it is used inappropriately, it could result in unfair denial of benefits or services.",True,False
HHS-0078-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Scalable automated NLP-assisted chart abstraction and feature extraction tool,"The overall goal of this study is to demonstrate the usability and value of currently available data sources and techniques in electronic medical records by harnessing claims and EHR data, including structured, semi-structured, and unstructured data, in a pharmacoepidemiology study. This study will use real-world longitudinal data from the Cerner Enviza Electronic Health Records (CE EHR) linked to claims with NLP technology applied to physician notes. NLP methods will be used to identify and contextualize pre-exposure confounding variables, incorporate unstructured EHR data into confounding adjustment, and for outcome ascertainment. Use case study; This study will seek to understand the relationship between use of montelukast among patients with asthma and neuropsychiatric events.",Initiation,,,Department of Health and Human Services,"Scalable automated NLP-assisted chart abstraction and feature extraction tool: 
The overall goal of this study is to demonstrate the usability and value of currently available data sources and techniques in electronic medical records by harnessing claims and EHR data, including structured, semi-structured, and unstructured data, in a pharmacoepidemiology study. This study will use real-world longitudinal data from the Cerner Enviza Electronic Health Records (CE EHR) linked to claims with NLP technology applied to physician notes. NLP methods will be used to identify and contextualize pre-exposure confounding variables, incorporate unstructured EHR data into confounding adjustment, and for outcome ascertainment. Use case study; This study will seek to understand the relationship between use of montelukast among patients with asthma and neuropsychiatric events.","This study aims to demonstrate the usability and value of electronic medical records by using various data sources and techniques. It will utilize real-world longitudinal data from the Cerner Enviza Electronic Health Records, linked to claims, and employ NLP technology to analyze physician notes. The study will focus on examining the connection between the use of montelukast among asthma patients and neuropsychiatric events.","This study aims to demonstrate the usability and value of electronic medical records by using various data sources and techniques. It will utilize real-world longitudinal data from the Cerner Enviza Electronic Health Records, linked to claims, and employ NLP technology to analyze physician notes. The study will focus on examining the connection between the use of montelukast among asthma patients and neuropsychiatric events.",,"Yes, this project is potentially a safety risk. The project involves analyzing electronic medical records and linking them to claims data to examine the connection between the use of montelukast among asthma patients and neuropsychiatric events. This falls under category (g) of the defined risks, which includes decisions regarding medical devices, clinical diagnosis, and determination of treatment.

Analyzing medical records and making decisions or recommendations related to patient treatment and medication use can have significant implications for patient safety. If the study results in inaccurate or flawed conclusions, it could potentially lead to inappropriate treatment decisions or the neglect of necessary interventions. Additionally, if the study involves accessing and analyzing sensitive patient data without proper privacy and security measures, it may pose a risk to patient confidentiality.

Therefore, further assessment and adherence to ethical and safety protocols are necessary to mitigate potential safety risks associated with this project.",True,False
DOT-0012-2023,DOT,"Office of Research, Development and Technology",,Automatic Track Change Detection Demonstration and Analysis,"Description: DeepCNet-based neural network to identify and classify track-related  features (e.g., track components, such as fasteners and ties) for ""change detection"" applications.
Input: Line-scan images from rail-bound inspection systems
Output: Notification of changes from status quo or between different inspections based on geolocation.",,,,Department of Transportation,"Automatic Track Change Detection Demonstration and Analysis: 
Description: DeepCNet-based neural network to identify and classify track-related  features (e.g., track components, such as fasteners and ties) for ""change detection"" applications.
Input: Line-scan images from rail-bound inspection systems
Output: Notification of changes from status quo or between different inspections based on geolocation.","The text describes the Automatic Track Change Detection system, which uses a DeepCNet-based neural network to identify and classify track-related features in line-scan images from rail-bound inspection systems. This system can detect changes in the track's status or between different inspections based on geolocation and provide notifications.","The text describes the Automatic Track Change Detection system, which uses a DeepCNet-based neural network to identify and classify track-related features in line-scan images from rail-bound inspection systems. This system can detect changes in the track's status or between different inspections based on geolocation and provide notifications.",,"Yes, the project described is potentially a safety risk. 

The project involves the use of the Automatic Track Change Detection system, which uses a neural network to identify and classify track-related features in rail-bound inspection systems. This system is responsible for detecting changes in the track's status or between different inspections and providing notifications based on geolocation.

Given that the safety of railway tracks is crucial for preventing accidents and ensuring the well-being of passengers and staff, any errors or inaccuracies in the track change detection system could pose significant safety risks. If the system fails to accurately detect track changes or provides incorrect notifications, it may lead to trains running on damaged or faulty tracks, increasing the likelihood of accidents, derailments, or other incidents.

Therefore, the potential for safety risks in this project arises due to the critical nature of track maintenance and the importance of accurate detection and notification of any changes or issues.",True,False
USAID-0005-2023,USAID,"Bureau for Development, Democracy, and Innovation (DDI)",,Project Vikela,Use AI to detect illegal rhino horn in airplane luggage X-Ray scanners,Operation and Maintenance,Machine Learning,,U.S. Agency for International Development,"Project Vikela: 
Use AI to detect illegal rhino horn in airplane luggage X-Ray scanners",Project Vikela aims to utilize artificial intelligence technology to identify and flag illegal rhino horn in X-ray scanners used for airplane luggage. The goal of this initiative is to enhance the detection and prevention of illegal wildlife trafficking by implementing AI solutions in airport security systems.,Project Vikela aims to utilize artificial intelligence technology to identify and flag illegal rhino horn in X-ray scanners used for airplane luggage. The goal of this initiative is to enhance the detection and prevention of illegal wildlife trafficking by implementing AI solutions in airport security systems.,"Yes, the project is potentially a safety risk. 

The project falls under the category of ""Industrial emissions and environmental impact control processes"" (risk f) as it involves the use of X-ray scanners in airport security systems. X-ray scanners emit radiation, and if not properly controlled or monitored, they can pose a risk to the health and safety of both airport personnel and passengers.

Additionally, the project also falls under the category of ""The design, construction, or testing of industrial equipment, systems, or structures that, if they failed, would pose a meaningful risk to safety"" (risk h). If the AI technology used to identify and flag illegal rhino horn in the X-ray scanners malfunctions or produces false positives or negatives, it can potentially compromise airport security and lead to the potential smuggling of illegal items or substances.

Therefore, due to the potential risks associated with radiation exposure and the reliability of AI technology, the project is potentially a safety risk.",,False,True
NASA-0003-2023,NASA,Ames Research Center,,High-Performance Quantum-Classical Hybrid Deep Generative Modeling Parameterized by Energy-based Models for Flight-Operations Anomaly Detection,"Our project conducts high-performance scalable and explainable machine learning for flight-operations anomaly
detection, with contributions from classical computing (enhanced performance, reduced cost) and quantum
computing (encoding of quantum correlations, quantum-resource estimates). Our deep-learning model takes time
series of 19 flight metrics collected by flight recorders of commercial aircraft as input and predicts operational and
safety-relevant anomalies during the take-off and landing phases of flight.",In-use,"Convolutional Neural Network, #K-Means Clustering, Variational Autoencoders",,National Aeronautics and Space Administration,"High-Performance Quantum-Classical Hybrid Deep Generative Modeling Parameterized by Energy-based Models for Flight-Operations Anomaly Detection: 
Our project conducts high-performance scalable and explainable machine learning for flight-operations anomaly
detection, with contributions from classical computing (enhanced performance, reduced cost) and quantum
computing (encoding of quantum correlations, quantum-resource estimates). Our deep-learning model takes time
series of 19 flight metrics collected by flight recorders of commercial aircraft as input and predicts operational and
safety-relevant anomalies during the take-off and landing phases of flight.",The project aims to develop a high-performance machine learning model for detecting anomalies in flight operations. The model combines classical and quantum computing techniques to improve performance and reduce costs. It uses data from flight recorders to predict anomalies during take-off and landing phases.,The project aims to develop a high-performance machine learning model for detecting anomalies in flight operations. The model combines classical and quantum computing techniques to improve performance and reduce costs. It uses data from flight recorders to predict anomalies during take-off and landing phases.,"Yes, the project is potentially a safety risk. According to the given definition, the project falls under category d, which includes the movements of vehicles, whether on land, underground, at sea, in the air, or in space. Flight operations involve the movement of aircraft in the air, and any anomalies during take-off and landing phases can have significant safety implications. If the machine learning model fails to accurately detect anomalies, it could lead to accidents or incidents during critical phases of flight. Therefore, the project has the potential to pose a safety risk.",,False,True
DOT-0010-2023,DOT,"Office of Research, Development and Technology",,Development of Predictive Analytics Using Autonomous Track Geometry Measurement System (ATGMS) Data,"Description: Leveraging large volumes of these recursive track geometry measurements to develop and implement automated machine-learning-based processes for analyzing, predicting, and reporting track locations of concern, including those with significant rates of degradation.
Input: Track geometry measurements and exceptions
Output: Inspection report that includes the trending of track geometry measures and time to failure (i.e., maintenance and safety limits).",,,,Department of Transportation,"Development of Predictive Analytics Using Autonomous Track Geometry Measurement System (ATGMS) Data: 
Description: Leveraging large volumes of these recursive track geometry measurements to develop and implement automated machine-learning-based processes for analyzing, predicting, and reporting track locations of concern, including those with significant rates of degradation.
Input: Track geometry measurements and exceptions
Output: Inspection report that includes the trending of track geometry measures and time to failure (i.e., maintenance and safety limits).","The Autonomous Track Geometry Measurement System (ATGMS) data can be used to develop predictive analytics for analyzing and predicting track locations of concern. By utilizing track geometry measurements and exceptions, the system can generate inspection reports that include trends in track geometry measures and estimate the time to failure, allowing for efficient maintenance and safety measures.","The Autonomous Track Geometry Measurement System (ATGMS) data can be used to develop predictive analytics for analyzing and predicting track locations of concern. By utilizing track geometry measurements and exceptions, the system can generate inspection reports that include trends in track geometry measures and estimate the time to failure, allowing for efficient maintenance and safety measures.","Yes, the project described could potentially be a safety risk. This is because it falls under the category of ""Physical movements"" within a transportation setting, as it involves analyzing and predicting track locations of concern for efficient maintenance and safety measures. If the Autonomous Track Geometry Measurement System (ATGMS) fails or provides inaccurate data, it could lead to track failures, derailments, or other safety incidents. Therefore, it is important to ensure the accuracy and reliability of the system to minimize safety risks.",,False,True
DOE-0096-2023,DOE,National Energy Technology Laboratory,,To develop and demonstrate drone- based geophysical and remote- sensing technologies to quantify critical minerals (CM).,"To develop and demonstrate drone-based geophysical and remote-
sensing technologies to quantify critical minerals (CM) in coal, coal 
related, unconventional and secondary sources or energy related waste 
streams. Drone-based geophysical surveys and remote sensing 
combined with artificial intelligence/machine learning (AI/ML) analytics 
for real-time integration and analytics has potential to transform 
characterization and monitoring for CM from conventional and 
secondary resources.",,"Artificial Intelligence, Robotic Processing Automation (RPA)",,Department of Energy,"To develop and demonstrate drone- based geophysical and remote- sensing technologies to quantify critical minerals (CM).: 
To develop and demonstrate drone-based geophysical and remote-
sensing technologies to quantify critical minerals (CM) in coal, coal 
related, unconventional and secondary sources or energy related waste 
streams. Drone-based geophysical surveys and remote sensing 
combined with artificial intelligence/machine learning (AI/ML) analytics 
for real-time integration and analytics has potential to transform 
characterization and monitoring for CM from conventional and 
secondary resources.","The goal of this project is to create and showcase drone-based technologies that can accurately measure critical minerals in various energy sources and waste streams. By using artificial intelligence and machine learning, these technologies have the potential to greatly improve the characterization and monitoring of critical minerals from both conventional and secondary sources.","The goal of this project is to create and showcase drone-based technologies that can accurately measure critical minerals in various energy sources and waste streams. By using artificial intelligence and machine learning, these technologies have the potential to greatly improve the characterization and monitoring of critical minerals from both conventional and secondary sources.","Yes, the project described has the potential to be a safety risk. It falls under category (a) as it involves the generation or movement of energy, specifically in the context of monitoring critical minerals in various energy sources and waste streams. If not handled properly, the use of drone-based technologies, artificial intelligence, and machine learning in this project could potentially disrupt or compromise the functioning of energy systems, leading to safety risks.",,False,True
HHS-0023-2023,HHS,CDC,CSELS,HaMLET: Harnessing Machine Learning to Eliminate Tuberculosis,HaMLET uses computer vision models to detect TB from chest x-rays to improve the quality of overseas health screenings for immigrants and refugees seeking entry to the U.S.,Development and Acquisition,,,Department of Health and Human Services,"HaMLET: Harnessing Machine Learning to Eliminate Tuberculosis: 
HaMLET uses computer vision models to detect TB from chest x-rays to improve the quality of overseas health screenings for immigrants and refugees seeking entry to the U.S.",HaMLET is a project that utilizes computer vision models to identify tuberculosis (TB) from chest x-rays. Its purpose is to enhance the accuracy of health screenings for immigrants and refugees who wish to enter the United States.,HaMLET is a project that utilizes computer vision models to identify tuberculosis (TB) from chest x-rays. Its purpose is to enhance the accuracy of health screenings for immigrants and refugees who wish to enter the United States.,,"Yes, the project is potentially a safety risk. The reason is that it falls under category h, which involves decisions regarding medical devices and health-risk assessments. In this case, the project involves making decisions about the health status of individuals based on computer vision models. If the accuracy of the models is not reliable, it could lead to misdiagnosis or false negatives, potentially allowing individuals with tuberculosis to enter the United States undetected. This poses a risk to public health, as it could contribute to the spread of the disease. Therefore, proper validation and testing of the computer vision models are essential to ensure the project's safety.",True,False
VA-0013-2023,VA,,,Nediser reports QA,"Nediser is a continuously trained artificial intelligence “radiology resident” that assists radiologists in confirming the X-ray properties in their radiology reports.  Nediser can select normal templates, detect hardware, evaluate patella alignment and leg length and angle discrepancy, and measure Cobb angles.",,,,Department of Veterans Affairs,"Nediser reports QA: 
Nediser is a continuously trained artificial intelligence “radiology resident” that assists radiologists in confirming the X-ray properties in their radiology reports.  Nediser can select normal templates, detect hardware, evaluate patella alignment and leg length and angle discrepancy, and measure Cobb angles.","Nediser is an AI system designed to help radiologists analyze X-ray properties accurately. It can identify normal templates, detect hardware, assess patella alignment and leg length and angle discrepancy, as well as measure Cobb angles.","Nediser is an AI system designed to help radiologists analyze X-ray properties accurately. It can identify normal templates, detect hardware, assess patella alignment and leg length and angle discrepancy, as well as measure Cobb angles.","Yes, the project described could potentially be a safety risk. While it does not directly involve any of the specific safety risks listed in the definition, the use of AI in medical imaging and diagnosis can have safety implications. If the AI system were to provide inaccurate or misleading analysis of X-ray properties, it could lead to incorrect diagnoses or treatment plans, potentially compromising patient safety. Therefore, thorough testing and validation of the AI system's accuracy and reliability would be crucial to mitigate any potential safety risks.",,False,True
USAID-0009-2023,USAID,Bureau for Global Health (GH),,Mali: AI predictions for the optimization of the allocation of the distribution of COVID-19 vaccines,AI technology was used to develop a pandemic preparedness AI model to support allocation of COVID-19 vaccines based on a multi-tiered strategy for target populations: 1) hotspots for COVID-19 positive cases and 2) pregnant/breastfeeding women using DHIS2 data. This was a proof-of-concept model.,Implementation,,,U.S. Agency for International Development,"Mali: AI predictions for the optimization of the allocation of the distribution of COVID-19 vaccines: 
AI technology was used to develop a pandemic preparedness AI model to support allocation of COVID-19 vaccines based on a multi-tiered strategy for target populations: 1) hotspots for COVID-19 positive cases and 2) pregnant/breastfeeding women using DHIS2 data. This was a proof-of-concept model.","AI technology was utilized in Mali to create a pandemic preparedness AI model for the distribution of COVID-19 vaccines. The model focused on targeting hotspots with positive cases and pregnant/breastfeeding women using DHIS2 data, serving as a proof-of-concept for optimizing vaccine allocation.","AI technology was utilized in Mali to create a pandemic preparedness AI model for the distribution of COVID-19 vaccines. The model focused on targeting hotspots with positive cases and pregnant/breastfeeding women using DHIS2 data, serving as a proof-of-concept for optimizing vaccine allocation.",,"Yes, the project described potentially poses a safety risk. 

The project involves the use of AI technology to distribute COVID-19 vaccines in Mali. While the focus is on targeting hotspots with positive cases and pregnant/breastfeeding women using DHIS2 data, it is important to consider the potential risks associated with AI technology in this context. 

If the AI model is not properly developed or trained, it could lead to inaccurate distribution of vaccines, potentially leaving vulnerable populations without adequate access to vaccines. This could have serious health implications and may hinder efforts to control the pandemic.

Additionally, if the AI model relies on personal data for targeting vaccine allocation, there is a risk of privacy breaches or misuse of sensitive information. It is crucial to ensure that proper security measures are in place to protect individuals' data and prevent unauthorized access.

Overall, while the project has the potential to optimize vaccine allocation and improve pandemic preparedness, the use of AI technology introduces risks that need to be carefully managed to ensure the safety and effectiveness of the distribution process.",True,False
DOI-0000-2023,DOI,BLM,,Land Use Plan Document and Data Mining and Analysis R&D,"Exploring the potential to identify patterns, rule alignment or conflicts, discovery, and mapping of geo history and/or rules. Inputs included unstructured planning documents. Outputs identify conflicts in resource management planning rules with proposed action locations requiring exclusion, restrictions, or stipluations as defined in the planning documents. ",Planned (not in production),Natural Language Processing and Geo Classification,,Department of Interior,"Land Use Plan Document and Data Mining and Analysis R&D: 
Exploring the potential to identify patterns, rule alignment or conflicts, discovery, and mapping of geo history and/or rules. Inputs included unstructured planning documents. Outputs identify conflicts in resource management planning rules with proposed action locations requiring exclusion, restrictions, or stipluations as defined in the planning documents. ","The Land Use Plan Document and Data Mining and Analysis R&D aims to uncover patterns and conflicts in planning documents related to resource management. This research explores the potential to identify these conflicts and map them, allowing for the exclusion, restriction, or stipulation of proposed action locations as defined in the planning documents.","The Land Use Plan Document and Data Mining and Analysis R&D aims to uncover patterns and conflicts in planning documents related to resource management. This research explores the potential to identify these conflicts and map them, allowing for the exclusion, restriction, or stipulation of proposed action locations as defined in the planning documents.",,"Yes, the project described above is potentially a safety risk. The project involves the use of data mining and analysis to uncover patterns and conflicts in planning documents related to resource management. While the specific risks are not explicitly mentioned in the project description, it falls under category ""a"" of the defined risks, which includes decisions to block, remove, hide, or limit the reach of protected speech. By excluding, restricting, or stipulating proposed action locations based on the analysis of planning documents, there is a potential for the project to infringe on individuals' rights to express their opinions and concerns regarding resource management. This can lead to conflicts, protests, or other safety risks if communities feel that their interests or voices are being ignored or suppressed.",True,False
DOE-0095-2023,DOE,National Energy Technology Laboratory,,To develop and create an autonomous robotic inspection system.,"The goal of the project is to prevent negative environmental and 
socioeconomic impacts of coal waste (coal ash and tailings) by 
developing an aerial robot-enabled inspection and monitoring system of 
active and abandoned coal ash and tailings storage facilities. The first 
objective of this project is the development of a programmable drone, 
equipped with several complementary sensors, that will autonomously 
inspect several structures of a storage facility. The second objective of 
this project is to create artificial intelligence-based hazard detection 
algorithms that will use multispectral and georeferenced images (i.e., 
thermal and visual) and 3D Point Clouds data collected by an 
autonomous drone to detect hazards in the storage facility structure that 
would indicate uncontrolled leakage to the environment or lead to the 
potential failure of the structure.",,"Artificial Intelligence, Robotic Processing Automation (RPA)",,Department of Energy,"To develop and create an autonomous robotic inspection system.: 
The goal of the project is to prevent negative environmental and 
socioeconomic impacts of coal waste (coal ash and tailings) by 
developing an aerial robot-enabled inspection and monitoring system of 
active and abandoned coal ash and tailings storage facilities. The first 
objective of this project is the development of a programmable drone, 
equipped with several complementary sensors, that will autonomously 
inspect several structures of a storage facility. The second objective of 
this project is to create artificial intelligence-based hazard detection 
algorithms that will use multispectral and georeferenced images (i.e., 
thermal and visual) and 3D Point Clouds data collected by an 
autonomous drone to detect hazards in the storage facility structure that 
would indicate uncontrolled leakage to the environment or lead to the 
potential failure of the structure.",The purpose of this project is to create a robotic inspection system that can autonomously monitor coal waste storage facilities. The first objective is to develop a drone that can inspect different structures within the facility. The second objective is to use artificial intelligence and various sensors to detect potential hazards in the storage facility that could lead to environmental damage or structural failure.,The purpose of this project is to create a robotic inspection system that can autonomously monitor coal waste storage facilities. The first objective is to develop a drone that can inspect different structures within the facility. The second objective is to use artificial intelligence and various sensors to detect potential hazards in the storage facility that could lead to environmental damage or structural failure.,"Yes, the project is potentially a safety risk.

Explanation: The project involves the design and development of a robotic inspection system for coal waste storage facilities. Coal waste storage facilities can pose significant risks to safety and the environment. The project aims to use a drone equipped with artificial intelligence and sensors to inspect the structures within the facility and detect potential hazards that could lead to environmental damage or structural failure.

The project falls under several categories of safety risks mentioned in the definition. It involves the transportation or management of industrial waste (category g) and the design, construction, or testing of industrial equipment (category h). If the robotic inspection system fails or is not properly designed, it could pose a meaningful risk to safety.

Furthermore, coal waste storage facilities can have significant environmental impact (category f). If the project fails to detect potential hazards or monitor the facility effectively, it could lead to environmental damage.

Overall, due to the nature of the project and the potential risks associated with coal waste storage facilities, it is important to carefully assess and mitigate any safety risks involved in the development and deployment of the robotic inspection system.",,False,True
USDA-0000-2023,USDA,USDA,APHIS,Predictive modeling of invasive pest species and category at the port of entry using machine learning algorithms,Macine learning algorithms are used to develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the port of entry.,Operation and Management,Machine Learning,,Department of Agriculture,"Predictive modeling of invasive pest species and category at the port of entry using machine learning algorithms: 
Macine learning algorithms are used to develop with inspection data and improve prediction ability of detecting invasive/quarantine significant pests at the port of entry.",Machine learning algorithms are utilized to create predictive models that enhance the accuracy of detecting invasive or quarantine significant pest species at the port of entry. These models are developed by analyzing inspection data and are aimed at improving the prediction ability of identifying such pests.,Machine learning algorithms are utilized to create predictive models that enhance the accuracy of detecting invasive or quarantine significant pest species at the port of entry. These models are developed by analyzing inspection data and are aimed at improving the prediction ability of identifying such pests.,,"Yes, the project potentially poses a safety risk. 

The project involves the use of machine learning algorithms to enhance the accuracy of detecting invasive or quarantine significant pest species at the port of entry. While this may seem like a beneficial application of technology, it falls under the category of ""law enforcement or surveillance-related risk assessments"" as mentioned in the defined risks.

The use of predictive models and AI algorithms in law enforcement or surveillance activities can raise concerns about privacy, potential biases, and the potential for misuse or abuse of power. In this case, the project involves monitoring and identifying pests, but it still falls within the broader category of surveillance-related activities.

Therefore, it is important to carefully consider the potential risks and safeguards associated with the project to ensure that it does not infringe on individual rights or lead to unintended consequences.",True,False
DHS-0011-2023,DHS,Customs and Border Protection,,Use of technology to identify proof of life,"The Use of technology to identify proof of life, or ""Liveness Detection,"" uses Artificial Intelligence to reduce fraudulent activity, primarily for use within the CBP One app.

The CBP One app is designed to provide the public with a single portal to a variety of CBP services. It includes different functionality for travelers, importers, brokers, carriers, International Organizations, and other entities under a single consolidated log-in, and uses guided questions to help users determine the correct services, forms, or applications needed.

The Liveness Detection component used by the authentication system for the CBP One app uses the user's mobile device camera in addition to Artificial Intelligence algorithms to determine if the face presented to the app is the person in front of the camera at the time of capture and not a photo, mask, or other spoofing mechanism. Being able to accept submitted data with confidence that the submitting individual is who and where they claim to be is critical to the functionality of the app within the agency environment. ",Development and Acquisition,Machine Vision,,Department of Homeland Security,"Use of technology to identify proof of life: 
The Use of technology to identify proof of life, or ""Liveness Detection,"" uses Artificial Intelligence to reduce fraudulent activity, primarily for use within the CBP One app.

The CBP One app is designed to provide the public with a single portal to a variety of CBP services. It includes different functionality for travelers, importers, brokers, carriers, International Organizations, and other entities under a single consolidated log-in, and uses guided questions to help users determine the correct services, forms, or applications needed.

The Liveness Detection component used by the authentication system for the CBP One app uses the user's mobile device camera in addition to Artificial Intelligence algorithms to determine if the face presented to the app is the person in front of the camera at the time of capture and not a photo, mask, or other spoofing mechanism. Being able to accept submitted data with confidence that the submitting individual is who and where they claim to be is critical to the functionality of the app within the agency environment. ",The CBP One app uses technology called Liveness Detection to verify the identity of users. This technology uses Artificial Intelligence and the user's mobile device camera to determine if the face presented is of the actual person and not a photo or mask. This feature is crucial for the app's functionality within the agency.,The CBP One app uses technology called Liveness Detection to verify the identity of users. This technology uses Artificial Intelligence and the user's mobile device camera to determine if the face presented is of the actual person and not a photo or mask. This feature is crucial for the app's functionality within the agency.,,"Yes, the project described is potentially a safety risk. The use of Liveness Detection technology in the CBP One app raises concerns regarding privacy and potential misuse. The use of facial recognition technology, especially when combined with artificial intelligence, can lead to intrusive surveillance and potential violations of individual rights.

Additionally, there is a risk of false positives or false negatives in the identification process. If the technology fails to accurately determine if the face presented is of the actual person, it can result in wrongful identification or unauthorized access. This could have serious consequences in the context of law enforcement or border security.

Furthermore, the collection and storage of biometric data, such as facial images, can pose significant privacy risks if not adequately protected. There is a potential for misuse or unauthorized access to this sensitive information, leading to identity theft or other malicious activities.

Considering the project's potential for privacy infringement and the possibility of inaccurate identification, it is important to thoroughly assess and mitigate these risks to ensure the safety and protection of individuals' rights.",True,False
DOE-0114-2023,DOE,National Energy Technology Laboratory,,To fill critical data gaps in big data analytics and machine learning applications to inform decision making and improve the ultimate recovery of unconventional oil and natural gas resources.,"Project will conduct numerical analysis of all-digital pressure sensing 
technology will be used to create a synthetic dataset with downhole 
pressure sensor readings for each stage and will be analyzed 
statistically with DA to integrate with software.",,"Artificial Intelligence, Big Data",,Department of Energy,"To fill critical data gaps in big data analytics and machine learning applications to inform decision making and improve the ultimate recovery of unconventional oil and natural gas resources.: 
Project will conduct numerical analysis of all-digital pressure sensing 
technology will be used to create a synthetic dataset with downhole 
pressure sensor readings for each stage and will be analyzed 
statistically with DA to integrate with software.","This project aims to enhance big data analytics and machine learning applications by addressing data gaps in the extraction of unconventional oil and natural gas resources. It involves conducting numerical analysis and using all-digital pressure sensing technology to generate a synthetic dataset for each stage, which will be statistically analyzed and integrated with software through data analytics.","This project aims to enhance big data analytics and machine learning applications by addressing data gaps in the extraction of unconventional oil and natural gas resources. It involves conducting numerical analysis and using all-digital pressure sensing technology to generate a synthetic dataset for each stage, which will be statistically analyzed and integrated with software through data analytics.","Yes, this project is potentially a safety risk. It falls under the category of ""f. Industrial emissions and environmental impact control processes"" as it involves the extraction of unconventional oil and natural gas resources. The use of big data analytics and machine learning in this project may have implications for the environment and the control of emissions. If not properly managed, the project could lead to negative environmental impacts and potential safety hazards.",,False,True
DHS-0038-2023,DHS,United States Citizenship and Immigration Services,,Predicted to Naturalize,"The Predicted to Naturalize model predicts when Legal Permanent Residents would be eligible to naturalize, and attempts to provide a current address. This model could potentially be used to send correspondence to USCIS customers of their resident status, and notify others of potential USCIS benefits.",Implementation,"Machine Learning, Clustering, Regression",,Department of Homeland Security,"Predicted to Naturalize: 
The Predicted to Naturalize model predicts when Legal Permanent Residents would be eligible to naturalize, and attempts to provide a current address. This model could potentially be used to send correspondence to USCIS customers of their resident status, and notify others of potential USCIS benefits.",The Predicted to Naturalize model is designed to predict the eligibility of Legal Permanent Residents for naturalization and provides their current address. It can be utilized to send important information to USCIS customers regarding their resident status and inform others about potential USCIS benefits.,The Predicted to Naturalize model is designed to predict the eligibility of Legal Permanent Residents for naturalization and provides their current address. It can be utilized to send important information to USCIS customers regarding their resident status and inform others about potential USCIS benefits.,,"Yes, the project described above is potentially a safety risk. The project involves making decisions regarding access to government benefits or services, determining eligibility for naturalization, and providing personal information such as current addresses. These activities have the potential to infringe on individuals' privacy and may also be susceptible to misuse or unauthorized access, posing a risk to the safety and security of individuals involved.",True,False
DOS-0005-2023,DOS,A,,Within Grade Increase Automation,"A Natural Language Processing (NLP) model is used in coordination with Intelligent Character Recognition (ICR) to identify and extract values from the JF-62 form for within grade increase payroll actions. Robotic Process Automation (RPA) is then used to validate the data against existing reports, then create a formatted file for approval and processing.",,,,Department of State,"Within Grade Increase Automation: 
A Natural Language Processing (NLP) model is used in coordination with Intelligent Character Recognition (ICR) to identify and extract values from the JF-62 form for within grade increase payroll actions. Robotic Process Automation (RPA) is then used to validate the data against existing reports, then create a formatted file for approval and processing.","A combination of Natural Language Processing and Intelligent Character Recognition is utilized to extract information from the JF-62 form for payroll actions related to within grade increase. The extracted data is then cross-verified with existing reports using Robotic Process Automation, and a formatted file is generated for approval and further processing.","A combination of Natural Language Processing and Intelligent Character Recognition is utilized to extract information from the JF-62 form for payroll actions related to within grade increase. The extracted data is then cross-verified with existing reports using Robotic Process Automation, and a formatted file is generated for approval and further processing.",,"Yes, the project described above is potentially a safety risk. The project involves the use of various technologies to process and extract information from forms related to payroll actions. While the project itself may not directly involve safety risks, it falls under the category of ""Determining the terms and conditions of employment"" and ""Financial-system access determinations.""

These categories include decisions that have significant implications for individuals, such as pay or promotion, performance management, and access to financial systems. If the project's algorithms or processes are flawed or biased, it could lead to unfair outcomes, discrimination, or financial harm for individuals.

Additionally, the use of Robotic Process Automation and the handling of sensitive employee data raise concerns about data privacy and security. If the project does not have proper safeguards in place to protect the information being processed and generated, it could pose a risk to the privacy and confidentiality of individuals' data.

Therefore, due to the potential for unfair outcomes, discrimination, financial harm, and data privacy/security risks, the project described above is potentially a safety risk.",True,False
HHS-0090-2023,HHS,FDA,CFSAN/OFAS,"AI Engine for Knowledge discovery, Post-market Surveillance and Signal Detection","The use of Artificial Intelligence in post-market surveillance and signal detection will enhance CFSAN's ability to detect potential problems associated with CFSAN commodities, including leveraging data to investigate potential issues with chronic, long-term exposure to food additives, color additives, food contact substances and contaminants or long-term use of cosmetics. OFAS Warp Intelligent Learning Engine (WILEE) project seeks establish an intelligent knowledge discovery and analytic agent for the Office. WILEE (pronounced Wiley) provides a horizon-scanning solution, analyzing data from the WILEE knowledgebase, to enable the Office to maintain a proactive posture and the capacity to forecast industry trends so that the Office can stay ahead of the development cycle and prepare for how to handle a large influx of submissions (operational risk - e.g., change in USDA rules regarding antimicrobial residue levels in poultry processing), prioritize actions based on risk or stakeholder perceived risk regarding substances under OFAS purview (e.g., yoga mat incident). WILEE will provide the Office with an advanced data driven risked based decision-making tool, that leverages AI technologies to integrate and process a large variety of data sources, generating reports with quick insights that will significantly improve our time-to-results. ",Implementation,,,Department of Health and Human Services,"AI Engine for Knowledge discovery, Post-market Surveillance and Signal Detection: 
The use of Artificial Intelligence in post-market surveillance and signal detection will enhance CFSAN's ability to detect potential problems associated with CFSAN commodities, including leveraging data to investigate potential issues with chronic, long-term exposure to food additives, color additives, food contact substances and contaminants or long-term use of cosmetics. OFAS Warp Intelligent Learning Engine (WILEE) project seeks establish an intelligent knowledge discovery and analytic agent for the Office. WILEE (pronounced Wiley) provides a horizon-scanning solution, analyzing data from the WILEE knowledgebase, to enable the Office to maintain a proactive posture and the capacity to forecast industry trends so that the Office can stay ahead of the development cycle and prepare for how to handle a large influx of submissions (operational risk - e.g., change in USDA rules regarding antimicrobial residue levels in poultry processing), prioritize actions based on risk or stakeholder perceived risk regarding substances under OFAS purview (e.g., yoga mat incident). WILEE will provide the Office with an advanced data driven risked based decision-making tool, that leverages AI technologies to integrate and process a large variety of data sources, generating reports with quick insights that will significantly improve our time-to-results. ","The use of Artificial Intelligence in post-market surveillance and signal detection will improve CFSAN's ability to detect potential problems with their commodities. The OFAS Warp Intelligent Learning Engine (WILEE) project aims to establish an intelligent knowledge discovery and analytic agent for the Office, providing them with a proactive approach to industry trends and a data-driven decision-making tool.","The use of Artificial Intelligence in post-market surveillance and signal detection will improve CFSAN's ability to detect potential problems with their commodities. The OFAS Warp Intelligent Learning Engine (WILEE) project aims to establish an intelligent knowledge discovery and analytic agent for the Office, providing them with a proactive approach to industry trends and a data-driven decision-making tool.",,"Yes, the project described could potentially be a safety risk. The use of Artificial Intelligence in post-market surveillance and signal detection has the potential to impact decisions related to health and safety. If the AI system incorrectly identifies potential problems with commodities, it could lead to false alarms or missed dangers, potentially putting consumers at risk. Additionally, if the AI system is not properly monitored or regulated, it could make decisions that prioritize industry trends over public health and safety. Therefore, further evaluation and safeguards should be implemented to ensure the project does not pose a safety risk.",True,False
DOS-0010-2023,DOS,CSO,,Automated Damage Assessments,"The Conflict Observatory program uses AI and machine learning on moderate and high-resolution commerical satellite imagery to document a variety of war crimes and other abuses in Ukraine, including automated damage assessments of a variety of buildings, including critical infrastructure, hospitals, schools, crop storage facilities.",,,,Department of State,"Automated Damage Assessments: 
The Conflict Observatory program uses AI and machine learning on moderate and high-resolution commerical satellite imagery to document a variety of war crimes and other abuses in Ukraine, including automated damage assessments of a variety of buildings, including critical infrastructure, hospitals, schools, crop storage facilities.","The Conflict Observatory program utilizes AI and machine learning to analyze satellite images and record war crimes and human rights violations in Ukraine. It specifically focuses on conducting automated assessments of various structures, such as critical infrastructure, hospitals, schools, and crop storage facilities, to determine the extent of damage caused by the conflict.","The Conflict Observatory program utilizes AI and machine learning to analyze satellite images and record war crimes and human rights violations in Ukraine. It specifically focuses on conducting automated assessments of various structures, such as critical infrastructure, hospitals, schools, and crop storage facilities, to determine the extent of damage caused by the conflict.","Yes, the project described above is potentially a safety risk. According to the provided definition of safety risks, it falls under the category of ""the functioning of dams, emergency services, electrical grids or the generation or movement of energy, fire safety systems, food safety mechanisms, integrity of elections and voting infrastructure, traffic control systems and other systems controlling physical transit, water and wastewater systems, and nuclear reactors, materials, and waste.""

The Conflict Observatory program involves analyzing satellite images to record war crimes and human rights violations in Ukraine. This analysis includes assessing critical infrastructure, hospitals, schools, and crop storage facilities to determine the extent of damage caused by the conflict. This process may potentially interfere with the functioning of critical infrastructure, including electrical grids, water and wastewater systems, and possibly even emergency services. It could also have implications for the safety and integrity of the structures being assessed.

While the project aims to contribute to the documentation of war crimes and human rights violations, it is important to carefully consider and address any potential safety risks associated with the implementation of such a program.",,False,True
HHS-0079-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),MASTER PLAN Y4,"The overall mission of the Innovation Center is to integrate longitudinal patient-level EHR data into the Sentinel System to enable in-depth investigations of medication outcomes using richer clinical data than are generally not available in insurance claims data. The Master Plan lays out a five-year roadmap for the Sentinel Innovation Center to achieve this vision through four key strategic areas: (1) data infrastructure; (2) feature engineering; (3) causal inference; and (4) detection analytics. The projects focus on utilizing emerging technologies including feature engineering, natural language processing, advanced analytics, and data interoperability to improve Sentinel's capabilities.",Initiation,,,Department of Health and Human Services,"MASTER PLAN Y4: 
The overall mission of the Innovation Center is to integrate longitudinal patient-level EHR data into the Sentinel System to enable in-depth investigations of medication outcomes using richer clinical data than are generally not available in insurance claims data. The Master Plan lays out a five-year roadmap for the Sentinel Innovation Center to achieve this vision through four key strategic areas: (1) data infrastructure; (2) feature engineering; (3) causal inference; and (4) detection analytics. The projects focus on utilizing emerging technologies including feature engineering, natural language processing, advanced analytics, and data interoperability to improve Sentinel's capabilities.","The Master Plan for the Sentinel Innovation Center outlines a five-year roadmap to integrate patient-level EHR data into the Sentinel System. This will allow for more in-depth investigations of medication outcomes using clinical data not typically found in insurance claims. The plan focuses on four strategic areas, including data infrastructure, feature engineering, causal inference, and detection analytics, and aims to enhance Sentinel's capabilities through the use of emerging technologies.","The Master Plan for the Sentinel Innovation Center outlines a five-year roadmap to integrate patient-level EHR data into the Sentinel System. This will allow for more in-depth investigations of medication outcomes using clinical data not typically found in insurance claims. The plan focuses on four strategic areas, including data infrastructure, feature engineering, causal inference, and detection analytics, and aims to enhance Sentinel's capabilities through the use of emerging technologies.",,"Yes, the project described potentially poses a safety risk. The project involves integrating patient-level Electronic Health Record (EHR) data into the Sentinel System, which aims to investigate medication outcomes using clinical data. This raises concerns about privacy and security, as the project involves handling sensitive medical information. If the data is not adequately protected, there is a risk of unauthorized access or misuse, which could compromise patient confidentiality and potentially lead to harm if the data falls into the wrong hands. Safeguards must be in place to ensure the secure handling and storage of the EHR data to mitigate this safety risk.",True,False
DHS-0016-2023,DHS,Cybersecurity and Infrastructure Security Agency,,AIS Scoring and Feedback,"AIS Automated Scoring & Feedback (AS&F) is uses descriptive analytics from organizational-centric intelligence to support confidence and opinion/reputation classification of indicators of compromise (IOCs). Looking at an indicator AS&F determines if the indicator is present in known-good list by cross-referencing organizational-centric intelligence data of known non-malicious/benign indicators and classifies accordingly if true. If not a known-good, determine if there are sightings of the indicator by cross-referencing organizational-centric intelligence and classify accordingly if true. If there are no sightings for the indicator, determine if this indicator has been verified by an analyst within our organizational-centric intelligence and classify accordingly if true. Lastly if the indicator has not been verified by an analyst, AS&F determines whether there are other reports within our organizational-centric intelligence about this indicator and classifies accordingly. AIS participants can triage against the populated opinion and/or confidence values to identify Indicator objects meeting or exceeding designated criteria and filter out the remaining data. AIS participants may also find value in utilizing the confidence score (if present) and the opinion value to understand whether any difference between the publisher and other organizations exists. Together, these enrichments can help those receiving information from AIS prioritize actioning and investigating Indicator objects.",Operation and Maintenance,Descriptive Analysis; Machine Learning; NLP,,Department of Homeland Security,"AIS Scoring and Feedback: 
AIS Automated Scoring & Feedback (AS&F) is uses descriptive analytics from organizational-centric intelligence to support confidence and opinion/reputation classification of indicators of compromise (IOCs). Looking at an indicator AS&F determines if the indicator is present in known-good list by cross-referencing organizational-centric intelligence data of known non-malicious/benign indicators and classifies accordingly if true. If not a known-good, determine if there are sightings of the indicator by cross-referencing organizational-centric intelligence and classify accordingly if true. If there are no sightings for the indicator, determine if this indicator has been verified by an analyst within our organizational-centric intelligence and classify accordingly if true. Lastly if the indicator has not been verified by an analyst, AS&F determines whether there are other reports within our organizational-centric intelligence about this indicator and classifies accordingly. AIS participants can triage against the populated opinion and/or confidence values to identify Indicator objects meeting or exceeding designated criteria and filter out the remaining data. AIS participants may also find value in utilizing the confidence score (if present) and the opinion value to understand whether any difference between the publisher and other organizations exists. Together, these enrichments can help those receiving information from AIS prioritize actioning and investigating Indicator objects.","AIS Automated Scoring & Feedback (AS&F) uses descriptive analytics to classify indicators of compromise (IOCs) based on organizational-centric intelligence. It checks if the indicator is present in a known-good list, if there are sightings of the indicator, if it has been verified by an analyst, and if there are other reports about the indicator. Participants can use the opinion and confidence values to filter and prioritize the data, and the confidence score and opinion value to compare with other organizations. This helps with actioning and investigating Indicator objects.","AIS Automated Scoring & Feedback (AS&F) uses descriptive analytics to classify indicators of compromise (IOCs) based on organizational-centric intelligence. It checks if the indicator is present in a known-good list, if there are sightings of the indicator, if it has been verified by an analyst, and if there are other reports about the indicator. Participants can use the opinion and confidence values to filter and prioritize the data, and the confidence score and opinion value to compare with other organizations. This helps with actioning and investigating Indicator objects.",,"Yes, the project described above potentially poses a safety risk. 

The project involves automated scoring and feedback based on indicators of compromise (IOCs) and uses descriptive analytics to classify these indicators. While the project itself may not seem directly related to safety risks, the definition provided includes several categories that could potentially be impacted by the project. 

For example, the project could potentially be used in law enforcement or surveillance-related risk assessments, such as cyber intrusions or physical location monitoring. If the project is used in these contexts without proper safeguards and oversight, it could lead to privacy violations or misuse of surveillance technologies, which could pose safety risks to individuals.

Additionally, the project's use in medical or health-related assessments raises concerns about the accuracy and reliability of the AI system in determining medical diagnoses, treatment recommendations, or mental health status detection. If the system produces incorrect or biased results, it could have serious consequences for patients' health and safety.

Overall, without more information on how the project is implemented and regulated, it is challenging to fully assess the safety risks. However, based on the information provided, there is a potential for the project to be a safety risk, especially if it is used in contexts that involve sensitive or critical decision-making processes.",True,False
DOL-0000-2023,DOL,,,Form Recognizer for Benefits Forms,Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.,Operation and Maintenance,Classification machine learning model involving computer vision,,Department of Labor,"Form Recognizer for Benefits Forms: 
Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.",Form Recognizer for Benefits Forms is a custom machine learning model that extracts data from intricate forms and assigns data entries to field headers. This model takes a document or scanned image of the form as input and generates a JSON response with extracted key/value pairs by utilizing the custom trained model.,Form Recognizer for Benefits Forms is a custom machine learning model that extracts data from intricate forms and assigns data entries to field headers. This model takes a document or scanned image of the form as input and generates a JSON response with extracted key/value pairs by utilizing the custom trained model.,,"Yes, the project described above is potentially a safety risk. 

This is because the project involves making decisions regarding access to or eligibility for government benefits or services, as well as detecting fraud and assigning penalties in the context of federal benefits. These decisions can have significant impacts on individuals' lives, as they may determine their access to essential resources and support systems. 

If the machine learning model used in this project is not accurate or reliable in identifying the correct key/value pairs from the forms, it could lead to incorrect decisions being made. This could result in individuals being wrongly denied access to benefits or services they are entitled to, or being penalized unfairly. 

Therefore, there is a potential safety risk associated with this project, as it involves making decisions that directly impact people's well-being and livelihoods. It is crucial to ensure the accuracy and fairness of the model and its outputs to mitigate these risks.",True,False
DOE-0015-2023,DOE,Fermi National Accelerator,,Streamining intelligent detectors for sPHENIX/EIC,"This project develops real-time algorithms for event filtering with tracking 
detectors for nuclear physics collider experiments.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"Streamining intelligent detectors for sPHENIX/EIC: 
This project develops real-time algorithms for event filtering with tracking 
detectors for nuclear physics collider experiments.",This project focuses on creating real-time algorithms for event filtering in nuclear physics collider experiments using tracking detectors. The goal is to improve the efficiency and accuracy of detection by developing intelligent detectors for sPHENIX/EIC.,This project focuses on creating real-time algorithms for event filtering in nuclear physics collider experiments using tracking detectors. The goal is to improve the efficiency and accuracy of detection by developing intelligent detectors for sPHENIX/EIC.,"Yes, this project is potentially a safety risk. 

The project involves the design and development of tracking detectors for nuclear physics collider experiments. Nuclear reactors, materials, and waste are listed as safety risks. Any project related to nuclear reactors and materials carries inherent safety risks due to the potential for radiation leaks and other accidents. Additionally, the project involves the transportation or management of industrial waste or controlled pollutants, which is also listed as a safety risk. 

Therefore, due to its association with nuclear physics and potential risks associated with the transportation and management of industrial waste, this project is potentially a safety risk.",,False,True
DOI-0020-2023,DOI,USGS,,WRA.HIHR.WAIEE Building capacity for assessment and prediction of post-wildfire water availability,"All listed objectives are focused on the western US:
· Collect multiple harmonized datasets from fire-affected basins in the western US that will advance development, calibration, and validation of water-quality models and assessment.
· Analyze harmonized datasets to assess regional differences in critical drivers of water quality impairment.
· Develop decision tree and standardized plan to determine locations to monitor after wildfire and ensure consistent post-fire water-quality data collection that accurately captures magnitude and duration of impairment.
· Develop rapid response plan to enable WSCs and WMA to be prepared for immediate responses for post-fire data collection and assessment.
· Establish the state of the science of critical drivers of post-fire water quality impairment in different ecoregions the western U.S.
· Characterize critical drivers, including in-stream and reservoir-sediment interface contributions, to post-fire water quality impairment.
· Build catalog of methods for measuring remotely sensed water quality after wildfire and apply multiple test cases of application.
· Develop catalog of critical data needs for geospatial prediction of wildfire impacts on water.
· Construct blueprint for incorporating missing critical water-quality impairment processes into modeling and prediction.
· Prepare plan with IWP for incorporating wildfire effects on water availability into rapid prediction.
· Participate in development and application of a framework for cross-Mission Area integration of predictive approaches spanning temporal and spatial scales for post-fire hazards.",Initiation,convolutional neural networks,,Department of Interior,"WRA.HIHR.WAIEE Building capacity for assessment and prediction of post-wildfire water availability: 
All listed objectives are focused on the western US:
· Collect multiple harmonized datasets from fire-affected basins in the western US that will advance development, calibration, and validation of water-quality models and assessment.
· Analyze harmonized datasets to assess regional differences in critical drivers of water quality impairment.
· Develop decision tree and standardized plan to determine locations to monitor after wildfire and ensure consistent post-fire water-quality data collection that accurately captures magnitude and duration of impairment.
· Develop rapid response plan to enable WSCs and WMA to be prepared for immediate responses for post-fire data collection and assessment.
· Establish the state of the science of critical drivers of post-fire water quality impairment in different ecoregions the western U.S.
· Characterize critical drivers, including in-stream and reservoir-sediment interface contributions, to post-fire water quality impairment.
· Build catalog of methods for measuring remotely sensed water quality after wildfire and apply multiple test cases of application.
· Develop catalog of critical data needs for geospatial prediction of wildfire impacts on water.
· Construct blueprint for incorporating missing critical water-quality impairment processes into modeling and prediction.
· Prepare plan with IWP for incorporating wildfire effects on water availability into rapid prediction.
· Participate in development and application of a framework for cross-Mission Area integration of predictive approaches spanning temporal and spatial scales for post-fire hazards.","The text outlines several objectives aimed at building capacity for assessing and predicting post-wildfire water availability in the western US. These objectives include collecting and analyzing datasets, developing standardized plans and rapid response strategies, establishing the state of the science on water quality impairment, cataloging measurement methods and data needs, and integrating predictive approaches for post-fire hazards across different scales.","The text outlines several objectives aimed at building capacity for assessing and predicting post-wildfire water availability in the western US. These objectives include collecting and analyzing datasets, developing standardized plans and rapid response strategies, establishing the state of the science on water quality impairment, cataloging measurement methods and data needs, and integrating predictive approaches for post-fire hazards across different scales.","Yes, the project is potentially a safety risk. 

The project involves assessing and predicting post-wildfire water availability in the western US. This falls under the category of water and wastewater systems, which are defined as safety risks. The project aims to collect and analyze datasets, develop plans, establish the state of the science, and integrate predictive approaches, all of which require the handling and management of water systems. 

If the project fails to accurately assess and predict post-wildfire water availability, it could lead to water scarcity, contamination, or other negative impacts on the water system, posing a meaningful risk to safety. Therefore, the project falls under the definition of a safety risk.",,False,True
HHS-0111-2023,HHS,NIH,National Institutes of Health (NIH) NHLBI,Detection of Implementation Science focus within incoming grant applications,"This tool uses natural language processing and machine learning to calculate an Implementation Science (IS) score that is used to predict if a newly submitted grant application proposes to use science that can be categorized as ""Implementation Science"" (a relatively new area of delineation). NHLBI uses the ""IS score"" in its decision for assigning the application to a particular division for routine grants management oversight and administration.",Operation and Maintenance,,,Department of Health and Human Services,"Detection of Implementation Science focus within incoming grant applications: 
This tool uses natural language processing and machine learning to calculate an Implementation Science (IS) score that is used to predict if a newly submitted grant application proposes to use science that can be categorized as ""Implementation Science"" (a relatively new area of delineation). NHLBI uses the ""IS score"" in its decision for assigning the application to a particular division for routine grants management oversight and administration.",A tool utilizing natural language processing and machine learning has been developed to analyze incoming grant applications and determine if they incorporate Implementation Science. The resulting IS score is utilized by NHLBI to assign applications to specific divisions for grants management oversight and administration.,A tool utilizing natural language processing and machine learning has been developed to analyze incoming grant applications and determine if they incorporate Implementation Science. The resulting IS score is utilized by NHLBI to assign applications to specific divisions for grants management oversight and administration.,,"Yes, the project is potentially a safety risk. The risks outlined in the project description do not directly pertain to safety concerns such as physical harm or danger. The risks listed in the project description primarily focus on decision-making processes, data analysis, and allocation of resources. While these risks may have implications for fairness, privacy, or ethical considerations, they do not pose a direct safety risk.",True,False
HHS-0025-2023,HHS,CDC,NCCDPHP/DDT,Validation Study of Deep Learning Algorithms to Explore the Potential Use of Artificial Intelligence for Public Health Surveillance of Eye Diseases,Applying deep learning algorithms for detecting diabetic retinopathy to the NHANES retinal photos. The purpose of this project is to determine whether these algorithms could be used in the future to replace ophthalmologist grading and grade retinal photos collected for surveillance purposes through the National Health and Nutrition Examination Survey (NHANES).,Development and Acquisition,,,Department of Health and Human Services,"Validation Study of Deep Learning Algorithms to Explore the Potential Use of Artificial Intelligence for Public Health Surveillance of Eye Diseases: 
Applying deep learning algorithms for detecting diabetic retinopathy to the NHANES retinal photos. The purpose of this project is to determine whether these algorithms could be used in the future to replace ophthalmologist grading and grade retinal photos collected for surveillance purposes through the National Health and Nutrition Examination Survey (NHANES).",This study aims to assess the effectiveness of using deep learning algorithms to detect diabetic retinopathy in retinal photos collected through NHANES. The goal is to determine if these algorithms can replace the need for ophthalmologist grading in public health surveillance of eye diseases.,This study aims to assess the effectiveness of using deep learning algorithms to detect diabetic retinopathy in retinal photos collected through NHANES. The goal is to determine if these algorithms can replace the need for ophthalmologist grading in public health surveillance of eye diseases.,,"Yes, the project is potentially a safety risk. The project involves using deep learning algorithms to detect diabetic retinopathy in retinal photos. If these algorithms are used to replace the need for ophthalmologist grading in public health surveillance of eye diseases, there is a risk of misdiagnosis or missed diagnoses. This could potentially lead to delayed or incorrect treatment for individuals with diabetic retinopathy, which can result in vision loss or other complications. It is crucial to ensure that the algorithms used are accurate and reliable before implementing them in public health surveillance.",True,False
DOS-0016-2023,DOS,GPA,,Global Audience Segmentation Framework,A prototype system that collects and analyzes the daily media clips reports from about 70 different Embassy Public Affairs Sections.,,,,Department of State,"Global Audience Segmentation Framework: 
A prototype system that collects and analyzes the daily media clips reports from about 70 different Embassy Public Affairs Sections.",The Global Audience Segmentation Framework is a prototype system that gathers and examines media clips reports from approximately 70 Embassy Public Affairs Sections on a daily basis. It aims to segment and categorize the global audience based on the collected data.,The Global Audience Segmentation Framework is a prototype system that gathers and examines media clips reports from approximately 70 Embassy Public Affairs Sections on a daily basis. It aims to segment and categorize the global audience based on the collected data.,,"Yes, the project described is potentially a safety risk. The project involves the gathering and examination of media clips reports from various sources on a daily basis, with the goal of segmenting and categorizing the global audience based on the collected data.

The potential safety risk arises from the fact that the project involves monitoring and analyzing individuals' online activities, which can infringe on their privacy rights. It also raises concerns about potential misuse of the collected data for surveillance or other purposes that may have negative implications for individuals' freedom of speech and expression.

Additionally, the project's ability to categorize the global audience based on collected data may lead to discriminatory practices and biased decision-making in various areas such as employment, education, access to government benefits, and child welfare. This could result in unjust treatment, unequal opportunities, and infringements on individuals' rights.

Overall, the project's focus on monitoring and categorizing individuals based on their online activities poses significant privacy and ethical concerns, making it a potential safety risk.",True,False
DOE-0146-2023,DOE,National Energy Technology Laboratory,,Use ML to reduce high-fidelity physical models to a fast calculation that requires minimal effort to initiate.,"The platform will combine an intuitive user interface and visualization 
capabilities from gaming software with the speed and enhanced detail in 
evaluating reservoir dynamics and processes through ML /reduced 
order model approaches. Advancements made with ML will alleviate the 
need for both the expert user and the computational infrastructure and 
make understanding subsurface fluid flow accessible to the everyday 
user with a moderate level of understanding of the physics of the 
system. ML will allow the experts to reduce the high-fidelity physical 
models to a fast calculation that requires a minimal amount of effort to 
initiate, but allows a user to investigate their own scenarios without the 
need for predetermined models. Application of the platform will rapidly 
enhance the experience base required for deploying and managing 
commercial-scale projects, particularly for CO2 storage projects where 
field experience is limited, because of the anticipated intuitive translation 
of subsurface dynamics in real-time.",,Other,,Department of Energy,"Use ML to reduce high-fidelity physical models to a fast calculation that requires minimal effort to initiate.: 
The platform will combine an intuitive user interface and visualization 
capabilities from gaming software with the speed and enhanced detail in 
evaluating reservoir dynamics and processes through ML /reduced 
order model approaches. Advancements made with ML will alleviate the 
need for both the expert user and the computational infrastructure and 
make understanding subsurface fluid flow accessible to the everyday 
user with a moderate level of understanding of the physics of the 
system. ML will allow the experts to reduce the high-fidelity physical 
models to a fast calculation that requires a minimal amount of effort to 
initiate, but allows a user to investigate their own scenarios without the 
need for predetermined models. Application of the platform will rapidly 
enhance the experience base required for deploying and managing 
commercial-scale projects, particularly for CO2 storage projects where 
field experience is limited, because of the anticipated intuitive translation 
of subsurface dynamics in real-time.","This text describes the use of machine learning (ML) to simplify and speed up the evaluation of reservoir dynamics and processes. By using ML, experts can quickly generate calculations that require minimal effort to initiate, allowing everyday users with a moderate understanding of the physics to investigate their own scenarios. This platform will be particularly useful for CO2 storage projects, where field experience is limited, as it provides real-time translation of subsurface dynamics.","This text describes the use of machine learning (ML) to simplify and speed up the evaluation of reservoir dynamics and processes. By using ML, experts can quickly generate calculations that require minimal effort to initiate, allowing everyday users with a moderate understanding of the physics to investigate their own scenarios. This platform will be particularly useful for CO2 storage projects, where field experience is limited, as it provides real-time translation of subsurface dynamics.","Yes, the project described is potentially a safety risk. This is because the project involves the evaluation of reservoir dynamics and processes, which falls under the category of ""the functioning of dams, emergency services, electrical grids or the generation or movement of energy."" Any inaccuracies or errors in the machine learning algorithms used for this purpose could potentially lead to unsafe conditions or disruptions in energy generation or movement. Therefore, proper safeguards and validation processes must be in place to ensure the safety and reliability of the ML platform in this context.",,False,True
VA-0025-2023,VA,,,VA-DoE Suicide Exemplar Project,The VA-DoE Suicide Exemplar project is currently utilizing artificial intelligence to improve VA's ability to identify Veterans at risk for suicide through three closely related projects that all involve collaborations with the Department of Energy.,,,,Department of Veterans Affairs,"VA-DoE Suicide Exemplar Project: 
The VA-DoE Suicide Exemplar project is currently utilizing artificial intelligence to improve VA's ability to identify Veterans at risk for suicide through three closely related projects that all involve collaborations with the Department of Energy.",The VA-DoE Suicide Exemplar Project is using artificial intelligence to enhance the VA's capability to identify veterans who may be at risk of suicide. This project includes three interconnected initiatives that involve partnerships with the Department of Energy.,The VA-DoE Suicide Exemplar Project is using artificial intelligence to enhance the VA's capability to identify veterans who may be at risk of suicide. This project includes three interconnected initiatives that involve partnerships with the Department of Energy.,,"Yes, the project described is potentially a safety risk. 

The project involves the use of artificial intelligence to identify veterans who may be at risk of suicide. While the goal of preventing suicide is commendable, the use of AI in such a sensitive and critical area of healthcare can raise concerns.

There are several potential risks associated with this project. Firstly, the use of AI in determining mental health status and suicide risk assessment may not be accurate or reliable. AI systems are only as good as the data they are trained on, and biases or inaccuracies in the data can lead to incorrect assessments, potentially resulting in false positives or negatives.

Secondly, there is the risk of privacy and data security. The project involves partnerships with the Department of Energy, which raises concerns about the security of sensitive information about veterans. If the AI system is not adequately protected, there is a possibility of unauthorized access to personal and confidential data, leading to privacy breaches and potential harm to individuals.

Lastly, the project raises ethical concerns about the potential misuse or abuse of the AI system. If the system is not properly regulated and monitored, there is a risk of it being used to make decisions regarding the allocation of resources, benefits, or services, which could have significant implications for veterans' well-being and access to support.

Overall, while the project's aim is to address an important issue, the potential safety risks associated with the use of AI in mental health assessments and decision-making processes make it a potentially risky endeavor. Proper safeguards and oversight would be necessary to mitigate these risks and ensure the project's effectiveness and safety.",True,False
DOE-0100-2023,DOE,National Energy Technology Laboratory,,To develop drag models for non- spherical particles through machine learning,"Produce comprehensive experimental and numerical datasets for gas-
solid flows in well-controlled settings to understand the aerodynamic 
drag of non-spherical particles in the dense regime. The datasets and 
the gained knowledge will train deep neural networks to formulate a 
general drag model for use directly in NETL MFiX-DEM module. This will 
help to advance the accuracy and prediction fidelity of the computational 
tools that will be used in designing and optimizing fluidized beds and 
chemical looping reactors",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To develop drag models for non- spherical particles through machine learning: 
Produce comprehensive experimental and numerical datasets for gas-
solid flows in well-controlled settings to understand the aerodynamic 
drag of non-spherical particles in the dense regime. The datasets and 
the gained knowledge will train deep neural networks to formulate a 
general drag model for use directly in NETL MFiX-DEM module. This will 
help to advance the accuracy and prediction fidelity of the computational 
tools that will be used in designing and optimizing fluidized beds and 
chemical looping reactors","In order to create accurate drag models for non-spherical particles using machine learning, comprehensive experimental and numerical datasets need to be created to understand the aerodynamic drag in dense gas-solid flows. These datasets and the knowledge gained from them will be used to train deep neural networks, which will then be used to develop a general drag model for the NETL MFiX-DEM module. This will improve the accuracy and prediction ability of computational tools used in designing and optimizing fluidized beds and chemical looping reactors.","In order to create accurate drag models for non-spherical particles using machine learning, comprehensive experimental and numerical datasets need to be created to understand the aerodynamic drag in dense gas-solid flows. These datasets and the knowledge gained from them will be used to train deep neural networks, which will then be used to develop a general drag model for the NETL MFiX-DEM module. This will improve the accuracy and prediction ability of computational tools used in designing and optimizing fluidized beds and chemical looping reactors.","Yes, the project described above has the potential to be a safety risk. 

The project involves the design and optimization of fluidized beds and chemical looping reactors, which are part of the generation or movement of energy. These systems can pose safety risks if not properly designed or operated, as they deal with high temperatures, pressure, and potentially hazardous materials.

Additionally, the project involves the use of machine learning and deep neural networks, which can introduce risks related to data privacy and security. If these systems are compromised or manipulated, it could have serious consequences for the accuracy and prediction ability of computational tools used in designing and optimizing these reactors.

Therefore, due to its involvement in energy generation, potential hazards, and the use of advanced technologies, the project described above is potentially a safety risk.",,False,True
DOE-0093-2023,DOE,National Energy Technology Laboratory,,To develop an AI-driven integrated autonomous robotic visual inspection (RVI) platform.,"The overall objective of the research is to develop an AI-driven 
integrated autonomous robotic visual inspection (RVI) platform that can 
perform real-time defect identification, dynamic path planning, and safe 
navigation in a closed-loop manner. The",,"Artificial Intelligence, Robotic Processing Automation (RPA)",,Department of Energy,"To develop an AI-driven integrated autonomous robotic visual inspection (RVI) platform.: 
The overall objective of the research is to develop an AI-driven 
integrated autonomous robotic visual inspection (RVI) platform that can 
perform real-time defect identification, dynamic path planning, and safe 
navigation in a closed-loop manner. The",research aims to create a platform that uses AI technology to enable a robot to autonomously inspect and identify defects in real-time. This platform will also be able to plan its own path and navigate safely in a closed-loop system.,research aims to create a platform that uses AI technology to enable a robot to autonomously inspect and identify defects in real-time. This platform will also be able to plan its own path and navigate safely in a closed-loop system.,"Yes, the project is potentially a safety risk. It falls under the category of ""Physical movements, including in human-robot teaming, such as the movements of a robotic appendage or body, within a workplace, school, housing, transportation, medical, or law enforcement setting."" As the project involves the development of a platform that uses AI technology to enable a robot to autonomously inspect and identify defects in real-time, there is a potential for physical movements within various settings. If the robot malfunctions or fails to navigate safely, it could pose a risk to the safety of individuals or property in those settings.",,False,True
HHS-0155-2023,HHS,OIG,OIG,Contracts and Grants Analytics Portal,"The Contracts and Grants Analytics Portal uses AI to enhance HHS OIG staff's ability to access grants related data quickly and easily by: quickly navigating directly to the text of relevant findings across thousands of audits, the ability to discover similar findings, analyze trends, compare data between OPDIVs, and the means to see preliminary assessments of potential anomalies between grantees.",Operation and Maintenance,,,Department of Health and Human Services,"Contracts and Grants Analytics Portal: 
The Contracts and Grants Analytics Portal uses AI to enhance HHS OIG staff's ability to access grants related data quickly and easily by: quickly navigating directly to the text of relevant findings across thousands of audits, the ability to discover similar findings, analyze trends, compare data between OPDIVs, and the means to see preliminary assessments of potential anomalies between grantees.","The Contracts and Grants Analytics Portal is an AI-powered tool that helps HHS OIG staff access grants data effortlessly. It enables them to quickly find relevant audit findings, discover similar patterns, analyze trends, compare data between different divisions, and assess potential anomalies among grantees.","The Contracts and Grants Analytics Portal is an AI-powered tool that helps HHS OIG staff access grants data effortlessly. It enables them to quickly find relevant audit findings, discover similar patterns, analyze trends, compare data between different divisions, and assess potential anomalies among grantees.",,"Yes, the project described potentially poses a safety risk. The project involves the use of AI-powered technology to analyze and assess data related to grants. This can potentially have implications in various areas such as healthcare, education, employment, and government benefits. These areas involve sensitive personal information and decision-making processes that can significantly impact individuals' lives. If the AI-powered tool is not properly developed, implemented, or monitored, there is a risk of biased or discriminatory outcomes, privacy breaches, and unfair treatment. Therefore, careful consideration and evaluation of the tool's design and implementation are required to mitigate potential safety risks.",True,False
DOE-0150-2023,DOE,National Energy Technology Laboratory,,Using ML to build predictive models of branching processes and develop novel algorithms for automated MIP solver tuning,"We will collect dual gaps obtained as a result of using different 
branching strategies and feed them into ALAMO, Pysmo, and other 
machine learning approaches to build predictive models of branching 
processes as a function of carefully chosen instance features. These 
models will then be deployed as part of the IDAES platform to facilitate 
optimization of advanced integrated energy systems.  o Currently, tuning 
MIP solvers for a particular application is approached by ad-hoc trial-and-
error methods that are tedious and often ineffective, limiting design 
engineers to solution of small problems. To address this challenge and 
facilitate the solution of energy systems currently intractable, we 
propose to develop novel algorithms for automated MIP solver tuning 
through the use of machine learning.",,Other,,Department of Energy,"Using ML to build predictive models of branching processes and develop novel algorithms for automated MIP solver tuning: 
We will collect dual gaps obtained as a result of using different 
branching strategies and feed them into ALAMO, Pysmo, and other 
machine learning approaches to build predictive models of branching 
processes as a function of carefully chosen instance features. These 
models will then be deployed as part of the IDAES platform to facilitate 
optimization of advanced integrated energy systems.  o Currently, tuning 
MIP solvers for a particular application is approached by ad-hoc trial-and-
error methods that are tedious and often ineffective, limiting design 
engineers to solution of small problems. To address this challenge and 
facilitate the solution of energy systems currently intractable, we 
propose to develop novel algorithms for automated MIP solver tuning 
through the use of machine learning.","The text explains that machine learning will be used to create predictive models of branching processes, which will then be used to improve the optimization of advanced integrated energy systems. Currently, MIP solver tuning is done through trial and error methods, but the proposal suggests developing new algorithms using machine learning to automate this process and solve currently intractable energy systems.","The text explains that machine learning will be used to create predictive models of branching processes, which will then be used to improve the optimization of advanced integrated energy systems. Currently, MIP solver tuning is done through trial and error methods, but the proposal suggests developing new algorithms using machine learning to automate this process and solve currently intractable energy systems.","Yes, the project described potentially poses a safety risk. 

According to the given definition of safety risks, the project falls under the category of ""a. The functioning of... electrical grids or the generation or movement of energy."" The project aims to use machine learning to optimize advanced integrated energy systems, which are critical infrastructure systems controlling the movement and generation of energy. 

If the algorithms developed using machine learning are not properly tested, validated, or implemented, they could potentially lead to malfunctions or disruptions in the energy systems. This could result in power outages, equipment failures, or other safety hazards that may pose risks to people's lives, property, or the environment. 

Therefore, it is important to carefully consider and mitigate the potential safety risks associated with the development and implementation of these algorithms in order to ensure the safe and reliable functioning of the energy systems.",,False,True
VA-0017-2023,VA,,,Predictor profiles of OUD and overdose,Machine learning prediction models evaluate the interactions of known and novel risk factors for opioid use disorder (OUD) and overdose in Post-9/11 Veterans. Several machine learning classification-tree modeling approaches are used to develop predictor profiles of OUD and overdose. ,,,,Department of Veterans Affairs,"Predictor profiles of OUD and overdose: 
Machine learning prediction models evaluate the interactions of known and novel risk factors for opioid use disorder (OUD) and overdose in Post-9/11 Veterans. Several machine learning classification-tree modeling approaches are used to develop predictor profiles of OUD and overdose. ",Machine learning prediction models are used to analyze both known and new risk factors for opioid use disorder (OUD) and overdose among Post-9/11 Veterans. These models help create predictor profiles for OUD and overdose through various classification-tree modeling approaches.,Machine learning prediction models are used to analyze both known and new risk factors for opioid use disorder (OUD) and overdose among Post-9/11 Veterans. These models help create predictor profiles for OUD and overdose through various classification-tree modeling approaches.,,"Yes, the project described above has the potential to be a safety risk. The use of machine learning prediction models to analyze risk factors for opioid use disorder and overdose can have significant implications for the well-being and safety of Post-9/11 Veterans.

The potential safety risks include:

1. Privacy and data security: The project involves analyzing sensitive and personal data of veterans, which raises concerns about the privacy and security of their information. If not adequately protected, this data could be vulnerable to misuse or unauthorized access, potentially compromising the safety and well-being of the veterans.

2. Stigmatization and discrimination: The use of predictive models to identify individuals at risk for OUD and overdose may lead to stigmatization and discrimination. Veterans who are identified as high-risk based on these models may face negative consequences, such as limited access to healthcare or employment opportunities, which can impact their safety and well-being.

3. Access to appropriate treatment: While the project aims to identify risk factors for OUD and overdose, the effectiveness and accessibility of appropriate treatment for veterans is crucial for their safety. If the project does not consider the availability and quality of treatment options, it may not effectively address the underlying issue and could potentially put veterans at greater risk.

Overall, the project's focus on opioid use disorder and overdose among Post-9/11 Veterans has the potential to be a safety risk if not implemented with proper safeguards to protect privacy, avoid stigmatization, and ensure access to appropriate treatment.",True,False
OPM-0000-2023,OPM,HRS/FSC/ASMG & OCIO/FITBS,,Human Resource Apprentice (HRA),"Evaluate the technical feasibility, validity, and affordability of providing AI-supported applicant review help to HR Specialists in USA Staffing. OPM will also evaluate prototype against fairness and bias standards to ensure it does not introduce adverse impact to the hiring process. The key metric that OPM is seeking is “can the AI solution deliver faster, more accurate evaluations of applicant qualifications when compared to experienced HR Specialists?”",Development and Acquisition,,,U.S. Office of Personnel Management,"Human Resource Apprentice (HRA): 
Evaluate the technical feasibility, validity, and affordability of providing AI-supported applicant review help to HR Specialists in USA Staffing. OPM will also evaluate prototype against fairness and bias standards to ensure it does not introduce adverse impact to the hiring process. The key metric that OPM is seeking is “can the AI solution deliver faster, more accurate evaluations of applicant qualifications when compared to experienced HR Specialists?”","The Human Resource Apprentice (HRA) is responsible for assessing whether it is feasible, valid, and affordable to provide AI-supported assistance to HR Specialists in USA Staffing for reviewing applicants. Additionally, the Office of Personnel Management (OPM) will evaluate the prototype to ensure it does not introduce any biases or unfairness in the hiring process. The main objective for OPM is to determine if the AI solution can deliver quicker and more accurate evaluations of applicant qualifications compared to experienced HR Specialists.","The Human Resource Apprentice (HRA) is responsible for assessing whether it is feasible, valid, and affordable to provide AI-supported assistance to HR Specialists in USA Staffing for reviewing applicants. Additionally, the Office of Personnel Management (OPM) will evaluate the prototype to ensure it does not introduce any biases or unfairness in the hiring process. The main objective for OPM is to determine if the AI solution can deliver quicker and more accurate evaluations of applicant qualifications compared to experienced HR Specialists.",,"Yes, the project described is potentially a safety risk. The project involves using AI to support HR Specialists in reviewing applicants for hiring. This raises concerns in regards to the potential for biases and unfairness in the hiring process. If the AI solution is not properly designed or trained, it could unintentionally introduce biases and discriminate against certain individuals or groups. This could lead to unfair hiring practices and potential legal issues. Therefore, the project needs to be carefully evaluated and tested to ensure that it does not introduce biases and unfairness in the hiring process.",True,False
DOE-0009-2023,DOE,Fermi National Accelerator,,Machine Learning for Accelerator Operations Using Big Data Analytics / L-CAPE,"Big data analytics for anomaly prediction and classification, enabling 
automatic mitigation, operational savings, and predictive maintenance of 
the Fermilab LINAC",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"Machine Learning for Accelerator Operations Using Big Data Analytics / L-CAPE: 
Big data analytics for anomaly prediction and classification, enabling 
automatic mitigation, operational savings, and predictive maintenance of 
the Fermilab LINAC","The use of big data analytics and machine learning in the L-CAPE project at Fermilab LINAC allows for the prediction and classification of anomalies, leading to automatic mitigation, cost savings, and predictive maintenance in accelerator operations. This technology enables operational efficiency and helps in avoiding potential issues in advance.","The use of big data analytics and machine learning in the L-CAPE project at Fermilab LINAC allows for the prediction and classification of anomalies, leading to automatic mitigation, cost savings, and predictive maintenance in accelerator operations. This technology enables operational efficiency and helps in avoiding potential issues in advance.",,"Yes, the project described is potentially a safety risk. The risks defined in the project description do not directly mention safety concerns. However, the use of big data analytics and machine learning in predicting and classifying anomalies in accelerator operations could potentially lead to safety issues if the system fails to accurately identify or mitigate potential risks. The project's focus on operational efficiency and cost savings may prioritize these objectives over safety considerations, which could increase the chances of safety incidents occurring.",True,False
DHS-0006-2023,DHS,Customs and Border Protection,,Data and Entity Resolution,"Automates data unification and entity resolution with a high level of trust at enterprise scale and speed.

Data and Entity Resolution uses Machine Learning modeling to ingest multiple data sources and develop models that associate disparate records to identify probable connections, unique entities, and/or identify commonalities between multiple independently submitted records.

The automation of entity resolution within the models is supported by a tool that enables non-technical end users to continuously train models through a user-friendly interface. ",Operation and Maintenance,Natural Language Processing (NLP),,Department of Homeland Security,"Data and Entity Resolution: 
Automates data unification and entity resolution with a high level of trust at enterprise scale and speed.

Data and Entity Resolution uses Machine Learning modeling to ingest multiple data sources and develop models that associate disparate records to identify probable connections, unique entities, and/or identify commonalities between multiple independently submitted records.

The automation of entity resolution within the models is supported by a tool that enables non-technical end users to continuously train models through a user-friendly interface. ",Data and Entity Resolution is a system that automatically merges and identifies connections between different data sources. It uses Machine Learning to develop models that can associate records and identify commonalities. Non-technical users can train these models through a user-friendly interface.,Data and Entity Resolution is a system that automatically merges and identifies connections between different data sources. It uses Machine Learning to develop models that can associate records and identify commonalities. Non-technical users can train these models through a user-friendly interface.,,"Yes, the project described above is potentially a safety risk. 

The project involves the use of machine learning to merge and identify connections between different data sources. This can have implications in various domains such as law enforcement, education, employment, healthcare, finance, and government services. 

In each of these domains, the project has the potential to impact individuals' rights and freedoms, as well as their access to resources and services. For example, in law enforcement, the project may be used for surveillance-related risk assessments, facial recognition, or decision-making related to sentencing or parole. In education, it may influence admissions processes, student monitoring, or disciplinary interventions. In healthcare, it may impact medical diagnosis, treatment decisions, or health insurance processes. 

The potential risks arise from the fact that decisions made based on the outputs of this project can have significant consequences for individuals, their privacy, and their rights. If the system is not properly trained or if biases are present in the data, it can result in unfair or discriminatory outcomes. It may also lead to false positives or negatives, affecting individuals' access to resources or services. 

Therefore, the project should be carefully evaluated and monitored to ensure that it does not pose a safety risk and that appropriate safeguards are in place to protect individuals' rights and prevent potential harm.",True,False
HHS-0068-2023,HHS,FDA,CDER/Office of Generic Drugs,Machine-Learning based Heterogeneous Treatment Effect Models for Prioritizing Product-Specific Guidance Development,"In this project, we propose to develop and implement a novel machine learning algorithm
for estimating heterogeneous treatment effects to prioritize PSG development.
Specifically, we propose three major tasks. First, we will address an important problem in
treatment effect estimation from observational data, where the observed variables may
contain confounders, i.e., variables that affect both the treatment and the outcome. We
will build on recent advances in variational autoencoder to introduce a data-driven method
to simultaneously estimate the hidden confounders and the treatment effect. Second, we
will evaluate our model on both synthetic datasets and previous treatment effect
estimation benchmarks. The ground truth data enable us to investigate model
interpretability. Third, we will validate the model with the real-world PSG data and explain
model output for a particular PSG via collaborating with FDA team. The real-world
datasets are crucial to validate our model, which may include Orange Book, FDA��s PSGs,
National Drug Code directory database, Risk Evaluation and Mitigation Strategies
(REMS) data and IQVIA National Sales Perspectives that are publicly available, as well
as internal ANDA submission data.",Development and Acquisition,,,Department of Health and Human Services,"Machine-Learning based Heterogeneous Treatment Effect Models for Prioritizing Product-Specific Guidance Development: 
In this project, we propose to develop and implement a novel machine learning algorithm
for estimating heterogeneous treatment effects to prioritize PSG development.
Specifically, we propose three major tasks. First, we will address an important problem in
treatment effect estimation from observational data, where the observed variables may
contain confounders, i.e., variables that affect both the treatment and the outcome. We
will build on recent advances in variational autoencoder to introduce a data-driven method
to simultaneously estimate the hidden confounders and the treatment effect. Second, we
will evaluate our model on both synthetic datasets and previous treatment effect
estimation benchmarks. The ground truth data enable us to investigate model
interpretability. Third, we will validate the model with the real-world PSG data and explain
model output for a particular PSG via collaborating with FDA team. The real-world
datasets are crucial to validate our model, which may include Orange Book, FDA��s PSGs,
National Drug Code directory database, Risk Evaluation and Mitigation Strategies
(REMS) data and IQVIA National Sales Perspectives that are publicly available, as well
as internal ANDA submission data.","The project aims to develop a machine learning algorithm for prioritizing the development of product-specific guidance (PSG) by estimating treatment effects. The algorithm will address the problem of confounders in observational data and use variational autoencoders to estimate both the hidden confounders and treatment effects simultaneously. The model will be evaluated on synthetic datasets, treatment effect benchmarks, and real-world PSG data, including publicly available databases and internal submission data. Collaboration with the FDA team will help validate the model and explain its output for specific PSGs.","The project aims to develop a machine learning algorithm for prioritizing the development of product-specific guidance (PSG) by estimating treatment effects. The algorithm will address the problem of confounders in observational data and use variational autoencoders to estimate both the hidden confounders and treatment effects simultaneously. The model will be evaluated on synthetic datasets, treatment effect benchmarks, and real-world PSG data, including publicly available databases and internal submission data. Collaboration with the FDA team will help validate the model and explain its output for specific PSGs.",,"Yes, the project described has the potential to be a safety risk. The project involves developing a machine learning algorithm that will be used to prioritize the development of product-specific guidance (PSG) by estimating treatment effects. This means that the algorithm will have a direct impact on medical decisions, potentially influencing the treatment and care of patients.

Medical decisions, such as determining clinical diagnosis and treatment, carry significant safety implications. If the machine learning algorithm used in this project is not accurate or reliable, it could lead to incorrect treatment decisions, potentially causing harm to patients. The algorithm's ability to estimate treatment effects and hidden confounders is crucial for ensuring patient safety.

Furthermore, collaboration with the FDA team indicates that the algorithm's output will have implications in the regulatory process. If the model's output is not properly validated and explained, it could lead to incorrect decisions regarding product-specific guidance, which may impact the safety and effectiveness of medical products.

Given the potential consequences on patient safety and regulatory decisions, this project should be approached with caution and rigorous validation procedures to mitigate any potential safety risks.",True,False
DOE-0033-2023,DOE,National Energy Technology Laboratory,,AI/ML methodology for rapid design of sorbents tuned to specific ash impoundment and/or landfill requirements.,"Computation of the descriptors (atomic property-weighted radial 
distribution functions) that will be used for the ML portion of the task; 
Fitting of a machine-learned model for the prediction of B sorption; 
Optimization and computational design of a sorbent for maximum 
sorption of B as a function of B concentration in the aqueous solution; 
Force field generation for an additional pollutant (if needed); Sorption 
calculations and ML fitting for the second pollutant (TBD); Optimization 
and computational design of a sorbent for maximum sorption of the 
second pollutant as a function of pollutant concentration in the aqueous 
solution.",,Other,,Department of Energy,"AI/ML methodology for rapid design of sorbents tuned to specific ash impoundment and/or landfill requirements.: 
Computation of the descriptors (atomic property-weighted radial 
distribution functions) that will be used for the ML portion of the task; 
Fitting of a machine-learned model for the prediction of B sorption; 
Optimization and computational design of a sorbent for maximum 
sorption of B as a function of B concentration in the aqueous solution; 
Force field generation for an additional pollutant (if needed); Sorption 
calculations and ML fitting for the second pollutant (TBD); Optimization 
and computational design of a sorbent for maximum sorption of the 
second pollutant as a function of pollutant concentration in the aqueous 
solution.","This text outlines the AI/ML methodology for quickly designing sorbents that meet specific requirements for ash impoundments or landfills. The process involves computing descriptors, creating a machine-learned model to predict sorption, optimizing and designing the sorbent for maximum sorption, and generating a force field for an additional pollutant if necessary. The methodology also includes sorption calculations and optimization for the second pollutant based on its concentration in the aqueous solution.","This text outlines the AI/ML methodology for quickly designing sorbents that meet specific requirements for ash impoundments or landfills. The process involves computing descriptors, creating a machine-learned model to predict sorption, optimizing and designing the sorbent for maximum sorption, and generating a force field for an additional pollutant if necessary. The methodology also includes sorption calculations and optimization for the second pollutant based on its concentration in the aqueous solution.","Yes, the project described is potentially a safety risk. 

According to the provided risks, the project involves the design and development of hazardous chemicals or biological entities (in this case, sorbents) for the purpose of managing industrial waste or controlled pollutants. This falls under risk category e, which states that the transport, safety, design, or development of hazardous chemicals or biological entities pose a potential safety risk. 

Additionally, the project involves the optimization and design of sorbents for maximum sorption, which may require the use of potentially damaging electromagnetic impulses (risk category c). 

Therefore, based on the defined risks, this project has the potential to pose safety risks.",,False,True
DOE-0144-2023,DOE,National Energy Technology Laboratory,,Use ML to analyze the existing H2 and natural gas pipelines to identify the key parameters that can enable the H2 transport and storage at a large scale,"This task aims to use geo-data science methods and geospatial 
information science to analyze the existing H2 and natural gas pipelines 
to identify the key parameters that can enable the H2 transport and 
storage at a large scale. The results can help to justify the importance of 
real-time pipeline monitoring and recommend optimized sensor 
deployment strategies to support smart maintenance and methane 
emissions reduction goals.",,"Big Data, Other",,Department of Energy,"Use ML to analyze the existing H2 and natural gas pipelines to identify the key parameters that can enable the H2 transport and storage at a large scale: 
This task aims to use geo-data science methods and geospatial 
information science to analyze the existing H2 and natural gas pipelines 
to identify the key parameters that can enable the H2 transport and 
storage at a large scale. The results can help to justify the importance of 
real-time pipeline monitoring and recommend optimized sensor 
deployment strategies to support smart maintenance and methane 
emissions reduction goals.","The objective is to utilize machine learning to examine current hydrogen (H2) and natural gas pipelines in order to determine the crucial factors that can facilitate the large-scale transportation and storage of H2. By using methods from geo-data science and geospatial information science, this analysis aims to identify these key parameters and provide insights to support real-time pipeline monitoring, optimized sensor deployment, and the reduction of methane emissions for efficient maintenance.","The objective is to utilize machine learning to examine current hydrogen (H2) and natural gas pipelines in order to determine the crucial factors that can facilitate the large-scale transportation and storage of H2. By using methods from geo-data science and geospatial information science, this analysis aims to identify these key parameters and provide insights to support real-time pipeline monitoring, optimized sensor deployment, and the reduction of methane emissions for efficient maintenance.","Yes, the project is potentially a safety risk. 

The project involves the transportation and storage of hydrogen (H2) and natural gas, which falls under the category of hazardous chemicals. The design, construction, and testing of such pipelines can pose a meaningful risk to safety if they were to fail. Additionally, the reduction of methane emissions mentioned in the project description suggests a concern for environmental impact control processes, which can also be a safety risk.

Therefore, given the involvement of hazardous chemicals, potential risks to safety, and the need for real-time pipeline monitoring, the project is potentially a safety risk.",,False,True
DOE-0053-2023,DOE,National Energy Technology Laboratory,,Machine learning based identification of current hazardous offshore metocean and bathymetric conditions that can impact safe offshore energy operations,"Build off user testing and further refine analytical logic to develop 
Version 2 of the OGA smart tool for release on EDX. Continue 
refinements to offshore hazard models, including wave and turbidity 
current models. Draft manuscripts detailing the OGA Tool models and 
algorithms. Assemble a metocean and seafloor database for release 
with the OGA Tool Version 2 online; strategize web-hosted versions of 
the OGA Tool and database.",,"Big Data, Neural Networks, Other",,Department of Energy,"Machine learning based identification of current hazardous offshore metocean and bathymetric conditions that can impact safe offshore energy operations: 
Build off user testing and further refine analytical logic to develop 
Version 2 of the OGA smart tool for release on EDX. Continue 
refinements to offshore hazard models, including wave and turbidity 
current models. Draft manuscripts detailing the OGA Tool models and 
algorithms. Assemble a metocean and seafloor database for release 
with the OGA Tool Version 2 online; strategize web-hosted versions of 
the OGA Tool and database.","The text discusses the development of Version 2 of the OGA smart tool, which uses machine learning to identify hazardous offshore conditions that can impact safe offshore energy operations. It mentions the refinement of offshore hazard models, the drafting of manuscripts detailing the tool's models and algorithms, and the assembly of a metocean and seafloor database for release with the tool. Additionally, it suggests strategizing web-hosted versions of the tool and database.","The text discusses the development of Version 2 of the OGA smart tool, which uses machine learning to identify hazardous offshore conditions that can impact safe offshore energy operations. It mentions the refinement of offshore hazard models, the drafting of manuscripts detailing the tool's models and algorithms, and the assembly of a metocean and seafloor database for release with the tool. Additionally, it suggests strategizing web-hosted versions of the tool and database.","Yes, the project is potentially a safety risk. 

The project involves the development of Version 2 of the OGA smart tool, which uses machine learning to identify hazardous offshore conditions that can impact safe offshore energy operations. This falls under the category of ""The functioning of dams, emergency services, electrical grids or the generation or movement of energy, fire safety systems, food safety mechanisms, integrity of elections and voting infrastructure, traffic control systems and other systems controlling physical transit, water and wastewater systems, and nuclear reactors, materials, and waste.""

The project aims to refine offshore hazard models, which is related to the ""design, construction, or testing of industrial equipment, systems, or structures that, if they failed, would pose a meaningful risk to safety."" Additionally, the assembly of a metocean and seafloor database for release with the tool can also have implications on safety.

Therefore, based on the risks defined and the project description, the project is potentially a safety risk.",,False,True
HHS-0057-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),"Relationships, Events, Contacts, and Outreach Network (RECON)",RECON AI for Recommender System| Sentiment Analysis,Operation and Maintenance,,,Department of Health and Human Services,"Relationships, Events, Contacts, and Outreach Network (RECON): 
RECON AI for Recommender System| Sentiment Analysis","RECON is an AI-powered platform that specializes in recommender systems and sentiment analysis for relationships, events, contacts, and outreach networks. It uses artificial intelligence to provide recommendations and analyze sentiments in these areas.","RECON is an AI-powered platform that specializes in recommender systems and sentiment analysis for relationships, events, contacts, and outreach networks. It uses artificial intelligence to provide recommendations and analyze sentiments in these areas.",,"Yes, the project described above is potentially a safety risk. This is because the project involves various aspects of decision-making and surveillance that can have significant implications on individuals' rights and well-being.

In particular, the project mentions capabilities such as surveillance, monitoring, and decision-making related to law enforcement, education, employment, health, finance, government benefits, and child welfare. These areas involve sensitive personal information and have the potential to impact individuals' lives and rights.

The use of AI-powered technology in making decisions or recommendations in these areas raises concerns about accuracy, fairness, and potential biases. The reliability and ethical implications of AI systems in decision-making processes are still being debated and can pose risks to individuals if not properly regulated and implemented.

Furthermore, the project's mention of detecting emotions, thoughts, or deception in humans raises privacy concerns and potential violations of personal autonomy. The collection and analysis of such data can infringe on individuals' rights to privacy and personal freedom.

Overall, the project's involvement in various sensitive domains and the potential impact on individuals' rights and well-being make it a potentially significant safety risk. Proper safeguards, regulations, and ethical considerations must be in place to mitigate these risks.",True,False
DOE-0140-2023,DOE,National Energy Technology Laboratory,,To verify and validate testing of advanced power generation technologies,"Verification and validation testing with direct support and collaboration 
from operating power plants with advanced power generation 
technologies and prime mover and downstream systems using near-
real-time data, resulting in better informed plant operators, and reduced 
disruptions, while meeting changing service demands based on 
enhanced operating flexibility",,"Artificial Intelligence, Big Data",,Department of Energy,"To verify and validate testing of advanced power generation technologies: 
Verification and validation testing with direct support and collaboration 
from operating power plants with advanced power generation 
technologies and prime mover and downstream systems using near-
real-time data, resulting in better informed plant operators, and reduced 
disruptions, while meeting changing service demands based on 
enhanced operating flexibility","Verification and validation testing of advanced power generation technologies is conducted with the assistance of operating power plants and their systems. This collaboration allows for the use of real-time data, leading to informed plant operators, minimized disruptions, and the ability to meet changing service demands.","Verification and validation testing of advanced power generation technologies is conducted with the assistance of operating power plants and their systems. This collaboration allows for the use of real-time data, leading to informed plant operators, minimized disruptions, and the ability to meet changing service demands.","Yes, the project described potentially poses a safety risk. According to the given definition, the project involves the functioning of energy generation systems, which can be considered a safety risk. The testing and validation of advanced power generation technologies may have the potential to cause disruptions or failures in the power plants or their systems, which could lead to safety hazards.",,False,True
SSA-0008-2023,SSA,"Office of Analytics, Review, and Oversight; Office of Hearing Operations, Office of Disability Systems",,Insight,"Insight is decision support software used by hearings and appeals-level Disability Program adjudicators to help maximize the quality, speed, and consistency of their decision making.  Insight analyzes the free text of disability decisions and other case data to offer adjudicators real-time alerts on potential quality issues and case-specific reference information within a web application.  It also offers adjudicators a series of interactive tools to help streamline their work.  Adjudicators can leverage these features to speed their work and fix issues before the case moves forward (e.g. to another reviewing employee or to the claimant).  Insight�s features are powered by several natural language processing and artificial intelligence packages and techniques.",,,,Social Security Administration,"Insight: 
Insight is decision support software used by hearings and appeals-level Disability Program adjudicators to help maximize the quality, speed, and consistency of their decision making.  Insight analyzes the free text of disability decisions and other case data to offer adjudicators real-time alerts on potential quality issues and case-specific reference information within a web application.  It also offers adjudicators a series of interactive tools to help streamline their work.  Adjudicators can leverage these features to speed their work and fix issues before the case moves forward (e.g. to another reviewing employee or to the claimant).  Insight�s features are powered by several natural language processing and artificial intelligence packages and techniques.","Insight is decision support software that aids Disability Program adjudicators in making high-quality, efficient, and consistent decisions. It analyzes the text of disability decisions and other case data to provide real-time alerts and reference information to adjudicators. With interactive tools, adjudicators can expedite their work and address any issues before the case progresses further. Insight utilizes natural language processing and artificial intelligence techniques to power its features.","Insight is decision support software that aids Disability Program adjudicators in making high-quality, efficient, and consistent decisions. It analyzes the text of disability decisions and other case data to provide real-time alerts and reference information to adjudicators. With interactive tools, adjudicators can expedite their work and address any issues before the case progresses further. Insight utilizes natural language processing and artificial intelligence techniques to power its features.",,"Yes, the project described above is potentially a safety risk. 

The project involves making decisions regarding access to government benefits or services, which can have significant consequences for individuals. If the decision support software, Insight, is not accurate or reliable, it may result in incorrect determinations of eligibility for benefits. This could lead to individuals being wrongly denied access to essential services or benefits they are entitled to, potentially causing harm or hardship.

Additionally, the project utilizes natural language processing and artificial intelligence techniques to analyze the text of disability decisions and other case data. If these techniques are not properly implemented or if there are biases in the algorithms used, it could result in unfair or discriminatory decisions. This could further exacerbate existing inequalities and put vulnerable individuals at risk.

Overall, the project's involvement in making decisions regarding government benefits and services, coupled with the potential for inaccuracies and biases, makes it a safety risk.",True,False
DOI-0013-2023,DOI,BSEE,,Level 1 Report Corrosion Level Classification,"Level 1 surveys obtained from BSEE report the condition of well platforms. The reports include images of well platform components, which can be used to estimate coating condition and structural condition, important factors in the overall condition of the facility. The reports are used to assess the well platforms for safety concerns. The reports are submitted to BSEE and are manually reviewed to determine whether a well platform needs additional audits. Because the manual review process is time-consuming, an automated screening system that can identify parts of the wells that exhibit excess corrosion may greatly reduce report processing time. BSEE entered into an Inter-Agency Agreement with NASA's Advanced Supercomputing Division to help research the use of various AI techniques.",Implementation,"Machine learning via deep learning models, such as a Residual Neural Network (ResNet) and Convolutional Neural Networks (CNN)",,Department of Interior,"Level 1 Report Corrosion Level Classification: 
Level 1 surveys obtained from BSEE report the condition of well platforms. The reports include images of well platform components, which can be used to estimate coating condition and structural condition, important factors in the overall condition of the facility. The reports are used to assess the well platforms for safety concerns. The reports are submitted to BSEE and are manually reviewed to determine whether a well platform needs additional audits. Because the manual review process is time-consuming, an automated screening system that can identify parts of the wells that exhibit excess corrosion may greatly reduce report processing time. BSEE entered into an Inter-Agency Agreement with NASA's Advanced Supercomputing Division to help research the use of various AI techniques.","Level 1 reports obtained from BSEE assess the condition of well platforms and include images that can estimate coating and structural condition. These reports are manually reviewed to determine safety concerns and the need for additional audits. To reduce processing time, BSEE has partnered with NASA to research the use of AI techniques in identifying excessive corrosion in well platform components.","Level 1 reports obtained from BSEE assess the condition of well platforms and include images that can estimate coating and structural condition. These reports are manually reviewed to determine safety concerns and the need for additional audits. To reduce processing time, BSEE has partnered with NASA to research the use of AI techniques in identifying excessive corrosion in well platform components.",,"Yes, the project described has the potential to be a safety risk. This is because it involves the use of AI techniques to identify excessive corrosion in well platform components. If the AI system fails to accurately detect corrosion, it could lead to safety concerns and potential accidents or failures in the well platforms. The incorrect assessment of coating and structural condition could result in the failure to address necessary repairs or maintenance, which could pose risks to the overall safety and stability of the well platforms.",True,False
HHS-0034-2023,HHS,CDC,NCHS,Detecting Stimulant and Opioid Misuse and Illicit Use,Analyze clinical notes to detect illicit use and miscue of stimulants and opioids,Initiation,,,Department of Health and Human Services,"Detecting Stimulant and Opioid Misuse and Illicit Use: 
Analyze clinical notes to detect illicit use and miscue of stimulants and opioids",The clinical notes are analyzed to identify instances of illicit use and misuse of stimulants and opioids. This helps in detecting cases where these substances are being used inappropriately or illegally.,The clinical notes are analyzed to identify instances of illicit use and misuse of stimulants and opioids. This helps in detecting cases where these substances are being used inappropriately or illegally.,,"Yes, the project described has the potential to be a safety risk. The analysis of clinical notes to identify instances of illicit use and misuse of stimulants and opioids is related to decisions regarding medical diagnosis and determination of treatment. Making decisions based on this analysis could impact patient safety if inaccurate or incomplete information is used to determine treatment plans or interventions. Additionally, there is a risk of privacy infringement if the analysis involves the unauthorized access or use of personal medical information.",True,False
DOS-0025-2023,DOS,R,,Deepfake Detector,"Deep learning model that takes in an image containing a person’s face and classifies the image as either being real (contains a real person’s face) or fake (synthetically generated face, a deepfake often created using Generative Adversarial Networks).",,,,Department of State,"Deepfake Detector: 
Deep learning model that takes in an image containing a person’s face and classifies the image as either being real (contains a real person’s face) or fake (synthetically generated face, a deepfake often created using Generative Adversarial Networks).",The Deepfake Detector is a deep learning model that can determine if an image contains a real person's face or a synthetically generated face created using Generative Adversarial Networks (deepfakes). It analyzes the image and classifies it as either real or fake.,The Deepfake Detector is a deep learning model that can determine if an image contains a real person's face or a synthetically generated face created using Generative Adversarial Networks (deepfakes). It analyzes the image and classifies it as either real or fake.,,"Yes, the project potentially poses a safety risk. 

The Deepfake Detector can be used for facial matching and facial sketching, which are mentioned in the risks defined. These activities can have significant ethical and privacy implications. Misuse or abuse of this technology could lead to false accusations, invasion of privacy, or violation of individual rights.

Additionally, the project falls under the category of determining the terms and conditions of employment. If the Deepfake Detector is used to make decisions related to hiring or promotion, it could potentially discriminate against individuals based on their appearance or create biases in the selection process.

Furthermore, there is always a risk associated with the development and use of deepfakes itself. Deepfakes can be used for malicious purposes, such as defamation, spreading misinformation, or creating fake evidence. The existence of a deepfake detector could also spur the development of more sophisticated deepfakes that can bypass detection systems, escalating the risks associated with fake media.

Therefore, the Deepfake Detector project has the potential to be a safety risk due to the ethical, privacy, and societal implications, as well as the potential for misuse or abuse of the technology.",True,False
DOI-0012-2023,DOI,BSEE,,Autonomous Drone Inspections,BSEE is exploring the potential development of autonomous systems in drones to detect methane and inspect unsafe to board platforms on the outer continental shelf. Using autonomous drones will allow some inspection capabilities to be performed while maintaining the safety of inspectors without requiring extensive training to operate the drones.,Development (not in production),Unknown at this time,,Department of Interior,"Autonomous Drone Inspections: 
BSEE is exploring the potential development of autonomous systems in drones to detect methane and inspect unsafe to board platforms on the outer continental shelf. Using autonomous drones will allow some inspection capabilities to be performed while maintaining the safety of inspectors without requiring extensive training to operate the drones.","The Bureau of Safety and Environmental Enforcement (BSEE) is considering using autonomous drones to detect methane and inspect unsafe platforms on the outer continental shelf. This technology would enable inspections to be conducted safely and efficiently, without the need for extensive training of human operators.","The Bureau of Safety and Environmental Enforcement (BSEE) is considering using autonomous drones to detect methane and inspect unsafe platforms on the outer continental shelf. This technology would enable inspections to be conducted safely and efficiently, without the need for extensive training of human operators.","Yes, the project described potentially poses a safety risk. The use of autonomous drones for detecting methane and inspecting unsafe platforms on the outer continental shelf falls under the category of physical movements within a workplace, transportation, and environmental impact control processes. If the autonomous drones malfunction or fail to detect methane accurately, it could lead to unsafe conditions on the platforms and potential environmental hazards. Therefore, there is a potential safety risk associated with this project.",,False,True
DHS-0012-2023,DHS,Customs and Border Protection,,Vessel Detection,"Integrated technologies and analytics enhance maritime detection and the sensor network. Machine-assisted and AI-enhanced detection and tracking allows for improved illicit vessel detection in areas with high volumes of legitimate trade and recreational water vessel traffic by increasing situational awareness and responsiveness to threats.

Vessel Detection allows an agent to set a search area with criteria (e.g., people, drones, vehicles) and transmit that criteria to the sensors.  Images detected by the sensors are auto-recognized using Artificial Intelligence. The AI algorithms filter, detect, and recognize objects and divides them into Items of Interest (IoI) and ""other"" objects. 

Detections of IoI are shared with other detection systems while detections of other objects (e.g., animals) are not shared. IoIs can be tracked and maintained across multiple sensors seamlessly.",Development and Acquisition,Machine Vision,,Department of Homeland Security,"Vessel Detection: 
Integrated technologies and analytics enhance maritime detection and the sensor network. Machine-assisted and AI-enhanced detection and tracking allows for improved illicit vessel detection in areas with high volumes of legitimate trade and recreational water vessel traffic by increasing situational awareness and responsiveness to threats.

Vessel Detection allows an agent to set a search area with criteria (e.g., people, drones, vehicles) and transmit that criteria to the sensors.  Images detected by the sensors are auto-recognized using Artificial Intelligence. The AI algorithms filter, detect, and recognize objects and divides them into Items of Interest (IoI) and ""other"" objects. 

Detections of IoI are shared with other detection systems while detections of other objects (e.g., animals) are not shared. IoIs can be tracked and maintained across multiple sensors seamlessly.","Vessel Detection utilizes integrated technologies and analytics to enhance maritime detection and the sensor network. This includes machine-assisted and AI-enhanced detection and tracking, which improves the identification of illicit vessels in areas with high levels of legitimate trade and recreational water vessel traffic. It allows for setting search criteria and transmitting them to sensors, which use AI algorithms to filter and recognize objects of interest, sharing them with other detection systems.","Vessel Detection utilizes integrated technologies and analytics to enhance maritime detection and the sensor network. This includes machine-assisted and AI-enhanced detection and tracking, which improves the identification of illicit vessels in areas with high levels of legitimate trade and recreational water vessel traffic. It allows for setting search criteria and transmitting them to sensors, which use AI algorithms to filter and recognize objects of interest, sharing them with other detection systems.",,"Yes, the project described above is potentially a safety risk. This is because it involves surveillance-related risk assessments and decisions related to law enforcement, as well as the detection and tracking of vessels. These activities can have implications for privacy, civil liberties, and potential misuse of data. Additionally, the use of AI algorithms and machine-assisted detection introduces the possibility of errors or biases that could affect the accuracy of the identification of illicit vessels, potentially leading to false positives or negatives. Overall, the project raises concerns about the potential for infringement on individual rights and the potential for errors or biases in the decision-making process.",True,False
HHS-0082-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Empirical evaluation of EHR-based signal detection approaches,"This project will develop approaches for abstracting and combining structured and unstructured EHR data as well as expanding TBSS methods to also identify signals for outcomes identifiable only through EHR data (e.g. natural language processing, laboratory values).",Initiation,,,Department of Health and Human Services,"Empirical evaluation of EHR-based signal detection approaches: 
This project will develop approaches for abstracting and combining structured and unstructured EHR data as well as expanding TBSS methods to also identify signals for outcomes identifiable only through EHR data (e.g. natural language processing, laboratory values).","The project aims to develop methods to analyze electronic health record (EHR) data and identify signals related to outcomes that can only be identified through EHR data, such as natural language processing and laboratory values. This will involve abstracting and combining both structured and unstructured EHR data, as well as expanding existing methods to include these additional sources of information.","The project aims to develop methods to analyze electronic health record (EHR) data and identify signals related to outcomes that can only be identified through EHR data, such as natural language processing and laboratory values. This will involve abstracting and combining both structured and unstructured EHR data, as well as expanding existing methods to include these additional sources of information.",,"Yes, the project is potentially a safety risk. The project involves analyzing electronic health record (EHR) data, which contains sensitive and personal information about individuals' health conditions. If not handled properly, the project could pose risks to privacy and confidentiality. Unauthorized access or breaches in the security of EHR data could lead to identity theft, medical fraud, or other harmful consequences for individuals. Therefore, proper measures should be taken to ensure the security and protection of the EHR data throughout the project.",True,False
USDA-0006-2023,USDA,USDA,APHIS,"Approximate string or fuzzy matching, used to automate matching similar, but not identical, text in administrative documents","The algorithm computes a string similarity metric which can be used to classify similar strings into a single category, reducing information duplication and onerous, manual error-checking",Operation and Management,Fuzzy matching,,Department of Agriculture,"Approximate string or fuzzy matching, used to automate matching similar, but not identical, text in administrative documents: 
The algorithm computes a string similarity metric which can be used to classify similar strings into a single category, reducing information duplication and onerous, manual error-checking","Approximate string or fuzzy matching is a technique used to automatically match similar but not exact text in administrative documents. By calculating a similarity metric, this algorithm can classify similar strings into one category, reducing the need for duplicate information and manual error-checking.","Approximate string or fuzzy matching is a technique used to automatically match similar but not exact text in administrative documents. By calculating a similarity metric, this algorithm can classify similar strings into one category, reducing the need for duplicate information and manual error-checking.",,"Yes, the project described above has the potential to be a safety risk. The project involves the use of approximate string or fuzzy matching techniques to automatically match similar but not exact text in administrative documents. While this may seem like a harmless project, it falls under category ""b"" mentioned in the risks definition, specifically related to law enforcement or surveillance-related risk assessments.

The use of this algorithm in law enforcement or surveillance applications raises concerns about potential privacy violations and the potential for biased or discriminatory decision-making. The project may involve the use of personal data, such as license plate numbers, iris matching, facial recognition, and social media monitoring, which can have significant safety implications if misused or abused.

Additionally, the project's involvement in decision-making processes related to sentencing, parole, probation, or bail could have severe consequences if the algorithm's classifications or recommendations are flawed or biased. This could lead to unfair treatment, wrongful convictions, or the release of potentially dangerous individuals.

Therefore, based on the risks defined and the nature of the project, it is reasonable to consider it potentially a safety risk.",True,False
HHS-0020-2023,HHS,ASPR,"Office of Information Management, Data, and Analytics/ODA",Product redistribution optimization,"Using AI and models, allow partners (jurisdictions, pharmacies, federal entities) to optimize redistribution of products based on various factors like distance, ordering/admins, equity, etc.",Development and Acquisition,,,Department of Health and Human Services,"Product redistribution optimization: 
Using AI and models, allow partners (jurisdictions, pharmacies, federal entities) to optimize redistribution of products based on various factors like distance, ordering/admins, equity, etc.","The use of AI and models can help partners optimize the redistribution of products. This optimization takes into account factors such as distance, ordering/administration, and equity, allowing for more efficient and equitable distribution of products among jurisdictions, pharmacies, and federal entities.","The use of AI and models can help partners optimize the redistribution of products. This optimization takes into account factors such as distance, ordering/administration, and equity, allowing for more efficient and equitable distribution of products among jurisdictions, pharmacies, and federal entities.","Yes, the project described above is potentially a safety risk. This is because it involves the optimization and redistribution of products, which can impact various systems and processes that are considered safety risks according to the provided definition.

Specifically, the project may have implications for the functioning of emergency services, as it could affect the distribution of essential products needed during emergencies. It may also impact the integrity of food safety mechanisms, as the redistribution process should ensure that products are safely handled and distributed.

Furthermore, if the project involves the transportation or management of industrial waste or controlled pollutants, it could pose risks to the environment and public health.

Overall, while the project itself may not directly involve physical movements or the delivery of harmful agents, its potential impact on various safety-critical systems and processes makes it a potential safety risk.",,False,True
NASA-0002-2023,NASA,Ames Research Center,,Biological and Physical Sciences Microscopy Benchmark Dataset,"This study uses fluorescence microscopy images from the Biological and Physical Sciences Open Science Data
Repositories (osdr.nasa.gov). The dataset consists of 93,488 images of individual nuclei from mouse fibroblast cells,
irradiated with Fe particles or X-rays and labeled for DNA double strand breaks using 53BP1 as a fluorescence
marker. DNA damage appears as small white foci in these images. The study simulates exposure to space radiation
and the dataset has been modified to be AI ready so that AI expert can test several AI tools on them. The dataset is
publicly available on the Registry of Open Data on AWS. Implementation AI tools developed in-house are also
available on the link.",In-use,Graphical Neural Network,https://github.com/NASA-IMPACT/bps-imagery-radiation-classification/tree/cnn_classifier,National Aeronautics and Space Administration,"Biological and Physical Sciences Microscopy Benchmark Dataset: 
This study uses fluorescence microscopy images from the Biological and Physical Sciences Open Science Data
Repositories (osdr.nasa.gov). The dataset consists of 93,488 images of individual nuclei from mouse fibroblast cells,
irradiated with Fe particles or X-rays and labeled for DNA double strand breaks using 53BP1 as a fluorescence
marker. DNA damage appears as small white foci in these images. The study simulates exposure to space radiation
and the dataset has been modified to be AI ready so that AI expert can test several AI tools on them. The dataset is
publicly available on the Registry of Open Data on AWS. Implementation AI tools developed in-house are also
available on the link.","This study utilizes a dataset of fluorescence microscopy images obtained from the Biological and Physical Sciences Open Science Data Repositories. The dataset comprises 93,488 images of mouse fibroblast cell nuclei, which were exposed to Fe particles or X-rays and labeled for DNA double strand breaks. The dataset has been modified to be AI compatible and is publicly accessible on the Registry of Open Data on AWS, along with AI tools developed by the researchers.","This study utilizes a dataset of fluorescence microscopy images obtained from the Biological and Physical Sciences Open Science Data Repositories. The dataset comprises 93,488 images of mouse fibroblast cell nuclei, which were exposed to Fe particles or X-rays and labeled for DNA double strand breaks. The dataset has been modified to be AI compatible and is publicly accessible on the Registry of Open Data on AWS, along with AI tools developed by the researchers.",,,False,False
HHS-0048-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),CCIIO Enrollment Resolution and Reconciliation System (CERRS),CERRS AI for Classification,Operation and Maintenance,,,Department of Health and Human Services,"CCIIO Enrollment Resolution and Reconciliation System (CERRS): 
CERRS AI for Classification",The CCIIO Enrollment Resolution and Reconciliation System (CERRS) is an AI system used for classification purposes. It is designed to help with the enrollment process and resolve any discrepancies or issues that may arise.,The CCIIO Enrollment Resolution and Reconciliation System (CERRS) is an AI system used for classification purposes. It is designed to help with the enrollment process and resolve any discrepancies or issues that may arise.,,,False,False
EPA-0002-2023,EPA,,,Enforcement Targeting,"EPA’s Office of Compliance, in partnership with the University of Chicago, built a proof-of-concept to improve enforcement of environmental regulations through facility inspections by the EPA and state partners. The resulting predictive analytics showed a 47% improvement of identifying violations of the Resource Conservation and Recovery Act.",,,,U.S. Environmental Protection Agency,"Enforcement Targeting: 
EPA’s Office of Compliance, in partnership with the University of Chicago, built a proof-of-concept to improve enforcement of environmental regulations through facility inspections by the EPA and state partners. The resulting predictive analytics showed a 47% improvement of identifying violations of the Resource Conservation and Recovery Act.",The EPA and the University of Chicago collaborated to develop a proof-of-concept that enhances the enforcement of environmental regulations through facility inspections. The use of predictive analytics led to a significant 47% improvement in identifying violations of the Resource Conservation and Recovery Act.,The EPA and the University of Chicago collaborated to develop a proof-of-concept that enhances the enforcement of environmental regulations through facility inspections. The use of predictive analytics led to a significant 47% improvement in identifying violations of the Resource Conservation and Recovery Act.,,,False,False
SSA-0006-2023,SSA,"Office of Analytics, Review, and Oversight",,Medicare Part D Subsidy Model,This model uses machine learning to identify cases most likely to have incorrect Medicare Part D subsidies and flag them for technician review.,,,,Social Security Administration,"Medicare Part D Subsidy Model: 
This model uses machine learning to identify cases most likely to have incorrect Medicare Part D subsidies and flag them for technician review.",The Medicare Part D Subsidy Model employs machine learning to pinpoint cases with potentially inaccurate Medicare Part D subsidies and highlights them for technician evaluation.,The Medicare Part D Subsidy Model employs machine learning to pinpoint cases with potentially inaccurate Medicare Part D subsidies and highlights them for technician evaluation.,,,False,False
DOI-0030-2023,DOI,USGS,,DOMESTIC WELL VULNERABILITY SES INDICATORS NEW HAMPSHIRE,"The goals of this work are to: (1) investigate homeowner-level statistical associations between datasets on private wells (geology and land use, construction, hydraulics, and chemistry) and SES (and SES proxy) data; (2) investigate statewide census block-group level statistical associations between datasets on private wells (geology and land use, construction, hydraulics, and probabilities of arsenic and uranium contamination) and demographic and SES (and SES proxy) data; (3) identify indicators or triggers of vulnerability to private well water availability and quality in New Hampshire; and (4) broadly disseminate information from this study to scientific and general audiences, as well as to targeted community groups. ",Initiation,Convolutional neural networks,,Department of Interior,"DOMESTIC WELL VULNERABILITY SES INDICATORS NEW HAMPSHIRE: 
The goals of this work are to: (1) investigate homeowner-level statistical associations between datasets on private wells (geology and land use, construction, hydraulics, and chemistry) and SES (and SES proxy) data; (2) investigate statewide census block-group level statistical associations between datasets on private wells (geology and land use, construction, hydraulics, and probabilities of arsenic and uranium contamination) and demographic and SES (and SES proxy) data; (3) identify indicators or triggers of vulnerability to private well water availability and quality in New Hampshire; and (4) broadly disseminate information from this study to scientific and general audiences, as well as to targeted community groups. ",This text discusses the goals of a study in New Hampshire on the statistical associations between private well data and socio-economic status (SES) data. The study aims to identify indicators of vulnerability to private well water availability and quality and disseminate the findings to various audiences.,This text discusses the goals of a study in New Hampshire on the statistical associations between private well data and socio-economic status (SES) data. The study aims to identify indicators of vulnerability to private well water availability and quality and disseminate the findings to various audiences.,,,False,False
DOE-0136-2023,DOE,National Energy Technology Laboratory,,To use AI to calibrate the simulation model by matching simulation data with production history data.,"Task 2 - Together with GEM, CMG’s intelligent optimization and analysis 
tool, CMOST Artificial Intelligence (AI), will be used to calibrate the 
simulation model by matching simulation results with production history 
data. . Based on the data sets, a series of simulation cases will be 
generated to perform parameter estimation using a systematic 
approach. As simulation jobs complete, the results will be analyzed 
using CMOST AI to determine how well they match production history. 
An optimizer will then determine parameter values for new simulation 
jobs.",,Artificial Intelligence Unknown,,Department of Energy,"To use AI to calibrate the simulation model by matching simulation data with production history data.: 
Task 2 - Together with GEM, CMG’s intelligent optimization and analysis 
tool, CMOST Artificial Intelligence (AI), will be used to calibrate the 
simulation model by matching simulation results with production history 
data. . Based on the data sets, a series of simulation cases will be 
generated to perform parameter estimation using a systematic 
approach. As simulation jobs complete, the results will be analyzed 
using CMOST AI to determine how well they match production history. 
An optimizer will then determine parameter values for new simulation 
jobs.","CMG's AI tool, CMOST AI, will be used to calibrate the simulation model by comparing simulation results with production history data. This will involve generating simulation cases and analyzing the results using CMOST AI. An optimizer will then determine parameter values for new simulation jobs.","CMG's AI tool, CMOST AI, will be used to calibrate the simulation model by comparing simulation results with production history data. This will involve generating simulation cases and analyzing the results using CMOST AI. An optimizer will then determine parameter values for new simulation jobs.",,,False,False
DOE-0024-2023,DOE,Lawrence Livermore National Laboratory,,"High-performance computing, semiconductors, and advanced computer hardware","Novel computer hardware architecture/configurations that can perform 
at the edge and/or in harsh environments",,,,Department of Energy,"High-performance computing, semiconductors, and advanced computer hardware: 
Novel computer hardware architecture/configurations that can perform 
at the edge and/or in harsh environments","The text discusses the need for novel computer hardware architecture and configurations that can function effectively in high-performance computing, semiconductors, and harsh environments. These advancements aim to enable computers to operate efficiently at the edge and withstand challenging conditions.","The text discusses the need for novel computer hardware architecture and configurations that can function effectively in high-performance computing, semiconductors, and harsh environments. These advancements aim to enable computers to operate efficiently at the edge and withstand challenging conditions.",,,False,False
HHS-0141-2023,HHS,NIH,National Institutes of Health (NIH) OD/DPCPSI/OPA,Automated approaches to analyzing scientific topics,"Developed and implemented a validated approach that uses natural language processing and AI/ML to group semantically similar documents (including grants, publications, or patents) and extract AI labels that accurately reflect the scientific focus of each topic to aid in NIH research portfolio analysis. ",Implementation,,,Department of Health and Human Services,"Automated approaches to analyzing scientific topics: 
Developed and implemented a validated approach that uses natural language processing and AI/ML to group semantically similar documents (including grants, publications, or patents) and extract AI labels that accurately reflect the scientific focus of each topic to aid in NIH research portfolio analysis. ","A validated approach has been developed and implemented to analyze scientific topics using natural language processing and AI/ML. This approach effectively groups similar documents such as grants, publications, or patents and extracts accurate AI labels that reflect the scientific focus of each topic. This aids in the analysis of NIH research portfolios.","A validated approach has been developed and implemented to analyze scientific topics using natural language processing and AI/ML. This approach effectively groups similar documents such as grants, publications, or patents and extracts accurate AI labels that reflect the scientific focus of each topic. This aids in the analysis of NIH research portfolios.",,,False,False
DOI-0011-2023,DOI,BSEE,,Well Risk,NASA's Advanced Supercomputer Division will utilize the work performed in the sustained casing pressure research to explore the development of machine learning models to identify various precursors of risk factors for wells. By identifying these risk factors it would help inform BSEE engineers of potential problems with the well during its various stages of development.,Development (not in production),"Machine learning via deep learning model, such as a Residual Neural Network (ResNet) and Convolutional Neural Networks (CNN)",,Department of Interior,"Well Risk: 
NASA's Advanced Supercomputer Division will utilize the work performed in the sustained casing pressure research to explore the development of machine learning models to identify various precursors of risk factors for wells. By identifying these risk factors it would help inform BSEE engineers of potential problems with the well during its various stages of development.",NASA's Advanced Supercomputer Division will use the research on sustained casing pressure to develop machine learning models for identifying risk factors in wells. This will assist BSEE engineers in detecting potential issues at different stages of well development.,NASA's Advanced Supercomputer Division will use the research on sustained casing pressure to develop machine learning models for identifying risk factors in wells. This will assist BSEE engineers in detecting potential issues at different stages of well development.,,,False,False
HHS-0129-2023,HHS,NIH,National Institutes of Health (NIH) NLM,CLARIN: Detecting clinicians' attitudes through clinical notes,"Understanding clinical notes and detecting bias is essential in supporting equity and diversity, as well as quality of care and decision support. NLM is using and developing AI approaches to detect clinicians' emotions, biases and burnout.",Development and Acquisition,,,Department of Health and Human Services,"CLARIN: Detecting clinicians' attitudes through clinical notes: 
Understanding clinical notes and detecting bias is essential in supporting equity and diversity, as well as quality of care and decision support. NLM is using and developing AI approaches to detect clinicians' emotions, biases and burnout.","The NLM is utilizing AI techniques to detect and comprehend the emotions, biases, and burnout of clinicians through clinical notes. This is crucial for promoting equity, diversity, and quality of care and decision support in the healthcare field.","The NLM is utilizing AI techniques to detect and comprehend the emotions, biases, and burnout of clinicians through clinical notes. This is crucial for promoting equity, diversity, and quality of care and decision support in the healthcare field.",,,False,False
NASA-0000-2023,NASA,Ames Research Center,,AdaStress,"Testing complex systems often requires computationally intensive Monte Carlo sampling approaches to identify
possible faults. In systems where the number of faults are low, but safety critical, this form of testing may be
infeasible due to the large number of samples needed to catch a rare fault. AdaStress instead uses reinforcement
learning to more efficiently sample low-likelihood, but high-impact faults.",In-use,Reinforcement Learning,,National Aeronautics and Space Administration,"AdaStress: 
Testing complex systems often requires computationally intensive Monte Carlo sampling approaches to identify
possible faults. In systems where the number of faults are low, but safety critical, this form of testing may be
infeasible due to the large number of samples needed to catch a rare fault. AdaStress instead uses reinforcement
learning to more efficiently sample low-likelihood, but high-impact faults.","AdaStress is a method that uses reinforcement learning to efficiently identify low-probability but highly important faults in complex systems. It replaces computationally intensive Monte Carlo sampling approaches, which may not be feasible for systems with a small number of critical faults.","AdaStress is a method that uses reinforcement learning to efficiently identify low-probability but highly important faults in complex systems. It replaces computationally intensive Monte Carlo sampling approaches, which may not be feasible for systems with a small number of critical faults.",,,False,False
DOE-0122-2023,DOE,National Energy Technology Laboratory,,To implement unsupervised learning based interaction force model for nonspherical particles in incompressible flows,"Develop a neural network-based interaction (drag and lifting) force 
model. A database will be constructed of the interaction force between 
the non-spherical particles and the fluid phase based on the particle-
resolved direct numerical simulation (PR-DNS) with immersed boundary-
based lattice Boltzmann method (IB-LBM). An unsupervised learning 
method, i.e., variational auto-encoder (VAE), will be used to improve the 
diversity of the non-spherical particle library and to extract the primitive 
shape factors determining the drag and lifting forces. The interaction 
force model will be trained and validated with a simple but effective multi-
layer feed-forward neural network: multi-layer perceptron (MLP), which 
will be concatenated after the encoder of the previously trained VAE for 
geometry feature extraction.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To implement unsupervised learning based interaction force model for nonspherical particles in incompressible flows: 
Develop a neural network-based interaction (drag and lifting) force 
model. A database will be constructed of the interaction force between 
the non-spherical particles and the fluid phase based on the particle-
resolved direct numerical simulation (PR-DNS) with immersed boundary-
based lattice Boltzmann method (IB-LBM). An unsupervised learning 
method, i.e., variational auto-encoder (VAE), will be used to improve the 
diversity of the non-spherical particle library and to extract the primitive 
shape factors determining the drag and lifting forces. The interaction 
force model will be trained and validated with a simple but effective multi-
layer feed-forward neural network: multi-layer perceptron (MLP), which 
will be concatenated after the encoder of the previously trained VAE for 
geometry feature extraction.","The text describes a plan to develop a neural network-based interaction force model for nonspherical particles in incompressible flows. The model will be trained using a database of interaction forces between the particles and the fluid, obtained through simulation. A variational auto-encoder will be used to improve the diversity of the particle library and extract shape factors, and a multi-layer perceptron will be used for feature extraction.","The text describes a plan to develop a neural network-based interaction force model for nonspherical particles in incompressible flows. The model will be trained using a database of interaction forces between the particles and the fluid, obtained through simulation. A variational auto-encoder will be used to improve the diversity of the particle library and extract shape factors, and a multi-layer perceptron will be used for feature extraction.",,,False,False
VA-0015-2023,VA,,,Prediction of Veterans' Suicidal Ideation following Transition from Military Service,Machine learning is used to identify predictors of veterans' suicidal ideation. The relevant data come from a web-based survey of veterans’ experiences within three months of separation and every six months after for the first three years after leaving military service.,,,,Department of Veterans Affairs,"Prediction of Veterans' Suicidal Ideation following Transition from Military Service: 
Machine learning is used to identify predictors of veterans' suicidal ideation. The relevant data come from a web-based survey of veterans’ experiences within three months of separation and every six months after for the first three years after leaving military service.","Machine learning is being used to determine factors that can predict veterans' thoughts of suicide after they transition from military service. The data used for this analysis is gathered from surveys conducted online, where veterans share their experiences within three months of leaving the military and continue to do so every six months for the first three years after their service.","Machine learning is being used to determine factors that can predict veterans' thoughts of suicide after they transition from military service. The data used for this analysis is gathered from surveys conducted online, where veterans share their experiences within three months of leaving the military and continue to do so every six months for the first three years after their service.",,,False,False
HHS-0151-2023,HHS,NIH,National Institutes of Health (NIH) OD/ORF,NIH Campus Cooling Load Forecaster,"This project forecasts the NIH campus's chilled water demand for the next four days. With this information, the NIH Central Utilities Plant management can plan and optimize the chiller plant's operation and maintenance.",Operation and Maintenance,,,Department of Health and Human Services,"NIH Campus Cooling Load Forecaster: 
This project forecasts the NIH campus's chilled water demand for the next four days. With this information, the NIH Central Utilities Plant management can plan and optimize the chiller plant's operation and maintenance.",The NIH Campus Cooling Load Forecaster predicts the amount of chilled water that will be needed on the NIH campus for the next four days. This helps the management of the central utilities plant to efficiently plan and optimize the operation and maintenance of the chiller plant.,The NIH Campus Cooling Load Forecaster predicts the amount of chilled water that will be needed on the NIH campus for the next four days. This helps the management of the central utilities plant to efficiently plan and optimize the operation and maintenance of the chiller plant.,,,False,False
DOT-0011-2023,DOT,"Office of Research, Development and Technology",,Crushed Aggregate Gradation Evaluation System,"Description: Deep learning computer vision algorithms aimed at analyzing aggregate particle size grading.
Input: Images of ballast cross sections
Output: Ballast fouling index",,,,Department of Transportation,"Crushed Aggregate Gradation Evaluation System: 
Description: Deep learning computer vision algorithms aimed at analyzing aggregate particle size grading.
Input: Images of ballast cross sections
Output: Ballast fouling index","The Crushed Aggregate Gradation Evaluation System is a computer-based tool that uses deep learning computer vision algorithms to analyze the particle size grading in aggregate materials. It takes images of ballast cross sections as input and provides an output known as the ballast fouling index, which indicates the level of contamination in the ballast.","The Crushed Aggregate Gradation Evaluation System is a computer-based tool that uses deep learning computer vision algorithms to analyze the particle size grading in aggregate materials. It takes images of ballast cross sections as input and provides an output known as the ballast fouling index, which indicates the level of contamination in the ballast.",,,False,False
DOI-0036-2023,DOI,USGS,,AI/ML for aquatic science,"This project aims to develop novel computational frameworks and AI algorithms for individual_x000D_
fish recognition, by leveraging AI, computer vision and deep learning. The main objectives of_x000D_
this project include:_x000D_
(1) Develop baseline AI models by exploiting visual features and pre-trained deep_x000D_
learning models._x000D_
(2) Improve individual fish recognition performance, as well as handling new individuals and_x000D_
exploring dynamic environments._x000D_
(3) Evaluate melanistic markings associated with “blotchy bass syndrome” to assess the_x000D_
capacity for AI detection of diseased fish._x000D_
(4) Evaluate deep learning models for individual recognition and respiration rate (ventilate_x000D_
rate) using video data collected in laboratory settings and natural streams.",Initiation,convolutional neural networks,,Department of Interior,"AI/ML for aquatic science: 
This project aims to develop novel computational frameworks and AI algorithms for individual_x000D_
fish recognition, by leveraging AI, computer vision and deep learning. The main objectives of_x000D_
this project include:_x000D_
(1) Develop baseline AI models by exploiting visual features and pre-trained deep_x000D_
learning models._x000D_
(2) Improve individual fish recognition performance, as well as handling new individuals and_x000D_
exploring dynamic environments._x000D_
(3) Evaluate melanistic markings associated with “blotchy bass syndrome” to assess the_x000D_
capacity for AI detection of diseased fish._x000D_
(4) Evaluate deep learning models for individual recognition and respiration rate (ventilate_x000D_
rate) using video data collected in laboratory settings and natural streams.","This project aims to use AI and deep learning to develop computational frameworks and algorithms for recognizing individual fish. The objectives include developing baseline AI models, improving recognition performance in dynamic environments, evaluating AI detection of diseased fish, and evaluating deep learning models for individual recognition and respiration rate using video data.","This project aims to use AI and deep learning to develop computational frameworks and algorithms for recognizing individual fish. The objectives include developing baseline AI models, improving recognition performance in dynamic environments, evaluating AI detection of diseased fish, and evaluating deep learning models for individual recognition and respiration rate using video data.",,,False,False
DOE-0149-2023,DOE,National Energy Technology Laboratory,,Using AI/ML to replace conventional geophysics inversion - does the process quicker than the typical method. Make geophysical results more user-friendly.,"The project will deploy a high sensitivity atomic magnetometer 
(potassium magnetometer or helium 4 magnetometer) on a sUAS 
platform. Baseline surveys using the sUAS platform with the magnetic 
receiver payload will be flown at the same CarbonSAFE site that 
baseline ground surveys were performed in EY21. Results of the 
forward modeling performed in EY20 will determine whether MT or 
CSEM (or both) methods will be tested. Using AI/ML to replace 
conventional geophysics inversion - does the process quicker than the 
typical method. Make geophysical results more user-friendly.",,Neural Networks,,Department of Energy,"Using AI/ML to replace conventional geophysics inversion - does the process quicker than the typical method. Make geophysical results more user-friendly.: 
The project will deploy a high sensitivity atomic magnetometer 
(potassium magnetometer or helium 4 magnetometer) on a sUAS 
platform. Baseline surveys using the sUAS platform with the magnetic 
receiver payload will be flown at the same CarbonSAFE site that 
baseline ground surveys were performed in EY21. Results of the 
forward modeling performed in EY20 will determine whether MT or 
CSEM (or both) methods will be tested. Using AI/ML to replace 
conventional geophysics inversion - does the process quicker than the 
typical method. Make geophysical results more user-friendly.","The project aims to use AI/ML to replace conventional geophysics inversion, which will make the process faster than the typical method and result in more user-friendly geophysical results. This will be done by deploying a high sensitivity atomic magnetometer on a small unmanned aerial system (sUAS) platform and conducting baseline surveys at a CarbonSAFE site. The results from previous modeling will determine which methods, such as MT or CSEM, will be tested.","The project aims to use AI/ML to replace conventional geophysics inversion, which will make the process faster than the typical method and result in more user-friendly geophysical results. This will be done by deploying a high sensitivity atomic magnetometer on a small unmanned aerial system (sUAS) platform and conducting baseline surveys at a CarbonSAFE site. The results from previous modeling will determine which methods, such as MT or CSEM, will be tested.",,,False,False
NASA-0028-2023,NASA,Marshall Space Flight Center,,ImageLabeler,Web-based Collaborative Machine Learning Training Data Generation Tool,In-use,,,National Aeronautics and Space Administration,"ImageLabeler: 
Web-based Collaborative Machine Learning Training Data Generation Tool","ImageLabeler is a collaborative web-based tool used for generating training data for machine learning. It allows multiple users to label and tag images collectively, making the process more efficient and accurate.","ImageLabeler is a collaborative web-based tool used for generating training data for machine learning. It allows multiple users to label and tag images collectively, making the process more efficient and accurate.",,,False,False
HHS-0069-2023,HHS,FDA,CDER/Office of Generic Drugs,Developing Tools based on Text Analysis and Machine Learning to Enhance PSG Review Efficiency,"1. Develop a novel neural summarization model in tandem with information retrieval system, tailored for PSG review, with dual attention over both sentence-level and word-level outputs by taking advantage of both extractive and abstractive summarization.
2. Evaluate the new model with the PSG data and the large CNN/Daily Mail dataset. 
3. Develop an open-source software package for text summarization model and the information retrieval system.",Development and Acquisition,,,Department of Health and Human Services,"Developing Tools based on Text Analysis and Machine Learning to Enhance PSG Review Efficiency: 
1. Develop a novel neural summarization model in tandem with information retrieval system, tailored for PSG review, with dual attention over both sentence-level and word-level outputs by taking advantage of both extractive and abstractive summarization.
2. Evaluate the new model with the PSG data and the large CNN/Daily Mail dataset. 
3. Develop an open-source software package for text summarization model and the information retrieval system.","The text discusses the development of tools for enhancing PSG (Polysomnography) review efficiency. This involves creating a neural summarization model that combines extractive and abstractive summarization techniques, along with an information retrieval system. The model is evaluated using PSG data and a large dataset from CNN/Daily Mail, and an open-source software package is developed for these tools.","The text discusses the development of tools for enhancing PSG (Polysomnography) review efficiency. This involves creating a neural summarization model that combines extractive and abstractive summarization techniques, along with an information retrieval system. The model is evaluated using PSG data and a large dataset from CNN/Daily Mail, and an open-source software package is developed for these tools.",,,False,False
DOE-0073-2023,DOE,National Energy Technology Laboratory,,To analyze data and derive insights and improve predictions to forecast wellbore kick events to reduce loss of control events.,"Use of neural networks and/or AI cluster data analysis methods to 
improve detection and forecasting of wellbore and drilling related loss of 
control events, known as kicks, to imrpove real-time detection and 
prediction of these conditions.",,"Neural Networks, Other",,Department of Energy,"To analyze data and derive insights and improve predictions to forecast wellbore kick events to reduce loss of control events.: 
Use of neural networks and/or AI cluster data analysis methods to 
improve detection and forecasting of wellbore and drilling related loss of 
control events, known as kicks, to imrpove real-time detection and 
prediction of these conditions.","The text suggests that analyzing data and utilizing neural networks or AI cluster data analysis methods can help improve the detection and forecasting of wellbore kick events. This can lead to better real-time detection and prediction of these events, ultimately reducing the occurrence of loss of control events during drilling.","The text suggests that analyzing data and utilizing neural networks or AI cluster data analysis methods can help improve the detection and forecasting of wellbore kick events. This can lead to better real-time detection and prediction of these events, ultimately reducing the occurrence of loss of control events during drilling.",,,False,False
DOJ-0003-2023,DOJ,Tax Division,,Privileged Material Identification,"The application scans documents and 
looks for attorney/client privileged 
information. It does this based on 
keyword input by the system 
operator.",In production: less than 6 months,,,Department of Justice,"Privileged Material Identification: 
The application scans documents and 
looks for attorney/client privileged 
information. It does this based on 
keyword input by the system 
operator.",The application scans documents to identify attorney/client privileged information by searching for specific keywords input by the system operator. This helps to identify and protect sensitive and confidential information.,The application scans documents to identify attorney/client privileged information by searching for specific keywords input by the system operator. This helps to identify and protect sensitive and confidential information.,,,False,False
DOC-0032-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,ProbSR (probability of subfreezing roads,A machine-learned algorithm that provides a 0-100% probability roads are subfreezing,,,,Department of Commerce,"ProbSR (probability of subfreezing roads: 
A machine-learned algorithm that provides a 0-100% probability roads are subfreezing","ProbSR is an algorithm that uses machine learning to predict the likelihood of roads being subfreezing, ranging from 0% to 100%. It helps determine the probability of encountering icy conditions while driving.","ProbSR is an algorithm that uses machine learning to predict the likelihood of roads being subfreezing, ranging from 0% to 100%. It helps determine the probability of encountering icy conditions while driving.",,,False,False
HHS-0019-2023,HHS,ASPR,"Office of Information Management, Data, and Analytics/Division of Supply Chain Control Tower",Ventilator Medication Model,Leveraging generalized additive model to project ventilated rate of COVID inpatients,Operation and Maintenance,,,Department of Health and Human Services,"Ventilator Medication Model: 
Leveraging generalized additive model to project ventilated rate of COVID inpatients","The ventilator medication model uses a generalized additive model to predict the rate at which COVID inpatients will require ventilators. This model helps to estimate the number of patients who will need ventilator support, aiding in resource allocation and planning for healthcare providers.","The ventilator medication model uses a generalized additive model to predict the rate at which COVID inpatients will require ventilators. This model helps to estimate the number of patients who will need ventilator support, aiding in resource allocation and planning for healthcare providers.",,,False,False
DOE-0041-2023,DOE,National Energy Technology Laboratory,,Database will be utilized to demonstrate targeted biocide strategies using AI to assess large DNA datasets.,"The team will develop a public DNA database that will advance 
knowledge in produced water management. This project consists of two 
phases: (1) the development and launching of the database, and (2) the 
demonstration of applicability of the database by conducting a network 
analysis. The work will be pursued as defined in the phases below. The 
fully characterized streams will be used by other FWPs to estimate 
overall resource recovery and will be used by other FWPs as training 
set for machine learning (ML) models to predict compositions when only 
limited measurements can or have been completed for the produced 
water.",,"Big Data, Other",,Department of Energy,"Database will be utilized to demonstrate targeted biocide strategies using AI to assess large DNA datasets.: 
The team will develop a public DNA database that will advance 
knowledge in produced water management. This project consists of two 
phases: (1) the development and launching of the database, and (2) the 
demonstration of applicability of the database by conducting a network 
analysis. The work will be pursued as defined in the phases below. The 
fully characterized streams will be used by other FWPs to estimate 
overall resource recovery and will be used by other FWPs as training 
set for machine learning (ML) models to predict compositions when only 
limited measurements can or have been completed for the produced 
water.","The team plans to create a DNA database for produced water management. This project will be carried out in two phases: developing and launching the database, and demonstrating its usefulness through network analysis. The fully characterized streams in the database will be used by other projects to estimate resource recovery and train machine learning models for predicting compositions of produced water.","The team plans to create a DNA database for produced water management. This project will be carried out in two phases: developing and launching the database, and demonstrating its usefulness through network analysis. The fully characterized streams in the database will be used by other projects to estimate resource recovery and train machine learning models for predicting compositions of produced water.",,,False,False
VA-0016-2023,VA,,,PredictMod,PredictMod uses artificial intelligence to determine if predictions can be made about diabetes based on the gut microbiome.,,,,Department of Veterans Affairs,"PredictMod: 
PredictMod uses artificial intelligence to determine if predictions can be made about diabetes based on the gut microbiome.","PredictMod is an artificial intelligence system that analyzes the gut microbiome to determine if predictions about diabetes can be made. It utilizes advanced technology to evaluate the relationship between the gut microbiome and diabetes, potentially providing valuable insights and predictions in this area.","PredictMod is an artificial intelligence system that analyzes the gut microbiome to determine if predictions about diabetes can be made. It utilizes advanced technology to evaluate the relationship between the gut microbiome and diabetes, potentially providing valuable insights and predictions in this area.",,,False,False
DOI-0035-2023,DOI,USGS,,Kaguya TC DTM Generation,"The primary goals for FY21 are to develop a processing pipeline for generating Kaguya TC DTMs, generate a test suite of 100 Kaguya TC DTMs using Ames Stereo Pipeline (ASP), and evaluate the resulting products.",Initiation,"extreme gradient boosted classification, stochastic gradient decent (LinearLearner®), multi-layer perceptron",,Department of Interior,"Kaguya TC DTM Generation: 
The primary goals for FY21 are to develop a processing pipeline for generating Kaguya TC DTMs, generate a test suite of 100 Kaguya TC DTMs using Ames Stereo Pipeline (ASP), and evaluate the resulting products.","The primary objectives for FY21 are to create a processing pipeline to produce Kaguya TC DTMs, generate a set of 100 Kaguya TC DTMs using Ames Stereo Pipeline (ASP), and assess the outcomes of this process.","The primary objectives for FY21 are to create a processing pipeline to produce Kaguya TC DTMs, generate a set of 100 Kaguya TC DTMs using Ames Stereo Pipeline (ASP), and assess the outcomes of this process.",,,False,False
NASA-0007-2023,NASA,Glenn Research Center,,Inverse Design of Materials,"Discovering new materials is typically a mix of art and science, with timelines to create and robustly test a new
material mix / manufacturing method ranging from ten to twenty years. This project seeks to enable rapid
discovery, optimization, qualifaction and deployment of fit-for-purpose materials. Supervised ML models are
trained to establish the relationship between how a material is made and how the material performs. Then Bayesian
optimization is used to select iterative optimal experiments to achieve the target material properties in a cost and
time efficient manner compared to traditional design of experiments. The project is currently being utilized in an
NESC investigation to improve SLS core stage weld quality. The technology will be used to select experiments for a
fully autonomous robotic lab that is currently being procured to design better insulating materials for electrified
aircraft. Outputs include recipes and approaches for new materials custom-tailored to applications with an 4x
speedup for the overall materials discovery / design lifecycle, and potential 10x throughput for the same cycle based
on parallizing discovery of multiple materials at once.",In-use,,,National Aeronautics and Space Administration,"Inverse Design of Materials: 
Discovering new materials is typically a mix of art and science, with timelines to create and robustly test a new
material mix / manufacturing method ranging from ten to twenty years. This project seeks to enable rapid
discovery, optimization, qualifaction and deployment of fit-for-purpose materials. Supervised ML models are
trained to establish the relationship between how a material is made and how the material performs. Then Bayesian
optimization is used to select iterative optimal experiments to achieve the target material properties in a cost and
time efficient manner compared to traditional design of experiments. The project is currently being utilized in an
NESC investigation to improve SLS core stage weld quality. The technology will be used to select experiments for a
fully autonomous robotic lab that is currently being procured to design better insulating materials for electrified
aircraft. Outputs include recipes and approaches for new materials custom-tailored to applications with an 4x
speedup for the overall materials discovery / design lifecycle, and potential 10x throughput for the same cycle based
on parallizing discovery of multiple materials at once.","This project aims to expedite the process of discovering and optimizing materials by using supervised ML models and Bayesian optimization. It is currently being used to improve weld quality in an NESC investigation and will be applied to designing insulating materials for electrified aircraft. The project's outputs include custom-tailored material recipes and approaches, with a 4x speedup in the overall discovery/design process and a potential 10x increase in throughput by parallelizing the discovery of multiple materials.","This project aims to expedite the process of discovering and optimizing materials by using supervised ML models and Bayesian optimization. It is currently being used to improve weld quality in an NESC investigation and will be applied to designing insulating materials for electrified aircraft. The project's outputs include custom-tailored material recipes and approaches, with a 4x speedup in the overall discovery/design process and a potential 10x increase in throughput by parallelizing the discovery of multiple materials.",,,False,False
DOE-0177-2023,DOE,Western Area Power Administration,,FIMS - Invoice BOT - Employee Reimbursements FIMS - Invoice BOT - Purchase Power,"PROCESS - Invoices are sent to the RPA Invoice Intake email box 
(RPAInvoiceIntake@WAPA.GOV). Once a day, unattended bot will 
extract information from PDF invoices. The invoice is classified to 
determine whether the invoice is an Employee Reimbursement or a 
Purchase Power Invoice.  The information extracted from the invoice is 
then review/validated by the Accounts Payable Technician. After 
validation, the bot will load the information into the WAPA Financial 
Management System.",Operation and Maintenance,"Artificial Intelligence, Document Understanding",,Department of Energy,"FIMS - Invoice BOT - Employee Reimbursements FIMS - Invoice BOT - Purchase Power: 
PROCESS - Invoices are sent to the RPA Invoice Intake email box 
(RPAInvoiceIntake@WAPA.GOV). Once a day, unattended bot will 
extract information from PDF invoices. The invoice is classified to 
determine whether the invoice is an Employee Reimbursement or a 
Purchase Power Invoice.  The information extracted from the invoice is 
then review/validated by the Accounts Payable Technician. After 
validation, the bot will load the information into the WAPA Financial 
Management System.",The FIMS-Invoice BOT is an automated system that processes invoices sent to the RPA Invoice Intake email box. The bot extracts information from PDF invoices and classifies them as either Employee Reimbursements or Purchase Power Invoices. The extracted information is then reviewed and validated by an Accounts Payable Technician before being loaded into the WAPA Financial Management System.,The FIMS-Invoice BOT is an automated system that processes invoices sent to the RPA Invoice Intake email box. The bot extracts information from PDF invoices and classifies them as either Employee Reimbursements or Purchase Power Invoices. The extracted information is then reviewed and validated by an Accounts Payable Technician before being loaded into the WAPA Financial Management System.,,,False,False
HHS-0102-2023,HHS,FDA,NCTR,Development of a Comprehensive Open Access Molecules with Androgenic Activity Resource (MAAR) to Facilitate Assessment of Chemicals,"Androgen receptor (AR) is a ligand-dependent transcription factor and a member of the nuclear receptor superfamily, which is activated by androgens. AR is the target for many drugs but it could also act as an off target for drugs and other chemicals. Therefore, detecting androgenic activity of drugs and other FDA regulated chemicals is critical for evaluation of drug safety and assessment of chemical risk. There is a large amount of androgenic activity data in the public domain, which could be an asset for the scientific community and regulatory science. However, the data are distributed across different and diverse sources and stored in different formats, limiting the use of the data in research and regulation. Therefore, a comprehensive, reliable resource to provide open access to the data and enable modeling and prediction of androgenic activity for untested chemicals is in urgent need. This project will develop a high-quality open access Molecules with Androgenic Activity Resource (MAAR) including data and predictive models fully compliant with the FAIR (Findable, Accessible, Interoperable, and Reusable) principles.  MAAR can be used to facilitate research on androgenic activity of chemicals and support regulatory decision making concerning efficacy and safety evaluation of drugs and chemicals in the FDA regulated products.",Implementation,,,Department of Health and Human Services,"Development of a Comprehensive Open Access Molecules with Androgenic Activity Resource (MAAR) to Facilitate Assessment of Chemicals: 
Androgen receptor (AR) is a ligand-dependent transcription factor and a member of the nuclear receptor superfamily, which is activated by androgens. AR is the target for many drugs but it could also act as an off target for drugs and other chemicals. Therefore, detecting androgenic activity of drugs and other FDA regulated chemicals is critical for evaluation of drug safety and assessment of chemical risk. There is a large amount of androgenic activity data in the public domain, which could be an asset for the scientific community and regulatory science. However, the data are distributed across different and diverse sources and stored in different formats, limiting the use of the data in research and regulation. Therefore, a comprehensive, reliable resource to provide open access to the data and enable modeling and prediction of androgenic activity for untested chemicals is in urgent need. This project will develop a high-quality open access Molecules with Androgenic Activity Resource (MAAR) including data and predictive models fully compliant with the FAIR (Findable, Accessible, Interoperable, and Reusable) principles.  MAAR can be used to facilitate research on androgenic activity of chemicals and support regulatory decision making concerning efficacy and safety evaluation of drugs and chemicals in the FDA regulated products.","The development of a Comprehensive Open Access Molecules with Androgenic Activity Resource (MAAR) is essential for evaluating the safety of drugs and chemicals. The resource will provide open access to androgenic activity data that is currently scattered across various sources, making it difficult to use for research and regulation. MAAR will comply with FAIR principles and support research on androgenic activity and regulatory decision making.","The development of a Comprehensive Open Access Molecules with Androgenic Activity Resource (MAAR) is essential for evaluating the safety of drugs and chemicals. The resource will provide open access to androgenic activity data that is currently scattered across various sources, making it difficult to use for research and regulation. MAAR will comply with FAIR principles and support research on androgenic activity and regulatory decision making.",,,False,False
NASA-0024-2023,NASA,Marshall Space Flight Center,,Deep Learning Approaches for mapping surface water using Sentinel-1,Uses a U-Net based architecture to map surface water using the Sentinel-1 SAR Images,In-use,,,National Aeronautics and Space Administration,"Deep Learning Approaches for mapping surface water using Sentinel-1: 
Uses a U-Net based architecture to map surface water using the Sentinel-1 SAR Images","The text discusses the use of deep learning techniques for mapping surface water using Sentinel-1 SAR images. It focuses on a specific architecture called U-Net, which is employed for this purpose.","The text discusses the use of deep learning techniques for mapping surface water using Sentinel-1 SAR images. It focuses on a specific architecture called U-Net, which is employed for this purpose.",,,False,False
DOE-0079-2023,DOE,National Energy Technology Laboratory,,"To build the first data analytics and artificial intelligence field laboratory for unconventional resources in the Powder River Basin, focusing on optimization of hydraulic fracture stimulations through the use of multiple diagnostic technologies.","To establish a tight oil Field Laboratory in the Powder River Basin and 
accelerate the development of three major unconventional oil resources 
through detailed geologic characterization and improved geologic 
models leading to significant advances in well completion and fracture 
stimulation designs specific to these three formations. Utilize multi-
variate analysis to understand the interrelationship between completion 
and stimulation controls on well productivity.",,"Artificial Intelligence, Big Data",,Department of Energy,"To build the first data analytics and artificial intelligence field laboratory for unconventional resources in the Powder River Basin, focusing on optimization of hydraulic fracture stimulations through the use of multiple diagnostic technologies.: 
To establish a tight oil Field Laboratory in the Powder River Basin and 
accelerate the development of three major unconventional oil resources 
through detailed geologic characterization and improved geologic 
models leading to significant advances in well completion and fracture 
stimulation designs specific to these three formations. Utilize multi-
variate analysis to understand the interrelationship between completion 
and stimulation controls on well productivity.","The text describes the creation of a data analytics and artificial intelligence laboratory in the Powder River Basin, aimed at optimizing hydraulic fracture stimulations for unconventional resources. The laboratory will focus on the development of three major unconventional oil resources through geological characterization and improved models, leading to advancements in well completion and fracture stimulation designs. Multi-variate analysis will be used to understand how completion and stimulation controls affect well productivity.","The text describes the creation of a data analytics and artificial intelligence laboratory in the Powder River Basin, aimed at optimizing hydraulic fracture stimulations for unconventional resources. The laboratory will focus on the development of three major unconventional oil resources through geological characterization and improved models, leading to advancements in well completion and fracture stimulation designs. Multi-variate analysis will be used to understand how completion and stimulation controls affect well productivity.",,,False,False
DOE-0169-2023,DOE,Pacific Northwest National Laboratory,,Elucidating Genetic and Environmental Risk Factors for Antipsychotic-induced Metabolic Adverse Effects Using AI,"Develop AI methids to  find phenotypes that capture complex interation 
between human genome, chronic diseases and a drug's chemical 
signature to predict adverse side-effects of a mental health drug on 
human population",,,,Department of Energy,"Elucidating Genetic and Environmental Risk Factors for Antipsychotic-induced Metabolic Adverse Effects Using AI: 
Develop AI methids to  find phenotypes that capture complex interation 
between human genome, chronic diseases and a drug's chemical 
signature to predict adverse side-effects of a mental health drug on 
human population","This text discusses the development of AI methods to identify and understand the genetic and environmental risk factors associated with metabolic adverse effects caused by antipsychotic drugs. The goal is to use these methods to predict the negative side-effects of these drugs on the human population by analyzing the complex interactions between the individual's genetic makeup, chronic diseases, and the chemical composition of the drug.","This text discusses the development of AI methods to identify and understand the genetic and environmental risk factors associated with metabolic adverse effects caused by antipsychotic drugs. The goal is to use these methods to predict the negative side-effects of these drugs on the human population by analyzing the complex interactions between the individual's genetic makeup, chronic diseases, and the chemical composition of the drug.",,,False,False
DOE-0091-2023,DOE,National Energy Technology Laboratory,,"To develop a novel platform for secure data logging and processing in fossil fuel power generation systems using blockchain and machine learning to reduce down time for fossil energy power plants, limit reductions of power and reduce cost for repairs.","Machine learning model development will consist of traditional machine 
learning and deep learning algorithms implementation for anomaly 
detection.  Machine learning server will be used to develop the 
traditional models using One-Class Support Vector Machine (SVM) and 
K-Mean Clustering and deep learning models using Recurrent Neural 
Network (RNN) and its various implementations like Long Short-Term 
Memory (LSTM), Gated Recurrent Unit (GRU), Generative Adversarial 
Network (GAN), and Autoencoders using the sensor data collected from 
secure sensor network.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To develop a novel platform for secure data logging and processing in fossil fuel power generation systems using blockchain and machine learning to reduce down time for fossil energy power plants, limit reductions of power and reduce cost for repairs.: 
Machine learning model development will consist of traditional machine 
learning and deep learning algorithms implementation for anomaly 
detection.  Machine learning server will be used to develop the 
traditional models using One-Class Support Vector Machine (SVM) and 
K-Mean Clustering and deep learning models using Recurrent Neural 
Network (RNN) and its various implementations like Long Short-Term 
Memory (LSTM), Gated Recurrent Unit (GRU), Generative Adversarial 
Network (GAN), and Autoencoders using the sensor data collected from 
secure sensor network.","The text discusses the development of a secure data logging and processing platform for fossil fuel power generation systems. This platform will use blockchain and machine learning techniques to reduce downtime, power reductions, and repair costs. The machine learning model development will involve implementing traditional machine learning and deep learning algorithms for anomaly detection using sensor data from a secure sensor network.","The text discusses the development of a secure data logging and processing platform for fossil fuel power generation systems. This platform will use blockchain and machine learning techniques to reduce downtime, power reductions, and repair costs. The machine learning model development will involve implementing traditional machine learning and deep learning algorithms for anomaly detection using sensor data from a secure sensor network.",,,False,False
HHS-0043-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Predictive Intelligence - Incident Assignment for Quality Service Center (QSC).,Predictive Intelligence (PI) is used for incident assignment within the Quality Service Center (QSC). The solution runs on incidents created from the ServiceNow Service Portal (https://cmsqualitysupport.servicenowservices.com/sp_ess). The solution analyzes the short description provided by the end user in order to find key words with previously submitted incidents and assigns the ticket to the appropriate assignment group. This solution is re-trained with the incident data in our production instance every 3-6 months based on need.,Operation and Maintenance,,,Department of Health and Human Services,"Predictive Intelligence - Incident Assignment for Quality Service Center (QSC).: 
Predictive Intelligence (PI) is used for incident assignment within the Quality Service Center (QSC). The solution runs on incidents created from the ServiceNow Service Portal (https://cmsqualitysupport.servicenowservices.com/sp_ess). The solution analyzes the short description provided by the end user in order to find key words with previously submitted incidents and assigns the ticket to the appropriate assignment group. This solution is re-trained with the incident data in our production instance every 3-6 months based on need.",Predictive Intelligence is a system used in the Quality Service Center to assign incidents. It analyzes the short descriptions provided by users to find keywords and assigns the ticket to the correct group. The system is regularly re-trained based on incident data every 3-6 months.,Predictive Intelligence is a system used in the Quality Service Center to assign incidents. It analyzes the short descriptions provided by users to find keywords and assigns the ticket to the correct group. The system is regularly re-trained based on incident data every 3-6 months.,,,False,False
TREAS-0013-2023,TREAS,,,Taxpayer Accessibility - Machine Translation (MT),"Taxpayer Accessibility Machine Translation (MT) is a SaaS based 
Commercial Off-the-Shelf (COTS) product that uses Amazon Translate, a 
neural machine translation (NMT) service. The MT solution implements 
customization features in the product which will have capabilities to 
integrate existing Linguistics Policies Tools and Services (LPTS) translations 
and workflows through a centralized repository formed by a collection of 
existing and customized IRS glossaries to return translations from English 
to Spanish (and Spanish to English) that more accurately reflect native-
tongue verbiage.",Implementation,,,Department of Treasury,"Taxpayer Accessibility - Machine Translation (MT): 
Taxpayer Accessibility Machine Translation (MT) is a SaaS based 
Commercial Off-the-Shelf (COTS) product that uses Amazon Translate, a 
neural machine translation (NMT) service. The MT solution implements 
customization features in the product which will have capabilities to 
integrate existing Linguistics Policies Tools and Services (LPTS) translations 
and workflows through a centralized repository formed by a collection of 
existing and customized IRS glossaries to return translations from English 
to Spanish (and Spanish to English) that more accurately reflect native-
tongue verbiage.","Taxpayer Accessibility Machine Translation (MT) is a SaaS product that uses Amazon Translate, a neural machine translation service. It allows integration of existing translations and workflows through a centralized repository of IRS glossaries, providing more accurate English-Spanish translations that reflect native language.","Taxpayer Accessibility Machine Translation (MT) is a SaaS product that uses Amazon Translate, a neural machine translation service. It allows integration of existing translations and workflows through a centralized repository of IRS glossaries, providing more accurate English-Spanish translations that reflect native language.",,,False,False
DOL-0011-2023,DOL,,,Call Recording Analysis,Automatic analysis of recorded calls made to Benefits Advisors in the DOL Interactive Voice Repsonse (IVR) center.,Initiation,Cloud based commercial-off-the-shelf pre-trained NLP models,,Department of Labor,"Call Recording Analysis: 
Automatic analysis of recorded calls made to Benefits Advisors in the DOL Interactive Voice Repsonse (IVR) center.","The text refers to the analysis of recorded calls made to Benefits Advisors in the DOL Interactive Voice Response center. This analysis is done automatically, most likely using AI or machine learning technology, to gain insights from the recorded calls.","The text refers to the analysis of recorded calls made to Benefits Advisors in the DOL Interactive Voice Response center. This analysis is done automatically, most likely using AI or machine learning technology, to gain insights from the recorded calls.",,,False,False
DOI-0027-2023,DOI,USGS,,WRA.WPID.IWP.PUMP Turbidity Forecasting,This project aims to advance the use of national hydrological forecast models for delivering water quality forecasts relevant to water resource managers. ,Initiation,Convolutional Neural Networks,,Department of Interior,"WRA.WPID.IWP.PUMP Turbidity Forecasting: 
This project aims to advance the use of national hydrological forecast models for delivering water quality forecasts relevant to water resource managers. ",The WRA.WPID.IWP.PUMP Turbidity Forecasting project focuses on improving national hydrological forecast models to provide water quality forecasts that are useful for water resource managers. The project aims to enhance the delivery of these forecasts for effective management of water resources.,The WRA.WPID.IWP.PUMP Turbidity Forecasting project focuses on improving national hydrological forecast models to provide water quality forecasts that are useful for water resource managers. The project aims to enhance the delivery of these forecasts for effective management of water resources.,,,False,False
DOE-0111-2023,DOE,National Energy Technology Laboratory,,To enhance the SimCCS toolset to better account for existent infrastructure and to more broadly engage other user bases to improve toolset performance and applicability.,"Continue development of the SimCCS toolset, which is utilized to 
determine optimal placement for CO2 pipeline rights of way (ROW) and 
infrastructure in a machine-learning driven methodology that that 
considers environmentally sensitive areas, Justice40 considerations, 
and utilization of existent infrastructure.",,Artificial Intelligence Unknown,,Department of Energy,"To enhance the SimCCS toolset to better account for existent infrastructure and to more broadly engage other user bases to improve toolset performance and applicability.: 
Continue development of the SimCCS toolset, which is utilized to 
determine optimal placement for CO2 pipeline rights of way (ROW) and 
infrastructure in a machine-learning driven methodology that that 
considers environmentally sensitive areas, Justice40 considerations, 
and utilization of existent infrastructure.","The goal is to improve the SimCCS toolset by incorporating existing infrastructure and expanding its user base. This will be achieved through ongoing development to optimize the toolset's performance and make it more applicable, by considering factors such as environmentally sensitive areas, Justice40 considerations, and utilizing existing infrastructure in determining the best placement for CO2 pipeline rights of way and infrastructure.","The goal is to improve the SimCCS toolset by incorporating existing infrastructure and expanding its user base. This will be achieved through ongoing development to optimize the toolset's performance and make it more applicable, by considering factors such as environmentally sensitive areas, Justice40 considerations, and utilizing existing infrastructure in determining the best placement for CO2 pipeline rights of way and infrastructure.",,,False,False
DOI-0021-2023,DOI,USGS,,WRA.NWC.WU Gap analysis for water use,"The USGS Water Use Program requires a formal and detailed gap analysis of water-use data for the nation in order to better understand uncertainty in water-use estimates and to help inform future data collection and modeling efforts.  The primary objectives of this project are to: 1) identify the dominant water-use categories in different areas of the U.S.; 2) identify gaps in the available data for those categories, primarily gaps in data that if filled will improve model performance; and 3) identify potential methods for data estimation that can be used to fill gaps and provide the most benefit to water-use modeling efforts.  Other objectives include:  1) increasing understanding of data quality to help inform uncertainty in model predictions; 2) collaboration with model developers to understand water-use model sensitivity to input data in order to focus and prioritize future data collection; and 3) improved quality of data related to the extraction, delivery, and consumptive use of water for the important water use categories in different regions.  Water-use categories include public supply, domestic, industrial, thermoelectric power, irrigation, livestock, and aquaculture.  National models currently are under development for public supply, irrigation and thermoelectric. ",Initiation,convolutional neural networks,,Department of Interior,"WRA.NWC.WU Gap analysis for water use: 
The USGS Water Use Program requires a formal and detailed gap analysis of water-use data for the nation in order to better understand uncertainty in water-use estimates and to help inform future data collection and modeling efforts.  The primary objectives of this project are to: 1) identify the dominant water-use categories in different areas of the U.S.; 2) identify gaps in the available data for those categories, primarily gaps in data that if filled will improve model performance; and 3) identify potential methods for data estimation that can be used to fill gaps and provide the most benefit to water-use modeling efforts.  Other objectives include:  1) increasing understanding of data quality to help inform uncertainty in model predictions; 2) collaboration with model developers to understand water-use model sensitivity to input data in order to focus and prioritize future data collection; and 3) improved quality of data related to the extraction, delivery, and consumptive use of water for the important water use categories in different regions.  Water-use categories include public supply, domestic, industrial, thermoelectric power, irrigation, livestock, and aquaculture.  National models currently are under development for public supply, irrigation and thermoelectric. ","The USGS Water Use Program is conducting a gap analysis of water-use data in order to improve understanding of uncertainty in water-use estimates and inform future data collection and modeling efforts. The objectives of the analysis include identifying dominant water-use categories, identifying gaps in available data, and finding methods for data estimation to improve modeling efforts. Other objectives include understanding data quality, collaborating with model developers, and improving data related to important water use categories in different regions.","The USGS Water Use Program is conducting a gap analysis of water-use data in order to improve understanding of uncertainty in water-use estimates and inform future data collection and modeling efforts. The objectives of the analysis include identifying dominant water-use categories, identifying gaps in available data, and finding methods for data estimation to improve modeling efforts. Other objectives include understanding data quality, collaborating with model developers, and improving data related to important water use categories in different regions.",,,False,False
NASA-0012-2023,NASA,Jet Propulsion Laboratory,,CLASP Coverage Planning & Scheduling,"The Compressed Large-scale Activity Scheduling and Planning (CLASP) project is a long-range scheduler for space-
based or aerial instruments that can be modelled as pushbrooms -- 1D line sensors dragged across the surface of
the body being observed. It addresses the problem of choosing the orientation and on/off times of a pushbroom
instrument or collection of pushbroom instruments such that the schedule covers as many target points as possible,
but without oversubscribing memory and energy. Orientation and time of observation is derived from geometric
computations that CLASP performs using the SPICE ephemeris toolkit. CLASP allows mission planning teams to start
with a baseline mission concept and simulate the mission's science return using models of science observations,
spacecraft operations, downlink, and spacecraft trajectory. This analysis can then be folded back into many aspects
of mission design -- including trajectory, spacecraft design, operations concept, and downlink concept. The long
planning horizons allow this analysis to span an entire mission. Actively in use for optimized scheduling for the
NISAR Mission, ECOSTRESS mission (study of water needs for plant areas), EMIT mission (minerology of arid dusty
regions), OCO-3 (atmospheric CO2) and more as well as used for numerous missions analysis and studies (e.g.
100+).",In mission,constraint-based heuristic Search,,National Aeronautics and Space Administration,"CLASP Coverage Planning & Scheduling: 
The Compressed Large-scale Activity Scheduling and Planning (CLASP) project is a long-range scheduler for space-
based or aerial instruments that can be modelled as pushbrooms -- 1D line sensors dragged across the surface of
the body being observed. It addresses the problem of choosing the orientation and on/off times of a pushbroom
instrument or collection of pushbroom instruments such that the schedule covers as many target points as possible,
but without oversubscribing memory and energy. Orientation and time of observation is derived from geometric
computations that CLASP performs using the SPICE ephemeris toolkit. CLASP allows mission planning teams to start
with a baseline mission concept and simulate the mission's science return using models of science observations,
spacecraft operations, downlink, and spacecraft trajectory. This analysis can then be folded back into many aspects
of mission design -- including trajectory, spacecraft design, operations concept, and downlink concept. The long
planning horizons allow this analysis to span an entire mission. Actively in use for optimized scheduling for the
NISAR Mission, ECOSTRESS mission (study of water needs for plant areas), EMIT mission (minerology of arid dusty
regions), OCO-3 (atmospheric CO2) and more as well as used for numerous missions analysis and studies (e.g.
100+).",The CLASP project is a scheduler for space-based or aerial instruments that are dragged across the surface of the body being observed. It helps choose the orientation and on/off times of these instruments to cover as many target points as possible without using too much memory and energy. It is currently being used for optimized scheduling for various missions and has been used for over 100 missions analysis and studies.,The CLASP project is a scheduler for space-based or aerial instruments that are dragged across the surface of the body being observed. It helps choose the orientation and on/off times of these instruments to cover as many target points as possible without using too much memory and energy. It is currently being used for optimized scheduling for various missions and has been used for over 100 missions analysis and studies.,,,False,False
DOC-0043-2023,DOC,National Telecommunications and Information Administration (NTIA),,WAWENETS,"The algorithm produces estimates of telecommunications speech quality and speech 
intelligibility.  The input is a recording of speech from a telecommunications system in 
digital file format.  The output is a single number that indicates speech quality (typically 
on a 1 to 5 scale) or speech intelligibility (typically on a 0 to 1 scale).",,,,Department of Commerce,"WAWENETS: 
The algorithm produces estimates of telecommunications speech quality and speech 
intelligibility.  The input is a recording of speech from a telecommunications system in 
digital file format.  The output is a single number that indicates speech quality (typically 
on a 1 to 5 scale) or speech intelligibility (typically on a 0 to 1 scale).",The WAWENETS algorithm analyzes speech recordings from telecommunications systems and provides a numerical rating for speech quality or speech intelligibility. This rating is typically on a scale of 1 to 5 for speech quality and 0 to 1 for speech intelligibility.,The WAWENETS algorithm analyzes speech recordings from telecommunications systems and provides a numerical rating for speech quality or speech intelligibility. This rating is typically on a scale of 1 to 5 for speech quality and 0 to 1 for speech intelligibility.,,,False,False
SSA-0002-2023,SSA,"Office of Analytics, Review, and Oversight",,Pre-Effectuation Review / Targeted Denial Review Models,These review models use machine learning to identify cases with greatest likelihood of disability eligibility determination error and refer them for quality review checks.  ,,,,Social Security Administration,"Pre-Effectuation Review / Targeted Denial Review Models: 
These review models use machine learning to identify cases with greatest likelihood of disability eligibility determination error and refer them for quality review checks.  ",The Pre-Effectuation Review and Targeted Denial Review models utilize machine learning to pinpoint cases that are most likely to have errors in determining disability eligibility. These models then recommend these cases for thorough quality review checks to ensure accuracy.,The Pre-Effectuation Review and Targeted Denial Review models utilize machine learning to pinpoint cases that are most likely to have errors in determining disability eligibility. These models then recommend these cases for thorough quality review checks to ensure accuracy.,,,False,False
DOE-0045-2023,DOE,National Energy Technology Laboratory,,Develop fast predictive models using novel machine-learning based methods.,"Accurate, fast predictive ML models form the foundation for the virtual 
learning platform. Generating training data then developing ML based 
models enables a Virtual Learning Environment (VLE) for exploring and 
testing strategies to optimize reservoir development, management & 
monitoring prior to field activities.",,Other,,Department of Energy,"Develop fast predictive models using novel machine-learning based methods.: 
Accurate, fast predictive ML models form the foundation for the virtual 
learning platform. Generating training data then developing ML based 
models enables a Virtual Learning Environment (VLE) for exploring and 
testing strategies to optimize reservoir development, management & 
monitoring prior to field activities.","This text highlights the importance of developing accurate and fast predictive machine learning (ML) models for a virtual learning platform. By generating training data and utilizing ML-based models, a Virtual Learning Environment (VLE) can be created to improve reservoir development, management, and monitoring strategies before field activities take place.","This text highlights the importance of developing accurate and fast predictive machine learning (ML) models for a virtual learning platform. By generating training data and utilizing ML-based models, a Virtual Learning Environment (VLE) can be created to improve reservoir development, management, and monitoring strategies before field activities take place.",,,False,False
DOC-0015-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,EcoCast: A dynamic ocean management tool to reduce bycatch and support sustainable fisheries,"Operational tool that uses boosted regression trees to model the distribution of swordfish 
and bycatch species in the California Current",,,,Department of Commerce,"EcoCast: A dynamic ocean management tool to reduce bycatch and support sustainable fisheries: 
Operational tool that uses boosted regression trees to model the distribution of swordfish 
and bycatch species in the California Current",EcoCast is an operational tool that uses boosted regression trees to model the distribution of swordfish and bycatch species in the California Current. Its purpose is to reduce bycatch and support sustainable fisheries by providing dynamic ocean management.,EcoCast is an operational tool that uses boosted regression trees to model the distribution of swordfish and bycatch species in the California Current. Its purpose is to reduce bycatch and support sustainable fisheries by providing dynamic ocean management.,,,False,False
DOE-0165-2023,DOE,Pacific Northwest National Laboratory,,Advancing Market-Ready Building Energy Management by Cost- Effective Differentiable Predictive Control,"An AI based differentiable programming framework for domain aware 
data efficient predictive modeling and AI based control policy synthesis 
as well as methods for safety verification and online learning. Domain 
aware deep learning models are used for learning and predicting the 
response of building systems and components and for optimizing the 
building energy system response to provide resilient operation and 
sustained energy efficiency.",,,,Department of Energy,"Advancing Market-Ready Building Energy Management by Cost- Effective Differentiable Predictive Control: 
An AI based differentiable programming framework for domain aware 
data efficient predictive modeling and AI based control policy synthesis 
as well as methods for safety verification and online learning. Domain 
aware deep learning models are used for learning and predicting the 
response of building systems and components and for optimizing the 
building energy system response to provide resilient operation and 
sustained energy efficiency.","This text describes a framework for advancing building energy management through AI-based predictive modeling and control. The framework utilizes domain-aware deep learning models to optimize the response of building systems and components, ensuring resilient operation and sustained energy efficiency. Additionally, the framework includes methods for safety verification and online learning.","This text describes a framework for advancing building energy management through AI-based predictive modeling and control. The framework utilizes domain-aware deep learning models to optimize the response of building systems and components, ensuring resilient operation and sustained energy efficiency. Additionally, the framework includes methods for safety verification and online learning.",,,False,False
DOT-0013-2023,DOT,PHMSA Office of Chief Counsel (PHC),,PHMSA Rule Making,"Artificial Intelligence Support for Rulemaking - Using ChatGPT to support the rulemanking processes to provide significant efficiencies, reduction of effort, or the ability to scale efforts for unusual levels of public scrutiny or interest (e.g. comments on a rulemaking).    ChatGPT will be used to provide: 
1.  Sentiment Analysis – Is the comment positive / negative or neutral towards the proposed rule.
2.  Relevance Analysis – Whether the particular comment posted is relevant to the proposed rule
3.  Synopsis of the posted comment.
4.  Cataloging of comments.
5.  Identification of duplicate comments.",This is a pilot initiative,"ChatGPT, NLP",,Department of Transportation,"PHMSA Rule Making: 
Artificial Intelligence Support for Rulemaking - Using ChatGPT to support the rulemanking processes to provide significant efficiencies, reduction of effort, or the ability to scale efforts for unusual levels of public scrutiny or interest (e.g. comments on a rulemaking).    ChatGPT will be used to provide: 
1.  Sentiment Analysis – Is the comment positive / negative or neutral towards the proposed rule.
2.  Relevance Analysis – Whether the particular comment posted is relevant to the proposed rule
3.  Synopsis of the posted comment.
4.  Cataloging of comments.
5.  Identification of duplicate comments.","The PHMSA is implementing the use of ChatGPT, an artificial intelligence system, to support its rulemaking processes. ChatGPT will provide sentiment analysis, relevance analysis, synopses of posted comments, cataloging of comments, and identification of duplicate comments. This will lead to increased efficiency, reduced effort, and the ability to handle high levels of public interest or scrutiny in rulemaking.","The PHMSA is implementing the use of ChatGPT, an artificial intelligence system, to support its rulemaking processes. ChatGPT will provide sentiment analysis, relevance analysis, synopses of posted comments, cataloging of comments, and identification of duplicate comments. This will lead to increased efficiency, reduced effort, and the ability to handle high levels of public interest or scrutiny in rulemaking.",,,False,False
TREAS-0000-2023,TREAS,,,Account Management Chatbot,"The Accounts Management Chatbot leverages a natural language 
understanding model within the eGain intent engine. This NLU maps 
utterances to a specific intents, and returns the appropriate knowledge 
article.",Operation and Maintenance,,,Department of Treasury,"Account Management Chatbot: 
The Accounts Management Chatbot leverages a natural language 
understanding model within the eGain intent engine. This NLU maps 
utterances to a specific intents, and returns the appropriate knowledge 
article.",The Account Management Chatbot uses a natural language understanding model to understand user queries and match them with specific intents. It then provides relevant knowledge articles as responses.,The Account Management Chatbot uses a natural language understanding model to understand user queries and match them with specific intents. It then provides relevant knowledge articles as responses.,,,False,False
DOE-0046-2023,DOE,National Energy Technology Laboratory,,"Develop, integrate, and automate the reduction of CFD models while preserving acceptable levels of accuracy. In general for CCSI2, this work intends to focuse on CFD applications.","Will leverage state-of-the-art, physics-based deep learning (DL) models 
to learn generalizable surrogates that may be used in place of CFD 
models to predict quantities required for downstream optimization. The 
products from this subtask can be immediately leveraged by other 
subtasks that are seeking to speed up their CFD simulation models to 
streamline their downstream analyses. Addtionally, improvements to the 
ML/AI interface in FOQUS. Includes support for vector variables in the 
ML/AI plugin and support for additional surrogate model tools (e.g., 
PyTorch, Sci-kit Learn) and additional normalization function forms in 
the ML/AI plugin.",,"Neural Networks, Other",,Department of Energy,"Develop, integrate, and automate the reduction of CFD models while preserving acceptable levels of accuracy. In general for CCSI2, this work intends to focuse on CFD applications.: 
Will leverage state-of-the-art, physics-based deep learning (DL) models 
to learn generalizable surrogates that may be used in place of CFD 
models to predict quantities required for downstream optimization. The 
products from this subtask can be immediately leveraged by other 
subtasks that are seeking to speed up their CFD simulation models to 
streamline their downstream analyses. Addtionally, improvements to the 
ML/AI interface in FOQUS. Includes support for vector variables in the 
ML/AI plugin and support for additional surrogate model tools (e.g., 
PyTorch, Sci-kit Learn) and additional normalization function forms in 
the ML/AI plugin.","This text explains the goal of developing, integrating, and automating the reduction of CFD models while maintaining accuracy. The focus is on using physics-based deep learning models to create surrogates that can replace CFD models for predicting quantities needed for optimization. The results of this work can be used to streamline downstream analyses and there are plans to improve the ML/AI interface in FOQUS by adding support for vector variables and additional surrogate model tools and normalization functions.","This text explains the goal of developing, integrating, and automating the reduction of CFD models while maintaining accuracy. The focus is on using physics-based deep learning models to create surrogates that can replace CFD models for predicting quantities needed for optimization. The results of this work can be used to streamline downstream analyses and there are plans to improve the ML/AI interface in FOQUS by adding support for vector variables and additional surrogate model tools and normalization functions.",,,False,False
EPA-0001-2023,EPA,,,Records Categorization,The records management technology team is using machine learning to predict the retention schedule for records. The machine learning model will be incorporated into a records management application to help users apply retention schedules when they submit new records.,,,,U.S. Environmental Protection Agency,"Records Categorization: 
The records management technology team is using machine learning to predict the retention schedule for records. The machine learning model will be incorporated into a records management application to help users apply retention schedules when they submit new records.",The records management technology team is using machine learning to predict how long records should be kept. This prediction model will be added to a records management application to assist users in applying the appropriate retention schedules to new records.,The records management technology team is using machine learning to predict how long records should be kept. This prediction model will be added to a records management application to assist users in applying the appropriate retention schedules to new records.,,,False,False
DOC-0037-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Steller sea lion automated count program,"NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory (MML) is 
mandated to monitor the endangered western Steller sea lion population in Alaska. MML 
conducts annual aerial surveys of known Steller sea lion sites across the southern 
Alaska coastline to capture visual imagery. It requires two full-time, independent counters 
to process overlapping imagery manually (to avoid double counting sea lions in multiple 
frames), and count and classify individuals by age and sex class. These counts are vital 
for population and ecosystem-based modeling to better understand the species and 
ecosystem, to inform sustainable fishery management decisions, and are eagerly 
anticipated by stakeholders like the NOAA Alaska Regional Office, industry, and 
environmental groups. MML worked with Kitware to develop detection and image 
registration pipelines with VIAME (updates to the DIVE program to support updated 
interface needs). MML is now working to assess the algorithms efficacy and develop a 
workflow to augment the traditional counting method (to RL 9).",,,,Department of Commerce,"Steller sea lion automated count program: 
NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory (MML) is 
mandated to monitor the endangered western Steller sea lion population in Alaska. MML 
conducts annual aerial surveys of known Steller sea lion sites across the southern 
Alaska coastline to capture visual imagery. It requires two full-time, independent counters 
to process overlapping imagery manually (to avoid double counting sea lions in multiple 
frames), and count and classify individuals by age and sex class. These counts are vital 
for population and ecosystem-based modeling to better understand the species and 
ecosystem, to inform sustainable fishery management decisions, and are eagerly 
anticipated by stakeholders like the NOAA Alaska Regional Office, industry, and 
environmental groups. MML worked with Kitware to develop detection and image 
registration pipelines with VIAME (updates to the DIVE program to support updated 
interface needs). MML is now working to assess the algorithms efficacy and develop a 
workflow to augment the traditional counting method (to RL 9).",The NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory conducts annual aerial surveys to monitor the endangered western Steller sea lion population in Alaska. They use visual imagery and manually process the images to count and classify individuals by age and sex class. They are now working with Kitware to develop detection and image registration pipelines to improve the counting method.,The NOAA Fisheries Alaska Fisheries Science Center's Marine Mammal Laboratory conducts annual aerial surveys to monitor the endangered western Steller sea lion population in Alaska. They use visual imagery and manually process the images to count and classify individuals by age and sex class. They are now working with Kitware to develop detection and image registration pipelines to improve the counting method.,,,False,False
HHS-0035-2023,HHS,CDC,NCHS,AI/ML Model Release Standards,"NCHS is creating a set of model release standards for AI/ML projects that should be adhered to throughout the Center, and could serve as a starting point for broader standards across the AI/ML development lifecycle to be created at NCHS and throughout CDC.",Development and Acquisition,,,Department of Health and Human Services,"AI/ML Model Release Standards: 
NCHS is creating a set of model release standards for AI/ML projects that should be adhered to throughout the Center, and could serve as a starting point for broader standards across the AI/ML development lifecycle to be created at NCHS and throughout CDC.",The NCHS is developing a set of model release standards for AI/ML projects that should be followed within the center. These standards could potentially be used as a basis for creating wider standards for AI/ML development at both NCHS and CDC.,The NCHS is developing a set of model release standards for AI/ML projects that should be followed within the center. These standards could potentially be used as a basis for creating wider standards for AI/ML development at both NCHS and CDC.,,,False,False
DOI-0033-2023,DOI,USGS,,21st Century Prospecting: AI-assisted Surveying of Critical Mineral Potential (Reimbursable),"Based on the mandate to assess critical minerals distributions in the US, MRP has entered into a partnership between USGS and DARPA.  The objective of this partnership is to accelerate advances in science for understanding critical minerals, assessing unknown resources, and increase mineral security for the Nation. ",Initiation,Long short term memory (LSTM) models,,Department of Interior,"21st Century Prospecting: AI-assisted Surveying of Critical Mineral Potential (Reimbursable): 
Based on the mandate to assess critical minerals distributions in the US, MRP has entered into a partnership between USGS and DARPA.  The objective of this partnership is to accelerate advances in science for understanding critical minerals, assessing unknown resources, and increase mineral security for the Nation. ","The US Mineral Resources Program (MRP) has partnered with USGS and DARPA to use AI-assisted surveying to assess the distribution of critical minerals in the US. This partnership aims to advance scientific understanding of these minerals, identify unknown resources, and enhance national mineral security.","The US Mineral Resources Program (MRP) has partnered with USGS and DARPA to use AI-assisted surveying to assess the distribution of critical minerals in the US. This partnership aims to advance scientific understanding of these minerals, identify unknown resources, and enhance national mineral security.",,,False,False
DOC-0045-2023,DOC,United States Patent and Trade Office (USPTO),,AI use for CPC classification,"System that classifies incoming patent application based on the cooperative patent 
classification scheme for operational assignment of work and symbol recommendation for 
aI search.  Backoffice processing system that uses incoming patent applications as input 
and outputs the resulting classification symbols.",,,,Department of Commerce,"AI use for CPC classification: 
System that classifies incoming patent application based on the cooperative patent 
classification scheme for operational assignment of work and symbol recommendation for 
aI search.  Backoffice processing system that uses incoming patent applications as input 
and outputs the resulting classification symbols.",The AI system is used to classify incoming patent applications according to the cooperative patent classification scheme. This classification helps assign work and recommend symbols for AI search. The system also processes incoming patent applications and generates classification symbols as output.,The AI system is used to classify incoming patent applications according to the cooperative patent classification scheme. This classification helps assign work and recommend symbols for AI search. The system also processes incoming patent applications and generates classification symbols as output.,,,False,False
HHS-0083-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Label comparison tool to support identification of safety-related changes in drug labeling,"A tool with AI capabilities used to assist humans in their review and comparison of drug labeling in PDF format to identify safety-related changes occurring over time. The FDA uses postmarket data to update drug labeling, which can include new and a broad range safety-related issues; safety updates may be added to various sections of drug labeling. The tool's BERT natural language processing was trained to identify potential text related to newly added safety issues between drug labeling. ",Development and Acquisition,,,Department of Health and Human Services,"Label comparison tool to support identification of safety-related changes in drug labeling: 
A tool with AI capabilities used to assist humans in their review and comparison of drug labeling in PDF format to identify safety-related changes occurring over time. The FDA uses postmarket data to update drug labeling, which can include new and a broad range safety-related issues; safety updates may be added to various sections of drug labeling. The tool's BERT natural language processing was trained to identify potential text related to newly added safety issues between drug labeling. ",The label comparison tool is an AI-powered tool designed to help humans review and compare drug labeling in PDF format. It specifically focuses on identifying safety-related changes that occur over time. The tool's BERT natural language processing has been trained to detect potential text related to newly added safety issues in drug labeling.,The label comparison tool is an AI-powered tool designed to help humans review and compare drug labeling in PDF format. It specifically focuses on identifying safety-related changes that occur over time. The tool's BERT natural language processing has been trained to detect potential text related to newly added safety issues in drug labeling.,,,False,False
HHS-0013-2023,HHS,ASPR,BARDA (DRIVe),Host-Based Diagnostics: Patchd,Wearable device and AI model to predict sepsis at home.,Development and Acquisition,,,Department of Health and Human Services,"Host-Based Diagnostics: Patchd: 
Wearable device and AI model to predict sepsis at home.","Patchd is a wearable device that uses an AI model to predict sepsis in the comfort of one's home. This host-based diagnostic tool aims to detect sepsis early, allowing for timely medical intervention and potentially saving lives.","Patchd is a wearable device that uses an AI model to predict sepsis in the comfort of one's home. This host-based diagnostic tool aims to detect sepsis early, allowing for timely medical intervention and potentially saving lives.",,,False,False
VA-0039-2023,VA,,,Social determinants of health extractor,"AI is used with clinical notes to identify social determinants of health (SDOH) information. The extracted SDOH variables can be used during associated health related analysis to determine, among other factors, whether SDOH can be a contributor to disease risks or healthcare inequality.",,,,Department of Veterans Affairs,"Social determinants of health extractor: 
AI is used with clinical notes to identify social determinants of health (SDOH) information. The extracted SDOH variables can be used during associated health related analysis to determine, among other factors, whether SDOH can be a contributor to disease risks or healthcare inequality.",AI technology is utilized to extract social determinants of health (SDOH) information from clinical notes. This extracted data can be utilized in health-related analysis to assess if SDOH factors like disease risks or healthcare inequality contribute to health outcomes.,AI technology is utilized to extract social determinants of health (SDOH) information from clinical notes. This extracted data can be utilized in health-related analysis to assess if SDOH factors like disease risks or healthcare inequality contribute to health outcomes.,,,False,False
DOE-0110-2023,DOE,National Energy Technology Laboratory,,To employ machine learning to study the dependence of electrochemical performance on microstructural details,"With a significant number of images. The Recipient will build deep 
learning methods at the object detection stage using the Region Based 
Convolutional Neural Network (RCNN) or You Only Look Once (YOLO) 
class of algorithms, the heart of which is a deep learning image 
classifier. Deep learning algorithms will also be built using convolutional 
layers followed by residual layers to extract feature vector descriptors in 
the second stage. In the third and fourth stages of affinity and 
association, a recurrent neural network approach can be used to build a 
tracker. All of these approaches require a large training set that will 
enable sophisticated models to be built to handle the complexity of the 
application.
With a limited number of images. In the case that there is are a limited 
number of images, the Recipient will still be able to follow the processing 
pipeline. The recipient will determine a suitable approach, with 
concurrence from the project manager. Two potential approaches 
include:
• Transfer learning: training the image classifier in the object detector on 
images of similar quality and appearance, and 
• Match filtering: detection, feature extraction, and matching based on 
traditional image processing and computer vision techniques.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To employ machine learning to study the dependence of electrochemical performance on microstructural details: 
With a significant number of images. The Recipient will build deep 
learning methods at the object detection stage using the Region Based 
Convolutional Neural Network (RCNN) or You Only Look Once (YOLO) 
class of algorithms, the heart of which is a deep learning image 
classifier. Deep learning algorithms will also be built using convolutional 
layers followed by residual layers to extract feature vector descriptors in 
the second stage. In the third and fourth stages of affinity and 
association, a recurrent neural network approach can be used to build a 
tracker. All of these approaches require a large training set that will 
enable sophisticated models to be built to handle the complexity of the 
application.
With a limited number of images. In the case that there is are a limited 
number of images, the Recipient will still be able to follow the processing 
pipeline. The recipient will determine a suitable approach, with 
concurrence from the project manager. Two potential approaches 
include:
• Transfer learning: training the image classifier in the object detector on 
images of similar quality and appearance, and 
• Match filtering: detection, feature extraction, and matching based on 
traditional image processing and computer vision techniques.","The recipient will use machine learning, specifically deep learning methods like RCNN or YOLO, to analyze the relationship between electrochemical performance and microstructural details in a large dataset of images. If there are a limited number of images, the recipient will either use transfer learning with similar images or traditional image processing and computer vision techniques for detection and feature extraction.","The recipient will use machine learning, specifically deep learning methods like RCNN or YOLO, to analyze the relationship between electrochemical performance and microstructural details in a large dataset of images. If there are a limited number of images, the recipient will either use transfer learning with similar images or traditional image processing and computer vision techniques for detection and feature extraction.",,,False,False
DOE-0097-2023,DOE,National Energy Technology Laboratory,,To develop and evaluate a general drag model for gas-solid flows via physics-informed deep machine learning,"The project will evaluate the performance of several ANN algorithms for 
machine learning, pertinent to the deep neural network (DNN) 
algorithms. The DNN candidates will include random forest (RF), BPNN, 
XGBoost, and other supervised deep neural network algorithms. The 
best DNN algorithm will be identified by ranking of these algorithms’ 
performance. The Recipient will integrate the deep learning ANN model 
(DNN model) into the multiphase flow simulation software MFiX-DEM, 
which is part of the NETL’s open source CFD suite of software MFiX. 
The DNN based drag model developed on TensorFlow will be 
implemented using NETL’s existing software links between MFiX and 
TensorFlow.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To develop and evaluate a general drag model for gas-solid flows via physics-informed deep machine learning: 
The project will evaluate the performance of several ANN algorithms for 
machine learning, pertinent to the deep neural network (DNN) 
algorithms. The DNN candidates will include random forest (RF), BPNN, 
XGBoost, and other supervised deep neural network algorithms. The 
best DNN algorithm will be identified by ranking of these algorithms’ 
performance. The Recipient will integrate the deep learning ANN model 
(DNN model) into the multiphase flow simulation software MFiX-DEM, 
which is part of the NETL’s open source CFD suite of software MFiX. 
The DNN based drag model developed on TensorFlow will be 
implemented using NETL’s existing software links between MFiX and 
TensorFlow.","This project aims to develop and evaluate a drag model for gas-solid flows using deep machine learning. The project will assess the performance of various deep neural network algorithms, including random forest, BPNN, and XGBoost. The best algorithm will be determined based on their ranking. The developed model will be integrated into the multiphase flow simulation software MFiX-DEM, using the existing software links between MFiX and TensorFlow.","This project aims to develop and evaluate a drag model for gas-solid flows using deep machine learning. The project will assess the performance of various deep neural network algorithms, including random forest, BPNN, and XGBoost. The best algorithm will be determined based on their ranking. The developed model will be integrated into the multiphase flow simulation software MFiX-DEM, using the existing software links between MFiX and TensorFlow.",,,False,False
HHS-0062-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Artificial Intelligence (AI) Explorers Program Pilot - Automated Technical Profile,90 day Pilot is to engage in research and development to investigate applications in the generation of a machine-readable Automated Technical Profile for CMS systems with the goal of inferring the technology fingerprint of CMS projects based on multiple data sources at different stages of their development lifecycle,Development and Acquisition,,,Department of Health and Human Services,"Artificial Intelligence (AI) Explorers Program Pilot - Automated Technical Profile: 
90 day Pilot is to engage in research and development to investigate applications in the generation of a machine-readable Automated Technical Profile for CMS systems with the goal of inferring the technology fingerprint of CMS projects based on multiple data sources at different stages of their development lifecycle",The Artificial Intelligence (AI) Explorers Program Pilot is a 90-day research and development initiative. Its aim is to explore the use of AI in creating a machine-readable Automated Technical Profile for CMS systems. The goal is to analyze various data sources at different stages of development to determine the technology used in CMS projects.,The Artificial Intelligence (AI) Explorers Program Pilot is a 90-day research and development initiative. Its aim is to explore the use of AI in creating a machine-readable Automated Technical Profile for CMS systems. The goal is to analyze various data sources at different stages of development to determine the technology used in CMS projects.,,,False,False
HHS-0061-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Drug cost anomaly detection,Identify anomalies in drug costs on Part D claims,Initiation,,,Department of Health and Human Services,"Drug cost anomaly detection: 
Identify anomalies in drug costs on Part D claims",The purpose of drug cost anomaly detection is to find irregularities in the prices of drugs listed on Part D claims. This process aims to identify any unusual or unexpected variations in drug costs to ensure accuracy and prevent fraudulent activities.,The purpose of drug cost anomaly detection is to find irregularities in the prices of drugs listed on Part D claims. This process aims to identify any unusual or unexpected variations in drug costs to ensure accuracy and prevent fraudulent activities.,,,False,False
HHS-0004-2023,HHS,ASPR,BARDA (CBRN & DRIVe),ReDIRECT: AriScience,AI to identify drug repurposing candidates,Development and Acquisition,,,Department of Health and Human Services,"ReDIRECT: AriScience: 
AI to identify drug repurposing candidates","AriScience has developed an AI technology called ReDIRECT, which can identify potential drug repurposing candidates. This technology uses artificial intelligence to analyze large amounts of data and identify existing drugs that could be repurposed for new therapeutic uses.","AriScience has developed an AI technology called ReDIRECT, which can identify potential drug repurposing candidates. This technology uses artificial intelligence to analyze large amounts of data and identify existing drugs that could be repurposed for new therapeutic uses.",,,False,False
USDA-0026-2023,USDA,USDA,NASS,Cropland Data Layer,"A machine learning algorithm is used to interpret readings from satellite-based sensors and CLASSIFY the type of crop or activity that falls in each 30 square meter pixel (a box of fixed size) on the ground.  The algorithms are trained on USDA&%2339;s Farm Services Agency data and other sources of data as sources of &quot;ground truth&quot;.  It allows us to not only produce a classification, but to assess the accuracy of the classification as well.  For commodities, like corn and soybeans, the CDL is highly accurate.  The CDL has been produced for national coverage since 2008.  Some summary and background about the CDL is available in a number of peer reviewed research papers and presentations
https://www.nass.usda.gov/Research_and_Science/Cropland/othercitations/index.php",Operation and Management,Machine Learning,,Department of Agriculture,"Cropland Data Layer: 
A machine learning algorithm is used to interpret readings from satellite-based sensors and CLASSIFY the type of crop or activity that falls in each 30 square meter pixel (a box of fixed size) on the ground.  The algorithms are trained on USDA&%2339;s Farm Services Agency data and other sources of data as sources of &quot;ground truth&quot;.  It allows us to not only produce a classification, but to assess the accuracy of the classification as well.  For commodities, like corn and soybeans, the CDL is highly accurate.  The CDL has been produced for national coverage since 2008.  Some summary and background about the CDL is available in a number of peer reviewed research papers and presentations
https://www.nass.usda.gov/Research_and_Science/Cropland/othercitations/index.php",The Cropland Data Layer (CDL) uses a machine learning algorithm to analyze satellite data and determine the type of crop or activity in each 30 square meter pixel on the ground. The algorithm is trained using USDA's Farm Services Agency data and other sources to ensure accuracy. The CDL has been produced since 2008 and has proven to be highly accurate for commodities like corn and soybeans.,The Cropland Data Layer (CDL) uses a machine learning algorithm to analyze satellite data and determine the type of crop or activity in each 30 square meter pixel on the ground. The algorithm is trained using USDA's Farm Services Agency data and other sources to ensure accuracy. The CDL has been produced since 2008 and has proven to be highly accurate for commodities like corn and soybeans.,,,False,False
USAID-0010-2023,USAID,Bureau for Global Health (GH),,Indonesia: AI predictions for improving forecasts for TB drugs,AI technology will be used to develop a forecasting AI model for TB sensitive drugs to inform more accurate annual quantification exercises for the MoH linked to their national data integration platform SatuSehat,Initiation,,,U.S. Agency for International Development,"Indonesia: AI predictions for improving forecasts for TB drugs: 
AI technology will be used to develop a forecasting AI model for TB sensitive drugs to inform more accurate annual quantification exercises for the MoH linked to their national data integration platform SatuSehat","Indonesia plans to utilize AI technology to create a forecasting model for TB drugs. This will help the Ministry of Health in accurately estimating the required quantities of these drugs each year through their integrated data platform, SatuSehat.","Indonesia plans to utilize AI technology to create a forecasting model for TB drugs. This will help the Ministry of Health in accurately estimating the required quantities of these drugs each year through their integrated data platform, SatuSehat.",,,False,False
DOC-0033-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,VIAME: Video and Image Analysis for the Marine Environment Software Toolkit,"The Video and Image Analysis for the Marine Environment Software Toolkit, commonly 
known as VIAME, is an open-source, modular software toolkit that allows users to employ 
high-level, deep-learning algorithms for automated annotation of imagery using a low 
code/no code graphical user interface. VIAME is available free of charge to all NOAA 
users.  The NOAA Fisheries Office of Science and Technology supports an annual 
maintenance contract covering technical and customer support by the developer, routine 
software updates, bug fixes, and development efforts that support broad, cross center 
application needs.",,,,Department of Commerce,"VIAME: Video and Image Analysis for the Marine Environment Software Toolkit: 
The Video and Image Analysis for the Marine Environment Software Toolkit, commonly 
known as VIAME, is an open-source, modular software toolkit that allows users to employ 
high-level, deep-learning algorithms for automated annotation of imagery using a low 
code/no code graphical user interface. VIAME is available free of charge to all NOAA 
users.  The NOAA Fisheries Office of Science and Technology supports an annual 
maintenance contract covering technical and customer support by the developer, routine 
software updates, bug fixes, and development efforts that support broad, cross center 
application needs.",VIAME is an open-source software toolkit called Video and Image Analysis for the Marine Environment. It allows users to use deep-learning algorithms to automatically annotate imagery using a graphical interface. It is free for all NOAA users and is supported by the NOAA Fisheries Office of Science and Technology.,VIAME is an open-source software toolkit called Video and Image Analysis for the Marine Environment. It allows users to use deep-learning algorithms to automatically annotate imagery using a graphical interface. It is free for all NOAA users and is supported by the NOAA Fisheries Office of Science and Technology.,,,False,False
DOC-0040-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Using k-means clustering to identify spatially and temporally consistent wave systems,"Postprocessing that uses k-means clustering to identify spatially and temporally consistent 
wave systems from the output of NWPS v1.3. Has been successfully evaluated in the field 
by NWS marine forecasters nationwide and has been implemented into operations on 
February 3, 2021.",,,,Department of Commerce,"Using k-means clustering to identify spatially and temporally consistent wave systems: 
Postprocessing that uses k-means clustering to identify spatially and temporally consistent 
wave systems from the output of NWPS v1.3. Has been successfully evaluated in the field 
by NWS marine forecasters nationwide and has been implemented into operations on 
February 3, 2021.","K-means clustering is used for postprocessing to identify consistent wave systems in terms of their location and time. This method has been tested and approved by NWS marine forecasters across the country and has been in operational use since February 3, 2021.","K-means clustering is used for postprocessing to identify consistent wave systems in terms of their location and time. This method has been tested and approved by NWS marine forecasters across the country and has been in operational use since February 3, 2021.",,,False,False
DOS-0027-2023,DOS,R,,TOPIQ,"GEC A&R’s TOPIQ tool automatically classifies text into topics for analyst review and interpretation. The tool uses Latent Dirichlet Allocation (LDA), a natural language processing technique that uncovers a specified number of topics from a collection of documents, and then assigns the probability that each document belongs to a topic.",,,,Department of State,"TOPIQ: 
GEC A&R’s TOPIQ tool automatically classifies text into topics for analyst review and interpretation. The tool uses Latent Dirichlet Allocation (LDA), a natural language processing technique that uncovers a specified number of topics from a collection of documents, and then assigns the probability that each document belongs to a topic.","The TOPIQ tool by GEC A&R is designed to classify text into topics automatically. It utilizes Latent Dirichlet Allocation (LDA), a natural language processing technique, to identify topics from a collection of documents and determine the probability of each document belonging to a specific topic.","The TOPIQ tool by GEC A&R is designed to classify text into topics automatically. It utilizes Latent Dirichlet Allocation (LDA), a natural language processing technique, to identify topics from a collection of documents and determine the probability of each document belonging to a specific topic.",,,False,False
HHS-0119-2023,HHS,NIH,National Institutes of Health (NIH) NIEHS,Automated approaches for table extraction,"This project developed an automated, model-based processes to reduce the time and level of effort for manual�extraction of data from tables. Published data tables are a particularly data-rich and challenging presentation of critical information in published research.",Development and Acquisition,,,Department of Health and Human Services,"Automated approaches for table extraction: 
This project developed an automated, model-based processes to reduce the time and level of effort for manual�extraction of data from tables. Published data tables are a particularly data-rich and challenging presentation of critical information in published research.","The project aimed to create automated methods for extracting data from tables, reducing the need for manual extraction. Tables in published research are complex and contain important data, making them a challenging but valuable source of information.","The project aimed to create automated methods for extracting data from tables, reducing the need for manual extraction. Tables in published research are complex and contain important data, making them a challenging but valuable source of information.",,,False,False
DOC-0017-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Deep learning algorithms to automate right whale photo id,"AI for right whale photo id began with a Kaggle competition and has since expanded to 
include several algorithms to match right whales from different viewpoints (aerial, lateral) 
and body part (head, fluke, peduncle). The system is now live and operational on the 
Flukebook platform for both North Atlantic and southern right whales. We have a paper in 
review at Mammalian Biology.",,,,Department of Commerce,"Deep learning algorithms to automate right whale photo id: 
AI for right whale photo id began with a Kaggle competition and has since expanded to 
include several algorithms to match right whales from different viewpoints (aerial, lateral) 
and body part (head, fluke, peduncle). The system is now live and operational on the 
Flukebook platform for both North Atlantic and southern right whales. We have a paper in 
review at Mammalian Biology.","Deep learning algorithms have been developed to automate the identification of right whales based on their photos. The algorithms can match the whales from different angles and body parts, and the system is currently being used on the Flukebook platform for both North Atlantic and southern right whales. A paper discussing this system is currently under review at Mammalian Biology.","Deep learning algorithms have been developed to automate the identification of right whales based on their photos. The algorithms can match the whales from different angles and body parts, and the system is currently being used on the Flukebook platform for both North Atlantic and southern right whales. A paper discussing this system is currently under review at Mammalian Biology.",,,False,False
VA-0028-2023,VA,,,Predicting hospitalization and corticosteroid use as a surrogate for IBD flares,"This work examines data from 20,368 Veterans Health Administration (VHA) patients with an irritable bowel disease (IBD) diagnosis between 2002 and 2009. Longitudinal labs and associated predictors were used in random forest models to predict hospitalizations and steroid usage as a surrogate for IBD Flares.",,,,Department of Veterans Affairs,"Predicting hospitalization and corticosteroid use as a surrogate for IBD flares: 
This work examines data from 20,368 Veterans Health Administration (VHA) patients with an irritable bowel disease (IBD) diagnosis between 2002 and 2009. Longitudinal labs and associated predictors were used in random forest models to predict hospitalizations and steroid usage as a surrogate for IBD Flares.","This study analyzed data from over 20,000 Veterans Health Administration patients diagnosed with irritable bowel disease (IBD) to predict hospitalizations and the use of corticosteroids as a proxy for IBD flares. The researchers used longitudinal lab data and various predictors to develop random forest models for making these predictions.","This study analyzed data from over 20,000 Veterans Health Administration patients diagnosed with irritable bowel disease (IBD) to predict hospitalizations and the use of corticosteroids as a proxy for IBD flares. The researchers used longitudinal lab data and various predictors to develop random forest models for making these predictions.",,,False,False
HHS-0096-2023,HHS,FDA,NCTR,Development of virtual animal models to simulate animal study results using Artificial Intelligence (AI),"Testing data from animal models provides crucial evidence for the safety evaluation of chemicals. These data have been an essential component in regulating drug, food, and chemical safety by regulatory agencies worldwide including FDA. As a result, a wealth of animal data is available from the public domain and other sources. As the toxicology community and regulatory agencies move towards a reduction, refinement, and replacement (3Rs principle) of animal studies, we proposed an AI-based generative adversarial network (GAN) architecture to learn from existing animal studies so that it can generate animal data for new and untested chemicals without conducting further animal experiments. The FDA has developed guidelines and frameworks to modernize toxicity assessment with alternative methods, such as the FDA Predictive Toxicology Roadmap and the Innovative Science and Technology Approaches for New Drugs (ISTAND). These programs facilitate the development and evaluation of alternative methodologies to expand the FDA's toxicology predictive capabilities, to reduce the use of animal testing, and to facilitate drug development. A virtual animal model with capability of simulating animal studies could serve as an alternative to animal studies to support the FDA mission.",Initiation,,,Department of Health and Human Services,"Development of virtual animal models to simulate animal study results using Artificial Intelligence (AI): 
Testing data from animal models provides crucial evidence for the safety evaluation of chemicals. These data have been an essential component in regulating drug, food, and chemical safety by regulatory agencies worldwide including FDA. As a result, a wealth of animal data is available from the public domain and other sources. As the toxicology community and regulatory agencies move towards a reduction, refinement, and replacement (3Rs principle) of animal studies, we proposed an AI-based generative adversarial network (GAN) architecture to learn from existing animal studies so that it can generate animal data for new and untested chemicals without conducting further animal experiments. The FDA has developed guidelines and frameworks to modernize toxicity assessment with alternative methods, such as the FDA Predictive Toxicology Roadmap and the Innovative Science and Technology Approaches for New Drugs (ISTAND). These programs facilitate the development and evaluation of alternative methodologies to expand the FDA's toxicology predictive capabilities, to reduce the use of animal testing, and to facilitate drug development. A virtual animal model with capability of simulating animal studies could serve as an alternative to animal studies to support the FDA mission.","The development of virtual animal models using AI can simulate animal study results, providing crucial evidence for the safety evaluation of chemicals. By learning from existing animal studies, these models can generate data for new and untested chemicals without the need for further animal experiments, aligning with the FDA's goal to reduce animal testing and enhance toxicology predictive capabilities.","The development of virtual animal models using AI can simulate animal study results, providing crucial evidence for the safety evaluation of chemicals. By learning from existing animal studies, these models can generate data for new and untested chemicals without the need for further animal experiments, aligning with the FDA's goal to reduce animal testing and enhance toxicology predictive capabilities.",,,False,False
GSA-0002-2023,GSA,FAS,,Category Taxonomy Refinement Using NLP,Uses token extraction from product descriptions more accurately shape intended markets for Product Service Codes (PSCs).,Operation and Maintenance,NLP,,U.S. General Services Administration,"Category Taxonomy Refinement Using NLP: 
Uses token extraction from product descriptions more accurately shape intended markets for Product Service Codes (PSCs).",This text suggests that NLP (Natural Language Processing) can be used to improve the categorization of products by extracting tokens from their descriptions. This can help accurately determine the target markets for specific Product Service Codes (PSCs).,This text suggests that NLP (Natural Language Processing) can be used to improve the categorization of products by extracting tokens from their descriptions. This can help accurately determine the target markets for specific Product Service Codes (PSCs).,,,False,False
HHS-0070-2023,HHS,FDA,CDER/Office of Generic Drugs,BEAM (Bioequivalence Assessment Mate) - a Data/Text Analytics Tool to Enhance Quality and Efficiency of Bioequivalence Assessment,"We aim to develop BEAM using verified data analytics packages, text mining, and artificial intelligence (AI) toolsets (including machine learning (ML)), to streamline the labor-intensive work during BE assessments to facilitate high-quality and efficient regulatory assessments.
",Development and Acquisition,,,Department of Health and Human Services,"BEAM (Bioequivalence Assessment Mate) - a Data/Text Analytics Tool to Enhance Quality and Efficiency of Bioequivalence Assessment: 
We aim to develop BEAM using verified data analytics packages, text mining, and artificial intelligence (AI) toolsets (including machine learning (ML)), to streamline the labor-intensive work during BE assessments to facilitate high-quality and efficient regulatory assessments.
","The goal is to create BEAM, a tool that uses data analytics, text mining, and artificial intelligence to improve the quality and efficiency of bioequivalence assessments. By automating labor-intensive tasks and utilizing machine learning, this tool will help regulatory assessments become more streamlined and effective.","The goal is to create BEAM, a tool that uses data analytics, text mining, and artificial intelligence to improve the quality and efficiency of bioequivalence assessments. By automating labor-intensive tasks and utilizing machine learning, this tool will help regulatory assessments become more streamlined and effective.",,,False,False
USDA-0004-2023,USDA,USDA,APHIS,Automated Detection & Mapping of Host Plants from Ground Level Imagery,Generate maps of target trees from ground-level (streetview) imagery,Development and Acquisition,Machine Learning,,Department of Agriculture,"Automated Detection & Mapping of Host Plants from Ground Level Imagery: 
Generate maps of target trees from ground-level (streetview) imagery",This text explains the process of automatically detecting and mapping host plants using ground-level imagery. The aim is to create maps specifically showing the location of target trees using streetview images.,This text explains the process of automatically detecting and mapping host plants using ground-level imagery. The aim is to create maps specifically showing the location of target trees using streetview images.,,,False,False
HHS-0059-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Drug Cost Increase Predictions,Use Historical drug costs increases to predict future increases,Initiation,,,Department of Health and Human Services,"Drug Cost Increase Predictions: 
Use Historical drug costs increases to predict future increases","By analyzing past trends in drug costs, it is possible to make predictions about future increases. This method utilizes historical data to forecast the likely rise in drug prices.","By analyzing past trends in drug costs, it is possible to make predictions about future increases. This method utilizes historical data to forecast the likely rise in drug prices.",,,False,False
HHS-0105-2023,HHS,FDA,NCTR,Towards Explainable AI: Advancing Predictive Modeling for Regulatory Use,"Artificial Intelligence (AI) is a broad discipline of training machines to think and accomplish complex intellectual tasks like humans. It learns from existing data/information to predict future outcomes, distill knowledge, offer advices, or plan action steps. The rise of AI has offered both opportunities and challenges to FDA in two aspects: (1) how to assess and evaluate marketed AI-centric products and (2) how to implement AI methods to improve the agency's operation. One of the key aspects of both regulatory applications is to understand the underlying features driving the AI performance and to the extension of its interpretability in the context of application.  
 
Different from the statistical evaluation (e.g., accuracy, sensitivity and specificity), model interpretability assessment lacks quantitative metrics. In most cases, the assessment tends to be subjective, where prior knowledge is often used as a ground-truth to explain the biological relevance of underlying features, e.g., whether the biomarkers featured by the model are in accordance with the existing findings. In reality, there is a trade-off between statistical performance and interpretability among different AI algorithms, and understanding the difference will improve the context of use of AI technologies in regulatory science.  

For that, we will investigate representative AI methods, in terms of their performance and interpretability, first through benchmark datasets that have been well-established in the research community, then extended to clinical/pre-clinical datasets. This project will provide basic parameters and offer an insightful guidance on developing explainable AI models to facilitate the real-world decision making in regulatory settings.",Implementation,,,Department of Health and Human Services,"Towards Explainable AI: Advancing Predictive Modeling for Regulatory Use: 
Artificial Intelligence (AI) is a broad discipline of training machines to think and accomplish complex intellectual tasks like humans. It learns from existing data/information to predict future outcomes, distill knowledge, offer advices, or plan action steps. The rise of AI has offered both opportunities and challenges to FDA in two aspects: (1) how to assess and evaluate marketed AI-centric products and (2) how to implement AI methods to improve the agency's operation. One of the key aspects of both regulatory applications is to understand the underlying features driving the AI performance and to the extension of its interpretability in the context of application.  
 
Different from the statistical evaluation (e.g., accuracy, sensitivity and specificity), model interpretability assessment lacks quantitative metrics. In most cases, the assessment tends to be subjective, where prior knowledge is often used as a ground-truth to explain the biological relevance of underlying features, e.g., whether the biomarkers featured by the model are in accordance with the existing findings. In reality, there is a trade-off between statistical performance and interpretability among different AI algorithms, and understanding the difference will improve the context of use of AI technologies in regulatory science.  

For that, we will investigate representative AI methods, in terms of their performance and interpretability, first through benchmark datasets that have been well-established in the research community, then extended to clinical/pre-clinical datasets. This project will provide basic parameters and offer an insightful guidance on developing explainable AI models to facilitate the real-world decision making in regulatory settings.",This text discusses the challenges faced by the FDA in assessing and evaluating AI products and implementing AI methods to improve their operations. It highlights the importance of understanding the underlying features driving AI performance and the need for interpretability in regulatory applications. The text proposes investigating representative AI methods to determine their performance and interpretability and provide guidance on developing explainable AI models for decision making in regulatory settings.,This text discusses the challenges faced by the FDA in assessing and evaluating AI products and implementing AI methods to improve their operations. It highlights the importance of understanding the underlying features driving AI performance and the need for interpretability in regulatory applications. The text proposes investigating representative AI methods to determine their performance and interpretability and provide guidance on developing explainable AI models for decision making in regulatory settings.,,,False,False
NASA-0019-2023,NASA,Langley Research Center,,Geophysical Observations Toolkit for Evaluating Coral Health (GOTECH),"Three capstone projects conducted 2021-2022 with Georgia Tech and University of Rochester to develop machine
learning models that can analyze satellite LIDAR imagery to detect coral reefs and monitor their health. Capstones
were conducted with support of Coral Vita (an NGO) and the National Institute of Aerospace. Results were
presented at United Nations COP27.",In-use,"support vector machine, artificial neural network",https://ntrs.nasa.gov/citations/20220010955,National Aeronautics and Space Administration,"Geophysical Observations Toolkit for Evaluating Coral Health (GOTECH): 
Three capstone projects conducted 2021-2022 with Georgia Tech and University of Rochester to develop machine
learning models that can analyze satellite LIDAR imagery to detect coral reefs and monitor their health. Capstones
were conducted with support of Coral Vita (an NGO) and the National Institute of Aerospace. Results were
presented at United Nations COP27.","In 2021-2022, Georgia Tech and the University of Rochester collaborated on three capstone projects to create machine learning models that can assess the condition of coral reefs using satellite LIDAR imagery. These projects were supported by Coral Vita and the National Institute of Aerospace, and their findings were shared at the United Nations COP27.","In 2021-2022, Georgia Tech and the University of Rochester collaborated on three capstone projects to create machine learning models that can assess the condition of coral reefs using satellite LIDAR imagery. These projects were supported by Coral Vita and the National Institute of Aerospace, and their findings were shared at the United Nations COP27.",,,False,False
DOL-0006-2023,DOL,,,Data Ingestion of Payroll Forms,Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.,Initiation,Classification machine learning model involving computer vision,,Department of Labor,"Data Ingestion of Payroll Forms: 
Custom machine learning model to extract data from complex forms to tag data entries to field headers. The input is a document or scanned image of the form and the output is a JSON response with key/value pairs extracted by running the form against the custom trained model.","A custom machine learning model is used to extract data from complex forms and label the data entries according to field headers. By inputting a document or scanned image of the form, the model generates a JSON response containing extracted key/value pairs based on the form's analysis with the trained model.","A custom machine learning model is used to extract data from complex forms and label the data entries according to field headers. By inputting a document or scanned image of the form, the model generates a JSON response containing extracted key/value pairs based on the form's analysis with the trained model.",,,False,False
DOI-0006-2023,DOI,BOR,,Improved Processing and Analysis of Test and Operating Data from Rotating Machines,"This project is exploring a better method to analyze DC ramp test data from rotating machines. Previous DC ramp test analysis requires engineering expertise to recognize characteristic curves from DC ramp test plots. DC ramp tests produce a plot of voltage vs current for a ramping voltage applied to a rotating machine. By using machine learning/AI tools, such as linear regression, the ramp test plots can be analyzed by computer software, rather than manual engineering analysis, to recognize characteristic curves. The anticipated result will be faster and more reliable analysis of field-performed DC ramp testing.",Investigating/Proof of concept,,,Department of Interior,"Improved Processing and Analysis of Test and Operating Data from Rotating Machines: 
This project is exploring a better method to analyze DC ramp test data from rotating machines. Previous DC ramp test analysis requires engineering expertise to recognize characteristic curves from DC ramp test plots. DC ramp tests produce a plot of voltage vs current for a ramping voltage applied to a rotating machine. By using machine learning/AI tools, such as linear regression, the ramp test plots can be analyzed by computer software, rather than manual engineering analysis, to recognize characteristic curves. The anticipated result will be faster and more reliable analysis of field-performed DC ramp testing.","This project aims to improve the analysis of DC ramp test data from rotating machines. Currently, engineering expertise is required to recognize characteristic curves from the test plots. By using machine learning and AI tools, such as linear regression, computer software can analyze the test plots and identify characteristic curves, leading to faster and more reliable analysis of field-performed DC ramp testing.","This project aims to improve the analysis of DC ramp test data from rotating machines. Currently, engineering expertise is required to recognize characteristic curves from the test plots. By using machine learning and AI tools, such as linear regression, computer software can analyze the test plots and identify characteristic curves, leading to faster and more reliable analysis of field-performed DC ramp testing.",,,False,False
DHS-0034-2023,DHS,United States Citizenship and Immigration Services,,I-539 approval prediction,"This project attempts to train and build a machine learning throughput analysis model to predict when an I-539 ""Application to Extend or Change Nonimmigrant Status"" case will be approved through eProcessing. Allows for some potential improvement for the approval process via eProcessing channel.",Development and Acquisition,"Machine Learning, Clustering",,Department of Homeland Security,"I-539 approval prediction: 
This project attempts to train and build a machine learning throughput analysis model to predict when an I-539 ""Application to Extend or Change Nonimmigrant Status"" case will be approved through eProcessing. Allows for some potential improvement for the approval process via eProcessing channel.","This project aims to develop a machine learning model that can accurately predict the approval timeline for I-539 cases submitted through eProcessing. The model has the potential to enhance the approval process of ""Application to Extend or Change Nonimmigrant Status"" by providing valuable insights and predictions.","This project aims to develop a machine learning model that can accurately predict the approval timeline for I-539 cases submitted through eProcessing. The model has the potential to enhance the approval process of ""Application to Extend or Change Nonimmigrant Status"" by providing valuable insights and predictions.",,,False,False
HHS-0124-2023,HHS,NIH,National Institutes of Health (NIH) NIGMS,JIT Automated Calculator (JAC),The JIT Automated Calculator (JAC) uses natural language processing to parse Just-In-Time (JIT) Other Support forms and determine how much outside support PIs are receiving from sources other than the pending application.,Implementation,,,Department of Health and Human Services,"JIT Automated Calculator (JAC): 
The JIT Automated Calculator (JAC) uses natural language processing to parse Just-In-Time (JIT) Other Support forms and determine how much outside support PIs are receiving from sources other than the pending application.",The JIT Automated Calculator (JAC) utilizes natural language processing to analyze Just-In-Time (JIT) Other Support forms and calculate the amount of external support received by Principal Investigators (PIs) apart from the pending application.,The JIT Automated Calculator (JAC) utilizes natural language processing to analyze Just-In-Time (JIT) Other Support forms and calculate the amount of external support received by Principal Investigators (PIs) apart from the pending application.,,,False,False
DOE-0042-2023,DOE,National Energy Technology Laboratory,,Demonstrate how ML-based approaches can help operators during active injection and post- injection monitoring,"To demonstrate how ML-based approaches can help operators during 
active injection and post-injection monitoring, it is necessary to 
understand their needs and identify how ML-based approaches can 
potentially meet or support those needs. Task 4 will establish data-
sharing protocols between SMART and the operator to create an 
exchange mechanism that is not intrusive to the operator and provides 
updates from ML results designed to enhance the operator decision 
process. Demonstrate application of ML-based approaches to improve 
site-monitoring and operations efforts performed during injection and 
post-injection phases, e.g., using IL-ICCS data, and developing value of 
information guidelines.",,Other,,Department of Energy,"Demonstrate how ML-based approaches can help operators during active injection and post- injection monitoring: 
To demonstrate how ML-based approaches can help operators during 
active injection and post-injection monitoring, it is necessary to 
understand their needs and identify how ML-based approaches can 
potentially meet or support those needs. Task 4 will establish data-
sharing protocols between SMART and the operator to create an 
exchange mechanism that is not intrusive to the operator and provides 
updates from ML results designed to enhance the operator decision 
process. Demonstrate application of ML-based approaches to improve 
site-monitoring and operations efforts performed during injection and 
post-injection phases, e.g., using IL-ICCS data, and developing value of 
information guidelines.","Task 4 aims to establish data-sharing protocols between SMART and operators in order to enhance their decision-making process. This includes using ML-based approaches to improve site-monitoring and operations efforts during injection and post-injection phases, such as utilizing IL-ICCS data and developing value of information guidelines.","Task 4 aims to establish data-sharing protocols between SMART and operators in order to enhance their decision-making process. This includes using ML-based approaches to improve site-monitoring and operations efforts during injection and post-injection phases, such as utilizing IL-ICCS data and developing value of information guidelines.",,,False,False
DOL-0007-2023,DOL,,,Hololens,AI used by Inspectors to visually inspect high and unsafe areas from a safe location.,Operation and Maintenance,,,Department of Labor,"Hololens: 
AI used by Inspectors to visually inspect high and unsafe areas from a safe location.",The Hololens is an artificial intelligence (AI) technology that allows inspectors to visually examine hazardous and elevated spaces from a secure position. This innovative tool ensures the safety of inspectors while conducting inspections in high-risk areas.,The Hololens is an artificial intelligence (AI) technology that allows inspectors to visually examine hazardous and elevated spaces from a secure position. This innovative tool ensures the safety of inspectors while conducting inspections in high-risk areas.,,,False,False
DOE-0137-2023,DOE,National Energy Technology Laboratory,,To use computational tools to optimize the design of solid CO2 sorbents.,"The objective of this project is to use computational tools to optimize the 
design of solid CO2 sorbents based on functionalized PIM-1 (or other 
porous, glassy polymers) impregnated with molecular primary amines. 
The expected outcome of this project is to inform, via computational 
methods, which polymer structure and which molecular amines can lead 
to a solid sorbent in which CO2 loading capacity, CO2 heat of 
adsorption, and overall CO2 mass transfer rate are optimal at extremely 
low CO2 partial pressures while amine leaching has been minimized.",,Other,,Department of Energy,"To use computational tools to optimize the design of solid CO2 sorbents.: 
The objective of this project is to use computational tools to optimize the 
design of solid CO2 sorbents based on functionalized PIM-1 (or other 
porous, glassy polymers) impregnated with molecular primary amines. 
The expected outcome of this project is to inform, via computational 
methods, which polymer structure and which molecular amines can lead 
to a solid sorbent in which CO2 loading capacity, CO2 heat of 
adsorption, and overall CO2 mass transfer rate are optimal at extremely 
low CO2 partial pressures while amine leaching has been minimized.","This project aims to optimize the design of solid CO2 sorbents by using computational tools. The desired outcome is to determine the best polymer structure and molecular amines that will result in a solid sorbent with optimal CO2 loading capacity, CO2 heat of adsorption, and CO2 mass transfer rate at very low CO2 partial pressures, while minimizing amine leaching.","This project aims to optimize the design of solid CO2 sorbents by using computational tools. The desired outcome is to determine the best polymer structure and molecular amines that will result in a solid sorbent with optimal CO2 loading capacity, CO2 heat of adsorption, and CO2 mass transfer rate at very low CO2 partial pressures, while minimizing amine leaching.",,,False,False
TREAS-0006-2023,TREAS,,,DATA Act,"The Digital Accountability and Transparency Act (DATA) Act Bot automates 
verifying that IRS Federal Procurement Data System (FPDS) reporting 
matches the information in contract documents (e.g. dollar amounts, 
dates, location of work). Natural language processing is used to extract 
unstructured information from contract documents. F1 scores are used to 
measure performance of validation models for each specific data element.",Planned (not in production),,,Department of Treasury,"DATA Act: 
The Digital Accountability and Transparency Act (DATA) Act Bot automates 
verifying that IRS Federal Procurement Data System (FPDS) reporting 
matches the information in contract documents (e.g. dollar amounts, 
dates, location of work). Natural language processing is used to extract 
unstructured information from contract documents. F1 scores are used to 
measure performance of validation models for each specific data element.","The DATA Act Bot uses natural language processing to compare IRS Federal Procurement Data System reporting with contract documents, ensuring that information such as dollar amounts, dates, and location of work matches. The validation models' performance for each data element is measured using F1 scores.","The DATA Act Bot uses natural language processing to compare IRS Federal Procurement Data System reporting with contract documents, ensuring that information such as dollar amounts, dates, and location of work matches. The validation models' performance for each data element is measured using F1 scores.",,,False,False
HUD-0000-2023,HUD,,,Consolidated Plan Pilot Analysis,"In March 2023, PD&R began a pilot project to analyze aspects of HUD's Consolidated Plans. HUD requires grantees of its formula block grant programs to submit Consolidated Plans, which are meant to identify and assess affordable housing and community development needs and market conditions. These plans are publicly available via HUD's website. HUD staff currently review these plans for compliance, but HUD lacks the capacity to do in-depth analysis of commonalities or trends contained within plans. This pilot project will explore creating a database and chat-bot that will enable HUD staff to query features of the nearly 1,000 active Consolidated Plans. This pilot exercise has the potential to inform grantees, technical assistance, and other programmatic tweaks, as well as inform how advanced data science tools can benefit our programs and operations.",,,,Department of Housing and Urban Development,"Consolidated Plan Pilot Analysis: 
In March 2023, PD&R began a pilot project to analyze aspects of HUD's Consolidated Plans. HUD requires grantees of its formula block grant programs to submit Consolidated Plans, which are meant to identify and assess affordable housing and community development needs and market conditions. These plans are publicly available via HUD's website. HUD staff currently review these plans for compliance, but HUD lacks the capacity to do in-depth analysis of commonalities or trends contained within plans. This pilot project will explore creating a database and chat-bot that will enable HUD staff to query features of the nearly 1,000 active Consolidated Plans. This pilot exercise has the potential to inform grantees, technical assistance, and other programmatic tweaks, as well as inform how advanced data science tools can benefit our programs and operations.","In March 2023, PD&R initiated a pilot project to analyze HUD's Consolidated Plans. These plans, which are publicly available on HUD's website, are currently reviewed by HUD staff for compliance, but there is a lack of capacity to analyze commonalities or trends within the plans. The pilot project aims to create a database and chat-bot that will allow HUD staff to query features of the Consolidated Plans, potentially informing grantees, technical assistance, programmatic adjustments, and the utilization of advanced data science tools.","In March 2023, PD&R initiated a pilot project to analyze HUD's Consolidated Plans. These plans, which are publicly available on HUD's website, are currently reviewed by HUD staff for compliance, but there is a lack of capacity to analyze commonalities or trends within the plans. The pilot project aims to create a database and chat-bot that will allow HUD staff to query features of the Consolidated Plans, potentially informing grantees, technical assistance, programmatic adjustments, and the utilization of advanced data science tools.",,,False,False
DOI-0028-2023,DOI,USGS,,WRA.WPID.IWP.PUMP ExaSheds stream temperature projections with process-guided deep learning,"This 3-year project will improve PGDL stream temperature models by adding new forms of process guidance and merging techniques developed by USGS and DOE staff in past projects. Model assessments will emphasize robustness to projections in not-previously-seen conditions, such as those of future climates, paving the way for reliable projections into future decades in the Delaware River Basin.",Initiation,Convolutional Neural Networks,,Department of Interior,"WRA.WPID.IWP.PUMP ExaSheds stream temperature projections with process-guided deep learning: 
This 3-year project will improve PGDL stream temperature models by adding new forms of process guidance and merging techniques developed by USGS and DOE staff in past projects. Model assessments will emphasize robustness to projections in not-previously-seen conditions, such as those of future climates, paving the way for reliable projections into future decades in the Delaware River Basin.","The WRA.WPID.IWP.PUMP project aims to enhance stream temperature models using process-guided deep learning. By incorporating new forms of process guidance and techniques from previous projects, the project seeks to improve the reliability of projections into future decades, specifically in the Delaware River Basin, by ensuring robustness in not-previously-seen conditions like future climates.","The WRA.WPID.IWP.PUMP project aims to enhance stream temperature models using process-guided deep learning. By incorporating new forms of process guidance and techniques from previous projects, the project seeks to improve the reliability of projections into future decades, specifically in the Delaware River Basin, by ensuring robustness in not-previously-seen conditions like future climates.",,,False,False
DOL-0014-2023,DOL,,,Case Recording summarization,Using an open source large language model to summarize publicly available case recording documents which are void of personal identifiable information (PII) or any other sensitive information. This is not hosted in the DOL technical environment and is reviewed by human note takers.,Development and Acquisition,Large language summarization model,,Department of Labor,"Case Recording summarization: 
Using an open source large language model to summarize publicly available case recording documents which are void of personal identifiable information (PII) or any other sensitive information. This is not hosted in the DOL technical environment and is reviewed by human note takers.",An open source large language model is utilized to summarize case recording documents that do not contain any personal identifiable information or sensitive data. The process is performed outside of the DOL technical environment and is carefully reviewed by human note takers.,An open source large language model is utilized to summarize case recording documents that do not contain any personal identifiable information or sensitive data. The process is performed outside of the DOL technical environment and is carefully reviewed by human note takers.,,,False,False
HHS-0060-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Brand vs Generic Market Share,Analyze generic drugs compared to brand drugs over time and forecast future market shares based on Part D claims volume,Initiation,,,Department of Health and Human Services,"Brand vs Generic Market Share: 
Analyze generic drugs compared to brand drugs over time and forecast future market shares based on Part D claims volume",This analysis compares the market shares of generic drugs and brand drugs over time and uses Part D claims volume to predict future market shares. It aims to provide insights into the competition between generic and brand drugs in the market.,This analysis compares the market shares of generic drugs and brand drugs over time and uses Part D claims volume to predict future market shares. It aims to provide insights into the competition between generic and brand drugs in the market.,,,False,False
DOC-0048-2023,DOC,United States Patent and Trade Office (USPTO),,Inventor Search Assistant (iSAT),"Service to help inventors ""get started"" identifying relevant documents, figures, and 
classification codes used to conduct a novelty search.  System takes a user entered short 
description of invention and provides a user selectable set of recommended documents, 
figures, and classification areas.",,,,Department of Commerce,"Inventor Search Assistant (iSAT): 
Service to help inventors ""get started"" identifying relevant documents, figures, and 
classification codes used to conduct a novelty search.  System takes a user entered short 
description of invention and provides a user selectable set of recommended documents, 
figures, and classification areas.","The Inventor Search Assistant (iSAT) is a service that assists inventors in conducting novelty searches. By entering a brief description of their invention, users can receive a selection of recommended documents, figures, and classification codes to aid in their search.","The Inventor Search Assistant (iSAT) is a service that assists inventors in conducting novelty searches. By entering a brief description of their invention, users can receive a selection of recommended documents, figures, and classification codes to aid in their search.",,,False,False
DOE-0109-2023,DOE,National Energy Technology Laboratory,,"To drive insights using machine learning-based dynamics, control, and health models and tools developed by NETL to gain valuable operational data, insights, and","ML will be used to develop dynamics, controls, and health models for 
operating power generation facilities",,Other,,Department of Energy,"To drive insights using machine learning-based dynamics, control, and health models and tools developed by NETL to gain valuable operational data, insights, and: 
ML will be used to develop dynamics, controls, and health models for 
operating power generation facilities",NETL will utilize machine learning techniques to create models and tools for power generation facilities. These models will provide valuable data and insights for operational purposes.,NETL will utilize machine learning techniques to create models and tools for power generation facilities. These models will provide valuable data and insights for operational purposes.,,,False,False
DOS-0028-2023,DOS,R,,Text Similarity,GEC A&R’s Text Similarity capability identified different texts that are identical or nearly identical by calculating cosine similarity between each text. Texts are then grouped if they share high cosine similarity and then available for analysts to review further.,,,,Department of State,"Text Similarity: 
GEC A&R’s Text Similarity capability identified different texts that are identical or nearly identical by calculating cosine similarity between each text. Texts are then grouped if they share high cosine similarity and then available for analysts to review further.","GEC A&R's Text Similarity capability compares texts and determines if they are the same or very similar by calculating cosine similarity. If texts have a high cosine similarity, they are grouped together and can be reviewed by analysts for further examination.","GEC A&R's Text Similarity capability compares texts and determines if they are the same or very similar by calculating cosine similarity. If texts have a high cosine similarity, they are grouped together and can be reviewed by analysts for further examination.",,,False,False
TREAS-0002-2023,TREAS,,,Coin quality inspection system,"Automated coin visual inspection tools to search for defects on production 
lines. Currently each coining press operator manually inspects coins for 
quality. Improve quality and eliminate waste.  Researching feasibility and 
tools.",Initiation,,,Department of Treasury,"Coin quality inspection system: 
Automated coin visual inspection tools to search for defects on production 
lines. Currently each coining press operator manually inspects coins for 
quality. Improve quality and eliminate waste.  Researching feasibility and 
tools.","The coin quality inspection system aims to automate the process of visually inspecting coins for defects on production lines. Currently, operators manually inspect coins for quality, leading to potential errors and waste. The goal is to enhance the quality control process by researching and implementing feasible automated tools.","The coin quality inspection system aims to automate the process of visually inspecting coins for defects on production lines. Currently, operators manually inspect coins for quality, leading to potential errors and waste. The goal is to enhance the quality control process by researching and implementing feasible automated tools.",,,False,False
DOE-0107-2023,DOE,National Energy Technology Laboratory,,To drive insights on water recovery from cooling tower plumes,"Study of plume formation and collection on mechanical (induced) draft 
cooling towers, partly in a high-fidelity controlled environment and partly 
on a full-scale industrial cooling tower. It will start by building the needed 
laboratory setup and installing various sensors on the lab cooling tower. 
At the same time a computational fluid dynamics (CFD) model will be 
implemented to get precise full-scale plume models. Using the insights 
into power-plant plume characteristics the project will iterate on and 
experimentally test electrodes and collectors, which make up modular 
panels, on the lab cooling tower. What has been learned from the full-
scale plume modeling and sensor data analysis will then be applied to 
develop a design model to build the optimal collection apparatus for 
given working conditions",,,,Department of Energy,"To drive insights on water recovery from cooling tower plumes: 
Study of plume formation and collection on mechanical (induced) draft 
cooling towers, partly in a high-fidelity controlled environment and partly 
on a full-scale industrial cooling tower. It will start by building the needed 
laboratory setup and installing various sensors on the lab cooling tower. 
At the same time a computational fluid dynamics (CFD) model will be 
implemented to get precise full-scale plume models. Using the insights 
into power-plant plume characteristics the project will iterate on and 
experimentally test electrodes and collectors, which make up modular 
panels, on the lab cooling tower. What has been learned from the full-
scale plume modeling and sensor data analysis will then be applied to 
develop a design model to build the optimal collection apparatus for 
given working conditions","The text describes a study that aims to understand water recovery from cooling tower plumes. The study involves investigating plume formation and collection on both a laboratory setup and a full-scale industrial cooling tower. Various sensors will be installed on the lab cooling tower, and a computational fluid dynamics model will be used to develop precise plume models. The project will also experiment with electrodes and collectors on the lab cooling tower based on insights from the full-scale plume modeling and sensor data analysis. Ultimately, the findings will be used to design an optimal collection apparatus for specific working conditions.","The text describes a study that aims to understand water recovery from cooling tower plumes. The study involves investigating plume formation and collection on both a laboratory setup and a full-scale industrial cooling tower. Various sensors will be installed on the lab cooling tower, and a computational fluid dynamics model will be used to develop precise plume models. The project will also experiment with electrodes and collectors on the lab cooling tower based on insights from the full-scale plume modeling and sensor data analysis. Ultimately, the findings will be used to design an optimal collection apparatus for specific working conditions.",,,False,False
DOE-0007-2023,DOE,Fermi National Accelerator,,In-pixel AI for future tracking detectors,"This project explores novel  AI-on-chip technology for intelligent 
detectors embedded with sensing technology",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"In-pixel AI for future tracking detectors: 
This project explores novel  AI-on-chip technology for intelligent 
detectors embedded with sensing technology",This project aims to develop AI-on-chip technology for advanced tracking detectors. The focus is on creating intelligent detectors that are equipped with sensing capabilities.,This project aims to develop AI-on-chip technology for advanced tracking detectors. The focus is on creating intelligent detectors that are equipped with sensing capabilities.,,,False,False
DOL-0017-2023,DOL,,,Expenditure Classification Autocoder,Custom machine learning model to assign a reported expense description from Consumer Expenditure Diary Survey respondents to expense classification categories known as item codes.,Development and Acquisition,"Natural Language Processing, Random Forest, Classification",,Department of Labor,"Expenditure Classification Autocoder: 
Custom machine learning model to assign a reported expense description from Consumer Expenditure Diary Survey respondents to expense classification categories known as item codes.",The Expenditure Classification Autocoder is a machine learning model that categorizes reported expense descriptions from Consumer Expenditure Diary Survey participants into item codes. This custom model streamlines the process of assigning expense classification categories to improve efficiency and accuracy.,The Expenditure Classification Autocoder is a machine learning model that categorizes reported expense descriptions from Consumer Expenditure Diary Survey participants into item codes. This custom model streamlines the process of assigning expense classification categories to improve efficiency and accuracy.,,,False,False
NASA-0001-2023,NASA,Ames Research Center,,Biological and Physical Sciences (BPS) RNA Sequencing Benchmark Training Dataset,"RNA sequencing data from spaceflown and control mouse liver samples, sourced from NASA GeneLab and
augmented with generative adversarial network to provide synthetic data points. The implementation uses
classification methods and hierarchical clustering to identify genes that are predictive of outcomes.",In-use,"GANs, Hierarchical Clustering",https://github.com/NASA-IMPACT/bps-numerical,National Aeronautics and Space Administration,"Biological and Physical Sciences (BPS) RNA Sequencing Benchmark Training Dataset: 
RNA sequencing data from spaceflown and control mouse liver samples, sourced from NASA GeneLab and
augmented with generative adversarial network to provide synthetic data points. The implementation uses
classification methods and hierarchical clustering to identify genes that are predictive of outcomes.",The Biological and Physical Sciences RNA Sequencing Benchmark Training Dataset consists of RNA sequencing data from both spaceflown and control mouse liver samples. The dataset includes real data from NASA GeneLab as well as synthetic data generated using a generative adversarial network. The dataset is used to identify predictive genes through classification methods and hierarchical clustering.,The Biological and Physical Sciences RNA Sequencing Benchmark Training Dataset consists of RNA sequencing data from both spaceflown and control mouse liver samples. The dataset includes real data from NASA GeneLab as well as synthetic data generated using a generative adversarial network. The dataset is used to identify predictive genes through classification methods and hierarchical clustering.,,,False,False
VA-0029-2023,VA,,,Predicting corticosteroid free endoscopic remission with Vedolizumab in ulcerative colitis,This work uses random forest modeling on a cohort of 594 patients with Vedolizumab to predict the outcome of corticosteroid-free biologic remission at week 52 on the testing cohort. Models were constructed using baseline data or data through week 6 of VDZ therapy.,,,,Department of Veterans Affairs,"Predicting corticosteroid free endoscopic remission with Vedolizumab in ulcerative colitis: 
This work uses random forest modeling on a cohort of 594 patients with Vedolizumab to predict the outcome of corticosteroid-free biologic remission at week 52 on the testing cohort. Models were constructed using baseline data or data through week 6 of VDZ therapy.",The researchers used a random forest model to predict whether patients with ulcerative colitis would achieve corticosteroid-free remission after 52 weeks of Vedolizumab treatment. They created models using either baseline data or data up until week 6 of therapy.,The researchers used a random forest model to predict whether patients with ulcerative colitis would achieve corticosteroid-free remission after 52 weeks of Vedolizumab treatment. They created models using either baseline data or data up until week 6 of therapy.,,,False,False
DHS-0039-2023,DHS,United States Citizenship and Immigration Services,,Sentiment Analysis - Surveys,"The Sentiment Analysis - Surveys system provides a statistical analysis of quantitative results from survey results and then uses Natural Language Processing (NLP) modeling software to assign ""sentiments"" to categories ranging from strongly positive to strongly negative. This allows survey administrators to glean valuable information from employee satisfaction surveys from both quantitative and qualitative data. This capability is currently available on demand.",Operation and Maintenance,R SQL and Databricks,,Department of Homeland Security,"Sentiment Analysis - Surveys: 
The Sentiment Analysis - Surveys system provides a statistical analysis of quantitative results from survey results and then uses Natural Language Processing (NLP) modeling software to assign ""sentiments"" to categories ranging from strongly positive to strongly negative. This allows survey administrators to glean valuable information from employee satisfaction surveys from both quantitative and qualitative data. This capability is currently available on demand.",The Sentiment Analysis - Surveys system analyzes survey results and assigns sentiments to different categories using Natural Language Processing modeling software. This helps survey administrators extract valuable information from employee satisfaction surveys by combining quantitative and qualitative data. This capability is currently accessible on demand.,The Sentiment Analysis - Surveys system analyzes survey results and assigns sentiments to different categories using Natural Language Processing modeling software. This helps survey administrators extract valuable information from employee satisfaction surveys by combining quantitative and qualitative data. This capability is currently accessible on demand.,,,False,False
NASA-0009-2023,NASA,Goddard Space Flight Center,,Titan Methane Cloud Detection (GSFC Planetary Sciences Lab),"Machine Learning applied to Cassini space probe imagery to detect and characterize methane clouds on Saturn's
moon Titan.",In-use,"Mask R-CNN, U-net image Recognition",https://gitlab.grc.nasa.gov/zyahn/titan-clouds-project,National Aeronautics and Space Administration,"Titan Methane Cloud Detection (GSFC Planetary Sciences Lab): 
Machine Learning applied to Cassini space probe imagery to detect and characterize methane clouds on Saturn's
moon Titan.",The GSFC Planetary Sciences Lab is using Machine Learning to analyze images from the Cassini space probe in order to identify and study methane clouds on Saturn's moon Titan. This approach allows for the detection and understanding of these clouds in a more efficient and detailed manner.,The GSFC Planetary Sciences Lab is using Machine Learning to analyze images from the Cassini space probe in order to identify and study methane clouds on Saturn's moon Titan. This approach allows for the detection and understanding of these clouds in a more efficient and detailed manner.,,,False,False
HHS-0132-2023,HHS,NIH,National Institutes of Health (NIH) NLM,Computed Author: author name disambiguation for PubMed,"PubMed users frequently use author names in queries for retrieving scientific literature. However, author name ambiguity (different authors share the same name) may lead to irrelevant retrieval results. NLM developed a machine-learning method to score the features for disambiguating a pair of papers with ambiguous names. Subsequently, agglomerative clustering is employed to collect all papers belong to the same authors from those classified pairs. Disambiguation performance is evaluated with manual verification of random samples of pairs from clustering results, with a higher accuracy than other state-of-the-art methods. It has been integrated into PubMed to facilitate author name searches.",Operation and Maintenance,,,Department of Health and Human Services,"Computed Author: author name disambiguation for PubMed: 
PubMed users frequently use author names in queries for retrieving scientific literature. However, author name ambiguity (different authors share the same name) may lead to irrelevant retrieval results. NLM developed a machine-learning method to score the features for disambiguating a pair of papers with ambiguous names. Subsequently, agglomerative clustering is employed to collect all papers belong to the same authors from those classified pairs. Disambiguation performance is evaluated with manual verification of random samples of pairs from clustering results, with a higher accuracy than other state-of-the-art methods. It has been integrated into PubMed to facilitate author name searches.","The National Library of Medicine (NLM) has developed a machine-learning method to accurately distinguish between authors with the same name in PubMed. They use a scoring system to identify and classify ambiguous pairs of papers, and then employ clustering to group all papers belonging to the same authors. This method has been integrated into PubMed to improve the accuracy of author name searches.","The National Library of Medicine (NLM) has developed a machine-learning method to accurately distinguish between authors with the same name in PubMed. They use a scoring system to identify and classify ambiguous pairs of papers, and then employ clustering to group all papers belonging to the same authors. This method has been integrated into PubMed to improve the accuracy of author name searches.",,,False,False
HHS-0031-2023,HHS,CDC,NCHS,Semi-Automated Nonresponse Detection for Surveys (SANDS),"NCHS has developed and release an item nonresponse detection model, to identify cases of item nonresponse (e.g., gibberish, uncertain/don't know, refusals, or high-risk) among open-text responses to help improve survey data and question and questionnaire design. The system is a Natural Language Processing (NLP) model pre-trained using Contrastive Learning and fine-tuned on a custom dataset from survey responses. ",Operation and Maintenance,,,Department of Health and Human Services,"Semi-Automated Nonresponse Detection for Surveys (SANDS): 
NCHS has developed and release an item nonresponse detection model, to identify cases of item nonresponse (e.g., gibberish, uncertain/don't know, refusals, or high-risk) among open-text responses to help improve survey data and question and questionnaire design. The system is a Natural Language Processing (NLP) model pre-trained using Contrastive Learning and fine-tuned on a custom dataset from survey responses. ","The NCHS has created SANDS, a model that can detect cases of item nonresponse in open-text survey responses. This model uses Natural Language Processing techniques and has been trained on a custom dataset to improve survey data quality and questionnaire design.","The NCHS has created SANDS, a model that can detect cases of item nonresponse in open-text survey responses. This model uses Natural Language Processing techniques and has been trained on a custom dataset to improve survey data quality and questionnaire design.",,,False,False
DOE-0123-2023,DOE,National Energy Technology Laboratory,,To improve control of hybrid SOFC- gas turbine power systems.,"Machine learning algorithms are being developed and compared to 
other control methods for SOFC-gas turbine hybrid  power generation 
systems.",,Other,,Department of Energy,"To improve control of hybrid SOFC- gas turbine power systems.: 
Machine learning algorithms are being developed and compared to 
other control methods for SOFC-gas turbine hybrid  power generation 
systems.",Machine learning algorithms are being used to enhance control of hybrid SOFC-gas turbine power systems. These algorithms are being compared with other control methods to determine their effectiveness in improving power generation efficiency.,Machine learning algorithms are being used to enhance control of hybrid SOFC-gas turbine power systems. These algorithms are being compared with other control methods to determine their effectiveness in improving power generation efficiency.,,,False,False
DOE-0162-2023,DOE,Office of Legacy Management,,Soil Moisture Modeling,"Use multisource machine learning to model soil moisture within the 
lysimeter embedded within a disposal cell",,,,Department of Energy,"Soil Moisture Modeling: 
Use multisource machine learning to model soil moisture within the 
lysimeter embedded within a disposal cell",The text suggests using a combination of different sources and machine learning techniques to create a model that can accurately predict soil moisture levels in the lysimeter located within a disposal cell. This approach aims to better understand and manage soil moisture in this specific area.,The text suggests using a combination of different sources and machine learning techniques to create a model that can accurately predict soil moisture levels in the lysimeter located within a disposal cell. This approach aims to better understand and manage soil moisture in this specific area.,,,False,False
DHS-0040-2023,DHS,United States Citizenship and Immigration Services,,Topic Modeling on Request For Evidence data sets,"Builds models that identify lists of topics and documents that are related to each topic. Topic Modeling provides methods for automatically organizing, understanding, searching, and summarizing text data. It can help with the following: discovering the hidden themes in the collection. classifying the documents into the discovered themes.",Development and Acquisition,"Natural Language Processing (NLP), Machine Learning, Clustering",,Department of Homeland Security,"Topic Modeling on Request For Evidence data sets: 
Builds models that identify lists of topics and documents that are related to each topic. Topic Modeling provides methods for automatically organizing, understanding, searching, and summarizing text data. It can help with the following: discovering the hidden themes in the collection. classifying the documents into the discovered themes.","Topic modeling on Request For Evidence data sets involves creating models that can identify and group documents based on related topics. This technique is useful for organizing, understanding, searching, and summarizing text data by discovering hidden themes and classifying documents accordingly.","Topic modeling on Request For Evidence data sets involves creating models that can identify and group documents based on related topics. This technique is useful for organizing, understanding, searching, and summarizing text data by discovering hidden themes and classifying documents accordingly.",,,False,False
DOS-0024-2023,DOS,R,,forecasting,"using statistical models, projecting expected outcome into the future; this has been applied to COVID cases as well as violent events in relation to tweets",,,,Department of State,"forecasting: 
using statistical models, projecting expected outcome into the future; this has been applied to COVID cases as well as violent events in relation to tweets",Forecasting involves using statistical models to predict future outcomes. It has been used to project the expected number of COVID cases and predict the occurrence of violent events by analyzing tweets.,Forecasting involves using statistical models to predict future outcomes. It has been used to project the expected number of COVID cases and predict the occurrence of violent events by analyzing tweets.,,,False,False
DOS-0012-2023,DOS,CSO,,Apptio,Working Capital Fund (IRM/WCF) uses Apptio to bill bureaus for consolidated services run from the WCF. Cost models are built in Apptio so bureaus can budget for the service costs in future FYs. Apptio has the capability to extrapolate future values using several available formulas.,,,,Department of State,"Apptio: 
Working Capital Fund (IRM/WCF) uses Apptio to bill bureaus for consolidated services run from the WCF. Cost models are built in Apptio so bureaus can budget for the service costs in future FYs. Apptio has the capability to extrapolate future values using several available formulas.",Apptio is used by Apptio: Working Capital Fund to bill bureaus for consolidated services and help them budget for future service costs. It has the ability to extrapolate future values using different formulas.,Apptio is used by Apptio: Working Capital Fund to bill bureaus for consolidated services and help them budget for future service costs. It has the ability to extrapolate future values using different formulas.,,,False,False
USAID-0008-2023,USAID,Bureau for Global Health (GH),,Serbia: AI predictions for the utilization of hospital beds,"AI technology was used to predict bed occupancy at hospitals with MoH data from 2019, with an overall median error by department around 20%. This was a proof-of-concept model developed at the request of the Institute of Public Health (IPH) Batut to understand how AI can work and the value add. CHISU was asked to subsequently focus on a different use case (waiting list optimization for scheduled imaging diagnostics services, specifically CT and MRI), which is considered higher priority to demonstrate the implementation of the national AI strategy and the effect of AI in data use for decision making by the government, and will be addressed in the 2023-4.",Implementation,,,U.S. Agency for International Development,"Serbia: AI predictions for the utilization of hospital beds: 
AI technology was used to predict bed occupancy at hospitals with MoH data from 2019, with an overall median error by department around 20%. This was a proof-of-concept model developed at the request of the Institute of Public Health (IPH) Batut to understand how AI can work and the value add. CHISU was asked to subsequently focus on a different use case (waiting list optimization for scheduled imaging diagnostics services, specifically CT and MRI), which is considered higher priority to demonstrate the implementation of the national AI strategy and the effect of AI in data use for decision making by the government, and will be addressed in the 2023-4.","AI technology was used in Serbia to predict bed occupancy at hospitals using data from 2019, with an average error of around 20% by department. This proof-of-concept model was developed at the request of the Institute of Public Health to understand the potential of AI and its value in decision-making.","AI technology was used in Serbia to predict bed occupancy at hospitals using data from 2019, with an average error of around 20% by department. This proof-of-concept model was developed at the request of the Institute of Public Health to understand the potential of AI and its value in decision-making.",,,False,False
HHS-0110-2023,HHS,NIH,National Institutes of Health (NIH) NCI,NanCI: Connecting Scientists,"Uses AI to match scientific content to users interests. By collecting papers into a folder a user can engage the tool to find similar articles in the scientific literature, and can refine the recommendations by up or down voting of recommendations. Users can also connect with others via their interests, and receive and make recommendations via this social network.",Development and Acquisition,,,Department of Health and Human Services,"NanCI: Connecting Scientists: 
Uses AI to match scientific content to users interests. By collecting papers into a folder a user can engage the tool to find similar articles in the scientific literature, and can refine the recommendations by up or down voting of recommendations. Users can also connect with others via their interests, and receive and make recommendations via this social network.",NanCI is an AI-powered platform that connects scientists by matching scientific content to their interests. Users can collect papers into a folder and use the tool to find similar articles in the scientific literature. They can also connect with other users based on shared interests and receive or make recommendations through the platform's social network.,NanCI is an AI-powered platform that connects scientists by matching scientific content to their interests. Users can collect papers into a folder and use the tool to find similar articles in the scientific literature. They can also connect with other users based on shared interests and receive or make recommendations through the platform's social network.,,,False,False
DOC-0044-2023,DOC,United States Patent and Trade Office (USPTO),,AI retrieval for patent search,"Augmentation for next generation patent search tool to assist examiners identify relevant 
documents and additional areas to search.  System takes input from published or 
unpublished applications and provides recommendations on further prior art areas to 
search, giving the user the ability to sort by similarity to concepts of their choosing.",,,,Department of Commerce,"AI retrieval for patent search: 
Augmentation for next generation patent search tool to assist examiners identify relevant 
documents and additional areas to search.  System takes input from published or 
unpublished applications and provides recommendations on further prior art areas to 
search, giving the user the ability to sort by similarity to concepts of their choosing.",The AI retrieval for patent search is an advanced tool that aids examiners in finding relevant documents and expanding their search. It analyzes both published and unpublished applications and suggests additional areas to explore based on the user's preference for similar concepts.,The AI retrieval for patent search is an advanced tool that aids examiners in finding relevant documents and expanding their search. It analyzes both published and unpublished applications and suggests additional areas to explore based on the user's preference for similar concepts.,,,False,False
VA-0027-2023,VA,,,Prediction of biologic response to thiopurines,"Using CPRS and CDW data, artificial intelligence is used to predict biologic response to thiopurines among Veterans with irritable bowel disease.",,,,Department of Veterans Affairs,"Prediction of biologic response to thiopurines: 
Using CPRS and CDW data, artificial intelligence is used to predict biologic response to thiopurines among Veterans with irritable bowel disease.",Artificial intelligence is utilized to predict the biologic response to thiopurines in Veterans with irritable bowel disease by analyzing data from CPRS and CDW. This allows for a more accurate prediction of how individuals will respond to this treatment.,Artificial intelligence is utilized to predict the biologic response to thiopurines in Veterans with irritable bowel disease by analyzing data from CPRS and CDW. This allows for a more accurate prediction of how individuals will respond to this treatment.,,,False,False
DOC-0042-2023,DOC,National Telecommunications and Information Administration (NTIA),,Data Science: Clutter,"NTIA’s Institute for Telecommunication Sciences (ITS) is investigating the use of AI to 
automatically identify and classify clutter obstructed radio frequency propagation paths. 
Clutter is vegetation, buildings, and other structures that cause radio signal loss through 
dispersion, reflection, and diffraction. It does not include terrain effects. The classifier is a 
convolutional neural network (CNN) trained using lidar data coinciding with radio 
frequency propagation measurements made by ITS. This trained CNN can be fed new 
radio path lidar data and a clutter classification label is predicted.",,,,Department of Commerce,"Data Science: Clutter: 
NTIA’s Institute for Telecommunication Sciences (ITS) is investigating the use of AI to 
automatically identify and classify clutter obstructed radio frequency propagation paths. 
Clutter is vegetation, buildings, and other structures that cause radio signal loss through 
dispersion, reflection, and diffraction. It does not include terrain effects. The classifier is a 
convolutional neural network (CNN) trained using lidar data coinciding with radio 
frequency propagation measurements made by ITS. This trained CNN can be fed new 
radio path lidar data and a clutter classification label is predicted.","The NTIA's Institute for Telecommunication Sciences (ITS) is using AI to automatically identify and classify clutter that obstructs radio frequency propagation paths. Clutter refers to vegetation, buildings, and other structures that cause radio signal loss through dispersion, reflection, and diffraction. They have developed a convolutional neural network (CNN) that is trained using lidar data and radio frequency propagation measurements, allowing it to predict clutter classification labels when given new radio path lidar data.","The NTIA's Institute for Telecommunication Sciences (ITS) is using AI to automatically identify and classify clutter that obstructs radio frequency propagation paths. Clutter refers to vegetation, buildings, and other structures that cause radio signal loss through dispersion, reflection, and diffraction. They have developed a convolutional neural network (CNN) that is trained using lidar data and radio frequency propagation measurements, allowing it to predict clutter classification labels when given new radio path lidar data.",,,False,False
NASA-0029-2023,NASA,Marshall Space Flight Center,,"Mapping sugarcane in Thailand using transfer learning, a lightweight convolutional neural network, NICFI high resolution satellite imagery and Google Earth Engine","Uses a U-Net based architecture with MobileNetV2 based encoder with transfer learning from global model to map
the sugarcane pixels in Thailand. This uses NICFI mosaic for the training purpose.",In-use,,,National Aeronautics and Space Administration,"Mapping sugarcane in Thailand using transfer learning, a lightweight convolutional neural network, NICFI high resolution satellite imagery and Google Earth Engine: 
Uses a U-Net based architecture with MobileNetV2 based encoder with transfer learning from global model to map
the sugarcane pixels in Thailand. This uses NICFI mosaic for the training purpose.","A lightweight convolutional neural network, called U-Net, combined with transfer learning, is used to map sugarcane pixels in Thailand. The network utilizes a MobileNetV2 based encoder and is trained using NICFI high resolution satellite imagery and Google Earth Engine, specifically the NICFI mosaic.","A lightweight convolutional neural network, called U-Net, combined with transfer learning, is used to map sugarcane pixels in Thailand. The network utilizes a MobileNetV2 based encoder and is trained using NICFI high resolution satellite imagery and Google Earth Engine, specifically the NICFI mosaic.",,,False,False
HHS-0137-2023,HHS,NIH,National Institutes of Health (NIH) NLM,ClinicalTrials.gov Protocol Registration and Results System Review Assistant,This research project aims to help ClinicalTrials.gov determine whether the addition of AI could make reviewing study records more efficient and effective.,Development and Acquisition,,,Department of Health and Human Services,"ClinicalTrials.gov Protocol Registration and Results System Review Assistant: 
This research project aims to help ClinicalTrials.gov determine whether the addition of AI could make reviewing study records more efficient and effective.",The research project seeks to determine if incorporating AI into the review process of study records on ClinicalTrials.gov would improve efficiency and effectiveness. It aims to assist ClinicalTrials.gov in evaluating the potential benefits of AI integration.,The research project seeks to determine if incorporating AI into the review process of study records on ClinicalTrials.gov would improve efficiency and effectiveness. It aims to assist ClinicalTrials.gov in evaluating the potential benefits of AI integration.,,,False,False
DOI-0024-2023,DOI,USGS,,WRA.HIHR.WQP Process-guided Deep Learning for Predicting Dissolved Oxygen on Stream Networks,"The objective of this project is to build a model that predicts daily minimum, mean, and maximum stream DO levels on stream segments in the Lower Delaware River Basin using nationally available datasets.",Initiation,Random Forest Classification,,Department of Interior,"WRA.HIHR.WQP Process-guided Deep Learning for Predicting Dissolved Oxygen on Stream Networks: 
The objective of this project is to build a model that predicts daily minimum, mean, and maximum stream DO levels on stream segments in the Lower Delaware River Basin using nationally available datasets.","The aim of this project is to develop a model that can accurately forecast the daily minimum, mean, and maximum levels of dissolved oxygen in stream segments within the Lower Delaware River Basin. This will be achieved by utilizing nationally accessible datasets and implementing a process-guided deep learning approach.","The aim of this project is to develop a model that can accurately forecast the daily minimum, mean, and maximum levels of dissolved oxygen in stream segments within the Lower Delaware River Basin. This will be achieved by utilizing nationally accessible datasets and implementing a process-guided deep learning approach.",,,False,False
DOS-0015-2023,DOS,GPA,,Facebook Ad Test Optimization System,GPA’s production media collection and analysis system that pulls data from half a dozen different open and commercial media clips services to give an up-to-date global picture of media coverage around the world.,,,,Department of State,"Facebook Ad Test Optimization System: 
GPA’s production media collection and analysis system that pulls data from half a dozen different open and commercial media clips services to give an up-to-date global picture of media coverage around the world.",The Facebook Ad Test Optimization System is a media collection and analysis system developed by GPA. It gathers data from various open and commercial media clips services to provide a real-time overview of media coverage worldwide.,The Facebook Ad Test Optimization System is a media collection and analysis system developed by GPA. It gathers data from various open and commercial media clips services to provide a real-time overview of media coverage worldwide.,,,False,False
HHS-0128-2023,HHS,NIH,National Institutes of Health (NIH) NLM,MEDIQA: Biomedical Question Answering,Using and developing AI approaches to automate question answering for different users. This project leverages NLM knowledge sources and traditional and neural machine learning to address a wide-range of biomedical information needs. This project aims for improving access with one-entry access point to NLM resources.,Initiation,,,Department of Health and Human Services,"MEDIQA: Biomedical Question Answering: 
Using and developing AI approaches to automate question answering for different users. This project leverages NLM knowledge sources and traditional and neural machine learning to address a wide-range of biomedical information needs. This project aims for improving access with one-entry access point to NLM resources.","The MEDIQA project focuses on using AI techniques to automate question answering in the biomedical field. By utilizing NLM knowledge sources and traditional as well as neural machine learning, the project aims to enhance accessibility to NLM resources by providing a single-entry access point.","The MEDIQA project focuses on using AI techniques to automate question answering in the biomedical field. By utilizing NLM knowledge sources and traditional as well as neural machine learning, the project aims to enhance accessibility to NLM resources by providing a single-entry access point.",,,False,False
HHS-0095-2023,HHS,FDA,CVM,Using XGBoost Machine Learning Method to Predict Antimicrobial Resistance from WGS data,"Genomic data and artificial intelligence/machine learning (AI/ML) are used to study antimicrobial resistance (AMR) in Salmonella, E. coli, Campylobacter, and Enterococcus, isolated from retail meats, humans, and food producing animals. The Boost Machine Learning Model (XGBoost) is implemented to improve upon categorical resistance vs susceptible predictions by predicting antimicrobial Minimum Inhibitory Concentrations (MICs) from WGS data.",Development and Acquisition,,,Department of Health and Human Services,"Using XGBoost Machine Learning Method to Predict Antimicrobial Resistance from WGS data: 
Genomic data and artificial intelligence/machine learning (AI/ML) are used to study antimicrobial resistance (AMR) in Salmonella, E. coli, Campylobacter, and Enterococcus, isolated from retail meats, humans, and food producing animals. The Boost Machine Learning Model (XGBoost) is implemented to improve upon categorical resistance vs susceptible predictions by predicting antimicrobial Minimum Inhibitory Concentrations (MICs) from WGS data.","The XGBoost machine learning method is utilized to predict antimicrobial resistance in various bacteria strains such as Salmonella, E. coli, Campylobacter, and Enterococcus. This model aims to enhance predictions by predicting the antimicrobial Minimum Inhibitory Concentrations (MICs) based on genomic data obtained from retail meats, humans, and food producing animals.","The XGBoost machine learning method is utilized to predict antimicrobial resistance in various bacteria strains such as Salmonella, E. coli, Campylobacter, and Enterococcus. This model aims to enhance predictions by predicting the antimicrobial Minimum Inhibitory Concentrations (MICs) based on genomic data obtained from retail meats, humans, and food producing animals.",,,False,False
DOE-0039-2023,DOE,National Energy Technology Laboratory,,"Data discovery, processing, and generation using machine learning for a range of CCS data and information","The team will focus on supporting ongoing geospatial data collection 
and publishing efforts leveraging the new EDX++ cloud computer 
capabilities through ArcGIS Enterprise Portal. The use of Arc Enterprise 
Portal will support the development of the Carbon Matchmaker tool, as 
well as support the release of a new version of GeoCube, which will be 
host to the updated Carbon Storage Open Database and NATCARB 
completed in EY21. NETL is supporting DOE-FECM in developing and 
releasing a survey and map for the Carbon Matchmaker, a tool 
developed to enable stakeholders to self-identify carbon dioxide related 
activities (production, utilization, storage, direct air capture, and 
infrastructure/transportation) to identify and connect stakeholders and 
support national collaborative opportunities. The ArcGIS Enterprise 
Portal will be leveraged to build out a new version of GeoCube with the 
migration of hundreds of spatial data layers into the new platform. The 
migration of data to an Arc Enterprise based GeoCube will enable 
easier version control for data integration and curation.",,"Big Data, Natural Language Processing, Other",,Department of Energy,"Data discovery, processing, and generation using machine learning for a range of CCS data and information: 
The team will focus on supporting ongoing geospatial data collection 
and publishing efforts leveraging the new EDX++ cloud computer 
capabilities through ArcGIS Enterprise Portal. The use of Arc Enterprise 
Portal will support the development of the Carbon Matchmaker tool, as 
well as support the release of a new version of GeoCube, which will be 
host to the updated Carbon Storage Open Database and NATCARB 
completed in EY21. NETL is supporting DOE-FECM in developing and 
releasing a survey and map for the Carbon Matchmaker, a tool 
developed to enable stakeholders to self-identify carbon dioxide related 
activities (production, utilization, storage, direct air capture, and 
infrastructure/transportation) to identify and connect stakeholders and 
support national collaborative opportunities. The ArcGIS Enterprise 
Portal will be leveraged to build out a new version of GeoCube with the 
migration of hundreds of spatial data layers into the new platform. The 
migration of data to an Arc Enterprise based GeoCube will enable 
easier version control for data integration and curation.","The team will use machine learning to discover, process, and generate data for CCS (carbon capture and storage) efforts. They will utilize the new EDX++ cloud computer capabilities through ArcGIS Enterprise Portal to support geospatial data collection and publishing. This includes developing the Carbon Matchmaker tool and updating GeoCube with the Carbon Storage Open Database and NATCARB. The use of ArcGIS Enterprise Portal will also allow for easier version control and integration of spatial data.","The team will use machine learning to discover, process, and generate data for CCS (carbon capture and storage) efforts. They will utilize the new EDX++ cloud computer capabilities through ArcGIS Enterprise Portal to support geospatial data collection and publishing. This includes developing the Carbon Matchmaker tool and updating GeoCube with the Carbon Storage Open Database and NATCARB. The use of ArcGIS Enterprise Portal will also allow for easier version control and integration of spatial data.",,,False,False
GSA-0004-2023,GSA,FAS (QP0A),,Contract Acquisition Lifecycle Intelligence (CALI),"CALI tool is an automated machine learning evaluation tool built to streamline the evaluation of vendor proposals against the solicitation requirements to support the Source Selection process. Once the Contracting Officer (CO) has received vendor proposals for a solicitation and is ready to perform the evaluation process, the CO will initiate evaluation by sending solicitation documents along with all associated vendor proposal documents to the Source Selection module, which will pass all documents to CALI. CALI will process the documents, associated metadata and begin analyzing the proposals in four key areas: format compliance, forms validation, reps & certs compliance, and requirements compliance. The designated evaluation members can review the evaluation results in CALI and submit finalized evaluation results back to the Source Selection module.  CALI is currently being trained with sample data from the EULAs under the Multiple Award Schedule (MAS) program.",Implementation,Natural Language Processing,,U.S. General Services Administration,"Contract Acquisition Lifecycle Intelligence (CALI): 
CALI tool is an automated machine learning evaluation tool built to streamline the evaluation of vendor proposals against the solicitation requirements to support the Source Selection process. Once the Contracting Officer (CO) has received vendor proposals for a solicitation and is ready to perform the evaluation process, the CO will initiate evaluation by sending solicitation documents along with all associated vendor proposal documents to the Source Selection module, which will pass all documents to CALI. CALI will process the documents, associated metadata and begin analyzing the proposals in four key areas: format compliance, forms validation, reps & certs compliance, and requirements compliance. The designated evaluation members can review the evaluation results in CALI and submit finalized evaluation results back to the Source Selection module.  CALI is currently being trained with sample data from the EULAs under the Multiple Award Schedule (MAS) program.",The CALI tool is an automated machine learning evaluation tool used in the Source Selection process. It streamlines the evaluation of vendor proposals by analyzing documents and metadata in four key areas. It is currently being trained with sample data from the Multiple Award Schedule program.,The CALI tool is an automated machine learning evaluation tool used in the Source Selection process. It streamlines the evaluation of vendor proposals by analyzing documents and metadata in four key areas. It is currently being trained with sample data from the Multiple Award Schedule program.,,,False,False
DOE-0172-2023,DOE,Pacific Northwest National Laboratory,,Physics-Informed Learning Machines for Multiscale and Multiphysics Problems (PhILMs),"PhILMs investigators are developing physics-informed learning 
machines by encoding physics knowledge into deep learning networks",,,,Department of Energy,"Physics-Informed Learning Machines for Multiscale and Multiphysics Problems (PhILMs): 
PhILMs investigators are developing physics-informed learning 
machines by encoding physics knowledge into deep learning networks","Researchers are working on creating physics-informed learning machines, known as PhILMs, which incorporate physics knowledge into deep learning networks. This approach aims to tackle problems that involve multiple scales and multiple physics aspects.","Researchers are working on creating physics-informed learning machines, known as PhILMs, which incorporate physics knowledge into deep learning networks. This approach aims to tackle problems that involve multiple scales and multiple physics aspects.",,,False,False
DOE-0108-2023,DOE,National Energy Technology Laboratory,,To drive insights through data-driven predictive modeling to forecast the remaining lifespan and future risk of offshore production platforms.,"An Artificial Neural Network and Gradient Boosted Regression Tree 
were developed and applied to predict the remaining lifespan of 
production platforms. These big data-driven models resulted in 
predictions with scored accuracies of 95–97%.",,"Artificial Intelligence, Big Data, Neural Networks, Other",,Department of Energy,"To drive insights through data-driven predictive modeling to forecast the remaining lifespan and future risk of offshore production platforms.: 
An Artificial Neural Network and Gradient Boosted Regression Tree 
were developed and applied to predict the remaining lifespan of 
production platforms. These big data-driven models resulted in 
predictions with scored accuracies of 95–97%.",The text describes the development and application of Artificial Neural Network and Gradient Boosted Regression Tree models to predict the remaining lifespan of offshore production platforms. These data-driven models achieved high prediction accuracies of 95-97%.,The text describes the development and application of Artificial Neural Network and Gradient Boosted Regression Tree models to predict the remaining lifespan of offshore production platforms. These data-driven models achieved high prediction accuracies of 95-97%.,,,False,False
DOT-0009-2023,DOT,NextGen (ANG),,Offshore Precipitation Capability (OPC),"OPC leverages data from several sources such as weather radar, lightning networks, satellite and numerical models to produce a radar-like depiction of precipitation. The algorithm then applies machine learning techniques based on years of satellite and model data to improve the accuracy of the location and intensity of the precipitation areas.","OPC runs in a pseudo-operational capacity via a webpage maintained by the Massachusetts Institute of Technology - Lincoln Lab, as well as in a test and evaluation capacity in a research mode.","AI, ML via a Convolutional Neural Network",,Department of Transportation,"Offshore Precipitation Capability (OPC): 
OPC leverages data from several sources such as weather radar, lightning networks, satellite and numerical models to produce a radar-like depiction of precipitation. The algorithm then applies machine learning techniques based on years of satellite and model data to improve the accuracy of the location and intensity of the precipitation areas.","OPC is a system that combines data from various sources to create a radar-like view of precipitation. By utilizing machine learning techniques and historical data, OPC enhances the precision of identifying and measuring the intensity of precipitation in specific locations.","OPC is a system that combines data from various sources to create a radar-like view of precipitation. By utilizing machine learning techniques and historical data, OPC enhances the precision of identifying and measuring the intensity of precipitation in specific locations.",,,False,False
DOI-0004-2023,DOI,BOR,,Snowcast Showdown,"Reclamation partnered with Bonneville Power Administration, NASA - Goddard Space Flight Center, U.S. Army Corps of Engineers, USDA - Natural Resources Conservation Service, U.S. Geological Survey, National Center for Atmospheric Research, DrivenData, HeroX, Ensemble, and NASA Tournament Lab to run the Snowcast Showdown Prize Competition. In this competition, particiapnts were asked to develop mehtods to estimate disrributed snow information by blending observations from different sources  using machine learning methods that provide flexible and efficient algorithms for data-driven models and real-time prediction/esimation. Winning methods are now being evaluated and folded into a follow-on project with NOAA's River Forecast Centers. ",Development and Acquisition,"Range of data driven, AI/ML techniques",,Department of Interior,"Snowcast Showdown: 
Reclamation partnered with Bonneville Power Administration, NASA - Goddard Space Flight Center, U.S. Army Corps of Engineers, USDA - Natural Resources Conservation Service, U.S. Geological Survey, National Center for Atmospheric Research, DrivenData, HeroX, Ensemble, and NASA Tournament Lab to run the Snowcast Showdown Prize Competition. In this competition, particiapnts were asked to develop mehtods to estimate disrributed snow information by blending observations from different sources  using machine learning methods that provide flexible and efficient algorithms for data-driven models and real-time prediction/esimation. Winning methods are now being evaluated and folded into a follow-on project with NOAA's River Forecast Centers. ",Reclamation collaborated with various organizations to organize the Snowcast Showdown Prize Competition. The competition aimed to create efficient algorithms using machine learning methods to estimate distributed snow information by combining data from different sources. The winning methods are currently being assessed and incorporated into a future project with NOAA's River Forecast Centers.,Reclamation collaborated with various organizations to organize the Snowcast Showdown Prize Competition. The competition aimed to create efficient algorithms using machine learning methods to estimate distributed snow information by combining data from different sources. The winning methods are currently being assessed and incorporated into a future project with NOAA's River Forecast Centers.,,,False,False
HHS-0092-2023,HHS,FDA,CTP/OS/DRSI,OSCAR,"OSCAR (Office of Science Customer Assistance Response) is a chatbot with predefined intents for customers to get help from Customer Service Center. It offers a 24/7 user interface allowing users to input questions and view previous responses, as well as a dashboard offering key metrics for admin users.",Operation and Maintenance,,,Department of Health and Human Services,"OSCAR: 
OSCAR (Office of Science Customer Assistance Response) is a chatbot with predefined intents for customers to get help from Customer Service Center. It offers a 24/7 user interface allowing users to input questions and view previous responses, as well as a dashboard offering key metrics for admin users.","OSCAR is a chatbot designed to assist customers in getting help from the Customer Service Center. It provides a user-friendly interface for users to ask questions, access past responses, and offers an admin dashboard with important metrics.","OSCAR is a chatbot designed to assist customers in getting help from the Customer Service Center. It provides a user-friendly interface for users to ask questions, access past responses, and offers an admin dashboard with important metrics.",,,False,False
DOT-0005-2023,DOT,AVS,,JASC Code classification in Safety Difficulty Reports (SDR),"AVS identified a need to derive the joint aircraft system codes (JASC) chapter codes from the narrative description within service difficulty reports (SDR), a form of safety event reporting from aircraft operators. A team of graduate students at George Mason University collaborated with AVS employees to apply Natural Language Processing (NLP) and Machine Learning to predict JASC codes. This method can be used to check SDR entries to ensure the correct codes were provided or to assign a code when one was not.",,"NLP, ML Classification",,Department of Transportation,"JASC Code classification in Safety Difficulty Reports (SDR): 
AVS identified a need to derive the joint aircraft system codes (JASC) chapter codes from the narrative description within service difficulty reports (SDR), a form of safety event reporting from aircraft operators. A team of graduate students at George Mason University collaborated with AVS employees to apply Natural Language Processing (NLP) and Machine Learning to predict JASC codes. This method can be used to check SDR entries to ensure the correct codes were provided or to assign a code when one was not.",AVS and George Mason University collaborated to develop a method using Natural Language Processing and Machine Learning to predict joint aircraft system codes (JASC) chapter codes from service difficulty reports (SDR). This method can be used to verify the accuracy of codes provided in SDR entries or assign codes when none were given.,AVS and George Mason University collaborated to develop a method using Natural Language Processing and Machine Learning to predict joint aircraft system codes (JASC) chapter codes from service difficulty reports (SDR). This method can be used to verify the accuracy of codes provided in SDR entries or assign codes when none were given.,,,False,False
DHS-0026-2023,DHS,"HQ, Customs and Border Protection, Cybersecurity and Infrastructure Security Agency, Countering Weapons of Mass Destruction, Immigration and Customs Enforcement, Intelligence and Analysis, Science and Technology",,RelativityOne,"RelativityOne is a document review platform used to gain efficiencies in document review in litigation, FOIA, and other arenas where large-scale document review and production is necessary.",Operation and Maintenance,"Machine learning, Continuous Active Learning, Clustering",,Department of Homeland Security,"RelativityOne: 
RelativityOne is a document review platform used to gain efficiencies in document review in litigation, FOIA, and other arenas where large-scale document review and production is necessary.",RelativityOne is a document review platform designed for efficient and large-scale document review and production in arenas like litigation and FOIA. It helps organizations streamline their review processes and improve productivity in handling vast amounts of documents.,RelativityOne is a document review platform designed for efficient and large-scale document review and production in arenas like litigation and FOIA. It helps organizations streamline their review processes and improve productivity in handling vast amounts of documents.,,,False,False
HHS-0127-2023,HHS,NIH,National Institutes of Health (NIH) NLM,CylanceProtect,Protection of Windows and Mac endpoints from Cyberthreats,Operation and Maintenance,,,Department of Health and Human Services,"CylanceProtect: 
Protection of Windows and Mac endpoints from Cyberthreats",CylanceProtect is a software that offers protection for Windows and Mac endpoints against cyberthreats. It safeguards these devices from potential security breaches and ensures their safety from malicious attacks.,CylanceProtect is a software that offers protection for Windows and Mac endpoints against cyberthreats. It safeguards these devices from potential security breaches and ensures their safety from malicious attacks.,,,False,False
DOE-0068-2023,DOE,National Energy Technology Laboratory,,Solving Field Equations on the Wafer Scale Engine,"The intent is to develop a collocated, finite volume code to allow 
maximum mesh flexibility and support advanced CFD capabilities found 
in modern CFD codes like Fluent, OpenFOAM, and MFiX.
NETL will take a metered approach to development towards a fully 
reacting CFD capability on the WSE. EY22 will be filled with API 
capability expansions needed to support general purpose CFD 
applications, such as general purpose finite volume formulations, 
collocated grid capabilities (Rhie & Chow Interpolation), bit stuffing to 
save memory when dealing with cell types, general purpose boundary 
conditions, etc. In addition, the code will be benchmarked in a series of 
tests towards a fully reacting CFD capability that will support problems 
of interest to FECM.",,"Big Data, Other",,Department of Energy,"Solving Field Equations on the Wafer Scale Engine: 
The intent is to develop a collocated, finite volume code to allow 
maximum mesh flexibility and support advanced CFD capabilities found 
in modern CFD codes like Fluent, OpenFOAM, and MFiX.
NETL will take a metered approach to development towards a fully 
reacting CFD capability on the WSE. EY22 will be filled with API 
capability expansions needed to support general purpose CFD 
applications, such as general purpose finite volume formulations, 
collocated grid capabilities (Rhie & Chow Interpolation), bit stuffing to 
save memory when dealing with cell types, general purpose boundary 
conditions, etc. In addition, the code will be benchmarked in a series of 
tests towards a fully reacting CFD capability that will support problems 
of interest to FECM.","The goal is to create a code that can solve field equations on the Wafer Scale Engine (WSE) by developing a collocated, finite volume code with maximum mesh flexibility and advanced CFD capabilities. The code will be expanded with API capabilities to support general purpose CFD applications and will be benchmarked in tests to support problems of interest to FECM.","The goal is to create a code that can solve field equations on the Wafer Scale Engine (WSE) by developing a collocated, finite volume code with maximum mesh flexibility and advanced CFD capabilities. The code will be expanded with API capabilities to support general purpose CFD applications and will be benchmarked in tests to support problems of interest to FECM.",,,False,False
VA-0038-2023,VA,,,Screening for esophageal adenocarcinoma,National VHA administrative data is used to adapt tools that use electronic health records to predict the risk for esophageal adenocarcinoma.,,,,Department of Veterans Affairs,"Screening for esophageal adenocarcinoma: 
National VHA administrative data is used to adapt tools that use electronic health records to predict the risk for esophageal adenocarcinoma.",National VHA administrative data is utilized to modify tools that utilize electronic health records in order to forecast the likelihood of esophageal adenocarcinoma.,National VHA administrative data is utilized to modify tools that utilize electronic health records in order to forecast the likelihood of esophageal adenocarcinoma.,,,False,False
USDA-0018-2023,USDA,USDA,Forest Service,Ecosystem Management Decision Support System (EMDS),"EMDS is a spatial decision support system for landscape analysis and planning that runs as a component of ArcGIS and QGIS. Users develop applications for their specific problem that may use any combination of four AI engines for 1) logic processing, 2) multi-criteria decision analysis, 3) Bayesian networks, and Prolog-based decision trees.",Operation and Management,Machine Learning,,Department of Agriculture,"Ecosystem Management Decision Support System (EMDS): 
EMDS is a spatial decision support system for landscape analysis and planning that runs as a component of ArcGIS and QGIS. Users develop applications for their specific problem that may use any combination of four AI engines for 1) logic processing, 2) multi-criteria decision analysis, 3) Bayesian networks, and Prolog-based decision trees.","The Ecosystem Management Decision Support System (EMDS) is a tool for landscape analysis and planning. It is integrated with ArcGIS and QGIS and allows users to create applications tailored to their specific needs. These applications can utilize four AI engines for various purposes, such as logic processing, multi-criteria decision analysis, Bayesian networks, and Prolog-based decision trees.","The Ecosystem Management Decision Support System (EMDS) is a tool for landscape analysis and planning. It is integrated with ArcGIS and QGIS and allows users to create applications tailored to their specific needs. These applications can utilize four AI engines for various purposes, such as logic processing, multi-criteria decision analysis, Bayesian networks, and Prolog-based decision trees.",,,False,False
HHS-0054-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Medicaid And CHIP Financial (MACFin) Anomaly Detection Model for DSH Audit,"MACFin AI team developed machine learning model to predict anomalies within DSH audit data. The model flags top outliers in the submitted DSH hospitals data in terms of extreme behavior in the data based on amounts and other characteristics of the data to isolate the most outliers in the data. For example, out of all DSH allocations, the model can identify the top 1-5% outliers in the data for further review and auditing. Such model facilitates targeted investigations for gaps and barriers. In addition, the model can support the process by minimizing overpayment and/or underpayment and amounts redistribution",Initiation,,,Department of Health and Human Services,"Medicaid And CHIP Financial (MACFin) Anomaly Detection Model for DSH Audit: 
MACFin AI team developed machine learning model to predict anomalies within DSH audit data. The model flags top outliers in the submitted DSH hospitals data in terms of extreme behavior in the data based on amounts and other characteristics of the data to isolate the most outliers in the data. For example, out of all DSH allocations, the model can identify the top 1-5% outliers in the data for further review and auditing. Such model facilitates targeted investigations for gaps and barriers. In addition, the model can support the process by minimizing overpayment and/or underpayment and amounts redistribution","The MACFin AI team created a machine learning model that predicts anomalies in DSH audit data. The model identifies the top outliers in the data, allowing for targeted investigations and minimizing overpayment or underpayment. This helps ensure accurate amounts redistribution.","The MACFin AI team created a machine learning model that predicts anomalies in DSH audit data. The model identifies the top outliers in the data, allowing for targeted investigations and minimizing overpayment or underpayment. This helps ensure accurate amounts redistribution.",,,False,False
DOE-0081-2023,DOE,National Energy Technology Laboratory,,To create and apply machine learning algorithms to predict carbon dioxide enhanced oil revoery improvements with rich gas in the Bell Creek Field and other selected fields.,"Create models with ML algorithms to predict CO2 EOR improvements 
with rich gas in the Bell Creek Field and other selected fields. The 
results of these models will be compared with the predictions of CMG’s 
reservoir simulations models.",,Artificial Intelligence Unknown,,Department of Energy,"To create and apply machine learning algorithms to predict carbon dioxide enhanced oil revoery improvements with rich gas in the Bell Creek Field and other selected fields.: 
Create models with ML algorithms to predict CO2 EOR improvements 
with rich gas in the Bell Creek Field and other selected fields. The 
results of these models will be compared with the predictions of CMG’s 
reservoir simulations models.",The goal is to use machine learning algorithms to predict improvements in carbon dioxide enhanced oil recovery (EOR) using rich gas in the Bell Creek Field and other chosen fields. The predictions made by these algorithms will be compared with the predictions from CMG's reservoir simulation models.,The goal is to use machine learning algorithms to predict improvements in carbon dioxide enhanced oil recovery (EOR) using rich gas in the Bell Creek Field and other chosen fields. The predictions made by these algorithms will be compared with the predictions from CMG's reservoir simulation models.,,,False,False
DOC-0046-2023,DOC,United States Patent and Trade Office (USPTO),,AI retrieval for TM design coding and Image search,"Clarivate COTS solution to assist examiner identification of similar trademark images, to 
suggest the correct assignment of mark image design codes, and to determine the 
potential acceptability of the identifications of goods and services.  System is anticipated 
to use both incoming trademark images and registered trademark images and output 
design codes and/or other related images.",,,,Department of Commerce,"AI retrieval for TM design coding and Image search: 
Clarivate COTS solution to assist examiner identification of similar trademark images, to 
suggest the correct assignment of mark image design codes, and to determine the 
potential acceptability of the identifications of goods and services.  System is anticipated 
to use both incoming trademark images and registered trademark images and output 
design codes and/or other related images.","Clarivate has developed an AI retrieval system that helps trademark examiners identify similar trademark images, assign appropriate design codes, and evaluate the acceptability of goods and services. The system utilizes both incoming and registered trademark images to generate design codes and related images as output.","Clarivate has developed an AI retrieval system that helps trademark examiners identify similar trademark images, assign appropriate design codes, and evaluate the acceptability of goods and services. The system utilizes both incoming and registered trademark images to generate design codes and related images as output.",,,False,False
DOS-0013-2023,DOS,F,,NLP for Foreign Assistance Appropriations Analysis,Natural language processing application for F/RA to streamline the extraction of earmarks and directives from the annual appropriations bill. Before NLP this was an entirely manual process.,,,,Department of State,"NLP for Foreign Assistance Appropriations Analysis: 
Natural language processing application for F/RA to streamline the extraction of earmarks and directives from the annual appropriations bill. Before NLP this was an entirely manual process.","The use of natural language processing (NLP) allows for the automation of earmark and directive extraction from the annual appropriations bill in Foreign Assistance Appropriations (F/RA) analysis. This eliminates the need for manual processing, making the task more efficient and streamlined.","The use of natural language processing (NLP) allows for the automation of earmark and directive extraction from the annual appropriations bill in Foreign Assistance Appropriations (F/RA) analysis. This eliminates the need for manual processing, making the task more efficient and streamlined.",,,False,False
DOC-0002-2023,DOC,International Trade Administration (ITA),,Consolidated Screening List,"The Consolidated Screening List (CSL) is a list of parties for which the United States 
Government maintains restrictions on certain exports, reexports, or transfers of items. It 
consists of the consolidation of 13 export screening lists of the Departments of 
Commerce, State, and Treasury.  The CSL search engine has “Fuzzy Name Search” 
capabilities, allowing a search without knowing the exact spelling of an entity’s name. In 
Fuzzy Name mode, the CSL returns a “score” for results that exactly or nearly match the 
searched name. This is particularly helpful when searching on CSL for names that have 
been translated into English from non-Latin alphabet languages.",,,,Department of Commerce,"Consolidated Screening List: 
The Consolidated Screening List (CSL) is a list of parties for which the United States 
Government maintains restrictions on certain exports, reexports, or transfers of items. It 
consists of the consolidation of 13 export screening lists of the Departments of 
Commerce, State, and Treasury.  The CSL search engine has “Fuzzy Name Search” 
capabilities, allowing a search without knowing the exact spelling of an entity’s name. In 
Fuzzy Name mode, the CSL returns a “score” for results that exactly or nearly match the 
searched name. This is particularly helpful when searching on CSL for names that have 
been translated into English from non-Latin alphabet languages.","The Consolidated Screening List is a compilation of 13 different export screening lists maintained by the US Government. It restricts certain exports, reexports, or transfers of items to parties on the list. The CSL search engine has a ""Fuzzy Name Search"" feature that allows users to search for entities without knowing the exact spelling of their name, which is useful for names translated into English from non-Latin alphabet languages.","The Consolidated Screening List is a compilation of 13 different export screening lists maintained by the US Government. It restricts certain exports, reexports, or transfers of items to parties on the list. The CSL search engine has a ""Fuzzy Name Search"" feature that allows users to search for entities without knowing the exact spelling of their name, which is useful for names translated into English from non-Latin alphabet languages.",,,False,False
DOE-0018-2023,DOE,Idaho National Laboratory,,Geo Threat Observable for structure cyber threat related to the energy sector,"Collection of open source threat inforamtion related to cyber issues in 
the energy sector, collected stored in graphdb and used in machine 
learning for similarities of threat enabling better reuse of cyber 
protections.",,,,Department of Energy,"Geo Threat Observable for structure cyber threat related to the energy sector: 
Collection of open source threat inforamtion related to cyber issues in 
the energy sector, collected stored in graphdb and used in machine 
learning for similarities of threat enabling better reuse of cyber 
protections.","The Geo Threat Observable is a collection of open source threat information specifically focused on cyber issues in the energy sector. This data is stored in a graph database and utilized in machine learning to identify similarities in threats, improving the effectiveness of cyber protections in the industry.","The Geo Threat Observable is a collection of open source threat information specifically focused on cyber issues in the energy sector. This data is stored in a graph database and utilized in machine learning to identify similarities in threats, improving the effectiveness of cyber protections in the industry.",,,False,False
DOC-0039-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Replacing unstructured WW3 in the Great Lakes with a Recurrent neural network and a boosted ensemble decision tree,"Investigated replacing unstructured WW3 in the Great Lakes with (i) a Recurrent Neural 
Network (RNN, especially an LSTM) developed by EMC and (ii) a boosted ensemble 
decision tree (XGBoost) developed by GLERL. These two AI models were trained on two 
decades of wave observations in Lake Erie and compared to the operational Great Lakes 
unstructured WW3.",,,,Department of Commerce,"Replacing unstructured WW3 in the Great Lakes with a Recurrent neural network and a boosted ensemble decision tree: 
Investigated replacing unstructured WW3 in the Great Lakes with (i) a Recurrent Neural 
Network (RNN, especially an LSTM) developed by EMC and (ii) a boosted ensemble 
decision tree (XGBoost) developed by GLERL. These two AI models were trained on two 
decades of wave observations in Lake Erie and compared to the operational Great Lakes 
unstructured WW3.","The possibility of replacing unstructured WW3 in the Great Lakes with a Recurrent Neural Network (RNN) and a boosted ensemble decision tree (XGBoost) was investigated. The RNN, specifically an LSTM developed by EMC, and the XGBoost developed by GLERL were trained on two decades of wave observations in Lake Erie. The performance of these AI models was then compared to the operational unstructured WW3 in the Great Lakes.","The possibility of replacing unstructured WW3 in the Great Lakes with a Recurrent Neural Network (RNN) and a boosted ensemble decision tree (XGBoost) was investigated. The RNN, specifically an LSTM developed by EMC, and the XGBoost developed by GLERL were trained on two decades of wave observations in Lake Erie. The performance of these AI models was then compared to the operational unstructured WW3 in the Great Lakes.",,,False,False
DOE-0017-2023,DOE,Idaho National Laboratory,,Deep Learning Malware Analysis for reusable cyber defenses.,"The INL uses machine learning (feed forward neural network) on a large 
data set of translated malware binaries in graph structures to identify 
commonality between malware.",,,,Department of Energy,"Deep Learning Malware Analysis for reusable cyber defenses.: 
The INL uses machine learning (feed forward neural network) on a large 
data set of translated malware binaries in graph structures to identify 
commonality between malware.","The INL utilizes a feed forward neural network to apply deep learning techniques on a vast dataset of translated malware binaries represented in graph structures. This approach enables the identification of shared characteristics among malware, facilitating the development of reusable cyber defenses.","The INL utilizes a feed forward neural network to apply deep learning techniques on a vast dataset of translated malware binaries represented in graph structures. This approach enables the identification of shared characteristics among malware, facilitating the development of reusable cyber defenses.",,,False,False
HHS-0028-2023,HHS,CDC,NCCDPHP/DNPAO,Identify infrastructure supports for physical activity (e.g. sidewalks) in satellite and roadway images,"The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is interested in developing and promoting machine learning techniques to identify sidewalks, bicycle lanes, and other infrastructure in images, both satellite and roadway images. The inputs would include image-based data. The outputs could be geocoded data tables, maps, GIS layers, or summary reports. ",Initiation,,,Department of Health and Human Services,"Identify infrastructure supports for physical activity (e.g. sidewalks) in satellite and roadway images: 
The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is interested in developing and promoting machine learning techniques to identify sidewalks, bicycle lanes, and other infrastructure in images, both satellite and roadway images. The inputs would include image-based data. The outputs could be geocoded data tables, maps, GIS layers, or summary reports. ","The Division of Nutrition, Physical Activity, and Obesity wants to use machine learning to identify sidewalks, bicycle lanes, and other infrastructure in satellite and roadway images. They will use image-based data as input and produce geocoded data tables, maps, GIS layers, or summary reports as output.","The Division of Nutrition, Physical Activity, and Obesity wants to use machine learning to identify sidewalks, bicycle lanes, and other infrastructure in satellite and roadway images. They will use image-based data as input and produce geocoded data tables, maps, GIS layers, or summary reports as output.",,,False,False
HHS-0098-2023,HHS,FDA,NCTR,Identify sex disparities in opioid drug safety signals in FDA adverse events report systems (FAERS) and social media Twitter to improve women health,"This proposal aims to address OWH 2023 Priority Area: Use of real world data and evidence to inform regulatory processes.

We propose to analyze sex differences in adverse events for opioid drugs in social media (Twitter) and the FDA Adverse Events Report Systems (FAERS). We will compare sex disparities identified from FAERS and Twitter to assess whether Twitter data can be used as an early warning system to signal the opioid-related issues specific to women. The identified sex disparities in adverse events for opioid drugs from this project could help improve women health.",Initiation,,,Department of Health and Human Services,"Identify sex disparities in opioid drug safety signals in FDA adverse events report systems (FAERS) and social media Twitter to improve women health: 
This proposal aims to address OWH 2023 Priority Area: Use of real world data and evidence to inform regulatory processes.

We propose to analyze sex differences in adverse events for opioid drugs in social media (Twitter) and the FDA Adverse Events Report Systems (FAERS). We will compare sex disparities identified from FAERS and Twitter to assess whether Twitter data can be used as an early warning system to signal the opioid-related issues specific to women. The identified sex disparities in adverse events for opioid drugs from this project could help improve women health.","This proposal seeks to analyze sex disparities in adverse events related to opioid drugs using data from social media (Twitter) and the FDA Adverse Events Report Systems (FAERS). By comparing the findings from both sources, the study aims to determine if Twitter data can serve as an early warning system for identifying opioid-related issues specific to women. The results of this project have the potential to contribute to improving women's health.","This proposal seeks to analyze sex disparities in adverse events related to opioid drugs using data from social media (Twitter) and the FDA Adverse Events Report Systems (FAERS). By comparing the findings from both sources, the study aims to determine if Twitter data can serve as an early warning system for identifying opioid-related issues specific to women. The results of this project have the potential to contribute to improving women's health.",,,False,False
USAID-0007-2023,USAID,Bureau for Global Health (GH),,Breakthrough RESEARCH’s Social Media Listening,"Social media listening draws on machine learning to synthesize and organize the vast quantities of data shared over social media platforms. Breakthrough RESEARCH carried out social listening on 12,301 social media posts in Nigeria to explore how gender-related online conversations manifest themselves and whether they have changed in the last five years. Using Crimson Hexagon’s machine learning algorithm, “Brightview,” publicly available social media content originating in the countries of interest was scraped by the algorithm, for posts relevant to RH/FP and youth. The resulting social media posts were then classified by topic, using language detected in the content. This provided a dataset categorizing conversations into overarching topics, allowing analyses to uncover key trends in topic specific conversation volume, insights about misinformation, attitudes and social norms, and more. The machine learning algorithm was able to identify relevant social media content. The 12,301 social media posts were qualitatively assessed and categorized, allowing researchers to monitor and track social media conversations far more expansively than allowed by research methods more traditionally used in public health and SBC programs.",Operation and Maintenance,,,U.S. Agency for International Development,"Breakthrough RESEARCH’s Social Media Listening: 
Social media listening draws on machine learning to synthesize and organize the vast quantities of data shared over social media platforms. Breakthrough RESEARCH carried out social listening on 12,301 social media posts in Nigeria to explore how gender-related online conversations manifest themselves and whether they have changed in the last five years. Using Crimson Hexagon’s machine learning algorithm, “Brightview,” publicly available social media content originating in the countries of interest was scraped by the algorithm, for posts relevant to RH/FP and youth. The resulting social media posts were then classified by topic, using language detected in the content. This provided a dataset categorizing conversations into overarching topics, allowing analyses to uncover key trends in topic specific conversation volume, insights about misinformation, attitudes and social norms, and more. The machine learning algorithm was able to identify relevant social media content. The 12,301 social media posts were qualitatively assessed and categorized, allowing researchers to monitor and track social media conversations far more expansively than allowed by research methods more traditionally used in public health and SBC programs.","Breakthrough RESEARCH conducted social media listening in Nigeria, analyzing 12,301 social media posts to examine gender-related online conversations over the past five years. By using Crimson Hexagon's machine learning algorithm, the posts were categorized by topic, allowing researchers to uncover trends, misinformation, attitudes, and social norms. This method provided a more comprehensive way to monitor and track social media conversations compared to traditional research methods in public health and SBC programs.","Breakthrough RESEARCH conducted social media listening in Nigeria, analyzing 12,301 social media posts to examine gender-related online conversations over the past five years. By using Crimson Hexagon's machine learning algorithm, the posts were categorized by topic, allowing researchers to uncover trends, misinformation, attitudes, and social norms. This method provided a more comprehensive way to monitor and track social media conversations compared to traditional research methods in public health and SBC programs.",,,False,False
DHS-0028-2023,DHS,Immigration and Customs Enforcement,,Machine Translation (Previously Language Translator),"Systran provides machine translation for over 100 different language combinations.  Currently the Innovation Lab has licenses for translating Chinese, Spanish, Arabic, Farsi, Russian, German, Ukrainian and Filipino to English.  Systran can translate plain text, word documents, and PDFS.  A web-based UI and API endpoint are available.",Operation and Maintenance,"Machine Learning, Natural Language Processing (NLP)",,Department of Homeland Security,"Machine Translation (Previously Language Translator): 
Systran provides machine translation for over 100 different language combinations.  Currently the Innovation Lab has licenses for translating Chinese, Spanish, Arabic, Farsi, Russian, German, Ukrainian and Filipino to English.  Systran can translate plain text, word documents, and PDFS.  A web-based UI and API endpoint are available.","Systran offers machine translation for more than 100 different language combinations, including Chinese, Spanish, Arabic, Farsi, Russian, German, Ukrainian, and Filipino to English. It can translate plain text, word documents, and PDFs, and provides a web-based user interface and API endpoint.","Systran offers machine translation for more than 100 different language combinations, including Chinese, Spanish, Arabic, Farsi, Russian, German, Ukrainian, and Filipino to English. It can translate plain text, word documents, and PDFs, and provides a web-based user interface and API endpoint.",,,False,False
VA-0022-2023,VA,,,Gait signatures in patients with peripheral artery disease,Machine learning is used to improve treatment of functional problems in patients with peripheral artery disease (PAD). Previously collected biomechanics data is used to identify representative gait signatures of PAD to 1) determine the gait signatures of patients with PAD and 2) the ability of limb acceleration measurements to identify and model the meaningful biomechanics measures from PAD data.,,,,Department of Veterans Affairs,"Gait signatures in patients with peripheral artery disease: 
Machine learning is used to improve treatment of functional problems in patients with peripheral artery disease (PAD). Previously collected biomechanics data is used to identify representative gait signatures of PAD to 1) determine the gait signatures of patients with PAD and 2) the ability of limb acceleration measurements to identify and model the meaningful biomechanics measures from PAD data.","Machine learning is being utilized to enhance the treatment of functional issues in patients with peripheral artery disease. By analyzing previously collected biomechanics data, researchers are able to identify characteristic gait signatures of PAD and assess the effectiveness of limb acceleration measurements in modeling important biomechanical measures from this data.","Machine learning is being utilized to enhance the treatment of functional issues in patients with peripheral artery disease. By analyzing previously collected biomechanics data, researchers are able to identify characteristic gait signatures of PAD and assess the effectiveness of limb acceleration measurements in modeling important biomechanical measures from this data.",,,False,False
HHS-0154-2023,HHS,NIH,National Institutes of Health (NIH) OD/ORF,Natural Language Processing Tool for Open Text Analysis,This project will improve facility readiness and reduce downtime by allowing other software to analyze data that was locked away in open text.,Development and Acquisition,,,Department of Health and Human Services,"Natural Language Processing Tool for Open Text Analysis: 
This project will improve facility readiness and reduce downtime by allowing other software to analyze data that was locked away in open text.","This project aims to enhance facility readiness and minimize downtime by enabling software to analyze previously inaccessible data stored in open text. With the help of a Natural Language Processing tool, valuable insights can be extracted from this data, improving overall operational efficiency.","This project aims to enhance facility readiness and minimize downtime by enabling software to analyze previously inaccessible data stored in open text. With the help of a Natural Language Processing tool, valuable insights can be extracted from this data, improving overall operational efficiency.",,,False,False
USDA-0024-2023,USDA,USDA,Forest Service,Geospatial and Remote Sensing Training Courses,"Several courses are offered which teach the use of software and scripting which allow for machine learning.  The courses change, but current topics include Intro and Advanced Change Detection, eCognition (software package), Geospatial Scripting for Google Earth Engine.  Some of the courses show how to use Collect Earth Online.",Operation and Management,Machine Learning,,Department of Agriculture,"Geospatial and Remote Sensing Training Courses: 
Several courses are offered which teach the use of software and scripting which allow for machine learning.  The courses change, but current topics include Intro and Advanced Change Detection, eCognition (software package), Geospatial Scripting for Google Earth Engine.  Some of the courses show how to use Collect Earth Online.","There are various geospatial and remote sensing training courses available that focus on teaching software and scripting techniques for machine learning. These courses cover a range of topics such as change detection, using software packages like eCognition, geospatial scripting for Google Earth Engine, and utilizing Collect Earth Online.","There are various geospatial and remote sensing training courses available that focus on teaching software and scripting techniques for machine learning. These courses cover a range of topics such as change detection, using software packages like eCognition, geospatial scripting for Google Earth Engine, and utilizing Collect Earth Online.",,,False,False
NASA-0023-2023,NASA,Marshall Space Flight Center,,Automatic Detection of Impervious Surfaces from Remotely Sensed Data Using Deep Learning,"Uses a U-Net based architecture with VGG-19 as an encoder block and custom decoder block to map the impervious
surfaces using Landsat and OSM data patches",In-use,,,National Aeronautics and Space Administration,"Automatic Detection of Impervious Surfaces from Remotely Sensed Data Using Deep Learning: 
Uses a U-Net based architecture with VGG-19 as an encoder block and custom decoder block to map the impervious
surfaces using Landsat and OSM data patches","The study proposes a method for automatically detecting impervious surfaces using remotely sensed data. It utilizes a U-Net based architecture, with VGG-19 as an encoder block and a custom decoder block, to accurately map impervious surfaces by analyzing Landsat and OSM data patches.","The study proposes a method for automatically detecting impervious surfaces using remotely sensed data. It utilizes a U-Net based architecture, with VGG-19 as an encoder block and a custom decoder block, to accurately map impervious surfaces by analyzing Landsat and OSM data patches.",,,False,False
VA-0034-2023,VA,,,GI Genius (Medtronic),The Medtronic GI Genius aids in detection of colon polyps through artificial intelligence.,,,,Department of Veterans Affairs,"GI Genius (Medtronic): 
The Medtronic GI Genius aids in detection of colon polyps through artificial intelligence.","The GI Genius, developed by Medtronic, is an artificial intelligence tool that helps in identifying colon polyps. It uses advanced technology to enhance the detection process and improve accuracy.","The GI Genius, developed by Medtronic, is an artificial intelligence tool that helps in identifying colon polyps. It uses advanced technology to enhance the detection process and improve accuracy.",,,False,False
DOC-0025-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,First Guess Excessive Rainfall Outlook,"Machine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is 
learned from the ERO with atmospheric variables. It is for the Day 1, 2, 3 products",,,,Department of Commerce,"First Guess Excessive Rainfall Outlook: 
Machine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is 
learned from the ERO with atmospheric variables. It is for the Day 1, 2, 3 products","The First Guess Excessive Rainfall Outlook is a machine learning product used by the WPC to predict excessive rainfall. It is based on atmospheric variables and provides outlooks for the Day 1, 2, and 3 periods.","The First Guess Excessive Rainfall Outlook is a machine learning product used by the WPC to predict excessive rainfall. It is based on atmospheric variables and provides outlooks for the Day 1, 2, and 3 periods.",,,False,False
DOE-0064-2023,DOE,National Energy Technology Laboratory,,Online real time system Identification,"Work will focus on using SI to monitor the condition of a power plant 
boiler at different process states. SI algorithms will be implemented 
within an MPC to provide continuous adaptability as the power plant 
ramps through the entire range of operating loads. Once the control 
algorithm has been developed to be effective on representative models, 
it will be tested on a high-fidelity commercial power plant simulator or on 
a real power plant facility. The online SI techniques will be tested on 
historical power plant data, dynamic models (including a power plant 
simulator), power generating equipment including laboratory pilot-scale 
power systems, and on power plants where feasible.",,"Artificial Intelligence, Big Data, Other",,Department of Energy,"Online real time system Identification: 
Work will focus on using SI to monitor the condition of a power plant 
boiler at different process states. SI algorithms will be implemented 
within an MPC to provide continuous adaptability as the power plant 
ramps through the entire range of operating loads. Once the control 
algorithm has been developed to be effective on representative models, 
it will be tested on a high-fidelity commercial power plant simulator or on 
a real power plant facility. The online SI techniques will be tested on 
historical power plant data, dynamic models (including a power plant 
simulator), power generating equipment including laboratory pilot-scale 
power systems, and on power plants where feasible.","The focus of this project is to use online system identification (SI) to monitor the condition of a power plant boiler during different process states. SI algorithms will be integrated into a Model Predictive Control (MPC) system to ensure continuous adaptability as the power plant operates at various loads. The effectiveness of the control algorithm will be tested on representative models and either a high-fidelity commercial power plant simulator or a real power plant facility. Additionally, the online SI techniques will be tested on historical power plant data, dynamic models, laboratory pilot-scale power systems, and feasible power plants.","The focus of this project is to use online system identification (SI) to monitor the condition of a power plant boiler during different process states. SI algorithms will be integrated into a Model Predictive Control (MPC) system to ensure continuous adaptability as the power plant operates at various loads. The effectiveness of the control algorithm will be tested on representative models and either a high-fidelity commercial power plant simulator or a real power plant facility. Additionally, the online SI techniques will be tested on historical power plant data, dynamic models, laboratory pilot-scale power systems, and feasible power plants.",,,False,False
DOE-0077-2023,DOE,National Energy Technology Laboratory,,To automate development of proxy models for power generation combustion systems.,"Detailed CFD of large combustion systems will be performed.   From 
the results, machine learning will be used to develop fast proxy models 
which can will provide results close to the CFD results, but in a small 
fraction of the time.   These fast models will then be used in real-time 
digital twin models of the power plant, which can be used to help the 
power plant operator to spot instrumentation failures or cyberattacks on 
the plant.",,Other,,Department of Energy,"To automate development of proxy models for power generation combustion systems.: 
Detailed CFD of large combustion systems will be performed.   From 
the results, machine learning will be used to develop fast proxy models 
which can will provide results close to the CFD results, but in a small 
fraction of the time.   These fast models will then be used in real-time 
digital twin models of the power plant, which can be used to help the 
power plant operator to spot instrumentation failures or cyberattacks on 
the plant.",This text describes a process of automating the development of proxy models for power generation combustion systems. It involves conducting detailed computational fluid dynamics (CFD) analysis of large combustion systems and using the results to create machine learning-based proxy models that can provide similar results in a shorter amount of time. These proxy models will be integrated into real-time digital twin models of power plants to assist operators in identifying instrumentation failures or cyberattacks.,This text describes a process of automating the development of proxy models for power generation combustion systems. It involves conducting detailed computational fluid dynamics (CFD) analysis of large combustion systems and using the results to create machine learning-based proxy models that can provide similar results in a shorter amount of time. These proxy models will be integrated into real-time digital twin models of power plants to assist operators in identifying instrumentation failures or cyberattacks.,,,False,False
HHS-0076-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Using Unsupervised Learning to Generate Code Mapping Algorithms to Harmonize Data Across Data Systems,The goal of this project is to assess the potential of data��driven statistical methods for detecting and reducing coding differences between healthcare systems in Sentinel. Findings will inform development and deployment of methods and computational tools for transferring knowledge learned from one site to another and pave the way towards scalable and automated harmonization of electronic health records data.,Implementation,,,Department of Health and Human Services,"Using Unsupervised Learning to Generate Code Mapping Algorithms to Harmonize Data Across Data Systems: 
The goal of this project is to assess the potential of data��driven statistical methods for detecting and reducing coding differences between healthcare systems in Sentinel. Findings will inform development and deployment of methods and computational tools for transferring knowledge learned from one site to another and pave the way towards scalable and automated harmonization of electronic health records data.","This project aims to evaluate the effectiveness of unsupervised learning in identifying and minimizing coding differences in healthcare systems. The findings will be used to create computational tools that can transfer knowledge between different sites, enabling automated harmonization of electronic health records data.","This project aims to evaluate the effectiveness of unsupervised learning in identifying and minimizing coding differences in healthcare systems. The findings will be used to create computational tools that can transfer knowledge between different sites, enabling automated harmonization of electronic health records data.",,,False,False
DOE-0011-2023,DOE,Fermi National Accelerator,,Next-Generation Beam Cooling and Control with Optical Stochastic Cooling,"This program leverages the physics and technology of optical stochastic 
cooling (OSC) to explore new possibilities in beam control and sensing.  
The planned architecture and performance of a new OSC system at 
IOTA should enable turn-by-turn programmability of the high-gain OSC.  
This capability can then be used in conjunction with other hardware 
systems as the basis of an action space for reinforcement learning (RL) 
methods.  The program aims to establish a new state of the art in beam 
cooling and a flexible set of tools for beam control and sensing at 
colliders and other accelerator facilities.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"Next-Generation Beam Cooling and Control with Optical Stochastic Cooling: 
This program leverages the physics and technology of optical stochastic 
cooling (OSC) to explore new possibilities in beam control and sensing.  
The planned architecture and performance of a new OSC system at 
IOTA should enable turn-by-turn programmability of the high-gain OSC.  
This capability can then be used in conjunction with other hardware 
systems as the basis of an action space for reinforcement learning (RL) 
methods.  The program aims to establish a new state of the art in beam 
cooling and a flexible set of tools for beam control and sensing at 
colliders and other accelerator facilities.","The program aims to use optical stochastic cooling (OSC) to improve beam control and sensing in colliders and accelerator facilities. By implementing a new OSC system at IOTA, the program plans to achieve turn-by-turn programmability and establish a new standard in beam cooling. This will provide a flexible set of tools for reinforcement learning methods and enhance overall beam control capabilities.","The program aims to use optical stochastic cooling (OSC) to improve beam control and sensing in colliders and accelerator facilities. By implementing a new OSC system at IOTA, the program plans to achieve turn-by-turn programmability and establish a new standard in beam cooling. This will provide a flexible set of tools for reinforcement learning methods and enhance overall beam control capabilities.",,,False,False
DOE-0032-2023,DOE,National Energy Technology Laboratory,,"AI/ML may be needed to extract data from text, image and tabular- based resources. NEWTS is partnering with university teams to use ML to fill in data gaps using predictive models.","NEWTS data requirements and database structure needs will be 
established by reviewing datasets and literature on energy-water 
streams. Data sources will be identified from regulatory agencies, 
government monitoring programs, as well as open-source literature. 
Metadata of each source will be compiled into a data catalog for 
tracking and reference. Datasets, including high-quality composition 
data for relevant streams, will be collected and downloaded. Acquired 
data will be processed into a structured format based on the 
prioritization of datasets to be included in NEWTS. Data acquisition and 
processing might entail the application of ML (e.g., natural language 
processing) to efficiently resurrect data trapped in historical reports 
(e.g., PDFs) or other unstructured formats. One research product of this 
subtask will be a release of the data catalog, which will be made 
available on",,"Natural Language Processing, Other",,Department of Energy,"AI/ML may be needed to extract data from text, image and tabular- based resources. NEWTS is partnering with university teams to use ML to fill in data gaps using predictive models.: 
NEWTS data requirements and database structure needs will be 
established by reviewing datasets and literature on energy-water 
streams. Data sources will be identified from regulatory agencies, 
government monitoring programs, as well as open-source literature. 
Metadata of each source will be compiled into a data catalog for 
tracking and reference. Datasets, including high-quality composition 
data for relevant streams, will be collected and downloaded. Acquired 
data will be processed into a structured format based on the 
prioritization of datasets to be included in NEWTS. Data acquisition and 
processing might entail the application of ML (e.g., natural language 
processing) to efficiently resurrect data trapped in historical reports 
(e.g., PDFs) or other unstructured formats. One research product of this 
subtask will be a release of the data catalog, which will be made 
available on","NEWTS is using AI/ML to extract data from various sources such as text, images, and tables. They are partnering with university teams to fill in data gaps using predictive models. They will establish data requirements and database structure by reviewing energy-water datasets and literature, and identify data sources from regulatory agencies, government monitoring programs, and open-source literature. They will compile metadata into a data catalog for tracking and reference, and collect and process datasets, potentially using ML techniques like natural language processing to extract data from historical reports or unstructured formats. The data catalog will be released and made available.","NEWTS is using AI/ML to extract data from various sources such as text, images, and tables. They are partnering with university teams to fill in data gaps using predictive models. They will establish data requirements and database structure by reviewing energy-water datasets and literature, and identify data sources from regulatory agencies, government monitoring programs, and open-source literature. They will compile metadata into a data catalog for tracking and reference, and collect and process datasets, potentially using ML techniques like natural language processing to extract data from historical reports or unstructured formats. The data catalog will be released and made available.",,,False,False
DOC-0035-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Using community-sourced underwater photography and image recognition software to study green sea turtle distribution and ecology in southern California,"The goal of this project is to study green turtles in and around La Jolla Cove in the San 
Diego Region-a highly populated site with ecotourism-by engaging with local 
photographers to collect green turtle underwater images.  The project uses publicly 
available facial recognition software (HotSpotter) to identify individual turtles, from which 
we determine population size, residency patterns, and foraging ecology",,,,Department of Commerce,"Using community-sourced underwater photography and image recognition software to study green sea turtle distribution and ecology in southern California: 
The goal of this project is to study green turtles in and around La Jolla Cove in the San 
Diego Region-a highly populated site with ecotourism-by engaging with local 
photographers to collect green turtle underwater images.  The project uses publicly 
available facial recognition software (HotSpotter) to identify individual turtles, from which 
we determine population size, residency patterns, and foraging ecology","This project aims to study green sea turtles in the highly populated region of La Jolla Cove in southern California. By collaborating with local photographers, underwater images of the turtles are collected and analyzed using facial recognition software. This allows for the identification of individual turtles, helping to determine population size, residency patterns, and foraging habits.","This project aims to study green sea turtles in the highly populated region of La Jolla Cove in southern California. By collaborating with local photographers, underwater images of the turtles are collected and analyzed using facial recognition software. This allows for the identification of individual turtles, helping to determine population size, residency patterns, and foraging habits.",,,False,False
DOC-0034-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,ENSO Outlooks using observed/analyzed fields,"LSTM model that uses ocean and atmospheric predictors throughout the tropical Pacific 
to forecast ONI values up to 1 year in advance. An extension of this was submitted to the 
cloud portfolio with the intent of adding a CNN layer that that uses reforecast data to 
improve the ONI forecasts.",,,,Department of Commerce,"ENSO Outlooks using observed/analyzed fields: 
LSTM model that uses ocean and atmospheric predictors throughout the tropical Pacific 
to forecast ONI values up to 1 year in advance. An extension of this was submitted to the 
cloud portfolio with the intent of adding a CNN layer that that uses reforecast data to 
improve the ONI forecasts.",The ENSO Outlooks utilize a LSTM model that incorporates ocean and atmospheric predictors in the tropical Pacific to predict ONI values for up to one year in advance. A proposed extension of this model involves incorporating a CNN layer that utilizes reforecast data to enhance the accuracy of ONI forecasts.,The ENSO Outlooks utilize a LSTM model that incorporates ocean and atmospheric predictors in the tropical Pacific to predict ONI values for up to one year in advance. A proposed extension of this model involves incorporating a CNN layer that utilizes reforecast data to enhance the accuracy of ONI forecasts.,,,False,False
HHS-0136-2023,HHS,NIH,National Institutes of Health (NIH) NLM,MTIX,Machine learning-based system for the automated indexing of MEDLINE articles with Medical Subject Headings (MeSH) terms. Automated indexing is achieved using a multi-stage neural text ranking approach. Automated indexing allows for cost-effective and timely indexing of MEDLINE articles.,Implementation,,,Department of Health and Human Services,"MTIX: 
Machine learning-based system for the automated indexing of MEDLINE articles with Medical Subject Headings (MeSH) terms. Automated indexing is achieved using a multi-stage neural text ranking approach. Automated indexing allows for cost-effective and timely indexing of MEDLINE articles.","MTIX is a machine learning system that automates the indexing of MEDLINE articles with MeSH terms. It uses a multi-stage neural text ranking approach to achieve automated indexing, resulting in cost-effective and timely indexing of the articles.","MTIX is a machine learning system that automates the indexing of MEDLINE articles with MeSH terms. It uses a multi-stage neural text ranking approach to achieve automated indexing, resulting in cost-effective and timely indexing of the articles.",,,False,False
DOE-0059-2023,DOE,National Energy Technology Laboratory,,ML-based approaches to improve site characterization efforts,"Demonstrate application of ML-based approaches to improve site-
characterization efforts performed during the pre-injection phase using 
data from either IBDP (for which data are currently available) or other 
opportunistic field demonstration or commercial projects (for which data 
may become available) and develop value of information guidelines. 
Demonstrate how ML-based rapid forecasting can be used to help with 
pre-injection reservoir management decisions under data uncertainties. 
Demonstrate how a visualization platform with ML-based models can",,Other,,Department of Energy,"ML-based approaches to improve site characterization efforts: 
Demonstrate application of ML-based approaches to improve site-
characterization efforts performed during the pre-injection phase using 
data from either IBDP (for which data are currently available) or other 
opportunistic field demonstration or commercial projects (for which data 
may become available) and develop value of information guidelines. 
Demonstrate how ML-based rapid forecasting can be used to help with 
pre-injection reservoir management decisions under data uncertainties. 
Demonstrate how a visualization platform with ML-based models can","improve site characterization efforts by utilizing data from existing projects or future opportunities. Additionally, show how ML-based rapid forecasting can assist in making reservoir management decisions in the pre-injection phase, even when faced with uncertainties in the data. Finally, demonstrate the benefits of a visualization platform integrated with ML-based models for site characterization.","improve site characterization efforts by utilizing data from existing projects or future opportunities. Additionally, show how ML-based rapid forecasting can assist in making reservoir management decisions in the pre-injection phase, even when faced with uncertainties in the data. Finally, demonstrate the benefits of a visualization platform integrated with ML-based models for site characterization.",,,False,False
DOE-0142-2023,DOE,National Energy Technology Laboratory,,UNET and other approaches for ML- based inversion,"Researchers will develop a design basis for risk-based monitoring 
considering data dimensionality, uncertainty, and inter-tool/module 
connectivity, and define the components of the monitoring design 
optimization tool (DREAM) to be incorporated into NRAP-Open-IAM and 
the SMART platform.",,"Artificial Intelligence, Other",,Department of Energy,"UNET and other approaches for ML- based inversion: 
Researchers will develop a design basis for risk-based monitoring 
considering data dimensionality, uncertainty, and inter-tool/module 
connectivity, and define the components of the monitoring design 
optimization tool (DREAM) to be incorporated into NRAP-Open-IAM and 
the SMART platform.","Researchers are working on developing a design basis for risk-based monitoring in ML-based inversion techniques like UNET. They aim to consider factors like data dimensionality, uncertainty, and inter-tool/module connectivity to optimize the monitoring design using the DREAM tool in NRAP-Open-IAM and the SMART platform.","Researchers are working on developing a design basis for risk-based monitoring in ML-based inversion techniques like UNET. They aim to consider factors like data dimensionality, uncertainty, and inter-tool/module connectivity to optimize the monitoring design using the DREAM tool in NRAP-Open-IAM and the SMART platform.",,,False,False
HHS-0145-2023,HHS,NIH,National Institutes of Health (NIH) OD/DPCPSI/OPA,Machine learning pipeline for mining citations from full-text scientific articles,"The NIH Office of Portfolio Analysis developed a machine learning pipeline to identify scientific articles that are freely available on the internet  and do not require an institutional library subscription to access. The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service. For more information see the publication describing this pipeline: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000385#sec003).",Operation and Maintenance,,,Department of Health and Human Services,"Machine learning pipeline for mining citations from full-text scientific articles: 
The NIH Office of Portfolio Analysis developed a machine learning pipeline to identify scientific articles that are freely available on the internet  and do not require an institutional library subscription to access. The pipeline harvests full-text pdfs, converts them to xml, and uses a Long Short-Term Memory (LSTM) recurrent neural network model that discriminates between reference text and other text in the scientific article. The LSTM-identified references are then passed through our Citation Resolution Service. For more information see the publication describing this pipeline: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000385#sec003).",The NIH Office of Portfolio Analysis has developed a machine learning pipeline that identifies freely available scientific articles on the internet. This pipeline converts full-text pdfs to xml and uses a Long Short-Term Memory (LSTM) recurrent neural network model to distinguish reference text from other text in the articles. The identified references are then processed through the Citation Resolution Service.,The NIH Office of Portfolio Analysis has developed a machine learning pipeline that identifies freely available scientific articles on the internet. This pipeline converts full-text pdfs to xml and uses a Long Short-Term Memory (LSTM) recurrent neural network model to distinguish reference text from other text in the articles. The identified references are then processed through the Citation Resolution Service.,,,False,False
HHS-0144-2023,HHS,NIH,National Institutes of Health (NIH) OD/DPCPSI/OPA,Prediction of transformative breakthroughs,"The ability to predict scientific breakthroughs at scale would accelerate the pace of discovery and improve the efficiency of research investments. The initiative has helped identify a common signature within co-citation networks that accurately predicts the occurrence of breakthroughs in biomedicine, on average more than 5 years in advance of the subsequent publication(s) that announced the discovery.�There is a patent application filed for this approach: U.S. Patent Application No. 63/257,818 (filed October 20, 2021)",Implementation,,,Department of Health and Human Services,"Prediction of transformative breakthroughs: 
The ability to predict scientific breakthroughs at scale would accelerate the pace of discovery and improve the efficiency of research investments. The initiative has helped identify a common signature within co-citation networks that accurately predicts the occurrence of breakthroughs in biomedicine, on average more than 5 years in advance of the subsequent publication(s) that announced the discovery.�There is a patent application filed for this approach: U.S. Patent Application No. 63/257,818 (filed October 20, 2021)","The ability to predict scientific breakthroughs on a large scale would speed up the process of discovery and make research investments more effective. Through the identification of common signatures in co-citation networks, this initiative has successfully predicted breakthroughs in biomedicine more than 5 years before they are announced through subsequent publications. A patent application has been filed for this approach.","The ability to predict scientific breakthroughs on a large scale would speed up the process of discovery and make research investments more effective. Through the identification of common signatures in co-citation networks, this initiative has successfully predicted breakthroughs in biomedicine more than 5 years before they are announced through subsequent publications. A patent application has been filed for this approach.",,,False,False
DOT-0003-2023,DOT,ATO,,Automated Delay detection using voice processing,"In order to get a full accounting of delay, automated voice detection of ATC and aircraft interaction is required.  Many delay events, such as vectoring, are not currently reported/detected/accounted for and voice detection would enable automated detection.",Initial development,Natural Language Processing;,,Department of Transportation,"Automated Delay detection using voice processing: 
In order to get a full accounting of delay, automated voice detection of ATC and aircraft interaction is required.  Many delay events, such as vectoring, are not currently reported/detected/accounted for and voice detection would enable automated detection.","Automated delay detection can be achieved through voice processing technology. This method is necessary to accurately track delays caused by various factors, such as vectoring, which are currently not reported or accounted for. Implementing voice detection would enable automated detection of these delay events.","Automated delay detection can be achieved through voice processing technology. This method is necessary to accurately track delays caused by various factors, such as vectoring, which are currently not reported or accounted for. Implementing voice detection would enable automated detection of these delay events.",,,False,False
HHS-0147-2023,HHS,NIH,National Institutes of Health (NIH) OD/OER,"Research, Condition, and Disease Categorization (RCDC) AI Validation Tool",The goal of the tool is to ensure RCDC categories are accurate and complete for public reporting of data. ,Development and Acquisition,,,Department of Health and Human Services,"Research, Condition, and Disease Categorization (RCDC) AI Validation Tool: 
The goal of the tool is to ensure RCDC categories are accurate and complete for public reporting of data. ","The RCDC AI Validation Tool aims to verify the accuracy and comprehensiveness of RCDC categories for public data reporting. Its purpose is to ensure that research, condition, and disease categorization are reliable and complete.","The RCDC AI Validation Tool aims to verify the accuracy and comprehensiveness of RCDC categories for public data reporting. Its purpose is to ensure that research, condition, and disease categorization are reliable and complete.",,,False,False
NASA-0017-2023,NASA,Jet Propulsion Laboratory,,TRN (Terrain Relative Navigation),"Terrain Relative Navigation (TRN) estimates position during Mars landing by automatically matching landmarks
identified in descent images to a map generated from orbital imagery. The position estimate is used to a select a
safe and reachable landing site in a region with many large hazards. TRN was used successfully by the Mars 2020
mission during its landing on February 18th, 2021 and will be used on Mars Sample Return Lander.",In-use,Computer vision and state Estimation.,,National Aeronautics and Space Administration,"TRN (Terrain Relative Navigation): 
Terrain Relative Navigation (TRN) estimates position during Mars landing by automatically matching landmarks
identified in descent images to a map generated from orbital imagery. The position estimate is used to a select a
safe and reachable landing site in a region with many large hazards. TRN was used successfully by the Mars 2020
mission during its landing on February 18th, 2021 and will be used on Mars Sample Return Lander.","Terrain Relative Navigation (TRN) is a system that helps determine the position of a spacecraft during landing on Mars by comparing descent images with a map created from orbital imagery. It was successfully used by the Mars 2020 mission to select a safe landing site amidst potential hazards, and will also be utilized for the Mars Sample Return Lander.","Terrain Relative Navigation (TRN) is a system that helps determine the position of a spacecraft during landing on Mars by comparing descent images with a map created from orbital imagery. It was successfully used by the Mars 2020 mission to select a safe landing site amidst potential hazards, and will also be utilized for the Mars Sample Return Lander.",,,False,False
DOE-0176-2023,DOE,Thomas Jefferson Laboratory,,Universal MCEG,"R&D on ML based MC event generator that serves as data 
compatification utility.",,,,Department of Energy,"Universal MCEG: 
R&D on ML based MC event generator that serves as data 
compatification utility.",The Universal MCEG is a research and development project focused on creating a machine learning-based Monte Carlo event generator. This generator has the purpose of compressing data and making it compatible for various applications.,The Universal MCEG is a research and development project focused on creating a machine learning-based Monte Carlo event generator. This generator has the purpose of compressing data and making it compatible for various applications.,,,False,False
VA-0009-2023,VA,,,Disentangling dementia patterns using artificial intelligence on brain imaging and electrophysiological data,This collaborative effort focuses on developing a deep learning framework to predict the various patterns of dementia seen on MRI and EEG and explore the use of these imaging modalities as biomarkers for various dementias and epilepsy disorders.  The VA is performing retrospective chart review to achieve this.,,,,Department of Veterans Affairs,"Disentangling dementia patterns using artificial intelligence on brain imaging and electrophysiological data: 
This collaborative effort focuses on developing a deep learning framework to predict the various patterns of dementia seen on MRI and EEG and explore the use of these imaging modalities as biomarkers for various dementias and epilepsy disorders.  The VA is performing retrospective chart review to achieve this.","A deep learning framework is being developed to predict dementia patterns observed on MRI and EEG, with the aim of using these imaging modalities as biomarkers for different forms of dementia and epilepsy disorders. The VA is conducting a retrospective chart review as part of this collaborative effort.","A deep learning framework is being developed to predict dementia patterns observed on MRI and EEG, with the aim of using these imaging modalities as biomarkers for different forms of dementia and epilepsy disorders. The VA is conducting a retrospective chart review as part of this collaborative effort.",,,False,False
USDA-0036-2023,USDA,USDA,OCIO,Intelligent Ticket Routing,"Routes BMC Remedy tickets to proper work group automatically utilizing python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, erms.",Operation and Management,Machine Learning,,Department of Agriculture,"Intelligent Ticket Routing: 
Routes BMC Remedy tickets to proper work group automatically utilizing python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, erms.","Intelligent Ticket Routing is a system that automatically directs BMC Remedy tickets to the appropriate work group. It uses various technologies including python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, and erms.","Intelligent Ticket Routing is a system that automatically directs BMC Remedy tickets to the appropriate work group. It uses various technologies including python, jupyterhub, scikit learn, gitlab, flask, gunicorn, nginx, and erms.",,,False,False
HHS-0022-2023,HHS,CDC,CSELS,TowerScout:Automated cooling tower detection from aerial imagery for Legionnaires' Disease outbreak investigation,"TowerScout scans aerial imagery and uses object detection and image classification models to detect cooling towers, which can be sources of community outbreaks of Legionnaires' Disease. ",Operation and Maintenance,,,Department of Health and Human Services,"TowerScout:Automated cooling tower detection from aerial imagery for Legionnaires' Disease outbreak investigation: 
TowerScout scans aerial imagery and uses object detection and image classification models to detect cooling towers, which can be sources of community outbreaks of Legionnaires' Disease. ","TowerScout is an automated system that scans aerial imagery to detect cooling towers, which are potential sources of Legionnaires' Disease outbreaks. By utilizing object detection and image classification models, TowerScout aids in the investigation and prevention of community outbreaks.","TowerScout is an automated system that scans aerial imagery to detect cooling towers, which are potential sources of Legionnaires' Disease outbreaks. By utilizing object detection and image classification models, TowerScout aids in the investigation and prevention of community outbreaks.",,,False,False
DOC-0005-2023,DOC,Minority Business Development Administration (MBDA),,Azure Chatbot,"Azure Chatbot is being leveraged to automate and streamline the user response to 
potential questions for MBDA users while interacting with the external facing MBDA 
website. The solution leverages AI based chatbot response coupled with Machine 
Learning and Natural Language Processing capabilities.",,,,Department of Commerce,"Azure Chatbot: 
Azure Chatbot is being leveraged to automate and streamline the user response to 
potential questions for MBDA users while interacting with the external facing MBDA 
website. The solution leverages AI based chatbot response coupled with Machine 
Learning and Natural Language Processing capabilities.",Azure Chatbot is used to automate and streamline user responses to potential questions on the MBDA website. It incorporates AI-based chatbot responses along with Machine Learning and Natural Language Processing capabilities.,Azure Chatbot is used to automate and streamline user responses to potential questions on the MBDA website. It incorporates AI-based chatbot responses along with Machine Learning and Natural Language Processing capabilities.,,,False,False
HHS-0139-2023,HHS,NIH,National Institutes of Health (NIH) NLM,Pangolin lineage classification of SARS-CoV-2 genome sequences,"The PangoLEARN machine learning tool provides lineage classification of SARS-CoV-2 genome sequences. Classification of SARS-CoV-2 genome sequences into defined lineages supports user retrieval of sequences based on classification and tracking of specific lineages, including those lineages associated with mutations that may decrease the effectiveness of therapeutics or protection provided by vaccination.",Operation and Maintenance,,,Department of Health and Human Services,"Pangolin lineage classification of SARS-CoV-2 genome sequences: 
The PangoLEARN machine learning tool provides lineage classification of SARS-CoV-2 genome sequences. Classification of SARS-CoV-2 genome sequences into defined lineages supports user retrieval of sequences based on classification and tracking of specific lineages, including those lineages associated with mutations that may decrease the effectiveness of therapeutics or protection provided by vaccination.",The PangoLEARN machine learning tool can classify SARS-CoV-2 genome sequences into specific lineages. This classification helps users find sequences based on their lineage and track lineages that may have mutations affecting treatments and vaccine effectiveness.,The PangoLEARN machine learning tool can classify SARS-CoV-2 genome sequences into specific lineages. This classification helps users find sequences based on their lineage and track lineages that may have mutations affecting treatments and vaccine effectiveness.,,,False,False
DOE-0028-2023,DOE,Lawrence Livermore National Laboratory,,"Robotics, automation, and advanced manufacturing","AI is being used for accelerating hardware development and 
interpretation of sensor data to improve process reliability",,,,Department of Energy,"Robotics, automation, and advanced manufacturing: 
AI is being used for accelerating hardware development and 
interpretation of sensor data to improve process reliability","AI is utilized in robotics, automation, and advanced manufacturing to enhance hardware development and analyze sensor data for increased process reliability.","AI is utilized in robotics, automation, and advanced manufacturing to enhance hardware development and analyze sensor data for increased process reliability.",,,False,False
DOE-0135-2023,DOE,National Energy Technology Laboratory,,To use advanced machine learning techniques to analyze static and dynamic measurements of proppant distribution and fracture geometry data.,"The project will use advanced ML techniques to analyze static and 
dynamic measurements of proppant distribution and fracture geometry 
data from thousands of microchips injected with proppant near the 
wellbore.",,Artificial Intelligence Unknown,,Department of Energy,"To use advanced machine learning techniques to analyze static and dynamic measurements of proppant distribution and fracture geometry data.: 
The project will use advanced ML techniques to analyze static and 
dynamic measurements of proppant distribution and fracture geometry 
data from thousands of microchips injected with proppant near the 
wellbore.",The project aims to analyze proppant distribution and fracture geometry data by utilizing advanced machine learning techniques. This analysis will be performed on static and dynamic measurements collected from numerous microchips that have been injected with proppant near the wellbore.,The project aims to analyze proppant distribution and fracture geometry data by utilizing advanced machine learning techniques. This analysis will be performed on static and dynamic measurements collected from numerous microchips that have been injected with proppant near the wellbore.,,,False,False
HHS-0024-2023,HHS,CDC,CSELS,Zero-shot learning to identify menstrual irregularities reported after COVID-19 vaccination,Zero-shot learning was used to identify and classify reports of menstrual irregularities after receiving COVID-19 vaccination,Operation and Maintenance,,,Department of Health and Human Services,"Zero-shot learning to identify menstrual irregularities reported after COVID-19 vaccination: 
Zero-shot learning was used to identify and classify reports of menstrual irregularities after receiving COVID-19 vaccination",The researchers used zero-shot learning to identify and categorize menstrual irregularities that were reported by individuals who had received the COVID-19 vaccination. This approach allowed them to analyze and classify these reports without prior training on this specific topic.,The researchers used zero-shot learning to identify and categorize menstrual irregularities that were reported by individuals who had received the COVID-19 vaccination. This approach allowed them to analyze and classify these reports without prior training on this specific topic.,,,False,False
DOE-0043-2023,DOE,National Energy Technology Laboratory,,Demonstrate the robust performance of our ML method in a commercial-scale synthetic data and integrate image-to-image mapping with convolutional neural networks,"Our method quickly incorporates streaming observations for accurate 
and timely forecasts with uncertainty quantification, taking reservoir 
simulation data as inputs and incorporating real-time observation 
streams for accurate, timely geological carbon storage forecasts.
Computation effort is distributed over many machines, facilitates 
coupled inversions using many ML models, and allows for ML-Driven 
optimization and sensitivity analysis",,"Neural Networks, Other",,Department of Energy,"Demonstrate the robust performance of our ML method in a commercial-scale synthetic data and integrate image-to-image mapping with convolutional neural networks: 
Our method quickly incorporates streaming observations for accurate 
and timely forecasts with uncertainty quantification, taking reservoir 
simulation data as inputs and incorporating real-time observation 
streams for accurate, timely geological carbon storage forecasts.
Computation effort is distributed over many machines, facilitates 
coupled inversions using many ML models, and allows for ML-Driven 
optimization and sensitivity analysis","The ML method we developed performs well in large-scale synthetic data and combines image mapping with convolutional neural networks. It efficiently incorporates real-time observations to provide accurate and timely forecasts for geological carbon storage. The method distributes computation across multiple machines, enabling coupled inversions, ML-driven optimization, and sensitivity analysis using multiple ML models.","The ML method we developed performs well in large-scale synthetic data and combines image mapping with convolutional neural networks. It efficiently incorporates real-time observations to provide accurate and timely forecasts for geological carbon storage. The method distributes computation across multiple machines, enabling coupled inversions, ML-driven optimization, and sensitivity analysis using multiple ML models.",,,False,False
DOE-0074-2023,DOE,National Energy Technology Laboratory,,"To apply machine learning applications to map carbon ore, rare earth element, and critical mineral resources","To identify information gaps, GIS and machine learning applications will 
be used to map carbon ore, rare earth element, and critical mineral 
resource infrastructure, and market data in consultation with NETL 
geospatial modeling activities. Research needs and technology gaps will 
be assessed, and resources targeted for sampling and characterization. 
This effort will provide a complete Northern Appalachian carbon ore, 
rare earth element, and critical mineral value chain basinal assessment 
to enable quick development of commercial projects.",,Artificial Intelligence Unknown,,Department of Energy,"To apply machine learning applications to map carbon ore, rare earth element, and critical mineral resources: 
To identify information gaps, GIS and machine learning applications will 
be used to map carbon ore, rare earth element, and critical mineral 
resource infrastructure, and market data in consultation with NETL 
geospatial modeling activities. Research needs and technology gaps will 
be assessed, and resources targeted for sampling and characterization. 
This effort will provide a complete Northern Appalachian carbon ore, 
rare earth element, and critical mineral value chain basinal assessment 
to enable quick development of commercial projects.","Machine learning and GIS applications will be used to map carbon ore, rare earth element, and critical mineral resources. This will involve identifying information gaps, assessing research needs and technology gaps, and targeting resources for sampling and characterization. The goal is to provide a comprehensive assessment of the value chain in the Northern Appalachian region and facilitate the rapid development of commercial projects.","Machine learning and GIS applications will be used to map carbon ore, rare earth element, and critical mineral resources. This will involve identifying information gaps, assessing research needs and technology gaps, and targeting resources for sampling and characterization. The goal is to provide a comprehensive assessment of the value chain in the Northern Appalachian region and facilitate the rapid development of commercial projects.",,,False,False
USDA-0007-2023,USDA,USDA,APHIS,Training machine learning models to automatically read file attachments and save information into a more convenient Excel format.,"Artificial intelligence used to automate document processing and information extraction. Program managers often need information from specific form fields that are sent as PDF email attachments. Many emailed documents are received each day, making manually opening each attachment and copying the needed information too time-consuming. ",Operation and Management,Machine Learning,,Department of Agriculture,"Training machine learning models to automatically read file attachments and save information into a more convenient Excel format.: 
Artificial intelligence used to automate document processing and information extraction. Program managers often need information from specific form fields that are sent as PDF email attachments. Many emailed documents are received each day, making manually opening each attachment and copying the needed information too time-consuming. ","Artificial intelligence is employed to automate the process of document processing and information extraction. This technology helps program managers extract required information from specific fields in PDF email attachments, saving time by eliminating the need for manual opening and copying of information from each attachment.","Artificial intelligence is employed to automate the process of document processing and information extraction. This technology helps program managers extract required information from specific fields in PDF email attachments, saving time by eliminating the need for manual opening and copying of information from each attachment.",,,False,False
USAID-0013-2023,USAID,Bureau for Latin America and the Caribbean,,NASA SERVIR - Mapping urban vulnerability using AI techniques,"This activity will improve urban vulnerability assessment in key population centers, particularly by co-creating replicable methods to use satellite imagery to map informal settlements. ",Initiation,,,U.S. Agency for International Development,"NASA SERVIR - Mapping urban vulnerability using AI techniques: 
This activity will improve urban vulnerability assessment in key population centers, particularly by co-creating replicable methods to use satellite imagery to map informal settlements. ",NASA SERVIR aims to enhance urban vulnerability assessment in major cities by developing AI techniques to map informal settlements using satellite imagery. The goal is to create standardized and reproducible methods that can be applied in various population centers.,NASA SERVIR aims to enhance urban vulnerability assessment in major cities by developing AI techniques to map informal settlements using satellite imagery. The goal is to create standardized and reproducible methods that can be applied in various population centers.,,,False,False
HHS-0085-2023,HHS,FDA,CDER/Office of Translational Sciences,Community Level Opioid Use Dynamics Modeling and Simulation,"The OUD project leverages artificial intelligence techniques, specifically Agent-Based Modeling (ABM), to design and carry out Community Level Opioid Use Dynamics Modeling and Simulation with a cohort of datasets and to investigate the propagation mechanisms involving various factors including geographical and social influences and more, and their impacts at a high level. The project also leveraged Machine Learning (ML), such as Classification, to identify data entry types (e.g., whether a particular data entry is entered by a person in the target population, e.g., a woman of child-bearing ages) as part of the training data generation task. ",Initiation,,,Department of Health and Human Services,"Community Level Opioid Use Dynamics Modeling and Simulation: 
The OUD project leverages artificial intelligence techniques, specifically Agent-Based Modeling (ABM), to design and carry out Community Level Opioid Use Dynamics Modeling and Simulation with a cohort of datasets and to investigate the propagation mechanisms involving various factors including geographical and social influences and more, and their impacts at a high level. The project also leveraged Machine Learning (ML), such as Classification, to identify data entry types (e.g., whether a particular data entry is entered by a person in the target population, e.g., a woman of child-bearing ages) as part of the training data generation task. ","The OUD project uses artificial intelligence techniques like Agent-Based Modeling (ABM) and Machine Learning (ML) to simulate and analyze the dynamics of opioid use in communities. By examining various factors such as geography and social influences, the project aims to understand how opioids spread and their overall impact. ML is also used to classify data entry types, helping generate accurate training data.","The OUD project uses artificial intelligence techniques like Agent-Based Modeling (ABM) and Machine Learning (ML) to simulate and analyze the dynamics of opioid use in communities. By examining various factors such as geography and social influences, the project aims to understand how opioids spread and their overall impact. ML is also used to classify data entry types, helping generate accurate training data.",,,False,False
GSA-0001-2023,GSA,FAS,,City Pairs Program Ticket Forecast and Scenario Analysis Tools,"Takes segment-level City Pair Program air travel purchase data and creates near-term forecasts for the current and upcoming fiscal year by month and at various levels of granularity including DOD vs Civilian, Agency, and Region.",Development and Acquisition,Time Series Forecast,https://github.helix.gsa.gov/EDA/City_Pair_Program_Forecast.git,U.S. General Services Administration,"City Pairs Program Ticket Forecast and Scenario Analysis Tools: 
Takes segment-level City Pair Program air travel purchase data and creates near-term forecasts for the current and upcoming fiscal year by month and at various levels of granularity including DOD vs Civilian, Agency, and Region.","The City Pairs Program Ticket Forecast and Scenario Analysis Tools use air travel purchase data to predict future ticket sales for the City Pair Program. It provides forecasts for the current and upcoming fiscal year, including monthly predictions and breakdowns by DOD vs Civilian, Agency, and Region.","The City Pairs Program Ticket Forecast and Scenario Analysis Tools use air travel purchase data to predict future ticket sales for the City Pair Program. It provides forecasts for the current and upcoming fiscal year, including monthly predictions and breakdowns by DOD vs Civilian, Agency, and Region.",,,False,False
NASA-0030-2023,NASA,Marshall Space Flight Center,,Predicting streamflow with deep learning,"Uses a long short-term memory model to predict streamflow at USGS gauges sites with inputs from the NASA Land
Information System and forecasts of precipitation",In-use,,,National Aeronautics and Space Administration,"Predicting streamflow with deep learning: 
Uses a long short-term memory model to predict streamflow at USGS gauges sites with inputs from the NASA Land
Information System and forecasts of precipitation",A long short-term memory model is utilized to forecast streamflow at USGS gauge sites. The model incorporates data from the NASA Land Information System and precipitation forecasts to make accurate predictions.,A long short-term memory model is utilized to forecast streamflow at USGS gauge sites. The model incorporates data from the NASA Land Information System and precipitation forecasts to make accurate predictions.,,,False,False
DOC-0013-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,ANN to improve CFS T and P outlooks,"Fan Y., Krasnopolsky, V., van den Dool H., Wu, C. , and Gottschalck J. (2021). Using 
Artificial Neural Networks to Improve CFS Week 3-4 Precipitation and Temperature 
Forecasts.",,,,Department of Commerce,"ANN to improve CFS T and P outlooks: 
Fan Y., Krasnopolsky, V., van den Dool H., Wu, C. , and Gottschalck J. (2021). Using 
Artificial Neural Networks to Improve CFS Week 3-4 Precipitation and Temperature 
Forecasts.",The study by Fan et al. (2021) proposes the use of Artificial Neural Networks (ANN) to enhance the accuracy of Climate Forecast System (CFS) Week 3-4 forecasts for precipitation and temperature. The researchers suggest that incorporating ANN into the forecasting model can lead to improved predictions in these weather variables.,The study by Fan et al. (2021) proposes the use of Artificial Neural Networks (ANN) to enhance the accuracy of Climate Forecast System (CFS) Week 3-4 forecasts for precipitation and temperature. The researchers suggest that incorporating ANN into the forecasting model can lead to improved predictions in these weather variables.,,,False,False
DOE-0002-2023,DOE,Brookhaven National Laboratory,,SMMM,"AI/ML is being used to evaluate measurements in real-time during 
simultaneous experiments on two beamlines and then drive subsequent 
data collection on both of the beamlines to maximize the scientific value 
generated per time.",,,,Department of Energy,"SMMM: 
AI/ML is being used to evaluate measurements in real-time during 
simultaneous experiments on two beamlines and then drive subsequent 
data collection on both of the beamlines to maximize the scientific value 
generated per time.","AI/ML technology is currently being employed to assess real-time measurements during concurrent experiments on two beamlines. It then utilizes this information to optimize data collection on both beamlines, effectively maximizing the scientific output within a given timeframe.","AI/ML technology is currently being employed to assess real-time measurements during concurrent experiments on two beamlines. It then utilizes this information to optimize data collection on both beamlines, effectively maximizing the scientific output within a given timeframe.",,,False,False
HHS-0112-2023,HHS,NIH,National Institutes of Health (NIH) NIAID,Federal IT Acquisition Reform Act (FITARA) Tool,The tool automates the identification of NIAID contracts that are IT-related.,Operation and Maintenance,,,Department of Health and Human Services,"Federal IT Acquisition Reform Act (FITARA) Tool: 
The tool automates the identification of NIAID contracts that are IT-related.",The Federal IT Acquisition Reform Act (FITARA) Tool automates the process of identifying IT-related contracts within the National Institute of Allergy and Infectious Diseases (NIAID). It simplifies the task by streamlining the identification process for NIAID contracts that fall under the IT category.,The Federal IT Acquisition Reform Act (FITARA) Tool automates the process of identifying IT-related contracts within the National Institute of Allergy and Infectious Diseases (NIAID). It simplifies the task by streamlining the identification process for NIAID contracts that fall under the IT category.,,,False,False
NASA-0031-2023,NASA,Marshall Space Flight Center,,Ship detection,Deep learning-based ship detection from high-resolution satellite imagery,In-use,,,National Aeronautics and Space Administration,"Ship detection: 
Deep learning-based ship detection from high-resolution satellite imagery",The process of ship detection involves using deep learning techniques to identify and locate ships in high-resolution satellite imagery. This method relies on advanced algorithms and neural networks to analyze the visual features of the images and accurately detect the presence of ships.,The process of ship detection involves using deep learning techniques to identify and locate ships in high-resolution satellite imagery. This method relies on advanced algorithms and neural networks to analyze the visual features of the images and accurately detect the presence of ships.,,,False,False
USDA-0021-2023,USDA,USDA,Forest Service,RMRS Raster Utility,"RMRS Raster Utility is a .NET object oriented library that simplifies data acquisition, raster sampling, and statistical and spatial modeling while reducing the processing time and storage space associated with raster analysis. It includes machine learning techniques.",Operation and Management,Machine Learning,https://collab.firelab.org/software/projects/rmrsraster,Department of Agriculture,"RMRS Raster Utility: 
RMRS Raster Utility is a .NET object oriented library that simplifies data acquisition, raster sampling, and statistical and spatial modeling while reducing the processing time and storage space associated with raster analysis. It includes machine learning techniques.","The RMRS Raster Utility is a library designed for data acquisition, raster sampling, and statistical and spatial modeling. It is built on the .NET framework and offers machine learning capabilities to improve efficiency and reduce storage space in raster analysis processes.","The RMRS Raster Utility is a library designed for data acquisition, raster sampling, and statistical and spatial modeling. It is built on the .NET framework and offers machine learning capabilities to improve efficiency and reduce storage space in raster analysis processes.",,,False,False
GSA-0010-2023,GSA,TTS,,Classifying Qualitative Data,"USAGov and USAGov en Español collect large amounts of qualitative data from survey comments, web searches and call center chat transcripts. Comments are grouped together by topic to determine where we need to make product updates/enhancements",Operation and Maintenance,Natural Language Processing (NLP),,U.S. General Services Administration,"Classifying Qualitative Data: 
USAGov and USAGov en Español collect large amounts of qualitative data from survey comments, web searches and call center chat transcripts. Comments are grouped together by topic to determine where we need to make product updates/enhancements","USAGov and USAGov en Español gather qualitative data from various sources such as survey comments, web searches, and call center chat transcripts. This data is then categorized by topic to identify areas that require product improvements or enhancements.","USAGov and USAGov en Español gather qualitative data from various sources such as survey comments, web searches, and call center chat transcripts. This data is then categorized by topic to identify areas that require product improvements or enhancements.",,,False,False
HHS-0008-2023,HHS,ASPR,BARDA (CBRN),Burn & Bast MCMs: SpectralMD,Determination of burn depth severity and burn size of injuries ,Development and Acquisition,,,Department of Health and Human Services,"Burn & Bast MCMs: SpectralMD: 
Determination of burn depth severity and burn size of injuries ","SpectralMD has developed a technology called Burn & Bast MCMs, which can accurately determine the severity and size of burn injuries. This innovative solution provides a reliable method for assessing burn depth, allowing medical professionals to make informed treatment decisions.","SpectralMD has developed a technology called Burn & Bast MCMs, which can accurately determine the severity and size of burn injuries. This innovative solution provides a reliable method for assessing burn depth, allowing medical professionals to make informed treatment decisions.",,,False,False
DHS-0008-2023,DHS,Customs and Border Protection,,Geospatial imagery utilizing annotation,"Leverages a commercial constellation of Synthetic Aperture Radar (SAR) satellites with readily available data, capable of imaging any location on Earth, day, and night, regardless of cloud cover. 

Utilizes AI, including machine vision, object, detection, object recognition, and annotation to detect airframes, military vehicles, and marine vessels, as well as built-in change detection capabilities for disaster response missions.",Development and Acquisition,Machine Vision,,Department of Homeland Security,"Geospatial imagery utilizing annotation: 
Leverages a commercial constellation of Synthetic Aperture Radar (SAR) satellites with readily available data, capable of imaging any location on Earth, day, and night, regardless of cloud cover. 

Utilizes AI, including machine vision, object, detection, object recognition, and annotation to detect airframes, military vehicles, and marine vessels, as well as built-in change detection capabilities for disaster response missions.","Geospatial imagery with annotation uses SAR satellites to capture images of any location on Earth, regardless of cloud cover or time of day. It utilizes AI technologies like machine vision and object detection to identify airframes, military vehicles, marine vessels, and can also detect changes for disaster response missions.","Geospatial imagery with annotation uses SAR satellites to capture images of any location on Earth, regardless of cloud cover or time of day. It utilizes AI technologies like machine vision and object detection to identify airframes, military vehicles, marine vessels, and can also detect changes for disaster response missions.",,,False,False
TREAS-0001-2023,TREAS,,,Appeals Case Memorandum,"The Appeals Case Memorandum (ACM) leverages natural language 
processing capabilities to assist with extraction, consolidation, and labeling 
of unstructured text from IRS ACM documents, automatic identification of 
key information, and processing results into a structured format. The 
outcome of this processes is for IRS staff to review appeals information for 
insights, which can be used upstream to enhance case quality, consistency, 
and performance. Summary of results involve detailed analysis on text 
relationships, issues, and citation narrative text paragraphs to provide 
insight on issues commonly adjusted during the appeals process.",Implementation,,,Department of Treasury,"Appeals Case Memorandum: 
The Appeals Case Memorandum (ACM) leverages natural language 
processing capabilities to assist with extraction, consolidation, and labeling 
of unstructured text from IRS ACM documents, automatic identification of 
key information, and processing results into a structured format. The 
outcome of this processes is for IRS staff to review appeals information for 
insights, which can be used upstream to enhance case quality, consistency, 
and performance. Summary of results involve detailed analysis on text 
relationships, issues, and citation narrative text paragraphs to provide 
insight on issues commonly adjusted during the appeals process.","The Appeals Case Memorandum (ACM) uses natural language processing to extract and organize unstructured text from IRS ACM documents. It identifies key information and presents it in a structured format for review by IRS staff. The results include detailed analysis on text relationships, issues, and citation narrative text paragraphs, providing insights on commonly adjusted issues during the appeals process.","The Appeals Case Memorandum (ACM) uses natural language processing to extract and organize unstructured text from IRS ACM documents. It identifies key information and presents it in a structured format for review by IRS staff. The results include detailed analysis on text relationships, issues, and citation narrative text paragraphs, providing insights on commonly adjusted issues during the appeals process.",,,False,False
DOE-0025-2023,DOE,Lawrence Livermore National Laboratory,,"Innovation methods, processes and promising practices that can affect the speed and effectiveness of innovation processes at scale.","Computational approaches that lead to faster insights into the 
development and deployment of large scale operations",,,,Department of Energy,"Innovation methods, processes and promising practices that can affect the speed and effectiveness of innovation processes at scale.: 
Computational approaches that lead to faster insights into the 
development and deployment of large scale operations","This text discusses the importance of innovation methods, processes, and practices in achieving faster and more effective innovation at a larger scale. It emphasizes the use of computational approaches to gain quicker insights into the development and implementation of large-scale operations.","This text discusses the importance of innovation methods, processes, and practices in achieving faster and more effective innovation at a larger scale. It emphasizes the use of computational approaches to gain quicker insights into the development and implementation of large-scale operations.",,,False,False
DOC-0036-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,An Interactive Machine Learning Signals in Passive Acoustic Recordings Toolkit for Classifying Species Identity of Cetacean Echolocation,"Develop robust automated machine learning detection and classification tools for acoustic 
species identification of toothed whale and dolphin echolocation clicks for up to 20 
species found in the Gulf of Mexico. Tool development project funded from June 2018 to May 2021. Tool will be used for automated analyses of long-term recordings from Gulf- wide passive acoustic moored instruments deployed from 2010-2025 to look at  environmental processes driving trends in marine mammal density and distribution.",,,,Department of Commerce,"An Interactive Machine Learning Signals in Passive Acoustic Recordings Toolkit for Classifying Species Identity of Cetacean Echolocation: 
Develop robust automated machine learning detection and classification tools for acoustic 
species identification of toothed whale and dolphin echolocation clicks for up to 20 
species found in the Gulf of Mexico. Tool development project funded from June 2018 to May 2021. Tool will be used for automated analyses of long-term recordings from Gulf- wide passive acoustic moored instruments deployed from 2010-2025 to look at  environmental processes driving trends in marine mammal density and distribution.",A toolkit is being developed to automate the detection and classification of toothed whale and dolphin echolocation clicks in the Gulf of Mexico. The project is funded from June 2018 to May 2021 and the toolkit will be used to analyze long-term recordings from passive acoustic instruments to study trends in marine mammal density and distribution.,A toolkit is being developed to automate the detection and classification of toothed whale and dolphin echolocation clicks in the Gulf of Mexico. The project is funded from June 2018 to May 2021 and the toolkit will be used to analyze long-term recordings from passive acoustic instruments to study trends in marine mammal density and distribution.,,,False,False
DOE-0020-2023,DOE,Lawrence Livermore National Laboratory,,"Advanced materials science, engineering, and exploration relevant to the other key technology focus areas","Enabling machine learning based technology to specialized materials for 
superior performance for scientific research and manufacturing systems",,,,Department of Energy,"Advanced materials science, engineering, and exploration relevant to the other key technology focus areas: 
Enabling machine learning based technology to specialized materials for 
superior performance for scientific research and manufacturing systems","The text states that advanced materials science, engineering, and exploration are crucial for enabling machine learning technology to be applied to specialized materials. This will result in improved performance for scientific research and manufacturing systems.","The text states that advanced materials science, engineering, and exploration are crucial for enabling machine learning technology to be applied to specialized materials. This will result in improved performance for scientific research and manufacturing systems.",,,False,False
DOS-0001-2023,DOS,A,,Product Service Code Automation ML Model,"A/LM developed a machine learning model to scan unstructured, user entered procurement data such as Requisition Title and Line Descriptions to automatically detect the commodity and services types being purchased for enhanced procurement categorization.",,,,Department of State,"Product Service Code Automation ML Model: 
A/LM developed a machine learning model to scan unstructured, user entered procurement data such as Requisition Title and Line Descriptions to automatically detect the commodity and services types being purchased for enhanced procurement categorization.","A/LM created a machine learning model that can analyze unstructured procurement data entered by users, like Requisition Title and Line Descriptions. This model automatically identifies the types of commodities and services being purchased, improving the categorization of procurement items.","A/LM created a machine learning model that can analyze unstructured procurement data entered by users, like Requisition Title and Line Descriptions. This model automatically identifies the types of commodities and services being purchased, improving the categorization of procurement items.",,,False,False
HHS-0152-2023,HHS,NIH,National Institutes of Health (NIH) OD/ORF,NIH Campus Steam Demand Forecaster,"This project forecasts the NIH campus steam demand for the next four days. With this information, the stakeholders at the NIH Central Utilities Plant can plan and optimize the plant operation and maintenance in advance.",Operation and Maintenance,,,Department of Health and Human Services,"NIH Campus Steam Demand Forecaster: 
This project forecasts the NIH campus steam demand for the next four days. With this information, the stakeholders at the NIH Central Utilities Plant can plan and optimize the plant operation and maintenance in advance.",The NIH Campus Steam Demand Forecaster predicts the steam demand for the next four days on the NIH campus. This helps the stakeholders at the NIH Central Utilities Plant to efficiently plan and optimize their operations and maintenance tasks.,The NIH Campus Steam Demand Forecaster predicts the steam demand for the next four days on the NIH campus. This helps the stakeholders at the NIH Central Utilities Plant to efficiently plan and optimize their operations and maintenance tasks.,,,False,False
DOE-0066-2023,DOE,National Energy Technology Laboratory,,Reduce computational cost of CFD simulations that screen for more efficient intensified solvent contactor geometries.,"Collaborate with Subtask 4.3 Machine Learning Support to reduce the 
computational complexity of validated CFD calculations using Deeper 
Fluids (DF), graph neural networks (GNNs), or similar ML approaches. 
Further development of ongoing process modeling/optimization 
ultimately informed by the CFD reduced order models (ROM) will also 
be a focus.",,"Neural Networks, Other",,Department of Energy,"Reduce computational cost of CFD simulations that screen for more efficient intensified solvent contactor geometries.: 
Collaborate with Subtask 4.3 Machine Learning Support to reduce the 
computational complexity of validated CFD calculations using Deeper 
Fluids (DF), graph neural networks (GNNs), or similar ML approaches. 
Further development of ongoing process modeling/optimization 
ultimately informed by the CFD reduced order models (ROM) will also 
be a focus.","The aim is to decrease the computational expense of CFD simulations that evaluate more effective solvent contactor designs. This will be achieved by working with Subtask 4.3 Machine Learning Support to employ Deeper Fluids (DF), graph neural networks (GNNs), or similar machine learning techniques to simplify validated CFD calculations. Additionally, the focus will be on advancing the ongoing process modeling/optimization with input from the CFD reduced order models (ROM).","The aim is to decrease the computational expense of CFD simulations that evaluate more effective solvent contactor designs. This will be achieved by working with Subtask 4.3 Machine Learning Support to employ Deeper Fluids (DF), graph neural networks (GNNs), or similar machine learning techniques to simplify validated CFD calculations. Additionally, the focus will be on advancing the ongoing process modeling/optimization with input from the CFD reduced order models (ROM).",,,False,False
DHS-0025-2023,DHS,HQ,,Text Analytics for Survey Responses (TASR),Text Analytics for Survey Responses (TASR) is an application for performing Natural Language Processing (NLP) and text analytics on survey responses. It is currently being applied by DHS OCHCO to analyze and extract significant topics/themes from unstructured text responses to open-ended questions in the quarterly DHS Pulse Surveys. Results of extracted topics/themes are provided to DHS Leadership to better inform agency-wide efforts to meet employees’ basic needs and improve job satisfaction,Operation and Maintenance,"Natural Language Processing (NLP), Latent Dirichlet Allocation",,Department of Homeland Security,"Text Analytics for Survey Responses (TASR): 
Text Analytics for Survey Responses (TASR) is an application for performing Natural Language Processing (NLP) and text analytics on survey responses. It is currently being applied by DHS OCHCO to analyze and extract significant topics/themes from unstructured text responses to open-ended questions in the quarterly DHS Pulse Surveys. Results of extracted topics/themes are provided to DHS Leadership to better inform agency-wide efforts to meet employees’ basic needs and improve job satisfaction",Text Analytics for Survey Responses (TASR) is a tool used by DHS OCHCO to analyze and extract important topics from survey responses. It helps DHS Leadership understand employees' needs and improve job satisfaction by providing insights from open-ended questions in the quarterly DHS Pulse Surveys.,Text Analytics for Survey Responses (TASR) is a tool used by DHS OCHCO to analyze and extract important topics from survey responses. It helps DHS Leadership understand employees' needs and improve job satisfaction by providing insights from open-ended questions in the quarterly DHS Pulse Surveys.,,,False,False
DOC-0011-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,A Hybrid Statistical-Dynamical System for the Seamless Prediction of Daily Extremes and Subseasonal to Seasonal Climate Variability,"Demonstrate the skill and suitability for operations of a statistical- dynamical prediction 
system that yields seamless probabilistic forecasts of daily extremes and sub seasonal-to-
seasonal temperature and precipitation. We recently demonstrated a Bayesian statistical 
method for post-processing seasonal forecasts of mean temperature and precipitation 
from the North American Multi-Model Ensemble (NMME). We now seek to test the utility 
of an updated hybrid statistical-dynamical prediction system that facilitates seamless sub 
seasonal and seasonal forecasting. Importantly, this method allows for the representation 
of daily extremes consistent with climate conditions. This project explores the use of 
machine learning.",,,,Department of Commerce,"A Hybrid Statistical-Dynamical System for the Seamless Prediction of Daily Extremes and Subseasonal to Seasonal Climate Variability: 
Demonstrate the skill and suitability for operations of a statistical- dynamical prediction 
system that yields seamless probabilistic forecasts of daily extremes and sub seasonal-to-
seasonal temperature and precipitation. We recently demonstrated a Bayesian statistical 
method for post-processing seasonal forecasts of mean temperature and precipitation 
from the North American Multi-Model Ensemble (NMME). We now seek to test the utility 
of an updated hybrid statistical-dynamical prediction system that facilitates seamless sub 
seasonal and seasonal forecasting. Importantly, this method allows for the representation 
of daily extremes consistent with climate conditions. This project explores the use of 
machine learning.","This text discusses the development of a hybrid statistical-dynamical prediction system that can accurately forecast daily extremes, as well as subseasonal to seasonal temperature and precipitation patterns. The system combines a Bayesian statistical method with machine learning to improve the accuracy of seasonal forecasts from the North American Multi-Model Ensemble (NMME). The goal is to create a seamless and reliable prediction system that can represent daily extremes in line with climate conditions.","This text discusses the development of a hybrid statistical-dynamical prediction system that can accurately forecast daily extremes, as well as subseasonal to seasonal temperature and precipitation patterns. The system combines a Bayesian statistical method with machine learning to improve the accuracy of seasonal forecasts from the North American Multi-Model Ensemble (NMME). The goal is to create a seamless and reliable prediction system that can represent daily extremes in line with climate conditions.",,,False,False
DOE-0061-2023,DOE,National Energy Technology Laboratory,,"ML-based reduced order models of reservoir response to Co2 injection into saline and/or hydrocarbon- bearing formations - as the basis for integrated assessment modeling of leakage risk (e.g., SACROC)","Generally, the approach used by NRAP researchers to address these 
questions is to develop a robust, science-based integrated assessment 
framework that links fast forecasting models of CO2 storage system 
components (e.g., storage reservoir; leakage pathways including wells, 
faults, and fractured caprock; intermediate formations; and receptors of 
concern, including groundwater aquifers and the atmosphere). 
Superimposed on this system model are various fit-for-purpose 
analytical capabilities that support analyses in support of stakeholder 
decision making for questions related to site-specific risk evolution, risk-
based area of review delineation, conformance assessment, and post-
injection site monitoring
In Task 2.0, researchers will augment and expand this functionality to 
demonstrate relevance to industry-standard site risk management 
methods (i.e., bowtie analysis framework) and to understand 
containment performance and leakage risk for scenarios where a site 
transitions from CO2 utilization for EOR to dedicated CO2 storage. To 
ensure that risk assessment efforts are informative to real geologic 
storage deployment scenarios, NRAP researchers will engage with a 
diverse set of stakeholders to establish an appropriate modeling and 
risk assessment design basis.",,Other,,Department of Energy,"ML-based reduced order models of reservoir response to Co2 injection into saline and/or hydrocarbon- bearing formations - as the basis for integrated assessment modeling of leakage risk (e.g., SACROC): 
Generally, the approach used by NRAP researchers to address these 
questions is to develop a robust, science-based integrated assessment 
framework that links fast forecasting models of CO2 storage system 
components (e.g., storage reservoir; leakage pathways including wells, 
faults, and fractured caprock; intermediate formations; and receptors of 
concern, including groundwater aquifers and the atmosphere). 
Superimposed on this system model are various fit-for-purpose 
analytical capabilities that support analyses in support of stakeholder 
decision making for questions related to site-specific risk evolution, risk-
based area of review delineation, conformance assessment, and post-
injection site monitoring
In Task 2.0, researchers will augment and expand this functionality to 
demonstrate relevance to industry-standard site risk management 
methods (i.e., bowtie analysis framework) and to understand 
containment performance and leakage risk for scenarios where a site 
transitions from CO2 utilization for EOR to dedicated CO2 storage. To 
ensure that risk assessment efforts are informative to real geologic 
storage deployment scenarios, NRAP researchers will engage with a 
diverse set of stakeholders to establish an appropriate modeling and 
risk assessment design basis.",The NRAP researchers are developing a comprehensive framework that links fast forecasting models of CO2 storage system components. They will expand this framework to demonstrate relevance to industry-standard site risk management methods and to understand containment performance and leakage risk in different scenarios. They will also engage with stakeholders to establish a modeling and risk assessment design basis that is relevant to real geologic storage deployment scenarios.,The NRAP researchers are developing a comprehensive framework that links fast forecasting models of CO2 storage system components. They will expand this framework to demonstrate relevance to industry-standard site risk management methods and to understand containment performance and leakage risk in different scenarios. They will also engage with stakeholders to establish a modeling and risk assessment design basis that is relevant to real geologic storage deployment scenarios.,,,False,False
DOE-0016-2023,DOE,Fermi National Accelerator,,Uncertainty Quantification and Instrument Automation to enable next generation cosmological discoveries,"This project will develop AI-based tools to enable critical sectors for near-
future cosmic applications. Uncertainty quantification is essential for 
performing discovery science now, and simulation-based inference 
offers a new approach. The automated design and control of 
instrumentation will be important for improving the efficiency of planning 
and executing cosmic experiments.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"Uncertainty Quantification and Instrument Automation to enable next generation cosmological discoveries: 
This project will develop AI-based tools to enable critical sectors for near-
future cosmic applications. Uncertainty quantification is essential for 
performing discovery science now, and simulation-based inference 
offers a new approach. The automated design and control of 
instrumentation will be important for improving the efficiency of planning 
and executing cosmic experiments.","This project aims to develop AI-based tools to facilitate advancements in cosmological discoveries. It emphasizes the significance of uncertainty quantification and simulation-based inference for discovery science. Additionally, the project highlights the importance of automated design and control of instrumentation to enhance the efficiency of planning and executing cosmic experiments.","This project aims to develop AI-based tools to facilitate advancements in cosmological discoveries. It emphasizes the significance of uncertainty quantification and simulation-based inference for discovery science. Additionally, the project highlights the importance of automated design and control of instrumentation to enhance the efficiency of planning and executing cosmic experiments.",,,False,False
HHS-0041-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Amazon Lex and Amazon Polly for the Marketplace Appeals Call Center,"CMS/OHI: Amazon Lex & Amazon Polly are used in conjunction with the Amazon Connect phone system (cloud based) for the Marketplace Appeals Call Center. Amazon Lex offers self-service capabilities with virtual contact center agents, interactive voice response (IVR), information response automation, and maximizing information by designing chatbots using existing call center transcripts. Amazon Polly turns text into speech, allowing the program to create applications that talk, and build entirely new categories of speech-enabled products.",Operation and Maintenance,,,Department of Health and Human Services,"Amazon Lex and Amazon Polly for the Marketplace Appeals Call Center: 
CMS/OHI: Amazon Lex & Amazon Polly are used in conjunction with the Amazon Connect phone system (cloud based) for the Marketplace Appeals Call Center. Amazon Lex offers self-service capabilities with virtual contact center agents, interactive voice response (IVR), information response automation, and maximizing information by designing chatbots using existing call center transcripts. Amazon Polly turns text into speech, allowing the program to create applications that talk, and build entirely new categories of speech-enabled products.","Amazon Lex and Amazon Polly are utilized in the Marketplace Appeals Call Center to enhance customer service. Amazon Lex provides self-service options with virtual agents and automated responses, while Amazon Polly converts text into speech, enabling the creation of speech-enabled applications and products.","Amazon Lex and Amazon Polly are utilized in the Marketplace Appeals Call Center to enhance customer service. Amazon Lex provides self-service options with virtual agents and automated responses, while Amazon Polly converts text into speech, enabling the creation of speech-enabled applications and products.",,,False,False
DOE-0023-2023,DOE,Lawrence Livermore National Laboratory,,"Cyber security, data storage, and data management technologies","Data-processing pipelines and user interfaces to process and 
aggregate large, bulk, and possibly unstructured datasets allowing for 
search and export of data for further analysis in secure way",,,,Department of Energy,"Cyber security, data storage, and data management technologies: 
Data-processing pipelines and user interfaces to process and 
aggregate large, bulk, and possibly unstructured datasets allowing for 
search and export of data for further analysis in secure way","The text highlights the importance of cyber security and data management technologies in processing and storing large datasets. It emphasizes the need for data-processing pipelines and user interfaces that can handle unstructured data efficiently, while ensuring a secure environment for searching, exporting, and analyzing the data.","The text highlights the importance of cyber security and data management technologies in processing and storing large datasets. It emphasizes the need for data-processing pipelines and user interfaces that can handle unstructured data efficiently, while ensuring a secure environment for searching, exporting, and analyzing the data.",,,False,False
USDA-0029-2023,USDA,USDA,NIFA,Climate Change Classification NLP,"The model classifies NIFA funded projects as climate change related or not climate related through natural language processing techniques. The model input features include text fields containing the project's title, non-technical summary, objectives and keywords. The target is a dummy variable classification of projects as climate change related or not climate change related.",Development and Acquisition,Natural Language Processing,,Department of Agriculture,"Climate Change Classification NLP: 
The model classifies NIFA funded projects as climate change related or not climate related through natural language processing techniques. The model input features include text fields containing the project's title, non-technical summary, objectives and keywords. The target is a dummy variable classification of projects as climate change related or not climate change related.","A model is used to classify NIFA funded projects as either climate change related or not using natural language processing techniques. The model takes into account various text fields like project title, non-technical summary, objectives, and keywords. The output is a classification of projects as climate change related or not.","A model is used to classify NIFA funded projects as either climate change related or not using natural language processing techniques. The model takes into account various text fields like project title, non-technical summary, objectives, and keywords. The output is a classification of projects as climate change related or not.",,,False,False
HHS-0081-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Creating a development network,"This project has the following specific Aims:
Aim 1: To convert structured data from EHRs and linked claims into Sentinel Common Data Model at each of the participating sites
Aim 2: To develop a standardized process for storage of free text notes locally at each site and develop steps for routine meta data extraction from these notes for facilitating direct investigator access for timely execution of future Sentinel tasks",Initiation,,,Department of Health and Human Services,"Creating a development network: 
This project has the following specific Aims:
Aim 1: To convert structured data from EHRs and linked claims into Sentinel Common Data Model at each of the participating sites
Aim 2: To develop a standardized process for storage of free text notes locally at each site and develop steps for routine meta data extraction from these notes for facilitating direct investigator access for timely execution of future Sentinel tasks","The project aims to convert structured data from electronic health records and linked claims into a common data model at each site. Additionally, it seeks to develop a standardized process for storing free text notes and extracting metadata from these notes to make it easier for investigators to access and complete future tasks.","The project aims to convert structured data from electronic health records and linked claims into a common data model at each site. Additionally, it seeks to develop a standardized process for storing free text notes and extracting metadata from these notes to make it easier for investigators to access and complete future tasks.",,,False,False
VA-0001-2023,VA,,,Artificial intelligence coach in cardiac surgery,"The artificial intelligence coach in cardiac surgery infers misalignment in team members’ mental models during complex healthcare task execution. Of interest are safety-critical domains (e.g., aviation, healthcare), where lack of shared mental models can lead to preventable errors and harm. Identifying model misalignment provides a building block for enabling computer-assisted interventions to improve teamwork and augment human cognition in the operating room.",,,,Department of Veterans Affairs,"Artificial intelligence coach in cardiac surgery: 
The artificial intelligence coach in cardiac surgery infers misalignment in team members’ mental models during complex healthcare task execution. Of interest are safety-critical domains (e.g., aviation, healthcare), where lack of shared mental models can lead to preventable errors and harm. Identifying model misalignment provides a building block for enabling computer-assisted interventions to improve teamwork and augment human cognition in the operating room.","The artificial intelligence coach in cardiac surgery is able to detect when team members have different understandings or approaches to complex healthcare tasks. This is particularly important in safety-critical fields like aviation and healthcare, where differing mental models can result in errors and harm. By identifying these differences, the coach can assist in improving teamwork and enhancing human cognitive abilities during surgeries.","The artificial intelligence coach in cardiac surgery is able to detect when team members have different understandings or approaches to complex healthcare tasks. This is particularly important in safety-critical fields like aviation and healthcare, where differing mental models can result in errors and harm. By identifying these differences, the coach can assist in improving teamwork and enhancing human cognitive abilities during surgeries.",,,False,False
HHS-0150-2023,HHS,NIH,National Institutes of Health (NIH) OD/ORF,Tool for Nature Gas Procurement Planning,"With this tool, NIH can establish a natural gas procurement plan and set realistic price targets based on current long-term forecasts.",Implementation,,,Department of Health and Human Services,"Tool for Nature Gas Procurement Planning: 
With this tool, NIH can establish a natural gas procurement plan and set realistic price targets based on current long-term forecasts.",The tool for natural gas procurement planning allows NIH to create a plan for acquiring natural gas and determine feasible price goals using up-to-date long-term projections. This tool helps in efficiently managing the procurement process for natural gas.,The tool for natural gas procurement planning allows NIH to create a plan for acquiring natural gas and determine feasible price goals using up-to-date long-term projections. This tool helps in efficiently managing the procurement process for natural gas.,,,False,False
NASA-0022-2023,NASA,Marshall Space Flight Center,,Airplane detection,Deep learning-based airplane detection from high-resolution satellite imagery,In-use,,,National Aeronautics and Space Administration,"Airplane detection: 
Deep learning-based airplane detection from high-resolution satellite imagery","A deep learning algorithm has been developed to detect airplanes in high-resolution satellite imagery. This technology utilizes advanced neural networks to accurately identify and locate airplanes, which can have various applications in surveillance, transportation, and security sectors.","A deep learning algorithm has been developed to detect airplanes in high-resolution satellite imagery. This technology utilizes advanced neural networks to accurately identify and locate airplanes, which can have various applications in surveillance, transportation, and security sectors.",,,False,False
DOE-0128-2023,DOE,National Energy Technology Laboratory,,To provide an effective quality assurance method for additively manufactured gas,"The primary goal of this project is to develop a cost-effective quality 
assurance (QA) method that can rapidly qualify laser powder bed fusion 
(LPBF) processed hot gas path turbine components (HGPTCs) through 
a machine learning framework which would assimilate in-situ monitoring 
and measurement, ex-situ characterization, and simulation data.  The 
project technical deliverable will be a rapid QA tool capable of: i) building 
a metadata package of process-structure-property data and models 
intended for LPBF-processed HGPTCs by mining both simulation and in-
situ/ex-situ characterization data; and ii) qualifying online/offline a 
manufactured component by inputting simulation with/without in-situ 
monitoring data to the developed algorithms to predict porosity and 
fatigue properties. The target application of this QA tool will be 
advanced HGPTC produced by LPBF in Inconel 718. Data mining 
techniques will be developed to consolidate and analyze the 
heterogeneous big data stemmed from the aforementioned methods of 
upfront simulation, online monitoring and post-build characterization, and 
thus enabling a collaborative learning about the process-microstructure-
properties relationship. The resultant QA package includes a process-
structure-property database and machine learning tools for using LPBF 
metal AM to fabricate HGPTC. The developed metadata package 
enables online/offline qualification of additively manufactured turbine 
components by inputting simulation with/without in-situ monitoring data 
to the developed machine learning algorithms to predict porosity and 
fatigue properties.",,Artificial Intelligence Unknown,,Department of Energy,"To provide an effective quality assurance method for additively manufactured gas: 
The primary goal of this project is to develop a cost-effective quality 
assurance (QA) method that can rapidly qualify laser powder bed fusion 
(LPBF) processed hot gas path turbine components (HGPTCs) through 
a machine learning framework which would assimilate in-situ monitoring 
and measurement, ex-situ characterization, and simulation data.  The 
project technical deliverable will be a rapid QA tool capable of: i) building 
a metadata package of process-structure-property data and models 
intended for LPBF-processed HGPTCs by mining both simulation and in-
situ/ex-situ characterization data; and ii) qualifying online/offline a 
manufactured component by inputting simulation with/without in-situ 
monitoring data to the developed algorithms to predict porosity and 
fatigue properties. The target application of this QA tool will be 
advanced HGPTC produced by LPBF in Inconel 718. Data mining 
techniques will be developed to consolidate and analyze the 
heterogeneous big data stemmed from the aforementioned methods of 
upfront simulation, online monitoring and post-build characterization, and 
thus enabling a collaborative learning about the process-microstructure-
properties relationship. The resultant QA package includes a process-
structure-property database and machine learning tools for using LPBF 
metal AM to fabricate HGPTC. The developed metadata package 
enables online/offline qualification of additively manufactured turbine 
components by inputting simulation with/without in-situ monitoring data 
to the developed machine learning algorithms to predict porosity and 
fatigue properties.","This project aims to develop a cost-effective quality assurance method for gas turbine components produced using laser powder bed fusion. The method will involve using machine learning algorithms to analyze data from in-situ monitoring, ex-situ characterization, and simulation to predict porosity and fatigue properties of the components. The goal is to create a rapid QA tool that can qualify additively manufactured turbine components and provide a process-structure-property database for future use.","This project aims to develop a cost-effective quality assurance method for gas turbine components produced using laser powder bed fusion. The method will involve using machine learning algorithms to analyze data from in-situ monitoring, ex-situ characterization, and simulation to predict porosity and fatigue properties of the components. The goal is to create a rapid QA tool that can qualify additively manufactured turbine components and provide a process-structure-property database for future use.",,,False,False
USAID-0004-2023,USAID,"Bureau for Development, Democracy, and Innovation (DDI)",,Morogoro youth empowerment through establishment of social innovation (YEESI) lab for problem-centered training in machine vision,"The project proposes to establish a social innovation lab for a machine vision program that will be used by youth in the Morogoro region of Tanzania. There are young people in the area who have studied information technologies and allied sciences, and while most of them can write computer programs, they cannot solve machine vision problems. This project aims to increase awareness among the youth of Morogoro and nearby regions to address machine vision problems in agriculture. Machine vision is a new and understudied practice in Tanzania; hence, this project will contribute to efforts in the creation of scientific societies that address the most pressing problems faced by more than 80% of Tanzania’s population who engage in farming. The main agricultural problems can be classified into five categories, as explained below: (1) Disease Detection and Classification: The project will develop experts who will solve problems in disease identification using machine vision for most of the diseases in crops and livestock, which are misdiagnosed by farmers. (2) Weed Classification: The project will develop algorithms that accurately identify weeds and contribute to the growing scientific database for automatic weed detection. (3) Pest Detection and Classification: Appropriate tools using machine vision for Integrated Pest Management (IPM) are needed in Tanzania, as IPM has been hindered due to a lack of extension officers to train farmers on mitigation and identification of pests in agriculture. (4) Crop Seedlings Stand Count and Yield Estimation: Use of machine vision and drones instead of scouting manually to estimate stand counts would provide appropriate mitigation strategies for replanting that would be beneficial to commercial farmers. Also of importance are algorithms to sort and estimate yield by counting the fruits and to estimate the amount of other agricultural products. (5) Crop Vigor Estimation: Most farmers apply inputs evenly across the farm because they cannot predetermine crop vigor. Accurate estimation of crop health would help farmers to mitigate the problems earlier and improve crop performance and avoid failure. Algorithms to determine crop vigor developed in this project will contribute to the improvement of the methods to estimate crop performance earlier.",Development and Acquisition,,,U.S. Agency for International Development,"Morogoro youth empowerment through establishment of social innovation (YEESI) lab for problem-centered training in machine vision: 
The project proposes to establish a social innovation lab for a machine vision program that will be used by youth in the Morogoro region of Tanzania. There are young people in the area who have studied information technologies and allied sciences, and while most of them can write computer programs, they cannot solve machine vision problems. This project aims to increase awareness among the youth of Morogoro and nearby regions to address machine vision problems in agriculture. Machine vision is a new and understudied practice in Tanzania; hence, this project will contribute to efforts in the creation of scientific societies that address the most pressing problems faced by more than 80% of Tanzania’s population who engage in farming. The main agricultural problems can be classified into five categories, as explained below: (1) Disease Detection and Classification: The project will develop experts who will solve problems in disease identification using machine vision for most of the diseases in crops and livestock, which are misdiagnosed by farmers. (2) Weed Classification: The project will develop algorithms that accurately identify weeds and contribute to the growing scientific database for automatic weed detection. (3) Pest Detection and Classification: Appropriate tools using machine vision for Integrated Pest Management (IPM) are needed in Tanzania, as IPM has been hindered due to a lack of extension officers to train farmers on mitigation and identification of pests in agriculture. (4) Crop Seedlings Stand Count and Yield Estimation: Use of machine vision and drones instead of scouting manually to estimate stand counts would provide appropriate mitigation strategies for replanting that would be beneficial to commercial farmers. Also of importance are algorithms to sort and estimate yield by counting the fruits and to estimate the amount of other agricultural products. (5) Crop Vigor Estimation: Most farmers apply inputs evenly across the farm because they cannot predetermine crop vigor. Accurate estimation of crop health would help farmers to mitigate the problems earlier and improve crop performance and avoid failure. Algorithms to determine crop vigor developed in this project will contribute to the improvement of the methods to estimate crop performance earlier.","The text describes a project that aims to establish a social innovation lab in Morogoro, Tanzania, to provide machine vision training to young people in the area. The project aims to address agricultural problems in the region, such as disease detection, weed classification, pest detection, crop yield estimation, and crop vigor estimation, by developing experts and algorithms in machine vision. Its goal is to contribute to the improvement of farming practices and the livelihoods of farmers in Tanzania.","The text describes a project that aims to establish a social innovation lab in Morogoro, Tanzania, to provide machine vision training to young people in the area. The project aims to address agricultural problems in the region, such as disease detection, weed classification, pest detection, crop yield estimation, and crop vigor estimation, by developing experts and algorithms in machine vision. Its goal is to contribute to the improvement of farming practices and the livelihoods of farmers in Tanzania.",,,False,False
DOE-0147-2023,DOE,National Energy Technology Laboratory,,Use of machine learning models to produce surrogates for efficient optimization,"We consider the use of machine learning models to produce surrogates 
for efficient optimization. The IDAES implementation will be 
demonstrated on a real-scale design problem focused on carbon 
capture (e.g., rigorous MEA model), or an integrated energy system.",,Other,,Department of Energy,"Use of machine learning models to produce surrogates for efficient optimization: 
We consider the use of machine learning models to produce surrogates 
for efficient optimization. The IDAES implementation will be 
demonstrated on a real-scale design problem focused on carbon 
capture (e.g., rigorous MEA model), or an integrated energy system.","Machine learning models can be used to create surrogates that enhance the efficiency of optimization processes. The implementation of this approach, known as IDAES, will be showcased through a practical application related to carbon capture or an integrated energy system.","Machine learning models can be used to create surrogates that enhance the efficiency of optimization processes. The implementation of this approach, known as IDAES, will be showcased through a practical application related to carbon capture or an integrated energy system.",,,False,False
HHS-0016-2023,HHS,ASPR,"Office of Information Management, Data and Analytics",emPOWER,Using the AI capabilities to rapidly develop the empower COVID-19 At Risk Population data tools and program,Operation and Maintenance,,,Department of Health and Human Services,"emPOWER: 
Using the AI capabilities to rapidly develop the empower COVID-19 At Risk Population data tools and program",The emPOWER program utilizes AI technology to quickly create data tools and a program specifically designed to assist and protect individuals at risk of contracting COVID-19. This initiative aims to provide valuable resources and support to vulnerable populations during the pandemic.,The emPOWER program utilizes AI technology to quickly create data tools and a program specifically designed to assist and protect individuals at risk of contracting COVID-19. This initiative aims to provide valuable resources and support to vulnerable populations during the pandemic.,,,False,False
USDA-0030-2023,USDA,USDA,NRCS,Operational water supply forecasting for western US rivers,"Western US water management is underpinned by forecasts of spring-summer river flow volumes made using operational hydrologic models. The USDA Natural Resources Conservation Service (NRCS) National Water and Climate Center operates the largest such forecast system regionally, carrying on a nearly century-old tradition. The NWCC recently developed a next-generation prototype for generating such operational water supply forecasts (WSFs), the multi-model machine-learning metasystem (M4), which integrates a variety of AI and other data-science technologies carefully chosen or developed to satisfy specific user needs. Required inputs are data around snow and precipitation from the NRCS Snow Survey and Water Supply Forecast program SNOTEL environmental monitoring network, but are flexible.  In hindcasting test-cases spanning diverse environments across the western US and Alaska, out-of-sample accuracy improved markedly over current benchmarks. Various technical design elements, including multi-model ensemble modeling, autonomous machine learning (AutoML), hyperparameter pre-calibration, and theory-guided data science, collectively permitted automated training and operation.  Live operational testing at a subset of sites additionally demonstrated logistical feasibility of workflows, as well as geophysical explainability of results in terms of known hydroclimatic processes, belying the black-box reputation of machine learning and enabling relatable forecast storylines for NRCS customers.",Development and Acquisition,Machine Learning,,Department of Agriculture,"Operational water supply forecasting for western US rivers: 
Western US water management is underpinned by forecasts of spring-summer river flow volumes made using operational hydrologic models. The USDA Natural Resources Conservation Service (NRCS) National Water and Climate Center operates the largest such forecast system regionally, carrying on a nearly century-old tradition. The NWCC recently developed a next-generation prototype for generating such operational water supply forecasts (WSFs), the multi-model machine-learning metasystem (M4), which integrates a variety of AI and other data-science technologies carefully chosen or developed to satisfy specific user needs. Required inputs are data around snow and precipitation from the NRCS Snow Survey and Water Supply Forecast program SNOTEL environmental monitoring network, but are flexible.  In hindcasting test-cases spanning diverse environments across the western US and Alaska, out-of-sample accuracy improved markedly over current benchmarks. Various technical design elements, including multi-model ensemble modeling, autonomous machine learning (AutoML), hyperparameter pre-calibration, and theory-guided data science, collectively permitted automated training and operation.  Live operational testing at a subset of sites additionally demonstrated logistical feasibility of workflows, as well as geophysical explainability of results in terms of known hydroclimatic processes, belying the black-box reputation of machine learning and enabling relatable forecast storylines for NRCS customers.","The USDA National Water and Climate Center has developed a next-generation prototype for generating operational water supply forecasts using a multi-model machine-learning system. This system has improved accuracy in predicting river flow volumes and has been tested in various locations across the western US and Alaska. The use of AI and other data-science technologies has allowed for automated training and operation, and the results are explainable in terms of known hydroclimatic processes, providing relatable forecast storylines for customers.","The USDA National Water and Climate Center has developed a next-generation prototype for generating operational water supply forecasts using a multi-model machine-learning system. This system has improved accuracy in predicting river flow volumes and has been tested in various locations across the western US and Alaska. The use of AI and other data-science technologies has allowed for automated training and operation, and the results are explainable in terms of known hydroclimatic processes, providing relatable forecast storylines for customers.",,,False,False
DOC-0022-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Edge AI survey payload development,"Continued support of multispectral aerial imaging payload running detection model 
pipelines in real-time. This is a nine camera (color, infrared, ultraviolet) payload controlled 
by dedicated on-board computers with GPUs. YOLO detection models run at a rate faster 
than image collection, allowing real-time processing of imagery as it comes off the 
cameras. Goals of effort are to reduce overall data burden (by TBs) and reduce the data 
processing timeline, expediting analysis and population assessment for arctic mammals.",,,,Department of Commerce,"Edge AI survey payload development: 
Continued support of multispectral aerial imaging payload running detection model 
pipelines in real-time. This is a nine camera (color, infrared, ultraviolet) payload controlled 
by dedicated on-board computers with GPUs. YOLO detection models run at a rate faster 
than image collection, allowing real-time processing of imagery as it comes off the 
cameras. Goals of effort are to reduce overall data burden (by TBs) and reduce the data 
processing timeline, expediting analysis and population assessment for arctic mammals.","The development of a multispectral aerial imaging payload is being supported, which includes nine cameras and on-board computers with GPUs. The payload is capable of running detection models in real-time, allowing for immediate processing of imagery and reducing the amount of data and time needed for analysis of arctic mammals.","The development of a multispectral aerial imaging payload is being supported, which includes nine cameras and on-board computers with GPUs. The payload is capable of running detection models in real-time, allowing for immediate processing of imagery and reducing the amount of data and time needed for analysis of arctic mammals.",,,False,False
VA-0023-2023,VA,,,Medication Safety (MedSafe) Clinical Decision Support (CDS),"Using VA electronic clinical data, the Medication Safety (MedSafe) Clinical Decision Support (CDS) system analyzes current clinical management for diabetes, hypertension, and chronic kidney disease, and makes patient-specific, evidence-based recommendations to primary care providers.  The system uses knowledge bases that encode clinical practice guideline recommendations and an automated execution engine to examine multiple comorbidities, laboratory test results, medications, and history of adverse drug events in evaluating patient clinical status and generating patient-specific recommendations",,,,Department of Veterans Affairs,"Medication Safety (MedSafe) Clinical Decision Support (CDS): 
Using VA electronic clinical data, the Medication Safety (MedSafe) Clinical Decision Support (CDS) system analyzes current clinical management for diabetes, hypertension, and chronic kidney disease, and makes patient-specific, evidence-based recommendations to primary care providers.  The system uses knowledge bases that encode clinical practice guideline recommendations and an automated execution engine to examine multiple comorbidities, laboratory test results, medications, and history of adverse drug events in evaluating patient clinical status and generating patient-specific recommendations","The MedSafe Clinical Decision Support system analyzes clinical data to provide evidence-based recommendations for primary care providers managing diabetes, hypertension, and chronic kidney disease. It examines multiple factors such as comorbidities, lab results, medications, and adverse drug events to generate patient-specific recommendations.","The MedSafe Clinical Decision Support system analyzes clinical data to provide evidence-based recommendations for primary care providers managing diabetes, hypertension, and chronic kidney disease. It examines multiple factors such as comorbidities, lab results, medications, and adverse drug events to generate patient-specific recommendations.",,,False,False
HHS-0029-2023,HHS,CDC,NCCDPHP/DNPAO,Identifying state and local policy provisions that promote or inhibit creating healthy built environments,"The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is interested in developing and promoting natural language processing and machine learning techniques to improve the efficiency of policy surveillance. Inputs are the text of state and local policies, including law (e.g., statute, legislation, regulation, court opinion), procedure, administrative action, etc. and outputs are datasets that capture relevant aspects of the policy as quantifiable information. To date (Apr 2023), DNAPO has not performed this work in-house, but is working with a contractor on various experiments comparing machine learning with traditional methods and identifying CDC, academic and other groups doing related work.",Initiation,,,Department of Health and Human Services,"Identifying state and local policy provisions that promote or inhibit creating healthy built environments: 
The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion is interested in developing and promoting natural language processing and machine learning techniques to improve the efficiency of policy surveillance. Inputs are the text of state and local policies, including law (e.g., statute, legislation, regulation, court opinion), procedure, administrative action, etc. and outputs are datasets that capture relevant aspects of the policy as quantifiable information. To date (Apr 2023), DNAPO has not performed this work in-house, but is working with a contractor on various experiments comparing machine learning with traditional methods and identifying CDC, academic and other groups doing related work.","The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion wants to use natural language processing and machine learning to make policy surveillance more efficient. They are currently working with a contractor to compare machine learning with traditional methods and identify other groups working on similar projects. As of April 2023, the division has not done this work in-house.","The Division of Nutrition, Physical Activity, and Obesity at the National Center for Chronic Disease Prevention and Health Promotion wants to use natural language processing and machine learning to make policy surveillance more efficient. They are currently working with a contractor to compare machine learning with traditional methods and identify other groups working on similar projects. As of April 2023, the division has not done this work in-house.",,,False,False
HHS-0133-2023,HHS,NIH,National Institutes of Health (NIH) NLM,NLM-Gene: towards automatic gene indexing in PubMed articles,"Gene indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, gene indexing is performed manually by expert indexers. To assist this time-consuming and resource-intensive process, NLM developed NLM-Gene, an automatic tool for finding gene names in the biomedical literature using advanced natural language processing and deep learning methods. Its performance has been assessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.",Initiation,,,Department of Health and Human Services,"NLM-Gene: towards automatic gene indexing in PubMed articles: 
Gene indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, gene indexing is performed manually by expert indexers. To assist this time-consuming and resource-intensive process, NLM developed NLM-Gene, an automatic tool for finding gene names in the biomedical literature using advanced natural language processing and deep learning methods. Its performance has been assessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.",NLM-Gene is an automatic tool developed by NLM to assist in the manual gene indexing process in PubMed articles. It uses advanced natural language processing and deep learning methods to find gene names in biomedical literature. The tool's performance has been evaluated on gold-standard datasets and is planned to be integrated into the production MEDLINE indexing pipeline.,NLM-Gene is an automatic tool developed by NLM to assist in the manual gene indexing process in PubMed articles. It uses advanced natural language processing and deep learning methods to find gene names in biomedical literature. The tool's performance has been evaluated on gold-standard datasets and is planned to be integrated into the production MEDLINE indexing pipeline.,,,False,False
HHS-0134-2023,HHS,NIH,National Institutes of Health (NIH) NLM,NLM-Chem: towards automatic chemical indexing in PubMed articles,"Chemical indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, chemicals indexing is performed manually by expert indexers. To assist this time-consuming and resource-intensive process, NLM developed NLM-Chem, an automatic tool for finding chemical names in the biomedical literature using advanced natural language processing and deep learning methods. Its performance has been assessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.",Initiation,,,Department of Health and Human Services,"NLM-Chem: towards automatic chemical indexing in PubMed articles: 
Chemical indexing is part of the NLM's MEDLINE citation indexing efforts for improving literature retrieval and information access. Currently, chemicals indexing is performed manually by expert indexers. To assist this time-consuming and resource-intensive process, NLM developed NLM-Chem, an automatic tool for finding chemical names in the biomedical literature using advanced natural language processing and deep learning methods. Its performance has been assessed on gold-standard evaluation datasets and is to be integrated into the production MEDLINE indexing pipeline.","The NLM has developed an automatic tool called NLM-Chem to assist in the manual process of chemical indexing in PubMed articles. This tool uses advanced natural language processing and deep learning methods to find chemical names in biomedical literature. After being assessed on evaluation datasets, NLM-Chem will be integrated into the production MEDLINE indexing pipeline.","The NLM has developed an automatic tool called NLM-Chem to assist in the manual process of chemical indexing in PubMed articles. This tool uses advanced natural language processing and deep learning methods to find chemical names in biomedical literature. After being assessed on evaluation datasets, NLM-Chem will be integrated into the production MEDLINE indexing pipeline.",,,False,False
DOE-0021-2023,DOE,Lawrence Livermore National Laboratory,,AI/ML and other software advances,"Model architecture development research, including workflows, 
algorithm and performance optimization",,,,Department of Energy,"AI/ML and other software advances: 
Model architecture development research, including workflows, 
algorithm and performance optimization","The text discusses research in model architecture development for AI/ML and other software advances. This research focuses on improving workflows, optimizing algorithms, and enhancing performance.","The text discusses research in model architecture development for AI/ML and other software advances. This research focuses on improving workflows, optimizing algorithms, and enhancing performance.",,,False,False
DOC-0030-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,SUVI Thematic Maps,"The GOES-16 Solar Ultraviolet Imager (SUVI) is NOAA's operational solar extreme-
ultraviolet imager. The SUVI Level 2 Thematic Map files in these directories are produced 
by NOAA's National Centers for Environmental Information in Boulder, Colorado. These 
data have been processed from Level 2 High Dynamic Range (HDR) composite SUVI 
images. The FITS file headers are populated with metadata to facilitate interpretation by 
users of these observations. Please note that these files are considered to be 
experimental and thus will be improved in future releases. Users requiring assistance with 
these files can contact the NCEI SUVI team by emailing goesr.suvi@noaa.gov. The SUVI 
Thematic Maps product is a Level 2 data product that (presently) uses a machine learning 
classifier to generate a pixel-by-pixel map of important solar features digested from all six 
SUVI spectral channels.",,,,Department of Commerce,"SUVI Thematic Maps: 
The GOES-16 Solar Ultraviolet Imager (SUVI) is NOAA's operational solar extreme-
ultraviolet imager. The SUVI Level 2 Thematic Map files in these directories are produced 
by NOAA's National Centers for Environmental Information in Boulder, Colorado. These 
data have been processed from Level 2 High Dynamic Range (HDR) composite SUVI 
images. The FITS file headers are populated with metadata to facilitate interpretation by 
users of these observations. Please note that these files are considered to be 
experimental and thus will be improved in future releases. Users requiring assistance with 
these files can contact the NCEI SUVI team by emailing goesr.suvi@noaa.gov. The SUVI 
Thematic Maps product is a Level 2 data product that (presently) uses a machine learning 
classifier to generate a pixel-by-pixel map of important solar features digested from all six 
SUVI spectral channels.","The SUVI Thematic Maps are produced by NOAA's National Centers for Environmental Information and are derived from Level 2 High Dynamic Range composite images from the GOES-16 Solar Ultraviolet Imager. These maps use a machine learning classifier to create a detailed map of solar features from all six SUVI spectral channels. Although considered experimental, future releases will improve these files, and users can contact the NCEI SUVI team for assistance.","The SUVI Thematic Maps are produced by NOAA's National Centers for Environmental Information and are derived from Level 2 High Dynamic Range composite images from the GOES-16 Solar Ultraviolet Imager. These maps use a machine learning classifier to create a detailed map of solar features from all six SUVI spectral channels. Although considered experimental, future releases will improve these files, and users can contact the NCEI SUVI team for assistance.",,,False,False
DOI-0002-2023,DOI,BOR,,Data Driven Sub-Seasonal Forecasting of Temperature and Precipitation,"Reclamation has run 2, year-long prize competitions where particants developed and deployed data driven methods for sub-seasonal (2-6 weeks into future) prediction of temperature and precipitation across the western US. Particpants outperformed benchmark forecasts from NOAA. Reclamation is currently working with Scripps Institute of Oceanography to further refine, evaluate, and pilot implement the most promising methods from these two copmetitions. Improving sub-seasonal forecasts has significant potential to enhance water management outcomes.  ",Development (not in production),"Range of data driven, AI/ML techniques (e.g. random forests)",,Department of Interior,"Data Driven Sub-Seasonal Forecasting of Temperature and Precipitation: 
Reclamation has run 2, year-long prize competitions where particants developed and deployed data driven methods for sub-seasonal (2-6 weeks into future) prediction of temperature and precipitation across the western US. Particpants outperformed benchmark forecasts from NOAA. Reclamation is currently working with Scripps Institute of Oceanography to further refine, evaluate, and pilot implement the most promising methods from these two copmetitions. Improving sub-seasonal forecasts has significant potential to enhance water management outcomes.  ","Reclamation has conducted two year-long prize competitions to improve sub-seasonal forecasting of temperature and precipitation in the western US. Participants were able to outperform benchmark forecasts from NOAA. Reclamation is now collaborating with Scripps Institute of Oceanography to evaluate and implement the most promising methods from these competitions, as improving sub-seasonal forecasts can greatly benefit water management outcomes.","Reclamation has conducted two year-long prize competitions to improve sub-seasonal forecasting of temperature and precipitation in the western US. Participants were able to outperform benchmark forecasts from NOAA. Reclamation is now collaborating with Scripps Institute of Oceanography to evaluate and implement the most promising methods from these competitions, as improving sub-seasonal forecasts can greatly benefit water management outcomes.",,,False,False
DOE-0098-2023,DOE,National Energy Technology Laboratory,,To develop and validate sensor hardware and analytical algorithms to lower plant operating expenses for the pulverized coal utility boiler fleet,"The objective is to develop and validate sensor hardware and analytical 
algorithms to lower plant operating expenses for the pulverized coal 
utility boiler fleet. The focus is on relatively inexpensive new “Internet of 
Things” technologies to minimize capital investment. Three technologies 
will be explored for demonstration and full-scale testing in a coal-fired 
power plant. The first focuses on gas and steam temperature control 
issues at low load. The second uses sensors and analytic algorithms for 
monitoring coal pulverizer operation at lower loads to reduce the 
minimum firing capability of coal burners. The third investigates new 
sensors and advanced controls to better balance air and fuel at each 
burner enabling reduction in the minimum firing capability of coal 
burners.",,,,Department of Energy,"To develop and validate sensor hardware and analytical algorithms to lower plant operating expenses for the pulverized coal utility boiler fleet: 
The objective is to develop and validate sensor hardware and analytical 
algorithms to lower plant operating expenses for the pulverized coal 
utility boiler fleet. The focus is on relatively inexpensive new “Internet of 
Things” technologies to minimize capital investment. Three technologies 
will be explored for demonstration and full-scale testing in a coal-fired 
power plant. The first focuses on gas and steam temperature control 
issues at low load. The second uses sensors and analytic algorithms for 
monitoring coal pulverizer operation at lower loads to reduce the 
minimum firing capability of coal burners. The third investigates new 
sensors and advanced controls to better balance air and fuel at each 
burner enabling reduction in the minimum firing capability of coal 
burners.","The goal is to develop and test sensor hardware and algorithms to decrease operating expenses for coal utility boilers. This will be done using affordable ""Internet of Things"" technologies. Three specific technologies will be explored, including temperature control, monitoring coal pulverizer operation, and improving air and fuel balance.","The goal is to develop and test sensor hardware and algorithms to decrease operating expenses for coal utility boilers. This will be done using affordable ""Internet of Things"" technologies. Three specific technologies will be explored, including temperature control, monitoring coal pulverizer operation, and improving air and fuel balance.",,,False,False
DOS-0030-2023,DOS,R,,Louvain Community Detection,"Takes in a social network and clusters nodes together into “communities” (i.e., similar nodes are grouped together)",,,,Department of State,"Louvain Community Detection: 
Takes in a social network and clusters nodes together into “communities” (i.e., similar nodes are grouped together)","Louvain Community Detection is a method that groups nodes in a social network into communities based on their similarity. It clusters similar nodes together, forming distinct groups within the network.","Louvain Community Detection is a method that groups nodes in a social network into communities based on their similarity. It clusters similar nodes together, forming distinct groups within the network.",,,False,False
DOT-0004-2023,DOT,AVS,,Regulatory Compliance Mapping Tool,"The AVS International office is required to identify means of compliance to ICAO Standards and Recommended Practices (SARPs).  Both SARPs and means of compliance evidence are text paragraphs scattered across thousands of pages of documents.  AOV identified a need to find each SARP, evaluate the text of many FAA Orders, and suggest evidence of compliance based upon the evaluation of the text.  The base dataset used by RCMT is the documents’ texts deconstructed into paragraphs.  RCMT processes all the documents’ paragraphs run through Natural Language Processing (NLP) (this process has an AI aspect) to extract the meaning (semantics) of the text.    RCMT then employs a recommender system (also using some AI technology) to take the texts augmented by the texts’ meaning to establish candidate matches between the ICAO SARPs and FAA text that provides means of compliance.",User Acceptance Testing to begin early spring '22,"ML (Recommender Algorithim) , NLP,",,Department of Transportation,"Regulatory Compliance Mapping Tool: 
The AVS International office is required to identify means of compliance to ICAO Standards and Recommended Practices (SARPs).  Both SARPs and means of compliance evidence are text paragraphs scattered across thousands of pages of documents.  AOV identified a need to find each SARP, evaluate the text of many FAA Orders, and suggest evidence of compliance based upon the evaluation of the text.  The base dataset used by RCMT is the documents’ texts deconstructed into paragraphs.  RCMT processes all the documents’ paragraphs run through Natural Language Processing (NLP) (this process has an AI aspect) to extract the meaning (semantics) of the text.    RCMT then employs a recommender system (also using some AI technology) to take the texts augmented by the texts’ meaning to establish candidate matches between the ICAO SARPs and FAA text that provides means of compliance.","The Regulatory Compliance Mapping Tool (RCMT) is used by the AVS International office to identify compliance with ICAO Standards and Recommended Practices (SARPs). RCMT analyzes thousands of pages of documents to find SARPs and evaluate FAA Orders, suggesting evidence of compliance based on the evaluation. It uses Natural Language Processing (NLP) and AI technology to extract the meaning of the text and establish matches between ICAO SARPs and FAA text.","The Regulatory Compliance Mapping Tool (RCMT) is used by the AVS International office to identify compliance with ICAO Standards and Recommended Practices (SARPs). RCMT analyzes thousands of pages of documents to find SARPs and evaluate FAA Orders, suggesting evidence of compliance based on the evaluation. It uses Natural Language Processing (NLP) and AI technology to extract the meaning of the text and establish matches between ICAO SARPs and FAA text.",,,False,False
USDA-0019-2023,USDA,USDA,Forest Service,Wildland Urban Interface - Mapping Wildfire Loss,"This is a proof-of-concept study to investigate the use of machine learning (deep learning / convolutional neural networks) and object-based image classification techniques to identify buildings, building loss, and defensible space around buildings before and after a wildfire event in wildland-urban interface settings.",Development and Acquisition,Machine Learning,https://www.sciencedirect.com/science/article/pii/S221242092100501X,Department of Agriculture,"Wildland Urban Interface - Mapping Wildfire Loss: 
This is a proof-of-concept study to investigate the use of machine learning (deep learning / convolutional neural networks) and object-based image classification techniques to identify buildings, building loss, and defensible space around buildings before and after a wildfire event in wildland-urban interface settings.","This study aims to assess the potential of machine learning and object-based image classification methods in identifying buildings, building loss, and defensible space in areas at risk of wildfires. The study focuses on pre- and post-wildfire events in wildland-urban interface settings to determine the effectiveness of these techniques in mapping wildfire damage.","This study aims to assess the potential of machine learning and object-based image classification methods in identifying buildings, building loss, and defensible space in areas at risk of wildfires. The study focuses on pre- and post-wildfire events in wildland-urban interface settings to determine the effectiveness of these techniques in mapping wildfire damage.",,,False,False
HHS-0122-2023,HHS,NIH,National Institutes of Health (NIH) NIGMS,Clinical Trial Predictor,"The Clinical Trial Predictor uses an ensemble of several natural language processing and machine learning algorithms to predict whether applications may involve clinical trials based on the  text of their titles, abstracts, narratives, specific aims, and research strategies.",Implementation,,,Department of Health and Human Services,"Clinical Trial Predictor: 
The Clinical Trial Predictor uses an ensemble of several natural language processing and machine learning algorithms to predict whether applications may involve clinical trials based on the  text of their titles, abstracts, narratives, specific aims, and research strategies.","The Clinical Trial Predictor utilizes various natural language processing and machine learning algorithms to forecast whether applications may contain clinical trials based on the content of their titles, abstracts, narratives, specific aims, and research strategies.
","The Clinical Trial Predictor utilizes various natural language processing and machine learning algorithms to forecast whether applications may contain clinical trials based on the content of their titles, abstracts, narratives, specific aims, and research strategies.
",,,False,False
DOI-0019-2023,DOI,USGS,,WOS.OS.NHM National Temperature Observations,"The objectives of this project are to reduce the burden on Science Centers for the collection, storage, analysis, and processing of quality assurance data with the expectation this will lead to an increase of deployed sensors in the water temperature network. More specifically the project will (1) modify software to allow for  processing and storage of discrete water temperature data collected during streamflow measurements, (2) implement workflows and QA checks in data collection software that supports new temperature policies and procedures (3) create a pilot program to support Science Centers in accomplishing 5-pt temperature checks.",Initiation,convolutional neural networks,,Department of Interior,"WOS.OS.NHM National Temperature Observations: 
The objectives of this project are to reduce the burden on Science Centers for the collection, storage, analysis, and processing of quality assurance data with the expectation this will lead to an increase of deployed sensors in the water temperature network. More specifically the project will (1) modify software to allow for  processing and storage of discrete water temperature data collected during streamflow measurements, (2) implement workflows and QA checks in data collection software that supports new temperature policies and procedures (3) create a pilot program to support Science Centers in accomplishing 5-pt temperature checks.","The WOS.OS.NHM National Temperature Observations project aims to lessen the workload of Science Centers by streamlining the collection, storage, analysis, and processing of quality assurance data. This will likely result in a greater number of sensors being used in the water temperature network. The project will involve modifying software to accommodate discrete water temperature data, implementing new temperature policies and procedures in data collection software, and creating a pilot program to assist Science Centers with 5-point temperature checks.","The WOS.OS.NHM National Temperature Observations project aims to lessen the workload of Science Centers by streamlining the collection, storage, analysis, and processing of quality assurance data. This will likely result in a greater number of sensors being used in the water temperature network. The project will involve modifying software to accommodate discrete water temperature data, implementing new temperature policies and procedures in data collection software, and creating a pilot program to assist Science Centers with 5-point temperature checks.",,,False,False
DOS-0014-2023,DOS,FSI,,eRecords M/L Metadata Enrichment,"The Department’s central eRecords archive leverages machine learning models to add additional metadata to assist with record discovery and review. This includes models for entity extraction, sentiment analysis, classification and identifying document types.",,,,Department of State,"eRecords M/L Metadata Enrichment: 
The Department’s central eRecords archive leverages machine learning models to add additional metadata to assist with record discovery and review. This includes models for entity extraction, sentiment analysis, classification and identifying document types.","The Department's eRecords archive uses machine learning models to enhance metadata, making it easier to find and review records. The models help extract entities, analyze sentiment, classify documents, and identify document types.","The Department's eRecords archive uses machine learning models to enhance metadata, making it easier to find and review records. The models help extract entities, analyze sentiment, classify documents, and identify document types.",,,False,False
USDA-0016-2023,USDA,USDA,FPAC,Land Change Analysis Tool (LCAT),We employ a random forest machine learning classifier to produce high resolution land cover maps from aerial and/or satellite imagery.  Training data is generate from a custom-built web application.  We built and operate a 192-node docker cluster to parallize CPU-intensive processing tasks.  We are publishing results through a publicly available  Image service.  To date we have mapped over 600 million acres and have generated over 700 thousand traiing samples.,Operation and Management,Machine Learning,https://cran.r-project.org/web/packages/randomForest/randomForest.pdf<br>https://cran.r-project.org/web/packages/clhs/clhs.pdf,Department of Agriculture,"Land Change Analysis Tool (LCAT): 
We employ a random forest machine learning classifier to produce high resolution land cover maps from aerial and/or satellite imagery.  Training data is generate from a custom-built web application.  We built and operate a 192-node docker cluster to parallize CPU-intensive processing tasks.  We are publishing results through a publicly available  Image service.  To date we have mapped over 600 million acres and have generated over 700 thousand traiing samples.","The Land Change Analysis Tool (LCAT) uses a random forest machine learning classifier to create detailed land cover maps using aerial and/or satellite imagery. They collect training data through a web application and process it using a 192-node docker cluster. The results are published through an Image service, and they have already mapped over 600 million acres and generated over 700 thousand training samples.","The Land Change Analysis Tool (LCAT) uses a random forest machine learning classifier to create detailed land cover maps using aerial and/or satellite imagery. They collect training data through a web application and process it using a 192-node docker cluster. The results are published through an Image service, and they have already mapped over 600 million acres and generated over 700 thousand training samples.",,,False,False
DOI-0029-2023,DOI,USGS,,Vegetation and Water Dynamics,"Major activities include tracking vegetation phenology as a basic input for drought monitoring and for capturing the unique phenological signatures associated with irrigated agriculture and invasive species. Drought mapping and monitoring focus on two conterminous US wide operational tools, VegDRI and QuickDRI, to inform drought severity in a timely fashion. A targeted livestock forage assessment tool is tailored to quantify drought effects in terms of livestock forage deficits in kg/ha for specific producer decision makers. High latitude systems have high carbon stocks, particularly the numerous wetlands. Understanding spatiotemporal surface water dynamics will inform of permafrost degradation and probable methane emission hot spots. Vegetation phenology signatures improve land cover class separations and capture unique phenological signatures associated with invasive species like cheatgrass. Understanding remote sensing sensitivity of phenology tracking at various spatial resolutions and varying degrees of noise associated with mixed pixel effects of other vegetation, soils, and water improves accuracy and consistency of estimations of phenology as well as derivative products tailored for specific land manager use. The determination of irrigated and non-irrigated system provides useful geospatial data for water management and can serve to isolate ecological comparisons or contrasts to either irrigated or non-irrigated land management.",Initiation,Convolutional Neural Networks,,Department of Interior,"Vegetation and Water Dynamics: 
Major activities include tracking vegetation phenology as a basic input for drought monitoring and for capturing the unique phenological signatures associated with irrigated agriculture and invasive species. Drought mapping and monitoring focus on two conterminous US wide operational tools, VegDRI and QuickDRI, to inform drought severity in a timely fashion. A targeted livestock forage assessment tool is tailored to quantify drought effects in terms of livestock forage deficits in kg/ha for specific producer decision makers. High latitude systems have high carbon stocks, particularly the numerous wetlands. Understanding spatiotemporal surface water dynamics will inform of permafrost degradation and probable methane emission hot spots. Vegetation phenology signatures improve land cover class separations and capture unique phenological signatures associated with invasive species like cheatgrass. Understanding remote sensing sensitivity of phenology tracking at various spatial resolutions and varying degrees of noise associated with mixed pixel effects of other vegetation, soils, and water improves accuracy and consistency of estimations of phenology as well as derivative products tailored for specific land manager use. The determination of irrigated and non-irrigated system provides useful geospatial data for water management and can serve to isolate ecological comparisons or contrasts to either irrigated or non-irrigated land management.","The text discusses various activities related to vegetation and water dynamics, such as tracking vegetation phenology for drought monitoring and identifying phenological signatures associated with irrigated agriculture and invasive species. It mentions the use of tools like VegDRI and QuickDRI for drought mapping and monitoring, as well as a livestock forage assessment tool for quantifying drought effects on livestock forage deficits. Additionally, understanding surface water dynamics and differentiating between irrigated and non-irrigated systems provides valuable geospatial data for water management and ecological comparisons.","The text discusses various activities related to vegetation and water dynamics, such as tracking vegetation phenology for drought monitoring and identifying phenological signatures associated with irrigated agriculture and invasive species. It mentions the use of tools like VegDRI and QuickDRI for drought mapping and monitoring, as well as a livestock forage assessment tool for quantifying drought effects on livestock forage deficits. Additionally, understanding surface water dynamics and differentiating between irrigated and non-irrigated systems provides valuable geospatial data for water management and ecological comparisons.",,,False,False
VA-0010-2023,VA,,,Machine learning (ML) for enhanced diagnostic error detection and ML classification of protein electrophoresis text,"Researchers are performing chart review to collect true/false positive annotations and construct a vector embedding of patient records, followed by similarity-based retrieval of unlabeled records ""near"" the labeled ones (semi-supervised approach). The aim is to use machine learning as a filter, after the rules-based retrieval, to improve specificity. Embedding inputs will be selected high-value structured data pertinent to stroke risk and possibly selected prior text notes.",,,,Department of Veterans Affairs,"Machine learning (ML) for enhanced diagnostic error detection and ML classification of protein electrophoresis text: 
Researchers are performing chart review to collect true/false positive annotations and construct a vector embedding of patient records, followed by similarity-based retrieval of unlabeled records ""near"" the labeled ones (semi-supervised approach). The aim is to use machine learning as a filter, after the rules-based retrieval, to improve specificity. Embedding inputs will be selected high-value structured data pertinent to stroke risk and possibly selected prior text notes.","Researchers are using machine learning to improve the detection of diagnostic errors and classify protein electrophoresis text. They are collecting true/false positive annotations through chart review and creating a vector embedding of patient records. This embedding will be used to retrieve unlabeled records similar to the labeled ones, and machine learning will be used as a filter to enhance specificity after rules-based retrieval. The selected inputs for embedding will include structured data related to stroke risk and potentially previous text notes.","Researchers are using machine learning to improve the detection of diagnostic errors and classify protein electrophoresis text. They are collecting true/false positive annotations through chart review and creating a vector embedding of patient records. This embedding will be used to retrieve unlabeled records similar to the labeled ones, and machine learning will be used as a filter to enhance specificity after rules-based retrieval. The selected inputs for embedding will include structured data related to stroke risk and potentially previous text notes.",,,False,False
DOE-0057-2023,DOE,National Energy Technology Laboratory,,Machine learning to refine and analyze data for CCS needs,"Utilze and apply different machine learning approaches to process data 
and generate new derivative data products that help address CCS 
stakeholder data-needs for resource evaluation, risk assessment, 
supply chain, social and environmental justice evaluations, regulatory 
compliance, and more.",,"Big Data, Other",,Department of Energy,"Machine learning to refine and analyze data for CCS needs: 
Utilze and apply different machine learning approaches to process data 
and generate new derivative data products that help address CCS 
stakeholder data-needs for resource evaluation, risk assessment, 
supply chain, social and environmental justice evaluations, regulatory 
compliance, and more.","Machine learning techniques are used to analyze and refine data for CCS (carbon capture and storage) requirements. These techniques generate new data products that assist in various areas such as resource evaluation, risk assessment, supply chain analysis, social and environmental justice evaluations, and regulatory compliance.","Machine learning techniques are used to analyze and refine data for CCS (carbon capture and storage) requirements. These techniques generate new data products that assist in various areas such as resource evaluation, risk assessment, supply chain analysis, social and environmental justice evaluations, and regulatory compliance.",,,False,False
DOE-0013-2023,DOE,Fermi National Accelerator,,Simulation-based inference for cosmology,"This project will develop and use simulation-based inference to estimate 
cosmological parameters related to cosmic acceleration in the early and 
late universe — via the cosmic microwave background and strong 
gravitational lensing, respectively. This will produce an analysis pipeline 
that can be deployed for next-generation cosmic surveys.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"Simulation-based inference for cosmology: 
This project will develop and use simulation-based inference to estimate 
cosmological parameters related to cosmic acceleration in the early and 
late universe — via the cosmic microwave background and strong 
gravitational lensing, respectively. This will produce an analysis pipeline 
that can be deployed for next-generation cosmic surveys.","The project aims to develop and utilize simulation-based inference to estimate cosmological parameters concerning cosmic acceleration in the early and late universe. By analyzing the cosmic microwave background and strong gravitational lensing, an analysis pipeline will be created that can be applied to future cosmic surveys.","The project aims to develop and utilize simulation-based inference to estimate cosmological parameters concerning cosmic acceleration in the early and late universe. By analyzing the cosmic microwave background and strong gravitational lensing, an analysis pipeline will be created that can be applied to future cosmic surveys.",,,False,False
DOL-0012-2023,DOL,,,Automatic Document Processing,Automatic processing of continuation of benefits form to extract pre-defined selection boxes.,Implementation,Cloud based commercial-off-the-shelf pre-trained NLP models,,Department of Labor,"Automatic Document Processing: 
Automatic processing of continuation of benefits form to extract pre-defined selection boxes.",Automatic Document Processing involves using technology to extract pre-defined selection boxes from a continuation of benefits form. This process is done automatically without manual intervention.,Automatic Document Processing involves using technology to extract pre-defined selection boxes from a continuation of benefits form. This process is done automatically without manual intervention.,,,False,False
HHS-0118-2023,HHS,NIH,National Institutes of Health (NIH) NIDCR,NIDCR Data Bank,"The project will permit intramural research program investigators to move large sets of unstructured data into a cloud archival storage, which will scale, provide cost effective data tiering, capture robust meta data sufficient for management and governance, and create secondary or tertiary opportunities for analysis leveraging cognitive services AI/ML/NLP toolsets.",Development and Acquisition,,,Department of Health and Human Services,"NIDCR Data Bank: 
The project will permit intramural research program investigators to move large sets of unstructured data into a cloud archival storage, which will scale, provide cost effective data tiering, capture robust meta data sufficient for management and governance, and create secondary or tertiary opportunities for analysis leveraging cognitive services AI/ML/NLP toolsets.","The NIDCR Data Bank project allows researchers to transfer large amounts of unorganized data into a cloud-based storage system. This storage system is scalable, cost-effective, and includes metadata for efficient management and governance. Additionally, it offers opportunities for further analysis using artificial intelligence and machine learning tools.","The NIDCR Data Bank project allows researchers to transfer large amounts of unorganized data into a cloud-based storage system. This storage system is scalable, cost-effective, and includes metadata for efficient management and governance. Additionally, it offers opportunities for further analysis using artificial intelligence and machine learning tools.",,,False,False
HHS-0149-2023,HHS,NIH,National Institutes of Health (NIH) OD/OER,NIH Grants Virtual Assistant,Chat Bot to assist users in finding grant related information via OER resources,Operation and Maintenance,,,Department of Health and Human Services,"NIH Grants Virtual Assistant: 
Chat Bot to assist users in finding grant related information via OER resources",The NIH has developed a virtual assistant called Chat Bot to help users in locating grant-related information through OER resources. This virtual assistant aims to provide assistance and guidance to individuals seeking information about grants.,The NIH has developed a virtual assistant called Chat Bot to help users in locating grant-related information through OER resources. This virtual assistant aims to provide assistance and guidance to individuals seeking information about grants.,,,False,False
DOC-0028-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,The Development of ProbSevere v3 - An improved nowcasting model in support of severe weather warning operations,"ProbSevere is a ML model that utilizes NWP, satellite, radar, and lightning data to nowcast 
severe wind, severe hail, and tornadoes. ProbSevere, which was transitioned to NWS 
operations in October 2020, is a proven tool that enhances operational severe weather 
warnings. This project aims to develop the next version of ProbSevere, ProbSevere v3. 
ProbSevere v3 utilizes additional data sets and improved machine learning techniques to 
improve upon the operational version of ProbSevere. ProbSevere v3 was successfully 
demonstrated in the 2021 Hazardous Weather Testbed and a JTTI proposal was recently 
submitted to facilitate an operational update. The development is funded by GOES-R.",,,,Department of Commerce,"The Development of ProbSevere v3 - An improved nowcasting model in support of severe weather warning operations: 
ProbSevere is a ML model that utilizes NWP, satellite, radar, and lightning data to nowcast 
severe wind, severe hail, and tornadoes. ProbSevere, which was transitioned to NWS 
operations in October 2020, is a proven tool that enhances operational severe weather 
warnings. This project aims to develop the next version of ProbSevere, ProbSevere v3. 
ProbSevere v3 utilizes additional data sets and improved machine learning techniques to 
improve upon the operational version of ProbSevere. ProbSevere v3 was successfully 
demonstrated in the 2021 Hazardous Weather Testbed and a JTTI proposal was recently 
submitted to facilitate an operational update. The development is funded by GOES-R.","ProbSevere v3 is an improved nowcasting model that uses various data sources to predict severe weather events such as wind, hail, and tornadoes. It has already been proven to enhance severe weather warnings and the development of the next version, ProbSevere v3, aims to further improve upon its capabilities by incorporating additional data sets and better machine learning techniques. The project has received funding from GOES-R and has successfully demonstrated its effectiveness in the 2021 Hazardous Weather Testbed, with a proposal submitted for an operational update.","ProbSevere v3 is an improved nowcasting model that uses various data sources to predict severe weather events such as wind, hail, and tornadoes. It has already been proven to enhance severe weather warnings and the development of the next version, ProbSevere v3, aims to further improve upon its capabilities by incorporating additional data sets and better machine learning techniques. The project has received funding from GOES-R and has successfully demonstrated its effectiveness in the 2021 Hazardous Weather Testbed, with a proposal submitted for an operational update.",,,False,False
DOE-0040-2023,DOE,National Energy Technology Laboratory,,"Data platform to expedite access and reuse of carbon ore data for materials, manufacturing and research","Data platform to expedite access and reuse of carbon ore data for 
materials, manufacturing and research.  Assembled using data science, 
NLP methods, and hosted in virtual, multi-cloud platform for online 
analytics.",,"Natural Language Processing, Other",,Department of Energy,"Data platform to expedite access and reuse of carbon ore data for materials, manufacturing and research: 
Data platform to expedite access and reuse of carbon ore data for 
materials, manufacturing and research.  Assembled using data science, 
NLP methods, and hosted in virtual, multi-cloud platform for online 
analytics.","A data platform has been developed to quickly and efficiently access and reuse carbon ore data for various purposes such as materials, manufacturing, and research. This platform utilizes data science and natural language processing (NLP) techniques and is hosted in a virtual, multi-cloud environment to enable online analytics.","A data platform has been developed to quickly and efficiently access and reuse carbon ore data for various purposes such as materials, manufacturing, and research. This platform utilizes data science and natural language processing (NLP) techniques and is hosted in a virtual, multi-cloud environment to enable online analytics.",,,False,False
DHS-0035-2023,DHS,United States Citizenship and Immigration Services,,Identity Match Option (IMO) Process with DBIS Data Marts,"The Identity Match Option (IMO) is used to derive a single identity across multiple systems for each applicant or beneficiary who interacts with USCIS. The IMO aims to aid in person-centric research and analytics. 

USCIS maintains a variety of systems to track specific interactions with individuals – benefits case management, appointment scheduling, background check validation, and customer service inquiries.  Each system captures its own person-centric data attributes (e.g. SSN, A-number, Name, DOB, address, etc.) related to individuals interacting with the agency. The identity derivation process uses standard entity matching algorithms included as part of the IMO product to leverage these individual instances of person-centric data attributes to derive identities. The system is able to account for a variety of data formats and potential data quality issues in the source data. The resulting identities are linked back to the original source records, allowing analysts to see an individual’s comprehensive immigration history with the agency, perform fraud detection, and identify data quality issues requiring resolution.",Operation and Maintenance,Criteria based identification,,Department of Homeland Security,"Identity Match Option (IMO) Process with DBIS Data Marts: 
The Identity Match Option (IMO) is used to derive a single identity across multiple systems for each applicant or beneficiary who interacts with USCIS. The IMO aims to aid in person-centric research and analytics. 

USCIS maintains a variety of systems to track specific interactions with individuals – benefits case management, appointment scheduling, background check validation, and customer service inquiries.  Each system captures its own person-centric data attributes (e.g. SSN, A-number, Name, DOB, address, etc.) related to individuals interacting with the agency. The identity derivation process uses standard entity matching algorithms included as part of the IMO product to leverage these individual instances of person-centric data attributes to derive identities. The system is able to account for a variety of data formats and potential data quality issues in the source data. The resulting identities are linked back to the original source records, allowing analysts to see an individual’s comprehensive immigration history with the agency, perform fraud detection, and identify data quality issues requiring resolution.","The Identity Match Option (IMO) process is used by USCIS to create a single identity for each applicant or beneficiary across multiple systems. This process uses standard entity matching algorithms to combine person-centric data attributes from various systems, allowing analysts to view an individual's immigration history, detect fraud, and resolve data quality issues.","The Identity Match Option (IMO) process is used by USCIS to create a single identity for each applicant or beneficiary across multiple systems. This process uses standard entity matching algorithms to combine person-centric data attributes from various systems, allowing analysts to view an individual's immigration history, detect fraud, and resolve data quality issues.",,,False,False
DOL-0009-2023,DOL,,,Official Document Validation,AI detection of mismatched addresses and garbled text in official letters sent to benefits recipients.,Implementation,Computer Vision,,Department of Labor,"Official Document Validation: 
AI detection of mismatched addresses and garbled text in official letters sent to benefits recipients.",AI technology can be used to validate official documents by detecting discrepancies in addresses and identifying text that is unreadable or distorted in letters sent to recipients of benefits. This helps ensure the accuracy and clarity of important communications.,AI technology can be used to validate official documents by detecting discrepancies in addresses and identifying text that is unreadable or distorted in letters sent to recipients of benefits. This helps ensure the accuracy and clarity of important communications.,,,False,False
DOI-0010-2023,DOI,BSEE,,Well Activity Report Classification,Researching the use of self-supervised and supervised deep neural networks to identify classification systems for significant well event using data from well Activity Reports,Development (not in production),"Natural language processing (NLP) along with supervised and self-supervised machine learning via deep learning models, such as a Residual Neural Network (ResNet) and Convolutional Neural Networks (CNN).",,Department of Interior,"Well Activity Report Classification: 
Researching the use of self-supervised and supervised deep neural networks to identify classification systems for significant well event using data from well Activity Reports",The text discusses the classification of significant well events using data from well Activity Reports. The research focuses on the use of self-supervised and supervised deep neural networks to identify classification systems for these events.,The text discusses the classification of significant well events using data from well Activity Reports. The research focuses on the use of self-supervised and supervised deep neural networks to identify classification systems for these events.,,,False,False
HHS-0097-2023,HHS,FDA,NCTR,Assessing and mitigating bias in applying Artificial Intelligence (AI) based natural language processing (NLP) of drug labeling documents,"As use of AI in biomedical sciences increases, significant concerns are raised regarding bias, stereotype, or prejudice in some AI systems. An AI system trained on inappropriate or inadequate data may reinforce biased patterns and thus provide biased predictions. Particularly, when the AI model was trained on dataset from different domains and then transferred to a new application domain, the system needs to be evaluated properly to avoid potential bias risks.
Given the increased number of transfer learning and AI applications in document analysis to support FDA review, this proposal is to conduct a comprehensive study to understand and assess the bias in applying AI based natural language processing of drug labeling documents, and to the extension of developing a strategy to mitigate such a bias.",Initiation,,,Department of Health and Human Services,"Assessing and mitigating bias in applying Artificial Intelligence (AI) based natural language processing (NLP) of drug labeling documents: 
As use of AI in biomedical sciences increases, significant concerns are raised regarding bias, stereotype, or prejudice in some AI systems. An AI system trained on inappropriate or inadequate data may reinforce biased patterns and thus provide biased predictions. Particularly, when the AI model was trained on dataset from different domains and then transferred to a new application domain, the system needs to be evaluated properly to avoid potential bias risks.
Given the increased number of transfer learning and AI applications in document analysis to support FDA review, this proposal is to conduct a comprehensive study to understand and assess the bias in applying AI based natural language processing of drug labeling documents, and to the extension of developing a strategy to mitigate such a bias.",This text discusses the concerns about bias in AI systems used for natural language processing of drug labeling documents. It emphasizes the need to properly evaluate AI models trained on different domains to avoid potential bias risks. The proposal suggests conducting a study to understand and assess bias in this application and develop strategies to mitigate it.,This text discusses the concerns about bias in AI systems used for natural language processing of drug labeling documents. It emphasizes the need to properly evaluate AI models trained on different domains to avoid potential bias risks. The proposal suggests conducting a study to understand and assess bias in this application and develop strategies to mitigate it.,,,False,False
HHS-0106-2023,HHS,FDA,NCTR,Identification of sex differences on prescription opioid use (POU)-related cardiovascular risks by big data analysis,"1) Prescription opioid use (POU) varies among patient population subgroups, such as gender, age, and ethnicity. POU can potentially cause various adverse effects in the respiratory, gastrointestinal, musculoskeletal, cardiovascular, immune, endocrine, and central nervous systems. Important sex differences have been observed in POU-associated cardiac endpoints. Currently, systematic knowledge is lacking for risk factors associated with the increased cardiotoxicity of POU in women. 2) Currently, the FDA utilizes two methods of analysis for data mining, the Proportional Reporting Ratio (PRR) and the Empirical Bayesian Geometric Mean (EBGM) to identify significant statistical associations between products and adverse events (AEs). These methods are not applicable when two or more reporting measures (e.g. gender, age, race, etc.) must be considered and compared. In this study, a novel statistical model will be developed to detect the safety signals when gender is considered as the third variable. Safety signals will then be detected and compared from combined multiple-layered real-world evidence in the form of EHRs from diverse sources. Sex-dependent differences in risk factors for cardiotoxicity from POU will be identified and analyzed using big data methods and AI-related tools. 3) The proposed project addresses the first of four priority areas of FDA's 2018 Strategic Policy Roadmap: Reduce the burden of addiction crises that are threatening American families, and two priority areas of Women's Health Research Roadmap: Priority Area 1: Advance Safety and Efficacy, and Priority Area 5: Expand Data Sources and Analysis. The results may provide information and knowledge to help the FDA drug reviewers and physicians be aware of sex differences to certain POU drugs and combinations of POU with other prescription drugs, therefore, preventing or reducing risk of the POU drug-induced CVD in women.",Development and Acquisition,,,Department of Health and Human Services,"Identification of sex differences on prescription opioid use (POU)-related cardiovascular risks by big data analysis: 
1) Prescription opioid use (POU) varies among patient population subgroups, such as gender, age, and ethnicity. POU can potentially cause various adverse effects in the respiratory, gastrointestinal, musculoskeletal, cardiovascular, immune, endocrine, and central nervous systems. Important sex differences have been observed in POU-associated cardiac endpoints. Currently, systematic knowledge is lacking for risk factors associated with the increased cardiotoxicity of POU in women. 2) Currently, the FDA utilizes two methods of analysis for data mining, the Proportional Reporting Ratio (PRR) and the Empirical Bayesian Geometric Mean (EBGM) to identify significant statistical associations between products and adverse events (AEs). These methods are not applicable when two or more reporting measures (e.g. gender, age, race, etc.) must be considered and compared. In this study, a novel statistical model will be developed to detect the safety signals when gender is considered as the third variable. Safety signals will then be detected and compared from combined multiple-layered real-world evidence in the form of EHRs from diverse sources. Sex-dependent differences in risk factors for cardiotoxicity from POU will be identified and analyzed using big data methods and AI-related tools. 3) The proposed project addresses the first of four priority areas of FDA's 2018 Strategic Policy Roadmap: Reduce the burden of addiction crises that are threatening American families, and two priority areas of Women's Health Research Roadmap: Priority Area 1: Advance Safety and Efficacy, and Priority Area 5: Expand Data Sources and Analysis. The results may provide information and knowledge to help the FDA drug reviewers and physicians be aware of sex differences to certain POU drugs and combinations of POU with other prescription drugs, therefore, preventing or reducing risk of the POU drug-induced CVD in women.","The text discusses the need to identify and analyze sex differences in prescription opioid use (POU)-related cardiovascular risks. Currently, there is a lack of systematic knowledge regarding risk factors associated with increased cardiotoxicity in women. The proposed project aims to develop a statistical model using big data methods and AI-related tools to detect safety signals in POU and identify sex-dependent differences in risk factors for cardiotoxicity. The results of this research may help the FDA and physicians prevent or reduce the risk of POU drug-induced cardiovascular disease in women.","The text discusses the need to identify and analyze sex differences in prescription opioid use (POU)-related cardiovascular risks. Currently, there is a lack of systematic knowledge regarding risk factors associated with increased cardiotoxicity in women. The proposed project aims to develop a statistical model using big data methods and AI-related tools to detect safety signals in POU and identify sex-dependent differences in risk factors for cardiotoxicity. The results of this research may help the FDA and physicians prevent or reduce the risk of POU drug-induced cardiovascular disease in women.",,,False,False
DOI-0018-2023,DOI,USGS,,Twitchell Rice AFRI,"A large, interdisciplinary study (led by UC Davis in collaboration with UC Berkeley, the USGS and several private consultants) will be investigating the effects (subsidence, gas flux and water quality) of converting acreage on Twitchell Island, a deeply subsided island in the Sacramento-San Joaquin Delta, from drained row crops to flooded rice production.  The USGS research objective is to assess water quality effects with respect to MeHg production under different rice management practices including tillage, flooding and fertilization quantifying the relative methylation potential of each practice.",Implementation,convolutional neural networks,,Department of Interior,"Twitchell Rice AFRI: 
A large, interdisciplinary study (led by UC Davis in collaboration with UC Berkeley, the USGS and several private consultants) will be investigating the effects (subsidence, gas flux and water quality) of converting acreage on Twitchell Island, a deeply subsided island in the Sacramento-San Joaquin Delta, from drained row crops to flooded rice production.  The USGS research objective is to assess water quality effects with respect to MeHg production under different rice management practices including tillage, flooding and fertilization quantifying the relative methylation potential of each practice.","A study led by UC Davis and in collaboration with UC Berkeley, the USGS, and private consultants will investigate the effects of converting drained row crops to flooded rice production on Twitchell Island in the Sacramento-San Joaquin Delta. The USGS's research objective is to assess the water quality effects, specifically MeHg production, under different rice management practices such as tillage, flooding, and fertilization, and determine the relative methylation potential of each practice.","A study led by UC Davis and in collaboration with UC Berkeley, the USGS, and private consultants will investigate the effects of converting drained row crops to flooded rice production on Twitchell Island in the Sacramento-San Joaquin Delta. The USGS's research objective is to assess the water quality effects, specifically MeHg production, under different rice management practices such as tillage, flooding, and fertilization, and determine the relative methylation potential of each practice.",,,False,False
DOE-0060-2023,DOE,National Energy Technology Laboratory,,ML-based proxy models and multi- level data driven fracture network imaging to support rapid decision making.,"ML-based proxy-models of fracture network, HF geometry, HF 
properties, bottomhole pressure and drainage volume contribute to 
fracture network, production forecast and well drainage volume 
visualizations.",,Other,,Department of Energy,"ML-based proxy models and multi- level data driven fracture network imaging to support rapid decision making.: 
ML-based proxy-models of fracture network, HF geometry, HF 
properties, bottomhole pressure and drainage volume contribute to 
fracture network, production forecast and well drainage volume 
visualizations.","The use of ML-based proxy models and multi-level data driven fracture network imaging enhances decision making by providing visualizations of fracture network, production forecast, and well drainage volume. These models consider factors such as fracture network, HF geometry, HF properties, bottomhole pressure, and drainage volume to generate accurate predictions.","The use of ML-based proxy models and multi-level data driven fracture network imaging enhances decision making by providing visualizations of fracture network, production forecast, and well drainage volume. These models consider factors such as fracture network, HF geometry, HF properties, bottomhole pressure, and drainage volume to generate accurate predictions.",,,False,False
HHS-0130-2023,HHS,NIH,National Institutes of Health (NIH) NLM,Best Match: New relevance search for PubMed,"PubMed is a free search engine for biomedical literature accessed by millions of users from around the world each day. With the rapid growth of biomedical literature, finding and retrieving the most relevant papers for a given query is increasingly challenging. NLM developed Best Match, a new relevance search algorithm for PubMed that leverages the intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date sort order. ",Operation and Maintenance,,,Department of Health and Human Services,"Best Match: New relevance search for PubMed: 
PubMed is a free search engine for biomedical literature accessed by millions of users from around the world each day. With the rapid growth of biomedical literature, finding and retrieving the most relevant papers for a given query is increasingly challenging. NLM developed Best Match, a new relevance search algorithm for PubMed that leverages the intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date sort order. ","PubMed, a widely-used search engine for biomedical literature, has introduced a new relevance search algorithm called Best Match. This algorithm, developed by NLM, uses machine-learning technology and user input to help users find the most relevant papers for their queries, overcoming the challenge posed by the increasing volume of biomedical literature. Best Match replaces the traditional date sort order, offering an alternative approach to retrieving information.","PubMed, a widely-used search engine for biomedical literature, has introduced a new relevance search algorithm called Best Match. This algorithm, developed by NLM, uses machine-learning technology and user input to help users find the most relevant papers for their queries, overcoming the challenge posed by the increasing volume of biomedical literature. Best Match replaces the traditional date sort order, offering an alternative approach to retrieving information.",,,False,False
DOE-0170-2023,DOE,Pacific Northwest National Laboratory,,Laboratory Automation,"Employing machine learning to identify regions of interest in SEM and 
TEM data. Automating data acquisition to improve efficiencies.",,,,Department of Energy,"Laboratory Automation: 
Employing machine learning to identify regions of interest in SEM and 
TEM data. Automating data acquisition to improve efficiencies.","Laboratory automation utilizes machine learning to efficiently and accurately identify specific areas of interest in scanning electron microscope (SEM) and transmission electron microscope (TEM) data. This process automates data acquisition, resulting in improved productivity and efficiency in laboratory operations.","Laboratory automation utilizes machine learning to efficiently and accurately identify specific areas of interest in scanning electron microscope (SEM) and transmission electron microscope (TEM) data. This process automates data acquisition, resulting in improved productivity and efficiency in laboratory operations.",,,False,False
DOE-0055-2023,DOE,National Energy Technology Laboratory,,Machine learning for legacy well evaluation,"Use machine learning to identify common attributes that correlated to 
well integrity issues to prioritize for monitoring and remediation.",,Other,,Department of Energy,"Machine learning for legacy well evaluation: 
Use machine learning to identify common attributes that correlated to 
well integrity issues to prioritize for monitoring and remediation.",Machine learning is utilized to detect patterns and attributes that are associated with well integrity problems in legacy wells. This enables the identification and prioritization of monitoring and remediation efforts for these issues.,Machine learning is utilized to detect patterns and attributes that are associated with well integrity problems in legacy wells. This enables the identification and prioritization of monitoring and remediation efforts for these issues.,,,False,False
DOE-0138-2023,DOE,National Energy Technology Laboratory,,To use data analytics and machine learning techniques to advance understanding of the characteristics of the Emerging Paradox Oil Play,"Using data analytics and machine learning techniques to advance 
understanding of the characteristics of the entire Parardox oil play 
through integration of geologic and log-derived “electrofacies” models 
and upscaling to 3D seismic data and propagation through the seismic 
volume.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"To use data analytics and machine learning techniques to advance understanding of the characteristics of the Emerging Paradox Oil Play: 
Using data analytics and machine learning techniques to advance 
understanding of the characteristics of the entire Parardox oil play 
through integration of geologic and log-derived “electrofacies” models 
and upscaling to 3D seismic data and propagation through the seismic 
volume.",The text states that data analytics and machine learning techniques will be utilized to enhance knowledge about the characteristics of the Emerging Paradox Oil Play. The goal is to integrate geologic and log-derived models with 3D seismic data to gain a comprehensive understanding of the entire Paradox oil play.,The text states that data analytics and machine learning techniques will be utilized to enhance knowledge about the characteristics of the Emerging Paradox Oil Play. The goal is to integrate geologic and log-derived models with 3D seismic data to gain a comprehensive understanding of the entire Paradox oil play.,,,False,False
DOE-0115-2023,DOE,National Energy Technology Laboratory,,"To help automate data discovery and preparations to support a range of CS models, tools, and products","AI & ML are used to help collect and process data from multipel sources 
to further integrate and characterize infromation to provide additional 
data and infromation to support a range of carbon storage work",,"Big Data, Natural Language Processing, Other",,Department of Energy,"To help automate data discovery and preparations to support a range of CS models, tools, and products: 
AI & ML are used to help collect and process data from multipel sources 
to further integrate and characterize infromation to provide additional 
data and infromation to support a range of carbon storage work","AI and ML technologies are employed to automate the collection and processing of data from multiple sources for various CS models, tools, and products. This integration and analysis of information helps in providing additional data and information to support different carbon storage tasks.","AI and ML technologies are employed to automate the collection and processing of data from multiple sources for various CS models, tools, and products. This integration and analysis of information helps in providing additional data and information to support different carbon storage tasks.",,,False,False
HHS-0156-2023,HHS,OIG,OIG,Text Analytics Portal,"The text analytics portal allows personnel without an analytics background to quickly examine text documents through a related set of search, topic modeling and entity recognition technologies; Initial implementation's focus is on HHS-OIG specific use cases.",Implementation,,,Department of Health and Human Services,"Text Analytics Portal: 
The text analytics portal allows personnel without an analytics background to quickly examine text documents through a related set of search, topic modeling and entity recognition technologies; Initial implementation's focus is on HHS-OIG specific use cases.","The text analytics portal enables non-analytics professionals to efficiently analyze text documents using search, topic modeling, and entity recognition technologies. It is primarily designed for HHS-OIG specific scenarios in its initial implementation.","The text analytics portal enables non-analytics professionals to efficiently analyze text documents using search, topic modeling, and entity recognition technologies. It is primarily designed for HHS-OIG specific scenarios in its initial implementation.",,,False,False
DOS-0019-2023,DOS,IRM,,AI Capabilities Embedded in SMART,"Models have been embedded in the backend of the SMART system on OpenNet to perform entity extraction of objects within cables, sentiment analysis of cables, keyword extraction of topics identified within cables, and historical data analysis to recommend addressees and passlines to users when composing cables.",,,,Department of State,"AI Capabilities Embedded in SMART: 
Models have been embedded in the backend of the SMART system on OpenNet to perform entity extraction of objects within cables, sentiment analysis of cables, keyword extraction of topics identified within cables, and historical data analysis to recommend addressees and passlines to users when composing cables.","The SMART system on OpenNet incorporates AI models in its backend to perform various tasks such as extracting objects within cables, analyzing the sentiment of cables, extracting keywords of identified topics, and analyzing historical data to provide recommendations to users when composing cables.","The SMART system on OpenNet incorporates AI models in its backend to perform various tasks such as extracting objects within cables, analyzing the sentiment of cables, extracting keywords of identified topics, and analyzing historical data to provide recommendations to users when composing cables.",,,False,False
SSA-0012-2023,SSA,Office of Retirement of Disability Programs,,Quick Disability Determinations Process,"The Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available. The Agency bases the QDD model�s predictive scores on historical data from application forms completed by millions of applicants. By identifying QDD cases early in the process, the Social Security Administration can prioritize this workload and expedite case processing.  The Agency routinely refines the QDD model to reflect the characteristics of the recent applicant population and optimize its ability to identify strong candidates for expedited processing. ",,,,Social Security Administration,"Quick Disability Determinations Process: 
The Quick Disability Determinations (QDD) process uses a computer-based predictive model to screen initial applications to identify cases where a favorable disability determination is highly likely and medical evidence is readily available. The Agency bases the QDD model�s predictive scores on historical data from application forms completed by millions of applicants. By identifying QDD cases early in the process, the Social Security Administration can prioritize this workload and expedite case processing.  The Agency routinely refines the QDD model to reflect the characteristics of the recent applicant population and optimize its ability to identify strong candidates for expedited processing. ",The Quick Disability Determinations (QDD) process uses a computer model to analyze initial disability applications and identify cases with a high likelihood of approval. This helps speed up the processing of these cases by prioritizing them. The model is regularly updated to improve its accuracy and efficiency.,The Quick Disability Determinations (QDD) process uses a computer model to analyze initial disability applications and identify cases with a high likelihood of approval. This helps speed up the processing of these cases by prioritizing them. The model is regularly updated to improve its accuracy and efficiency.,,,False,False
HHS-0117-2023,HHS,NIH,National Institutes of Health (NIH) NIDCR,NIDCR Digital Transformation Initiative (DTI),"An initiative to create a natural language processing chatbot to improve efficiency, transparency, and consistency for NIDCR employees. ",Development and Acquisition,,,Department of Health and Human Services,"NIDCR Digital Transformation Initiative (DTI): 
An initiative to create a natural language processing chatbot to improve efficiency, transparency, and consistency for NIDCR employees. ","The NIDCR Digital Transformation Initiative aims to enhance the productivity, clarity, and uniformity for NIDCR employees by developing a chatbot that utilizes natural language processing technology. This initiative intends to streamline operations, enhance communication, and maintain consistency within the organization.","The NIDCR Digital Transformation Initiative aims to enhance the productivity, clarity, and uniformity for NIDCR employees by developing a chatbot that utilizes natural language processing technology. This initiative intends to streamline operations, enhance communication, and maintain consistency within the organization.",,,False,False
DOE-0166-2023,DOE,Pacific Northwest National Laboratory,,AI techniques for identification of suitable delivery parking spaces in an urban scenario,"We are using AI (Graph Neural Network) to determine importance of 
parking spaces in a city network for curb management to promote 
adoption of electric vehicles for freight delivery",,,,Department of Energy,"AI techniques for identification of suitable delivery parking spaces in an urban scenario: 
We are using AI (Graph Neural Network) to determine importance of 
parking spaces in a city network for curb management to promote 
adoption of electric vehicles for freight delivery","AI techniques, specifically Graph Neural Networks, are being employed to assess the significance of parking spaces within a city's network. The aim is to effectively manage curbs and encourage the use of electric vehicles for freight delivery.","AI techniques, specifically Graph Neural Networks, are being employed to assess the significance of parking spaces within a city's network. The aim is to effectively manage curbs and encourage the use of electric vehicles for freight delivery.",,,False,False
DOC-0001-2023,DOC,International Trade Administration (ITA),,Chatbot Pilot,"Chatbot embedded into trade.gov to assist ITA clients with FAQs, locating information and 
content, suggesting events and services.  ITA clients would enter input into the chatbot in 
the form of questions or responses to prompts.  The chatbot would scan ITA content 
libraries and input from ITA staff and return answers and suggestions based on client 
persona (exporter, foreign buyer, investor).",,,,Department of Commerce,"Chatbot Pilot: 
Chatbot embedded into trade.gov to assist ITA clients with FAQs, locating information and 
content, suggesting events and services.  ITA clients would enter input into the chatbot in 
the form of questions or responses to prompts.  The chatbot would scan ITA content 
libraries and input from ITA staff and return answers and suggestions based on client 
persona (exporter, foreign buyer, investor).","A chatbot will be integrated into trade.gov, providing assistance to ITA clients by answering frequently asked questions, helping them locate information and content, and suggesting events and services. By inputting questions or responding to prompts, ITA clients can receive answers and suggestions tailored to their specific roles as exporters, foreign buyers, or investors, as the chatbot scans through ITA content libraries and information from ITA staff.","A chatbot will be integrated into trade.gov, providing assistance to ITA clients by answering frequently asked questions, helping them locate information and content, and suggesting events and services. By inputting questions or responding to prompts, ITA clients can receive answers and suggestions tailored to their specific roles as exporters, foreign buyers, or investors, as the chatbot scans through ITA content libraries and information from ITA staff.",,,False,False
HHS-0000-2023,HHS,ACF,ACF Children's Bureau,Information Gateway OneReach Application,"The Information Gateway hotline connects to a phone IVR managed by OneReach AI. OneReach maintains a database of state hotlines for reporting child abuse and neglect that it can connect a caller to based on their inbound phone area code. Additionally, OneReach offers a limited FAQ texting service that utilizes natural language processing to answer user queries. User queries are used for reinforcement training by a human AI trainer and to develop additional FAQs.",Operation and Maintenance,,,Department of Health and Human Services,"Information Gateway OneReach Application: 
The Information Gateway hotline connects to a phone IVR managed by OneReach AI. OneReach maintains a database of state hotlines for reporting child abuse and neglect that it can connect a caller to based on their inbound phone area code. Additionally, OneReach offers a limited FAQ texting service that utilizes natural language processing to answer user queries. User queries are used for reinforcement training by a human AI trainer and to develop additional FAQs.","The Information Gateway hotline is linked to a phone IVR system operated by OneReach AI. Through their database of state hotlines, OneReach can connect callers to the appropriate hotline based on their phone area code. Furthermore, OneReach provides a texting service that uses natural language processing to respond to user queries, which are used for training purposes and to create more FAQs.","The Information Gateway hotline is linked to a phone IVR system operated by OneReach AI. Through their database of state hotlines, OneReach can connect callers to the appropriate hotline based on their phone area code. Furthermore, OneReach provides a texting service that uses natural language processing to respond to user queries, which are used for training purposes and to create more FAQs.",,,False,False
DOE-0131-2023,DOE,National Energy Technology Laboratory,,To provide integrated boiler management through advanced condition monitoring and component assessment.,"The Integrated Creep-Fatigue Management System represents an 
online boiler damage monitoring system applicable to creep and fatigue.  
The system will be configured to allow connectivity to the plant data 
historian (e.g., OSISoft:PI) and to commercial finite element software 
(e.g., ANSYS and Abaqus). In addition to configuring interaction with 
finite element software, existing damage mechanism monitoring 
modules will also be deployed using online analytical calculations. This 
functionality will be applied to terminal tubes entering the boiler header 
for which the combined mechanisms of creep and oxidation can be 
calculated without the need for a finite element analysis.",,,,Department of Energy,"To provide integrated boiler management through advanced condition monitoring and component assessment.: 
The Integrated Creep-Fatigue Management System represents an 
online boiler damage monitoring system applicable to creep and fatigue.  
The system will be configured to allow connectivity to the plant data 
historian (e.g., OSISoft:PI) and to commercial finite element software 
(e.g., ANSYS and Abaqus). In addition to configuring interaction with 
finite element software, existing damage mechanism monitoring 
modules will also be deployed using online analytical calculations. This 
functionality will be applied to terminal tubes entering the boiler header 
for which the combined mechanisms of creep and oxidation can be 
calculated without the need for a finite element analysis.",The Integrated Creep-Fatigue Management System is an online boiler damage monitoring system that can be connected to plant data historian and commercial finite element software. It includes damage mechanism monitoring modules and can calculate combined creep and oxidation mechanisms without the need for finite element analysis.,The Integrated Creep-Fatigue Management System is an online boiler damage monitoring system that can be connected to plant data historian and commercial finite element software. It includes damage mechanism monitoring modules and can calculate combined creep and oxidation mechanisms without the need for finite element analysis.,,,False,False
DOI-0037-2023,DOI,USGS,,TMDL and Data Mining Investigations,"Apply data-mining techniques, include artificial neural network models, the hydrologic investigations.",Operation and Maintenance,"Deep convolutional neural networks; ResNet, MobileNet, UNet, RetinaNet",https://github.com/dbuscombe-usgs/MLMONDAYS,Department of Interior,"TMDL and Data Mining Investigations: 
Apply data-mining techniques, include artificial neural network models, the hydrologic investigations.","Data mining techniques, such as artificial neural network models, are used in TMDL investigations to analyze hydrologic data. These techniques help in understanding and predicting the impact of pollutants on water bodies.","Data mining techniques, such as artificial neural network models, are used in TMDL investigations to analyze hydrologic data. These techniques help in understanding and predicting the impact of pollutants on water bodies.",,,False,False
HHS-0088-2023,HHS,FDA,CDER/Office of Translational Sciences/Office of Clinical Pharmacology,Clinical Study Data Auto-transcribing Platform (AI Analyst) for Generating Evidence to Support Drug Labelling,"The AI Analyst platform is trained to auto-author clinical study reports from the source data to assess the strength and robustness of analytical evidence for supporting drug labelling languages.  The platform directly transcribes SDTM (Study Data Tabulation Model) datasets of phase I/II studies into full-length clinical study reports autonomously with minimal human input.  The underlying AI algorithm mimics the subject matter experts (e.g., clinicians, statisticians, and data managers) thinking process to decipher the full details of study design and conduct, and interpret the study results according to the study design.  It consists of multiple layers of data pattern recognitions.  The algorithm addresses the challenging nature of assessing clinical study results, including huge variety of study designs, unpredictable study conduct, variations of data reporting nomenclature/format, and wide range of study-specific analysis methods.  The platform has been trained and tested with hundreds of NDA/BLA submissions and over 1500 clinical trials.  The compatible study types include most drug label supporting studies, such as drug interaction, renal/hepatic impairment, and bioequivalence.  In 2022, the Office of Clinical Pharmacology (OCP/OTS/CDER) initiated the RealTime Analysis Depot (RAD) project aiming to routinely apply the AI platform to support the review of NME, 505b2 and 351K submissions.",Implementation,,,Department of Health and Human Services,"Clinical Study Data Auto-transcribing Platform (AI Analyst) for Generating Evidence to Support Drug Labelling: 
The AI Analyst platform is trained to auto-author clinical study reports from the source data to assess the strength and robustness of analytical evidence for supporting drug labelling languages.  The platform directly transcribes SDTM (Study Data Tabulation Model) datasets of phase I/II studies into full-length clinical study reports autonomously with minimal human input.  The underlying AI algorithm mimics the subject matter experts (e.g., clinicians, statisticians, and data managers) thinking process to decipher the full details of study design and conduct, and interpret the study results according to the study design.  It consists of multiple layers of data pattern recognitions.  The algorithm addresses the challenging nature of assessing clinical study results, including huge variety of study designs, unpredictable study conduct, variations of data reporting nomenclature/format, and wide range of study-specific analysis methods.  The platform has been trained and tested with hundreds of NDA/BLA submissions and over 1500 clinical trials.  The compatible study types include most drug label supporting studies, such as drug interaction, renal/hepatic impairment, and bioequivalence.  In 2022, the Office of Clinical Pharmacology (OCP/OTS/CDER) initiated the RealTime Analysis Depot (RAD) project aiming to routinely apply the AI platform to support the review of NME, 505b2 and 351K submissions.",The AI Analyst platform transcribes clinical study data into reports to assess the evidence supporting drug labelling. It mimics the thinking process of subject matter experts and can handle various study designs and data formats. The platform has been tested with numerous submissions and clinical trials and will be used to support the review of certain submissions in the future.,The AI Analyst platform transcribes clinical study data into reports to assess the evidence supporting drug labelling. It mimics the thinking process of subject matter experts and can handle various study designs and data formats. The platform has been tested with numerous submissions and clinical trials and will be used to support the review of certain submissions in the future.,,,False,False
HHS-0071-2023,HHS,FDA,CDER/Office of New Drugs,Application of Statistical Modeling and Natural Language Processing for Adverse Event Analysis,"Drug-induced adverse events (AEs) are difficult to predict for early signal detection, and there is a need to develop new tools and methods to monitor the safety of marketed drugs, including novel approaches for evidence generation. This project will utilize natural language processing (NLP) and data mining (DM) to extract information from approved drug labeling that can be used for statistical modeling to determine when the selected AEs are generally labeled (pre- or post-market) and identify patterns of detection, such as predictive factors, within the first 3 years of marketing of novel drugs. This project is intended to increase our understanding of timing/early detection of AEs, which can be applied to targeted monitoring of novel drugs. Funding will be used to support an ORISE fellow.",Initiation,,,Department of Health and Human Services,"Application of Statistical Modeling and Natural Language Processing for Adverse Event Analysis: 
Drug-induced adverse events (AEs) are difficult to predict for early signal detection, and there is a need to develop new tools and methods to monitor the safety of marketed drugs, including novel approaches for evidence generation. This project will utilize natural language processing (NLP) and data mining (DM) to extract information from approved drug labeling that can be used for statistical modeling to determine when the selected AEs are generally labeled (pre- or post-market) and identify patterns of detection, such as predictive factors, within the first 3 years of marketing of novel drugs. This project is intended to increase our understanding of timing/early detection of AEs, which can be applied to targeted monitoring of novel drugs. Funding will be used to support an ORISE fellow.",This project aims to develop new tools and methods for monitoring the safety of marketed drugs by using natural language processing and data mining to extract information from approved drug labeling. The goal is to determine when adverse events are generally labeled and identify patterns of detection within the first 3 years of marketing novel drugs. Funding will support an ORISE fellow for this project.,This project aims to develop new tools and methods for monitoring the safety of marketed drugs by using natural language processing and data mining to extract information from approved drug labeling. The goal is to determine when adverse events are generally labeled and identify patterns of detection within the first 3 years of marketing novel drugs. Funding will support an ORISE fellow for this project.,,,False,False
VA-0008-2023,VA,,,Digital command center,The Digital Command Center seeks to consolidate all data in a medical center and apply predictive prescriptive analytics to allow leaders to better optimize hospital performance.  ,,,,Department of Veterans Affairs,"Digital command center: 
The Digital Command Center seeks to consolidate all data in a medical center and apply predictive prescriptive analytics to allow leaders to better optimize hospital performance.  ","The Digital Command Center is a system that aims to gather and analyze all data within a medical center. By utilizing predictive and prescriptive analytics, hospital leaders can make more informed decisions to improve the overall performance of the hospital.","The Digital Command Center is a system that aims to gather and analyze all data within a medical center. By utilizing predictive and prescriptive analytics, hospital leaders can make more informed decisions to improve the overall performance of the hospital.",,,False,False
DOL-0003-2023,DOL,,,Text to Speech Conversion,Text to speech (Neural) for more realistic human sounding applications using natural language processing models.,Operation and Maintenance,Cloud based commercial-off-the-shelf pre-trained NLP models,,Department of Labor,"Text to Speech Conversion: 
Text to speech (Neural) for more realistic human sounding applications using natural language processing models.",Text to speech conversion refers to the process of converting written text into spoken words with the help of neural networks. This technique aims to create more lifelike and human-sounding applications by utilizing natural language processing models.,Text to speech conversion refers to the process of converting written text into spoken words with the help of neural networks. This technique aims to create more lifelike and human-sounding applications by utilizing natural language processing models.,,,False,False
DOE-0171-2023,DOE,Pacific Northwest National Laboratory,,Managing curb allocation in cities,"This project's goal is to develop a city-scale dynamic curb use 
simulation tool and an open-source curb management platform that 
address the challenge of increased demand for curb-side parking.",,,,Department of Energy,"Managing curb allocation in cities: 
This project's goal is to develop a city-scale dynamic curb use 
simulation tool and an open-source curb management platform that 
address the challenge of increased demand for curb-side parking.",The project aims to create a simulation tool and a curb management platform to efficiently handle the growing demand for curb-side parking in cities. These tools will help cities manage the allocation of curbs and optimize the use of available space.,The project aims to create a simulation tool and a curb management platform to efficiently handle the growing demand for curb-side parking in cities. These tools will help cities manage the allocation of curbs and optimize the use of available space.,,,False,False
USDA-0001-2023,USDA,USDA,APHIS,Detection of pre-symptomatic HLB infected citrus,Identify pixels with HLB infection signature in multispectral and thermal imagery,Operation and Management,Visual Analysis,,Department of Agriculture,"Detection of pre-symptomatic HLB infected citrus: 
Identify pixels with HLB infection signature in multispectral and thermal imagery",The text states that the goal is to detect citrus trees infected with HLB before symptoms appear. This is done by identifying specific pixels in multispectral and thermal imagery that indicate HLB infection.,The text states that the goal is to detect citrus trees infected with HLB before symptoms appear. This is done by identifying specific pixels in multispectral and thermal imagery that indicate HLB infection.,,,False,False
DOE-0155-2023,DOE,National Energy Technology Laboratory,,"With sensor technologies and network developed, in the future, AI/ML may be used to accelerate data processing of sensor data from the sensor network.","With sensor technologies and network developed, in the future, AI/ML 
may be used to accelerate data processing of sensor data from the 
sensor network to identify and predict risks and failures in plugged wells.",,,,Department of Energy,"With sensor technologies and network developed, in the future, AI/ML may be used to accelerate data processing of sensor data from the sensor network.: 
With sensor technologies and network developed, in the future, AI/ML 
may be used to accelerate data processing of sensor data from the 
sensor network to identify and predict risks and failures in plugged wells.",AI/ML can be utilized in the future to speed up the processing of sensor data from a sensor network. This can help in identifying and predicting risks and failures in plugged wells.,AI/ML can be utilized in the future to speed up the processing of sensor data from a sensor network. This can help in identifying and predicting risks and failures in plugged wells.,,,False,False
DOI-0022-2023,DOI,USGS,,WRA.NWC.IWAA National Extent Hydrogeologic Framework for NWC,"The primary objectives of this project are to (1) provide Nationally consistent predictions of groundwater quality (salinity and nutrients) relevant for human and ecological uses and its influence on surface-water, and (2) develop strategies for integrating these predictions into comprehensive water-availability assessments including the National Water Census and regional Integrated Water Availability Assessments. These primary objectives are organized by task as follows:
Task 1: Groundwater-Quality Prediction – salinity
· Provide accurate and reliable predictions of groundwater salinity at appropriate resolutions to document groundwater availability for human and ecological uses.
Task 2: Groundwater-Quality Prediction – nutrients
· Provide accurate and reliable predictions of nutrient concentrations in groundwater at appropriate resolutions to document groundwater availability for human and ecological uses.
Task 3: Incorporate Groundwater-Quality Predictions into Comprehensive Assessments of Water Availability
· Develop and refine strategies for coupling predictions of groundwater quality with groundwater flow and flux simulations from process-based models (e.g., GSFLOW, General Simulation Models) to quantify the amount of groundwater of a specified quality that is available and to better determine the affect of groundwater on surface-water quantity and quality.",Initiation,convolutional neural networks,,Department of Interior,"WRA.NWC.IWAA National Extent Hydrogeologic Framework for NWC: 
The primary objectives of this project are to (1) provide Nationally consistent predictions of groundwater quality (salinity and nutrients) relevant for human and ecological uses and its influence on surface-water, and (2) develop strategies for integrating these predictions into comprehensive water-availability assessments including the National Water Census and regional Integrated Water Availability Assessments. These primary objectives are organized by task as follows:
Task 1: Groundwater-Quality Prediction – salinity
· Provide accurate and reliable predictions of groundwater salinity at appropriate resolutions to document groundwater availability for human and ecological uses.
Task 2: Groundwater-Quality Prediction – nutrients
· Provide accurate and reliable predictions of nutrient concentrations in groundwater at appropriate resolutions to document groundwater availability for human and ecological uses.
Task 3: Incorporate Groundwater-Quality Predictions into Comprehensive Assessments of Water Availability
· Develop and refine strategies for coupling predictions of groundwater quality with groundwater flow and flux simulations from process-based models (e.g., GSFLOW, General Simulation Models) to quantify the amount of groundwater of a specified quality that is available and to better determine the affect of groundwater on surface-water quantity and quality.","The aim of the WRA.NWC.IWAA National Extent Hydrogeologic Framework for NWC project is to deliver consistent predictions of groundwater quality and its impact on surface water, as well as strategies for integrating these predictions into water availability assessments. This involves predicting groundwater salinity and nutrient concentrations, and incorporating these predictions into comprehensive assessments of water availability by coupling them with groundwater flow and flux simulations.","The aim of the WRA.NWC.IWAA National Extent Hydrogeologic Framework for NWC project is to deliver consistent predictions of groundwater quality and its impact on surface water, as well as strategies for integrating these predictions into water availability assessments. This involves predicting groundwater salinity and nutrient concentrations, and incorporating these predictions into comprehensive assessments of water availability by coupling them with groundwater flow and flux simulations.",,,False,False
HHS-0099-2023,HHS,FDA,NCTR,Prediction of adverse events from drug - endogenous ligand - target networks generated using 3D-similarity and machine learning methods.,"Excluding areas of the biochemical space near activity cliffs [1], molecular similarity [2] has long proven to be an outstanding tool in virtual screening [3], absorption, distribution, metabolism, and excretion (ADME) [4], drug design [5] and toxicology [6]. Among these, the toxicological response is the most challenging task due to its immense complexity involving multiple pathways and protein targets. Although many adverse drug reactions (ADRs) result from genetic polymorphisms and factors such as the patient's medical history and the treatment dosage and regimen, on a fundamental level all ADRs are initiated by the binding of a drug molecule to a target, whether intended (therapeutic target) or non-intended (off-target interactions with promiscuous proteins) [7]. While molecular similarity approaches designed to identify off-target interaction sites have been explored since the late 2000s [8, 9], most have been focused on drug design, repurposing and more generally, efficacy, whereas relatively few have been applied to toxicology [10, 11].
Since there are multiple approaches to molecular similarity (structural, functional, whole molecule, pharmacophore, etc. [12]), the performance of any of the above applications depends strongly on the metrics by which similarity is quantified. For the past 10 years, DSB has been working on creating a universal molecular modeling approach utilizing unique three-dimensional fingerprints encoding both the steric and electrostatic fields governing the interactions between ligands and receptors. It has been demonstrated that these fingerprints could quantify reliably both the structural and functional similarities between molecules [13, 14] and their application for prediction of adverse events from AI generated drug - endogenous ligand - target networks could provide new insights into yet unknown mechanisms of toxicity.",Initiation,,,Department of Health and Human Services,"Prediction of adverse events from drug - endogenous ligand - target networks generated using 3D-similarity and machine learning methods.: 
Excluding areas of the biochemical space near activity cliffs [1], molecular similarity [2] has long proven to be an outstanding tool in virtual screening [3], absorption, distribution, metabolism, and excretion (ADME) [4], drug design [5] and toxicology [6]. Among these, the toxicological response is the most challenging task due to its immense complexity involving multiple pathways and protein targets. Although many adverse drug reactions (ADRs) result from genetic polymorphisms and factors such as the patient's medical history and the treatment dosage and regimen, on a fundamental level all ADRs are initiated by the binding of a drug molecule to a target, whether intended (therapeutic target) or non-intended (off-target interactions with promiscuous proteins) [7]. While molecular similarity approaches designed to identify off-target interaction sites have been explored since the late 2000s [8, 9], most have been focused on drug design, repurposing and more generally, efficacy, whereas relatively few have been applied to toxicology [10, 11].
Since there are multiple approaches to molecular similarity (structural, functional, whole molecule, pharmacophore, etc. [12]), the performance of any of the above applications depends strongly on the metrics by which similarity is quantified. For the past 10 years, DSB has been working on creating a universal molecular modeling approach utilizing unique three-dimensional fingerprints encoding both the steric and electrostatic fields governing the interactions between ligands and receptors. It has been demonstrated that these fingerprints could quantify reliably both the structural and functional similarities between molecules [13, 14] and their application for prediction of adverse events from AI generated drug - endogenous ligand - target networks could provide new insights into yet unknown mechanisms of toxicity.","The use of molecular similarity has been a valuable tool in various areas of drug development and toxicology. However, predicting adverse drug reactions remains challenging due to the complexity of the biological pathways involved. A new approach using three-dimensional fingerprints encoding both structural and functional similarities between molecules shows promise in predicting adverse events and uncovering unknown mechanisms of toxicity.","The use of molecular similarity has been a valuable tool in various areas of drug development and toxicology. However, predicting adverse drug reactions remains challenging due to the complexity of the biological pathways involved. A new approach using three-dimensional fingerprints encoding both structural and functional similarities between molecules shows promise in predicting adverse events and uncovering unknown mechanisms of toxicity.",,,False,False
USDA-0003-2023,USDA,USDA,APHIS,Detection of aquatic weeds,Identify and locate aquatic weeds,Operation and Management,Machine Learning,,Department of Agriculture,"Detection of aquatic weeds: 
Identify and locate aquatic weeds","The process of detecting aquatic weeds involves identifying and locating these plants in water bodies. This is done in order to effectively manage and control their growth, as weeds can have negative impacts on ecosystems and water quality.","The process of detecting aquatic weeds involves identifying and locating these plants in water bodies. This is done in order to effectively manage and control their growth, as weeds can have negative impacts on ecosystems and water quality.",,,False,False
USDA-0009-2023,USDA,USDA,ARS,4% Repair Dashboard,"The model reviews the descriptions of expenses tagged to repairs and maintenance and classifies expenses as ""repair"" or ""not repair"" based on keywords in context.",Operation and Management,Natural Language Processing,,Department of Agriculture,"4% Repair Dashboard: 
The model reviews the descriptions of expenses tagged to repairs and maintenance and classifies expenses as ""repair"" or ""not repair"" based on keywords in context.","The 4% Repair Dashboard is a model that analyzes expense descriptions to determine whether they are related to repairs and maintenance. It uses keywords in the context to classify expenses as either ""repair"" or ""not repair"".","The 4% Repair Dashboard is a model that analyzes expense descriptions to determine whether they are related to repairs and maintenance. It uses keywords in the context to classify expenses as either ""repair"" or ""not repair"".",,,False,False
HHS-0100-2023,HHS,FDA,NCTR,Predictive toxicology models of drug placental permeability using 3D-fingerprints and machine learning,"The human placenta plays a pivotal role in fetal growth, development, and fetal exposure to chemicals and therapeutics. The ability to predict placental permeability of chemicals during pregnancy is an important factor that can inform regulatory decisions related to fetal safety and clinical trials with women of child-bearing potential (WOCBP). The human placenta contains transport proteins, which facilitate the transfer of various endogenous substances and xenobiotics. Several mechanisms allow this transfer: i) passive diffusion, ii) active transport, iii) facilitated diffusion, iv) pinocytosis, and v) phagocytosis. Among these, passive and active transport are the two major routes. Small, non-ionized, highly lipophilic drugs cross the placenta via passive diffusion; however, relatively large molecules (MW > 500 Da) with low lipophilicity are carried by transporters. While prediction of the ability of drugs to cross the placenta via diffusion is straight-forward, the complexity of molecular interactions between drugs and transporters has proven to be a challenging problem to solve. Virtually, all QSARs (Quantitative Structure Activity Relationships) published to date model small datasets (usually not exceeding 100 drugs) and utilize weak validation strategies [1-5].
In this proposal, 3D-molecular similarities of endogenous placental transporter ligands to known drug substrates will be used to identify the most likely mode of drug transportation (active/passive) and build predictive, quantitative and categorical 3D-SDAR models by linking their molecular characteristics to placental permeability. Permeability data will be collected via mining the literature, the CDER databases, and conducting empirical assessments using in vitro NAMs with confirmation using rodent models. Predictability will be validated using: i) blind test sets including known controls and ii) a small set of drugs with unknown permeabilities, which will be tested in in vitro and in vivo models.",Initiation,,,Department of Health and Human Services,"Predictive toxicology models of drug placental permeability using 3D-fingerprints and machine learning: 
The human placenta plays a pivotal role in fetal growth, development, and fetal exposure to chemicals and therapeutics. The ability to predict placental permeability of chemicals during pregnancy is an important factor that can inform regulatory decisions related to fetal safety and clinical trials with women of child-bearing potential (WOCBP). The human placenta contains transport proteins, which facilitate the transfer of various endogenous substances and xenobiotics. Several mechanisms allow this transfer: i) passive diffusion, ii) active transport, iii) facilitated diffusion, iv) pinocytosis, and v) phagocytosis. Among these, passive and active transport are the two major routes. Small, non-ionized, highly lipophilic drugs cross the placenta via passive diffusion; however, relatively large molecules (MW > 500 Da) with low lipophilicity are carried by transporters. While prediction of the ability of drugs to cross the placenta via diffusion is straight-forward, the complexity of molecular interactions between drugs and transporters has proven to be a challenging problem to solve. Virtually, all QSARs (Quantitative Structure Activity Relationships) published to date model small datasets (usually not exceeding 100 drugs) and utilize weak validation strategies [1-5].
In this proposal, 3D-molecular similarities of endogenous placental transporter ligands to known drug substrates will be used to identify the most likely mode of drug transportation (active/passive) and build predictive, quantitative and categorical 3D-SDAR models by linking their molecular characteristics to placental permeability. Permeability data will be collected via mining the literature, the CDER databases, and conducting empirical assessments using in vitro NAMs with confirmation using rodent models. Predictability will be validated using: i) blind test sets including known controls and ii) a small set of drugs with unknown permeabilities, which will be tested in in vitro and in vivo models.",This text discusses the importance of predicting the placental permeability of drugs during pregnancy in order to ensure fetal safety and inform regulatory decisions. The proposal suggests using 3D-molecular similarities of placental transporter ligands to known drug substrates to build predictive models for drug transportation across the placenta. This will be validated using blind test sets and empirical assessments.,This text discusses the importance of predicting the placental permeability of drugs during pregnancy in order to ensure fetal safety and inform regulatory decisions. The proposal suggests using 3D-molecular similarities of placental transporter ligands to known drug substrates to build predictive models for drug transportation across the placenta. This will be validated using blind test sets and empirical assessments.,,,False,False
DOE-0124-2023,DOE,National Energy Technology Laboratory,,"To leverage disparate data to update assessments, analytics, and infromation for NATCARB and CS Atlas","ML Is utilized to parse and generate additional data and information that 
can be parsed and labeled to provide additional inputs for geologic 
carbon storgae assessments from multiple sources.",,Other,,Department of Energy,"To leverage disparate data to update assessments, analytics, and infromation for NATCARB and CS Atlas: 
ML Is utilized to parse and generate additional data and information that 
can be parsed and labeled to provide additional inputs for geologic 
carbon storgae assessments from multiple sources.","Machine learning is used to analyze and generate new data that can be used to update assessments and information for NATCARB and CS Atlas. This allows for the inclusion of data from various sources, enhancing the accuracy of geologic carbon storage assessments.","Machine learning is used to analyze and generate new data that can be used to update assessments and information for NATCARB and CS Atlas. This allows for the inclusion of data from various sources, enhancing the accuracy of geologic carbon storage assessments.",,,False,False
NASA-0025-2023,NASA,Marshall Space Flight Center,,Deep Learning-based Hurricane Intensity Estimator,"A web-based situational awareness tool that uses deep learning on satellite images to objectively estimate
windspeed of a hurricane",In-use,,,National Aeronautics and Space Administration,"Deep Learning-based Hurricane Intensity Estimator: 
A web-based situational awareness tool that uses deep learning on satellite images to objectively estimate
windspeed of a hurricane","The Deep Learning-based Hurricane Intensity Estimator is a web tool that utilizes deep learning algorithms to accurately estimate the windspeed of a hurricane. This is achieved by analyzing satellite images, allowing for an objective and reliable assessment of the hurricane's intensity.","The Deep Learning-based Hurricane Intensity Estimator is a web tool that utilizes deep learning algorithms to accurately estimate the windspeed of a hurricane. This is achieved by analyzing satellite images, allowing for an objective and reliable assessment of the hurricane's intensity.",,,False,False
USDA-0002-2023,USDA,USDA,APHIS,High throughput phenotyping in citrus orchards,"Locate, count, and categorize citrus trees in an orchard to monitor orchard health",Operation and Management,Machine Learning,,Department of Agriculture,"High throughput phenotyping in citrus orchards: 
Locate, count, and categorize citrus trees in an orchard to monitor orchard health","High throughput phenotyping in citrus orchards involves efficiently identifying, tallying, and classifying citrus trees to effectively track the overall health of the orchard. This method enables quick and accurate assessment of the orchard's condition.","High throughput phenotyping in citrus orchards involves efficiently identifying, tallying, and classifying citrus trees to effectively track the overall health of the orchard. This method enables quick and accurate assessment of the orchard's condition.",,,False,False
OPM-0002-2023,OPM,HRS/USAJOBS,,Similar Job Recommendations,USAJOBS is planning to use natural language processing to provide better matches between posted job opportunities in order to help users identify opportunities of interest.,Development and Acquisition,Natural Language Processing,,U.S. Office of Personnel Management,"Similar Job Recommendations: 
USAJOBS is planning to use natural language processing to provide better matches between posted job opportunities in order to help users identify opportunities of interest.",USAJOBS intends to enhance job matching by utilizing natural language processing. This technology will assist users in finding relevant job opportunities that align with their interests and preferences.,USAJOBS intends to enhance job matching by utilizing natural language processing. This technology will assist users in finding relevant job opportunities that align with their interests and preferences.,,,False,False
DOE-0012-2023,DOE,Fermi National Accelerator,,READS: Real-time Edge AI for Distributed Systems,"This project will develop and deploy low-latency controls and prediction 
algorithms at the Fermilab accelerator complex",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"READS: Real-time Edge AI for Distributed Systems: 
This project will develop and deploy low-latency controls and prediction 
algorithms at the Fermilab accelerator complex",The project aims to create and implement fast-response controls and predictive algorithms for the Fermilab accelerator complex. These measures will be deployed in real-time to enhance the efficiency and performance of the distributed systems.,The project aims to create and implement fast-response controls and predictive algorithms for the Fermilab accelerator complex. These measures will be deployed in real-time to enhance the efficiency and performance of the distributed systems.,,,False,False
HHS-0131-2023,HHS,NIH,National Institutes of Health (NIH) NLM,SingleCite: Improving single citation search in PubMed,"A search that is targeted at finding a specific document in databases is called a Single Citation search, which is particularly important for scholarly databases, such as PubMed, because it is a typical information need of the users. NLM developed SingleCite, an automated algorithm that establishes a query-document mapping by building a regression function to predict the probability of a retrieved document being the target based on three variables: the score of the highest scoring retrieved document, the difference in score between the two top retrieved documents, and the fraction of a query matched by the candidate citation. SingleCite shows superior performance in benchmarking experiments and is applied to rescue queries that would fail otherwise.",Operation and Maintenance,,,Department of Health and Human Services,"SingleCite: Improving single citation search in PubMed: 
A search that is targeted at finding a specific document in databases is called a Single Citation search, which is particularly important for scholarly databases, such as PubMed, because it is a typical information need of the users. NLM developed SingleCite, an automated algorithm that establishes a query-document mapping by building a regression function to predict the probability of a retrieved document being the target based on three variables: the score of the highest scoring retrieved document, the difference in score between the two top retrieved documents, and the fraction of a query matched by the candidate citation. SingleCite shows superior performance in benchmarking experiments and is applied to rescue queries that would fail otherwise.",SingleCite is an automated algorithm developed by NLM to improve single citation searches in PubMed. It establishes a query-document mapping by predicting the probability of a retrieved document being the target based on three variables. SingleCite has demonstrated superior performance in benchmarking experiments and is used to rescue queries that would otherwise fail.,SingleCite is an automated algorithm developed by NLM to improve single citation searches in PubMed. It establishes a query-document mapping by predicting the probability of a retrieved document being the target based on three variables. SingleCite has demonstrated superior performance in benchmarking experiments and is used to rescue queries that would otherwise fail.,,,False,False
VA-0037-2023,VA,,,Interpretation/triage of eye images,"Artificial intelligence supports triage of eye patients cared for through telehealth, interprets eye images, and assesses health risks based on retina photos. The goal is to improve diagnosis of a variety of conditions, including glaucoma, macular degeneration, and diabetic retinopathy.",,,,Department of Veterans Affairs,"Interpretation/triage of eye images: 
Artificial intelligence supports triage of eye patients cared for through telehealth, interprets eye images, and assesses health risks based on retina photos. The goal is to improve diagnosis of a variety of conditions, including glaucoma, macular degeneration, and diabetic retinopathy.","Artificial intelligence is used to triage and interpret eye images, helping healthcare providers assess health risks and improve diagnosis for various eye conditions such as glaucoma, macular degeneration, and diabetic retinopathy, particularly in telehealth settings.","Artificial intelligence is used to triage and interpret eye images, helping healthcare providers assess health risks and improve diagnosis for various eye conditions such as glaucoma, macular degeneration, and diabetic retinopathy, particularly in telehealth settings.",,,False,False
NASA-0013-2023,NASA,Jet Propulsion Laboratory,,Hybrid On-Board and Ground-Based Processing of Massive Sensor Data (HyspIRI IPM),"Future space missions will enable unprecedented monitoring of the Earth's environment and will generate immense
volumes of science data. Getting this data to ground communications stations, through science processing, and
delivered to end users is a tremendous challenge. On the ground, the spacecraft's orbit is projected, and automated
mission-planning tools determine which onboard-processing mode the spacecraft should use. The orbit determines
the type of terrain that the spacecraft would be overflying—land, ice, coast, or ocean, for instance. Each terrain
mask implies a set of requested modes and priorities. For example, when a spacecraft overflies polar or
mountainous regions, producing snow and ice coverage maps can provide valuable science data. The science team
can adjust these priorities on the basis of additional information (such as external knowledge of an active volcano, a
flooded area, an active wildfire, or a harmful algal bloom). The mission-planning tool accepts all these requests and
priorities, then determines which onboard-processing algorithms will be active by selecting the highest-priority
requests that fit within the onboard CPU resources, band-processing limitations, and downlink bandwidth.In the
intelligent onboard processing concept, HyspIRI's onboard processing algorithms would consist of expert-derived
decision tree classifiers, machine-learned classifiers such as SVM classifiers and regressions, classification and
regression trees (CART), Bayesian maximum-likelihood classifiers, spectral angle mappers, and direct
implementations of spectral band indices and science products",In mission,constraint-based heuristic Search,,National Aeronautics and Space Administration,"Hybrid On-Board and Ground-Based Processing of Massive Sensor Data (HyspIRI IPM): 
Future space missions will enable unprecedented monitoring of the Earth's environment and will generate immense
volumes of science data. Getting this data to ground communications stations, through science processing, and
delivered to end users is a tremendous challenge. On the ground, the spacecraft's orbit is projected, and automated
mission-planning tools determine which onboard-processing mode the spacecraft should use. The orbit determines
the type of terrain that the spacecraft would be overflying—land, ice, coast, or ocean, for instance. Each terrain
mask implies a set of requested modes and priorities. For example, when a spacecraft overflies polar or
mountainous regions, producing snow and ice coverage maps can provide valuable science data. The science team
can adjust these priorities on the basis of additional information (such as external knowledge of an active volcano, a
flooded area, an active wildfire, or a harmful algal bloom). The mission-planning tool accepts all these requests and
priorities, then determines which onboard-processing algorithms will be active by selecting the highest-priority
requests that fit within the onboard CPU resources, band-processing limitations, and downlink bandwidth.In the
intelligent onboard processing concept, HyspIRI's onboard processing algorithms would consist of expert-derived
decision tree classifiers, machine-learned classifiers such as SVM classifiers and regressions, classification and
regression trees (CART), Bayesian maximum-likelihood classifiers, spectral angle mappers, and direct
implementations of spectral band indices and science products","Future space missions will generate large amounts of science data, creating a challenge in transmitting and processing this data. Ground-based tools determine the spacecraft's orbit and prioritize onboard-processing modes based on the type of terrain being overflown. The intelligent onboard processing concept of the HyspIRI mission includes various algorithms such as decision tree classifiers, SVM classifiers, and spectral band indices for data analysis.","Future space missions will generate large amounts of science data, creating a challenge in transmitting and processing this data. Ground-based tools determine the spacecraft's orbit and prioritize onboard-processing modes based on the type of terrain being overflown. The intelligent onboard processing concept of the HyspIRI mission includes various algorithms such as decision tree classifiers, SVM classifiers, and spectral band indices for data analysis.",,,False,False
DOE-0054-2023,DOE,National Energy Technology Laboratory,,Machine Learning for geophysical data inversion,"Use machine learning to generate synthetic seismic and gravity data, 
and data driven inversion for leak detection",,Other,,Department of Energy,"Machine Learning for geophysical data inversion: 
Use machine learning to generate synthetic seismic and gravity data, 
and data driven inversion for leak detection","Machine learning is utilized in geophysical data inversion to create synthetic seismic and gravity data. Additionally, data-driven inversion techniques are employed for the purpose of leak detection.","Machine learning is utilized in geophysical data inversion to create synthetic seismic and gravity data. Additionally, data-driven inversion techniques are employed for the purpose of leak detection.",,,False,False
NASA-0006-2023,NASA,Glenn Research Center,,Application that provides bio-inspired solutions to engineering problems (PeTaL),"PeTaL (the Periodic Table of Life) is an open source artificial intelligence (AI) design tool that leverages data and
information from nature and technology to advance biomimicry research and development. PeTaL is envisioned to
streamline various steps of the bio-inspired design process by integrating new and existing tools and methodologies
around its core ontological framework (Shyam et al., 2019; Unsworth et al., 2019). To be as comprehensive as
possible, PeTaL requires mass curation of standardized data through which it can learn, interpret, and output
predictive solutions to design queries. PeTaL is intended to be used by designers and engineers who seek nature’s
solutions to their design and engineering problems, as well as by biologists who seek to extend the application of
their scientific discoveries.
In Production: Classification of biology journal articles into functional categories.
In Development: Joint text summarization and named entity recognition task involving open-access biology journal
articles using large language models such as those available from OpenAI.",In-use,"LLM prompt engineering, BERT text classification, Natural Language Processing",https://github.com/nasa-petal,National Aeronautics and Space Administration,"Application that provides bio-inspired solutions to engineering problems (PeTaL): 
PeTaL (the Periodic Table of Life) is an open source artificial intelligence (AI) design tool that leverages data and
information from nature and technology to advance biomimicry research and development. PeTaL is envisioned to
streamline various steps of the bio-inspired design process by integrating new and existing tools and methodologies
around its core ontological framework (Shyam et al., 2019; Unsworth et al., 2019). To be as comprehensive as
possible, PeTaL requires mass curation of standardized data through which it can learn, interpret, and output
predictive solutions to design queries. PeTaL is intended to be used by designers and engineers who seek nature’s
solutions to their design and engineering problems, as well as by biologists who seek to extend the application of
their scientific discoveries.
In Production: Classification of biology journal articles into functional categories.
In Development: Joint text summarization and named entity recognition task involving open-access biology journal
articles using large language models such as those available from OpenAI.","PeTaL is an open source AI design tool that uses data from nature and technology to advance biomimicry research and development. It streamlines the bio-inspired design process by integrating various tools and methodologies, and requires curated data for predictive solutions. It is intended for use by designers, engineers, and biologists seeking nature's solutions to design and engineering problems. Currently, it classifies biology journal articles into functional categories, and is being developed to involve text summarization and named entity recognition tasks using large language models.","PeTaL is an open source AI design tool that uses data from nature and technology to advance biomimicry research and development. It streamlines the bio-inspired design process by integrating various tools and methodologies, and requires curated data for predictive solutions. It is intended for use by designers, engineers, and biologists seeking nature's solutions to design and engineering problems. Currently, it classifies biology journal articles into functional categories, and is being developed to involve text summarization and named entity recognition tasks using large language models.",,,False,False
DOC-0047-2023,DOC,United States Patent and Trade Office (USPTO),,Enriched Citation,"Data dissemination system that identifies which references, or prior art, were cited in 
specific patent application office actions, including: bibliographic information of the 
reference, the claims that the prior art was cited against, and the relevant sections that 
the examiner relied upon.  System extracts information from unstructured office actions 
and provides the information through a structured public facing API.",,,,Department of Commerce,"Enriched Citation: 
Data dissemination system that identifies which references, or prior art, were cited in 
specific patent application office actions, including: bibliographic information of the 
reference, the claims that the prior art was cited against, and the relevant sections that 
the examiner relied upon.  System extracts information from unstructured office actions 
and provides the information through a structured public facing API.","The Enriched Citation system is a data dissemination system that identifies the references cited in patent office actions. It provides detailed information about these references, including bibliographic information, the claims they were cited against, and the sections relied upon by examiners. The system extracts this information from unstructured office actions and offers it through a structured public API.","The Enriched Citation system is a data dissemination system that identifies the references cited in patent office actions. It provides detailed information about these references, including bibliographic information, the claims they were cited against, and the sections relied upon by examiners. The system extracts this information from unstructured office actions and offers it through a structured public API.",,,False,False
USDA-0033-2023,USDA,USDA,NRCS,Digital Imagery (no-change) for NRI program,Using neural networks and other AI technologies to detect no-changes in digital imagery for the NRI (national resources inventory) program ,Initiation,neural networks,,Department of Agriculture,"Digital Imagery (no-change) for NRI program: 
Using neural networks and other AI technologies to detect no-changes in digital imagery for the NRI (national resources inventory) program ",The NRI program utilizes neural networks and AI technologies to identify no-changes in digital imagery. This allows for efficient monitoring and assessment of national resources.,The NRI program utilizes neural networks and AI technologies to identify no-changes in digital imagery. This allows for efficient monitoring and assessment of national resources.,,,False,False
DOL-0004-2023,DOL,,,Claims Document Processing,To identify if physician’s note contains causal language by training custom natural language processing models.,Implementation,Natural language processing for (a) document classification and (b) sentence-level causal passage detection,,Department of Labor,"Claims Document Processing: 
To identify if physician’s note contains causal language by training custom natural language processing models.",Claims Document Processing involves training custom natural language processing models to determine if a physician's note contains causal language. This is done to identify any statements that establish a cause-and-effect relationship in the note.,Claims Document Processing involves training custom natural language processing models to determine if a physician's note contains causal language. This is done to identify any statements that establish a cause-and-effect relationship in the note.,,,False,False
DHS-0019-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Cyber Incident Reporting,Cyber incident handling specialists utilize advanced automation tools to process data received through various threat intelligence and cyber incident channels. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data received through covered CIRCIA entities.,Initiation,"Machine Learning, Natural Language Processing (NLP)",,Department of Homeland Security,"Cyber Incident Reporting: 
Cyber incident handling specialists utilize advanced automation tools to process data received through various threat intelligence and cyber incident channels. These tools leverage Machine Learning and Natural Language Processing to increase the accuracy and relevance of data that is filtered and presented to human analysts and decision-makers. Machine Learning techniques also assist to aggregate the information in reports for presentation and further analysis. This includes data received through covered CIRCIA entities.","Cyber incident handling specialists use automation tools powered by Machine Learning and Natural Language Processing to process data from threat intelligence and cyber incident channels. These tools improve the accuracy and relevance of filtered data presented to human analysts and decision-makers, as well as help aggregate information in reports for analysis. The data received includes information from covered CIRCIA entities.","Cyber incident handling specialists use automation tools powered by Machine Learning and Natural Language Processing to process data from threat intelligence and cyber incident channels. These tools improve the accuracy and relevance of filtered data presented to human analysts and decision-makers, as well as help aggregate information in reports for analysis. The data received includes information from covered CIRCIA entities.",,,False,False
HHS-0026-2023,HHS,CDC,NCCDPHP/DNPAO,Automating extraction of sidewalk networks from street-level images,A team of scientists participating in CDC's Data Science Upskilling Program are building a computer vision model to extract information on the presence of sidewalks from street-level images from Mapillary.,Development and Acquisition,,,Department of Health and Human Services,"Automating extraction of sidewalk networks from street-level images: 
A team of scientists participating in CDC's Data Science Upskilling Program are building a computer vision model to extract information on the presence of sidewalks from street-level images from Mapillary.",Scientists in the CDC's Data Science Upskilling Program are developing a computer vision model that can automatically extract sidewalk networks from street-level images sourced from Mapillary. This model aims to provide valuable information about the presence of sidewalks in various locations.,Scientists in the CDC's Data Science Upskilling Program are developing a computer vision model that can automatically extract sidewalk networks from street-level images sourced from Mapillary. This model aims to provide valuable information about the presence of sidewalks in various locations.,,,False,False
HHS-0002-2023,HHS,AHRQ,AHRQ,Chatbot,Provide interface to allow user to conversationally ask questions about AHRQ content to replace public inquiry telephone line,Operation and Maintenance,,,Department of Health and Human Services,"Chatbot: 
Provide interface to allow user to conversationally ask questions about AHRQ content to replace public inquiry telephone line","The chatbot serves as an interface to enable users to ask questions about AHRQ content in a conversational manner, serving as a replacement for the public inquiry telephone line. Users can easily engage with the chatbot to inquire about AHRQ information and receive prompt responses.","The chatbot serves as an interface to enable users to ask questions about AHRQ content in a conversational manner, serving as a replacement for the public inquiry telephone line. Users can easily engage with the chatbot to inquire about AHRQ information and receive prompt responses.",,,False,False
VA-0031-2023,VA,,,Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus,A machine learning model is used to predict disease progression among veterans with hepatitis C virus.,,,,Department of Veterans Affairs,"Reinforcement learning evaluation of treatment policies for patients with hepatitis C virus: 
A machine learning model is used to predict disease progression among veterans with hepatitis C virus.",A machine learning model is utilized to forecast disease progression in veterans with hepatitis C virus. This reinforcement learning evaluation aims to assess treatment policies for these patients.,A machine learning model is utilized to forecast disease progression in veterans with hepatitis C virus. This reinforcement learning evaluation aims to assess treatment policies for these patients.,,,False,False
TREAS-0005-2023,TREAS,,,CX Analytics,"IRS' Customer Experience (CX) Analytics is a capability that uses multiple, 
customer service-related data sources to identify 
issues/anomalies/improvement opportunities across the customer service 
channel modes.",Implementation,,,Department of Treasury,"CX Analytics: 
IRS' Customer Experience (CX) Analytics is a capability that uses multiple, 
customer service-related data sources to identify 
issues/anomalies/improvement opportunities across the customer service 
channel modes.","IRS' Customer Experience (CX) Analytics is a tool that analyzes customer service data to find problems, anomalies, and areas for improvement across different service channels. It uses various sources of customer-related information to identify issues and suggest ways to enhance the overall customer experience.","IRS' Customer Experience (CX) Analytics is a tool that analyzes customer service data to find problems, anomalies, and areas for improvement across different service channels. It uses various sources of customer-related information to identify issues and suggest ways to enhance the overall customer experience.",,,False,False
DOC-0016-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Coastal Change Analysis Program (C-CAP),"Beginning in 2015, C-CAP embarked on operational high resolution land cover 
development effort that utilized geographic object-based image analysis and ML 
algorithms such as Random Forest to classify coastal land cover from 1m multispectral 
imagery. More recently, C-CAP has been relying on a CNN approach for the deriving the 
impervious surface component of their land cover products. The majority of the work is 
accomplished through external contracts. Prior to the high-res effort, C-CAP focused on 
developing Landsat based moderate resolution multi-date land cover for the coastal U.S. 
In 2002, C-CAP adopted a methodology that employed Classification and Regression Trees 
for land cover data development.",,,,Department of Commerce,"Coastal Change Analysis Program (C-CAP): 
Beginning in 2015, C-CAP embarked on operational high resolution land cover 
development effort that utilized geographic object-based image analysis and ML 
algorithms such as Random Forest to classify coastal land cover from 1m multispectral 
imagery. More recently, C-CAP has been relying on a CNN approach for the deriving the 
impervious surface component of their land cover products. The majority of the work is 
accomplished through external contracts. Prior to the high-res effort, C-CAP focused on 
developing Landsat based moderate resolution multi-date land cover for the coastal U.S. 
In 2002, C-CAP adopted a methodology that employed Classification and Regression Trees 
for land cover data development.","The Coastal Change Analysis Program (C-CAP) has been using geographic object-based image analysis and ML algorithms to classify coastal land cover from high-resolution imagery since 2015. They have recently started using a CNN approach for deriving the impervious surface component of their land cover products. Prior to this, C-CAP focused on developing moderate resolution land cover using Landsat data, adopting a methodology that employed Classification and Regression Trees in 2002.","The Coastal Change Analysis Program (C-CAP) has been using geographic object-based image analysis and ML algorithms to classify coastal land cover from high-resolution imagery since 2015. They have recently started using a CNN approach for deriving the impervious surface component of their land cover products. Prior to this, C-CAP focused on developing moderate resolution land cover using Landsat data, adopting a methodology that employed Classification and Regression Trees in 2002.",,,False,False
DOL-0008-2023,DOL,,,DOL Intranet Website Chatbot Assistant,"Conversational chatbot on DOL intranet websites to help answer common procurement questions, as well as specific contract questions.",Initiation,Cloud based commercial-off-the-shelf pre-trained NLP models,,Department of Labor,"DOL Intranet Website Chatbot Assistant: 
Conversational chatbot on DOL intranet websites to help answer common procurement questions, as well as specific contract questions.",The DOL Intranet Website Chatbot Assistant is a conversational chatbot that is available on DOL intranet websites. It is designed to assist users by answering common procurement questions and providing information about specific contracts.,The DOL Intranet Website Chatbot Assistant is a conversational chatbot that is available on DOL intranet websites. It is designed to assist users by answering common procurement questions and providing information about specific contracts.,,,False,False
DOE-0069-2023,DOE,National Energy Technology Laboratory,,To drive insights on the dependencies between the natural gas and electricity sectors to increase reliability of the NG system,"Commercially available models will be used to generate predictive 
scenarios",,Big Data,,Department of Energy,"To drive insights on the dependencies between the natural gas and electricity sectors to increase reliability of the NG system: 
Commercially available models will be used to generate predictive 
scenarios",Commercially available models will be utilized to create predictive scenarios that will enhance the understanding of the interconnections between the natural gas and electricity sectors. This will ultimately improve the reliability of the natural gas system.,Commercially available models will be utilized to create predictive scenarios that will enhance the understanding of the interconnections between the natural gas and electricity sectors. This will ultimately improve the reliability of the natural gas system.,,,False,False
HHS-0055-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Medicaid And CHIP Financial (MACFin) DSH Payment Forecasting model,"Forecasting model to predict future DSH payment (next 1 year) based on historical data and trends (ex: last 1-3 years). Multiple models were trained based on time series (i.e., statistical models) and machine learning based model and compared for best performance in terms of average means error on DSH payment amount across all hospitals. DSH data were highly disorganized, the team spent time cleaning and combing the data from over 6 years for all states to conduct full model implementation and meaningful analysis. Predicting future DSH payment facilitates early planning and recommendations around trends, redistributions, etc. Modified models can also be built to predict other DSH-related metrics like payment-to-uncompensated ratio, underpayment, or overpayment",Initiation,,,Department of Health and Human Services,"Medicaid And CHIP Financial (MACFin) DSH Payment Forecasting model: 
Forecasting model to predict future DSH payment (next 1 year) based on historical data and trends (ex: last 1-3 years). Multiple models were trained based on time series (i.e., statistical models) and machine learning based model and compared for best performance in terms of average means error on DSH payment amount across all hospitals. DSH data were highly disorganized, the team spent time cleaning and combing the data from over 6 years for all states to conduct full model implementation and meaningful analysis. Predicting future DSH payment facilitates early planning and recommendations around trends, redistributions, etc. Modified models can also be built to predict other DSH-related metrics like payment-to-uncompensated ratio, underpayment, or overpayment","The Medicaid And CHIP Financial (MACFin) DSH Payment Forecasting model is used to predict future DSH payments based on historical data and trends. The model was trained using time series and machine learning techniques to determine the best performance in terms of average means error. The team had to clean and organize data from over 6 years for all states in order to implement the model effectively and provide meaningful analysis. This forecasting helps with early planning and recommendations related to trends and redistributions, and modified models can also be used for predicting other DSH-related metrics.","The Medicaid And CHIP Financial (MACFin) DSH Payment Forecasting model is used to predict future DSH payments based on historical data and trends. The model was trained using time series and machine learning techniques to determine the best performance in terms of average means error. The team had to clean and organize data from over 6 years for all states in order to implement the model effectively and provide meaningful analysis. This forecasting helps with early planning and recommendations related to trends and redistributions, and modified models can also be used for predicting other DSH-related metrics.",,,False,False
NASA-0005-2023,NASA,Ames Research Center,,Pre-trained microscopy image neural network Encoders,"Convolutional Neural Network encoders were trained on over 100,000 microscopy images of materials. When
deployed in downstream microscopy tasks through transfer learning, encoders pre-trained on MicroNet outperform
ImageNet encoders. These pre-trained MicroNet encoders have been successfully deployed for semantic
segmentation, instance segmentation, and regression tasks. Current work is ongoing to deploy the encoders for
generative tasks and 3D texture synthesis tasks. The technology has been used to quantify the microstructure of
numerous materials including SLS core stage welds, Ni-based superalloys, composites, and oxide dispersion
strengthened alloys. Establishing the relationship between processing (how a material is made), microstructure (the
atomisitc and phase arrangement of a material), and properties of materials is fundemental to the design and
development of new materials. Microstructure is often analyzed qualitatively or by tedious manual measurements.
This technology enables and improves the rapid quantification of material microstructure from microscope images
for use in data-driven approaches to design materials faster.",In-use,Transfer learning,https://github.com/nasa/pretrained-microscopy-models,National Aeronautics and Space Administration,"Pre-trained microscopy image neural network Encoders: 
Convolutional Neural Network encoders were trained on over 100,000 microscopy images of materials. When
deployed in downstream microscopy tasks through transfer learning, encoders pre-trained on MicroNet outperform
ImageNet encoders. These pre-trained MicroNet encoders have been successfully deployed for semantic
segmentation, instance segmentation, and regression tasks. Current work is ongoing to deploy the encoders for
generative tasks and 3D texture synthesis tasks. The technology has been used to quantify the microstructure of
numerous materials including SLS core stage welds, Ni-based superalloys, composites, and oxide dispersion
strengthened alloys. Establishing the relationship between processing (how a material is made), microstructure (the
atomisitc and phase arrangement of a material), and properties of materials is fundemental to the design and
development of new materials. Microstructure is often analyzed qualitatively or by tedious manual measurements.
This technology enables and improves the rapid quantification of material microstructure from microscope images
for use in data-driven approaches to design materials faster.","Pre-trained microscopy image neural network Encoders have been developed and trained on over 100,000 microscopy images of materials. These encoders outperform ImageNet encoders when used in downstream microscopy tasks, such as semantic segmentation, instance segmentation, and regression tasks. The technology allows for the rapid quantification of material microstructure from microscope images, which is crucial for designing and developing new materials.","Pre-trained microscopy image neural network Encoders have been developed and trained on over 100,000 microscopy images of materials. These encoders outperform ImageNet encoders when used in downstream microscopy tasks, such as semantic segmentation, instance segmentation, and regression tasks. The technology allows for the rapid quantification of material microstructure from microscope images, which is crucial for designing and developing new materials.",,,False,False
USDA-0011-2023,USDA,USDA,ARS,NAL Automated indexing,"Cogito (vendor) software, uses AI for automated subject indexing to annotate peer reviewed journal articles (~500,000 annually) using the National Ag Library Thesaurus concept space (NALT). Only NALT concepts are annotated as metadata to content in the Library's bibliographic citation database, AGRICOLA, PubAg, and Ag Data Commons.",Operation and Management,Natural Language Processing,,Department of Agriculture,"NAL Automated indexing: 
Cogito (vendor) software, uses AI for automated subject indexing to annotate peer reviewed journal articles (~500,000 annually) using the National Ag Library Thesaurus concept space (NALT). Only NALT concepts are annotated as metadata to content in the Library's bibliographic citation database, AGRICOLA, PubAg, and Ag Data Commons.","The NAL Automated indexing system, Cogito, utilizes artificial intelligence to automatically add subject indexing to around 500,000 peer-reviewed journal articles every year. This software uses the National Ag Library Thesaurus concept space (NALT) to annotate the articles, with only NALT concepts being used as metadata in the Library's bibliographic citation databases such as AGRICOLA, PubAg, and Ag Data Commons.","The NAL Automated indexing system, Cogito, utilizes artificial intelligence to automatically add subject indexing to around 500,000 peer-reviewed journal articles every year. This software uses the National Ag Library Thesaurus concept space (NALT) to annotate the articles, with only NALT concepts being used as metadata in the Library's bibliographic citation databases such as AGRICOLA, PubAg, and Ag Data Commons.",,,False,False
HHS-0067-2023,HHS,FDA,CDER/Office of Generic Drugs,Development of Machine Learning Approaches to Population Pharmacokinetic Model Selection and Evaluation of Application to Model-Based Bioequivalence Analysis,"1. Development of a deep learning/reinforcement learning approach to population pharmacokinetic model selections
2. Implementation of an established Genetic algorithm approach to population pharmacokinetic model selections in Python.",Development and Acquisition,,,Department of Health and Human Services,"Development of Machine Learning Approaches to Population Pharmacokinetic Model Selection and Evaluation of Application to Model-Based Bioequivalence Analysis: 
1. Development of a deep learning/reinforcement learning approach to population pharmacokinetic model selections
2. Implementation of an established Genetic algorithm approach to population pharmacokinetic model selections in Python.","The text describes the development of two approaches to population pharmacokinetic model selection. The first approach involves using deep learning/reinforcement learning, while the second approach utilizes a genetic algorithm implemented in Python. Both approaches aim to improve model-based bioequivalence analysis.","The text describes the development of two approaches to population pharmacokinetic model selection. The first approach involves using deep learning/reinforcement learning, while the second approach utilizes a genetic algorithm implemented in Python. Both approaches aim to improve model-based bioequivalence analysis.",,,False,False
DOE-0090-2023,DOE,National Energy Technology Laboratory,,To develop a general drag model for assemblies of non-spherical particles created with artificial neural networks,"The project plans to develop a more accurate artificial neural network 
(ANN)-based method for modeling the momentum exchange in fluid-
solid multiphase mixtures to significantly improve the accuracy and 
reduce the uncertainty of multiphase numerical codes and, in particular, 
of MFiX, by developing and providing a general and accurate method for 
determining the drag coefficients of assemblies of non-spherical 
particles for wide ranges of Reynolds numbers, Stokes numbers, and 
fluid-solid properties and characteristics. The research team will achieve 
this goal by conducting numerical computations with a validated in-
house CFD code and using artificial intelligence methods to develop an 
ANN that will be implemented in TensorFlow and linked with the MFiX 
code.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To develop a general drag model for assemblies of non-spherical particles created with artificial neural networks: 
The project plans to develop a more accurate artificial neural network 
(ANN)-based method for modeling the momentum exchange in fluid-
solid multiphase mixtures to significantly improve the accuracy and 
reduce the uncertainty of multiphase numerical codes and, in particular, 
of MFiX, by developing and providing a general and accurate method for 
determining the drag coefficients of assemblies of non-spherical 
particles for wide ranges of Reynolds numbers, Stokes numbers, and 
fluid-solid properties and characteristics. The research team will achieve 
this goal by conducting numerical computations with a validated in-
house CFD code and using artificial intelligence methods to develop an 
ANN that will be implemented in TensorFlow and linked with the MFiX 
code.","The project aims to develop an artificial neural network (ANN) method to model the momentum exchange in fluid-solid mixtures of non-spherical particles. This will improve the accuracy and reduce uncertainty in numerical codes, particularly in the MFiX code, by providing a reliable method for determining drag coefficients for various Reynolds numbers, Stokes numbers, and fluid-solid properties. The research team will use validated CFD code and artificial intelligence techniques to develop the ANN, which will be implemented in TensorFlow and linked with the MFiX code.","The project aims to develop an artificial neural network (ANN) method to model the momentum exchange in fluid-solid mixtures of non-spherical particles. This will improve the accuracy and reduce uncertainty in numerical codes, particularly in the MFiX code, by providing a reliable method for determining drag coefficients for various Reynolds numbers, Stokes numbers, and fluid-solid properties. The research team will use validated CFD code and artificial intelligence techniques to develop the ANN, which will be implemented in TensorFlow and linked with the MFiX code.",,,False,False
DOI-0015-2023,DOI,USGS,,"Data Mining, Machine Learning and the IHS Markit Databases","Support the current DOI Secretarial Priority Project (Smart Energy Development) focused on the issue of identifying areas of potential conflict between energy development and alternative priorities, through the application of machine learning techniques to extract spatial patterns related to future development._x000D_
_x000D_
Lay the groundwork for the addition of new sets of skills, new types of analyses, and new products for the ERP and for the Mission Area; build internal knowledge about what machine learning can do for the ERP.",Implementation,"Random Forest Regression, XGBoost",,Department of Interior,"Data Mining, Machine Learning and the IHS Markit Databases: 
Support the current DOI Secretarial Priority Project (Smart Energy Development) focused on the issue of identifying areas of potential conflict between energy development and alternative priorities, through the application of machine learning techniques to extract spatial patterns related to future development._x000D_
_x000D_
Lay the groundwork for the addition of new sets of skills, new types of analyses, and new products for the ERP and for the Mission Area; build internal knowledge about what machine learning can do for the ERP.","The use of data mining, machine learning, and IHS Markit databases can assist in identifying potential conflicts between energy development and other priorities. This will lay the foundation for introducing new skills, analyses, and products for the ERP and Mission Area, while also increasing understanding of the capabilities of machine learning in the ERP.","The use of data mining, machine learning, and IHS Markit databases can assist in identifying potential conflicts between energy development and other priorities. This will lay the foundation for introducing new skills, analyses, and products for the ERP and Mission Area, while also increasing understanding of the capabilities of machine learning in the ERP.",,,False,False
HHS-0012-2023,HHS,ASPR,BARDA (DRIVe),Digital MCM: Visual Dx,Using smartphone image with AI to detect the presence of mPox,Development and Acquisition,,,Department of Health and Human Services,"Digital MCM: Visual Dx: 
Using smartphone image with AI to detect the presence of mPox",Digital MCM's Visual Dx is a smartphone app that utilizes artificial intelligence to identify the presence of mPox in images.,Digital MCM's Visual Dx is a smartphone app that utilizes artificial intelligence to identify the presence of mPox in images.,,,False,False
DOE-0001-2023,DOE,Brookhaven National Laboratory,,Machine Learning for Autonomous Control of Scientific User Facilities,"BNL will work alongside SLAC, to implement ML algorithm(s) into NSLS-
II Operations to interpret accelerator data more intelligently.  We intend 
to train said algorithms with 5+ years of archived device-data from 
accelerator components, records of previous fault causes (to connect to 
data-symptoms) and stored beam current.",,,,Department of Energy,"Machine Learning for Autonomous Control of Scientific User Facilities: 
BNL will work alongside SLAC, to implement ML algorithm(s) into NSLS-
II Operations to interpret accelerator data more intelligently.  We intend 
to train said algorithms with 5+ years of archived device-data from 
accelerator components, records of previous fault causes (to connect to 
data-symptoms) and stored beam current.","BNL and SLAC will collaborate to integrate machine learning algorithms into NSLS-II Operations at scientific user facilities. The goal is to enable intelligent interpretation of accelerator data by training the algorithms with archived device data, records of previous fault causes, and stored beam current spanning over 5 years.","BNL and SLAC will collaborate to integrate machine learning algorithms into NSLS-II Operations at scientific user facilities. The goal is to enable intelligent interpretation of accelerator data by training the algorithms with archived device data, records of previous fault causes, and stored beam current spanning over 5 years.",,,False,False
GSA-0005-2023,GSA,FAS / GSA IT (IC),,Chatbot for Federal Acquisition Community,"The introduction of a chatbot will enable the GSA FAS NCSC (National Customer Support Center) to streamline the customer experience process, and automate providing answers to documented commonly asked questions through public facing knowledge articles.  The end goal is this will reduce staffing requirements for NCSC’s live chat programs and allow the NCSC resources to be dedicated to other proactive customer services initiatives.  Customers will still have the option to connect to a live agent if they choose by requesting an agent.",Operation and Maintenance,Virtual assistant; Natural Language Processing (NLP),,U.S. General Services Administration,"Chatbot for Federal Acquisition Community: 
The introduction of a chatbot will enable the GSA FAS NCSC (National Customer Support Center) to streamline the customer experience process, and automate providing answers to documented commonly asked questions through public facing knowledge articles.  The end goal is this will reduce staffing requirements for NCSC’s live chat programs and allow the NCSC resources to be dedicated to other proactive customer services initiatives.  Customers will still have the option to connect to a live agent if they choose by requesting an agent.","The GSA FAS NCSC plans to implement a chatbot to improve customer experience by automating responses to frequently asked questions. This will reduce the need for live chat agents and free up resources for other customer service initiatives, although customers can still request to speak with a live agent if desired.","The GSA FAS NCSC plans to implement a chatbot to improve customer experience by automating responses to frequently asked questions. This will reduce the need for live chat agents and free up resources for other customer service initiatives, although customers can still request to speak with a live agent if desired.",,,False,False
USDA-0014-2023,USDA,USDA,FNS,Retailer Receipt Analysis,"The Retailer Receipt Analysis is a Proof of Concept (POC) that uses Optical Character Recognition (OCR), an application of artificial intelligence on a sample (no more than 1000) of FNS receipt and invoice data. Consultants will use this data to demonstrate how the existing manual process can be automated, saving staff time, ensuring accurate review, and detecting difficult patterns. The goal of this POC will pave the way for a review system that (1) has an automated workflow and learns from analyst feedback (2) can incorporate know SNAP fraud patterns, look for new patterns, and visualize alerts on these patterns on retailer invoices and receipts.",Development and Acquisition,Machine Learning,,Department of Agriculture,"Retailer Receipt Analysis: 
The Retailer Receipt Analysis is a Proof of Concept (POC) that uses Optical Character Recognition (OCR), an application of artificial intelligence on a sample (no more than 1000) of FNS receipt and invoice data. Consultants will use this data to demonstrate how the existing manual process can be automated, saving staff time, ensuring accurate review, and detecting difficult patterns. The goal of this POC will pave the way for a review system that (1) has an automated workflow and learns from analyst feedback (2) can incorporate know SNAP fraud patterns, look for new patterns, and visualize alerts on these patterns on retailer invoices and receipts.","The Retailer Receipt Analysis is a Proof of Concept (POC) that uses OCR on a sample of FNS receipt and invoice data to automate the manual process, save time, ensure accuracy, and detect difficult patterns. The goal is to develop a review system with an automated workflow that learns from analyst feedback, can identify known SNAP fraud patterns, detect new patterns, and visually highlight alerts on retailer invoices and receipts.","The Retailer Receipt Analysis is a Proof of Concept (POC) that uses OCR on a sample of FNS receipt and invoice data to automate the manual process, save time, ensure accuracy, and detect difficult patterns. The goal is to develop a review system with an automated workflow that learns from analyst feedback, can identify known SNAP fraud patterns, detect new patterns, and visually highlight alerts on retailer invoices and receipts.",,,False,False
USDA-0035-2023,USDA,USDA,OCIO,Acquisition Approval Request Compliance Tool,"A natural language processing (NLP) model was developed to utilize the text in procurement header and line descriptions within USDA's Integrated Acquisition System (IAS) to determine the likelihood that an award is IT-related, and therefore might require an AAR. The model uses the text characteristics for awards that have an AAR number entered into IAS and then calculates the probability of being IT-related for those procurements that did not have an AAR Number entered in IAS.",Operation and Management,Natural Language Processing,,Department of Agriculture,"Acquisition Approval Request Compliance Tool: 
A natural language processing (NLP) model was developed to utilize the text in procurement header and line descriptions within USDA's Integrated Acquisition System (IAS) to determine the likelihood that an award is IT-related, and therefore might require an AAR. The model uses the text characteristics for awards that have an AAR number entered into IAS and then calculates the probability of being IT-related for those procurements that did not have an AAR Number entered in IAS.",The Acquisition Approval Request Compliance Tool is a natural language processing model that analyzes text in procurement descriptions to determine the likelihood of an award being IT-related and requiring an AAR. It uses the characteristics of awards with AAR numbers to calculate the probability of IT-relatedness for procurements without an AAR number.,The Acquisition Approval Request Compliance Tool is a natural language processing model that analyzes text in procurement descriptions to determine the likelihood of an award being IT-related and requiring an AAR. It uses the characteristics of awards with AAR numbers to calculate the probability of IT-relatedness for procurements without an AAR number.,,,False,False
VA-0011-2023,VA,,,Behavidence,Behavidence is a mental health tracking app. Veterans download the app onto their phone and it compares their phone usage to that of a digital phenotype that represents people with confirmed diagnosis of mental health conditions. ,,,,Department of Veterans Affairs,"Behavidence: 
Behavidence is a mental health tracking app. Veterans download the app onto their phone and it compares their phone usage to that of a digital phenotype that represents people with confirmed diagnosis of mental health conditions. ","Behavidence is an app that helps veterans track their mental health. By comparing their phone usage to a digital phenotype of individuals with confirmed mental health diagnoses, the app provides valuable insights and support.","Behavidence is an app that helps veterans track their mental health. By comparing their phone usage to a digital phenotype of individuals with confirmed mental health diagnoses, the app provides valuable insights and support.",,,False,False
DOE-0037-2023,DOE,National Energy Technology Laboratory,,Computational methods for the characterization of CO2 chemisorption in amine- functionalized MOFs.,"Databases of MOFs will be screened using computational methods to 
identify promising MOFs. Software will be further developed to allow for 
the addition of desirable functional groups (amines) to metal centers 
and/or ligands of MOFs. The team will calculate the reaction enthalpy for 
CO2 sorption in amine functionalized MOFs and further computational 
methods for the characterization of CO2 chemisorption in amine-
functionalized MOFs will be developed.",,Other,,Department of Energy,"Computational methods for the characterization of CO2 chemisorption in amine- functionalized MOFs.: 
Databases of MOFs will be screened using computational methods to 
identify promising MOFs. Software will be further developed to allow for 
the addition of desirable functional groups (amines) to metal centers 
and/or ligands of MOFs. The team will calculate the reaction enthalpy for 
CO2 sorption in amine functionalized MOFs and further computational 
methods for the characterization of CO2 chemisorption in amine-
functionalized MOFs will be developed.",Researchers will use computational methods to analyze databases of metal-organic frameworks (MOFs) and identify potential MOFs that are amine-functionalized. They will also develop software to add amine functional groups to the metal centers and/or ligands of MOFs. The team will calculate the reaction enthalpy for CO2 sorption in amine-functionalized MOFs and develop additional computational methods for characterizing CO2 chemisorption in these MOFs.,Researchers will use computational methods to analyze databases of metal-organic frameworks (MOFs) and identify potential MOFs that are amine-functionalized. They will also develop software to add amine functional groups to the metal centers and/or ligands of MOFs. The team will calculate the reaction enthalpy for CO2 sorption in amine-functionalized MOFs and develop additional computational methods for characterizing CO2 chemisorption in these MOFs.,,,False,False
DOE-0151-2023,DOE,National Energy Technology Laboratory,,Using ML to design sensing materials which can work under harsh environments.,"The team proposes to develop an ML approach that relies upon 
established experimental and theoretical evidence to gain a 
comprehensive ML model and boost the gas sensing material design. 
The essence of this approach will be to assess materials’ optimal 
performance at a specific condition, such as temperature, pressure, and 
radiation levels. The development of the package will occur in several 
steps: (1) building a materials database from various sources; (2) using 
ML techniques to build, evaluate, and optimize an ML model; (3) 
predicting the temperature dependence of sensing properties, such as 
gas selectivity, for FECM relevant gas species to screen the materials in 
the material bank, or proposing new sensing materials; and (4) exploring 
the gas sensing mechanisms suited for high-temperature application for 
those predicted most promising gas sensing materials.",,Other,,Department of Energy,"Using ML to design sensing materials which can work under harsh environments.: 
The team proposes to develop an ML approach that relies upon 
established experimental and theoretical evidence to gain a 
comprehensive ML model and boost the gas sensing material design. 
The essence of this approach will be to assess materials’ optimal 
performance at a specific condition, such as temperature, pressure, and 
radiation levels. The development of the package will occur in several 
steps: (1) building a materials database from various sources; (2) using 
ML techniques to build, evaluate, and optimize an ML model; (3) 
predicting the temperature dependence of sensing properties, such as 
gas selectivity, for FECM relevant gas species to screen the materials in 
the material bank, or proposing new sensing materials; and (4) exploring 
the gas sensing mechanisms suited for high-temperature application for 
those predicted most promising gas sensing materials.",The team plans to use ML and established evidence to create a comprehensive ML model for designing gas sensing materials that can withstand harsh environments. This approach involves evaluating materials' performance under specific conditions and predicting temperature dependence of sensing properties to screen existing materials or propose new ones for high-temperature applications.,The team plans to use ML and established evidence to create a comprehensive ML model for designing gas sensing materials that can withstand harsh environments. This approach involves evaluating materials' performance under specific conditions and predicting temperature dependence of sensing properties to screen existing materials or propose new ones for high-temperature applications.,,,False,False
DOL-0016-2023,DOL,,,Scanner Data Product Classification,"BLS receives bulk data from some corporations related to the cost of goods they sell and services they provide. Consumer Price Index (CPI) staff have hand-coded a segment of the items in these data into Entry Level Item (ELI) codes. To accept and make use of these bulk data transfers at scale, BLS has begun to use machine learning to label data with ELI codes. The machine learning model takes as input word frequency counts from item descriptions. Logistic regression is then used to estimate the probability of each item being classified in each ELI category based on the word frequency categorizations. The highest probability category is selected for inclusion in the data. Any selected classifications that do not meet a certain probability threshold are flagged for human review.",Operation and Maintenance,"Natural Langauge Processing, Logistic Regression, Classification",,Department of Labor,"Scanner Data Product Classification: 
BLS receives bulk data from some corporations related to the cost of goods they sell and services they provide. Consumer Price Index (CPI) staff have hand-coded a segment of the items in these data into Entry Level Item (ELI) codes. To accept and make use of these bulk data transfers at scale, BLS has begun to use machine learning to label data with ELI codes. The machine learning model takes as input word frequency counts from item descriptions. Logistic regression is then used to estimate the probability of each item being classified in each ELI category based on the word frequency categorizations. The highest probability category is selected for inclusion in the data. Any selected classifications that do not meet a certain probability threshold are flagged for human review.","The Bureau of Labor Statistics (BLS) receives data from corporations about the cost of their goods and services. BLS has started using machine learning to label this data with Entry Level Item (ELI) codes based on word frequency counts from item descriptions. Logistic regression is used to estimate the probability of each item being classified in each ELI category, and any classifications below a certain probability threshold are flagged for human review.","The Bureau of Labor Statistics (BLS) receives data from corporations about the cost of their goods and services. BLS has started using machine learning to label this data with Entry Level Item (ELI) codes based on word frequency counts from item descriptions. Logistic regression is used to estimate the probability of each item being classified in each ELI category, and any classifications below a certain probability threshold are flagged for human review.",,,False,False
HHS-0113-2023,HHS,NIH,National Institutes of Health (NIH) NIAID,"Division of Allergy, Immunology, and Transplantation (DAIT) AIDS-Related Research Solution","The tool uses natural language processing (NLP), text extraction, and classification algorithms to predict both high/medium/low priority and area of research for a grant application. The incoming grant applications are ranked based on these predictions and more highly-ranked applications are prioritized for review.",Operation and Maintenance,,,Department of Health and Human Services,"Division of Allergy, Immunology, and Transplantation (DAIT) AIDS-Related Research Solution: 
The tool uses natural language processing (NLP), text extraction, and classification algorithms to predict both high/medium/low priority and area of research for a grant application. The incoming grant applications are ranked based on these predictions and more highly-ranked applications are prioritized for review.","The Division of Allergy, Immunology, and Transplantation (DAIT) has developed a solution to aid in AIDS-related research. This tool utilizes natural language processing, text extraction, and classification algorithms to predict the priority level and research area for grant applications. By ranking the applications based on these predictions, the tool helps prioritize higher-ranked applications for review.","The Division of Allergy, Immunology, and Transplantation (DAIT) has developed a solution to aid in AIDS-related research. This tool utilizes natural language processing, text extraction, and classification algorithms to predict the priority level and research area for grant applications. By ranking the applications based on these predictions, the tool helps prioritize higher-ranked applications for review.",,,False,False
HHS-0153-2023,HHS,NIH,National Institutes of Health (NIH) OD/ORF,Chiller Plant Optimization,This project will help to reduce the energy usage for producing chilled water to cool the NIH campus.,Development and Acquisition,,,Department of Health and Human Services,"Chiller Plant Optimization: 
This project will help to reduce the energy usage for producing chilled water to cool the NIH campus.","The goal of the Chiller Plant Optimization project is to decrease the amount of energy required to produce chilled water and cool the NIH campus. By implementing efficiency measures, the project aims to reduce energy usage and improve overall sustainability.","The goal of the Chiller Plant Optimization project is to decrease the amount of energy required to produce chilled water and cool the NIH campus. By implementing efficiency measures, the project aims to reduce energy usage and improve overall sustainability.",,,False,False
DOE-0126-2023,DOE,National Energy Technology Laboratory,,To leverage ML models to increase the size and complexity of problems that can be optimized within IDAES.,"The objective is to leverage ML models as surrogates for complex unit 
operations or to bridge between scales to increase the size and 
complexity of models that can be optimized within IDAES.",,Other,,Department of Energy,"To leverage ML models to increase the size and complexity of problems that can be optimized within IDAES.: 
The objective is to leverage ML models as surrogates for complex unit 
operations or to bridge between scales to increase the size and 
complexity of models that can be optimized within IDAES.",The goal is to use ML models as substitutes for complex unit operations or to connect different scales in order to expand the range of problems that can be optimized in IDAES. This would allow for larger and more complex models to be handled within IDAES.,The goal is to use ML models as substitutes for complex unit operations or to connect different scales in order to expand the range of problems that can be optimized in IDAES. This would allow for larger and more complex models to be handled within IDAES.,,,False,False
DOC-0026-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,"CoralNet: Ongoing operational use, improvement, and development, of machine vision point classification","CoralNet is our operational point annotation software for benthic photo quadrat 
annotation. Our development of our classifiers has allowed us to significantly reduce our 
human annotation, and we continue to co-develop (and co-fund) new developments in 
CoralNet,",,,,Department of Commerce,"CoralNet: Ongoing operational use, improvement, and development, of machine vision point classification: 
CoralNet is our operational point annotation software for benthic photo quadrat 
annotation. Our development of our classifiers has allowed us to significantly reduce our 
human annotation, and we continue to co-develop (and co-fund) new developments in 
CoralNet,","CoralNet is a point annotation software used for classifying benthic photos. The development of classifiers has reduced the need for human annotation, and ongoing improvements and developments are being made to the software.","CoralNet is a point annotation software used for classifying benthic photos. The development of classifiers has reduced the need for human annotation, and ongoing improvements and developments are being made to the software.",,,False,False
DOE-0051-2023,DOE,National Energy Technology Laboratory,,Geochemically Informed Leak Detection (GILD),"A Bayesian Belief Network has been developed to interogate the altered 
geochemistry around a potential CO2 leakage site. The use of the BNN 
and site specific parameters will reduce the percentage of false 
positives with this method.",,"Artificial Intelligence, Other",,Department of Energy,"Geochemically Informed Leak Detection (GILD): 
A Bayesian Belief Network has been developed to interogate the altered 
geochemistry around a potential CO2 leakage site. The use of the BNN 
and site specific parameters will reduce the percentage of false 
positives with this method.","A Bayesian Belief Network called Geochemically Informed Leak Detection (GILD) has been created to analyze changes in geochemistry near a possible CO2 leakage area. By utilizing this network and site-specific data, the method can effectively decrease the occurrence of false positives.","A Bayesian Belief Network called Geochemically Informed Leak Detection (GILD) has been created to analyze changes in geochemistry near a possible CO2 leakage area. By utilizing this network and site-specific data, the method can effectively decrease the occurrence of false positives.",,,False,False
HHS-0115-2023,HHS,NIH,National Institutes of Health (NIH) NIAID,Tuberculosis (TB) Case Browser Image Text Detection,A tool to detect text in images that could be potentially Personally Identifiable Information (PII)/ Protected Health Information (PHI) in TB Portals.,Operation and Maintenance,,,Department of Health and Human Services,"Tuberculosis (TB) Case Browser Image Text Detection: 
A tool to detect text in images that could be potentially Personally Identifiable Information (PII)/ Protected Health Information (PHI) in TB Portals.",The TB Case Browser Image Text Detection is a tool designed to identify text in images within TB Portals that may contain Personally Identifiable Information or Protected Health Information. Its purpose is to ensure the privacy and security of sensitive data related to tuberculosis cases.,The TB Case Browser Image Text Detection is a tool designed to identify text in images within TB Portals that may contain Personally Identifiable Information or Protected Health Information. Its purpose is to ensure the privacy and security of sensitive data related to tuberculosis cases.,,,False,False
HHS-0032-2023,HHS,CDC,NCHS,Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation in Record Linkage,"CDC's National Center for Health Statistics (NCHS) Data Linkage Program has implemented both supervised and unsupervised machine learning (ML) techniques in their linkage algorithms. The Sequential Coverage Algorithm (SCA), a supervised ML algorithm, is used to develop joining methods (or blocking groups) when working with very large datasets. The unsupervised partial Expectation-Maximization (EM) estimation is used to estimate the proportion of pairs that are matches within each block. Both methods improve linkage accuracy and efficiency.",Operation and Maintenance,,,Department of Health and Human Services,"Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation in Record Linkage: 
CDC's National Center for Health Statistics (NCHS) Data Linkage Program has implemented both supervised and unsupervised machine learning (ML) techniques in their linkage algorithms. The Sequential Coverage Algorithm (SCA), a supervised ML algorithm, is used to develop joining methods (or blocking groups) when working with very large datasets. The unsupervised partial Expectation-Maximization (EM) estimation is used to estimate the proportion of pairs that are matches within each block. Both methods improve linkage accuracy and efficiency.","The CDC's National Center for Health Statistics (NCHS) Data Linkage Program uses the Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation techniques in their linkage algorithms. SCA is a supervised machine learning algorithm that helps with joining methods for large datasets, while the unsupervised EM estimation is used to estimate the proportion of matching pairs in each block. These methods enhance the accuracy and efficiency of the linkage process.","The CDC's National Center for Health Statistics (NCHS) Data Linkage Program uses the Sequential Coverage Algorithm (SCA) and partial Expectation-Maximization (EM) estimation techniques in their linkage algorithms. SCA is a supervised machine learning algorithm that helps with joining methods for large datasets, while the unsupervised EM estimation is used to estimate the proportion of matching pairs in each block. These methods enhance the accuracy and efficiency of the linkage process.",,,False,False
SSA-0010-2023,SSA,"Office of Disability Information Systems, Office of Hearing Operations, Office of Appellate Operations",,Duplicate Identification Process (DIP),"Duplicate Identification Process's (DIP's) objective is to help the user to�identify and flag�and mark duplicates�more efficiently, reducing the amount�of time spent to review�cases for�hearings.�DIP uses artificial�intelligence software in the form of image recognition technology to accurately�identify duplicates consistent with SSA�policy.?",,,,Social Security Administration,"Duplicate Identification Process (DIP): 
Duplicate Identification Process's (DIP's) objective is to help the user to�identify and flag�and mark duplicates�more efficiently, reducing the amount�of time spent to review�cases for�hearings.�DIP uses artificial�intelligence software in the form of image recognition technology to accurately�identify duplicates consistent with SSA�policy.?",The Duplicate Identification Process (DIP) aims to improve the efficiency of identifying and flagging duplicate cases for hearings. It utilizes artificial intelligence software and image recognition technology to accurately identify duplicates in accordance with SSA policy.,The Duplicate Identification Process (DIP) aims to improve the efficiency of identifying and flagging duplicate cases for hearings. It utilizes artificial intelligence software and image recognition technology to accurately identify duplicates in accordance with SSA policy.,,,False,False
DOE-0112-2023,DOE,National Energy Technology Laboratory,,To evaluate current infrastructure throughout a study area and evaluating future infrastructure needs to accelerate the deployment of CCUS,"One key task focuses on evaluating current infrastructure throughout the 
Initiative study area and evaluating future infrastructure needs to 
accelerate the deployment of CCUS. LANL will utilize its unique 
technologies for this project focusing on SimCCS, with a minor 
consulting role using NRAP and machine learning algorithms.",,Artificial Intelligence Unknown,,Department of Energy,"To evaluate current infrastructure throughout a study area and evaluating future infrastructure needs to accelerate the deployment of CCUS: 
One key task focuses on evaluating current infrastructure throughout the 
Initiative study area and evaluating future infrastructure needs to 
accelerate the deployment of CCUS. LANL will utilize its unique 
technologies for this project focusing on SimCCS, with a minor 
consulting role using NRAP and machine learning algorithms.","The text states that one of the main tasks is to evaluate current infrastructure and future infrastructure needs in order to speed up the deployment of CCUS (carbon capture, utilization, and storage). LANL will primarily use SimCCS technology for this project, while also providing some minor consulting using NRAP and machine learning algorithms.","The text states that one of the main tasks is to evaluate current infrastructure and future infrastructure needs in order to speed up the deployment of CCUS (carbon capture, utilization, and storage). LANL will primarily use SimCCS technology for this project, while also providing some minor consulting using NRAP and machine learning algorithms.",,,False,False
DOC-0041-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Picky,"Using CNN to pick out objects of a particular size from sides scan imagery.  Presents users 
with a probability that allows for automation of contact picking in the field.  Side scan 
imagery is simple one channel intensity image which lends itself well to basic CNN 
techniques.",,,,Department of Commerce,"Picky: 
Using CNN to pick out objects of a particular size from sides scan imagery.  Presents users 
with a probability that allows for automation of contact picking in the field.  Side scan 
imagery is simple one channel intensity image which lends itself well to basic CNN 
techniques.","The Picky system utilizes CNN (Convolutional Neural Network) to identify objects of a specific size in side scan imagery. It provides users with a probability that enables automated selection of contacts in real-time. Side scan imagery, being a one-channel intensity image, is well-suited for basic CNN techniques.","The Picky system utilizes CNN (Convolutional Neural Network) to identify objects of a specific size in side scan imagery. It provides users with a probability that enables automated selection of contacts in real-time. Side scan imagery, being a one-channel intensity image, is well-suited for basic CNN techniques.",,,False,False
HHS-0017-2023,HHS,ASPR,"Office of Information Management, Data and Analytics/Division of Supply Chain Control Tower",Community Access to Testing,Utilizing several ML models to forecast a surge in the pandemic,Operation and Maintenance,,,Department of Health and Human Services,"Community Access to Testing: 
Utilizing several ML models to forecast a surge in the pandemic","ML models are being used to predict an increase in the pandemic, improving community access to testing.","ML models are being used to predict an increase in the pandemic, improving community access to testing.",,,False,False
NARA-0000-2023,NARA,Information Service,,AI Pilot Project to Screen and Flag for Personally Identifiable Information (PII) in Digitized Archival Records,"The NARA Information Service (I) team collaborating with the Office of Innovation (V), Research Services (R), and the Office of General Counsel (NGC) on a pilot project to use artificial intelligence (AI) tools available on the Amazon Web Services Platform (AWS) and/or Google Cloud Platform to identify and redact Social Security Numbers, Dates of Birth, and other personally identifiable information (PII) in digitized archival records. 

This pilot project will screen digitized pages already in the National Archives Catalog (NAC or the Catalog) and both internal NARA and external partner digitized pages that are in the queue to be added to the Catalog. PII Detection pilot can detect PII information in all documents and parent document groups that have National Archives Identifier (NAID) associated with them and are accessible via NARA Catalog API. PII Detection pilot uses a weighted scoring algorithm to rank the documents with most sensitive information (defined by agency needs) with higher scores. 

Agency further plans to enhance this prototype into a User Interface driven tool that can be used by the Legal, Business and Security team to run preliminary scans on unpublished Information. Agency also plans to enhance to this prototype by further adding custom entities for detection.",Planned (not in production),1. Textraction Machine Learning (ML) service which used OCR to extract the text/data from scanned images 2. Automated NLP (Natural Language processing) to detect PII information out of the extracted text from scanned images.,,National Archives and Records Administration,"AI Pilot Project to Screen and Flag for Personally Identifiable Information (PII) in Digitized Archival Records: 
The NARA Information Service (I) team collaborating with the Office of Innovation (V), Research Services (R), and the Office of General Counsel (NGC) on a pilot project to use artificial intelligence (AI) tools available on the Amazon Web Services Platform (AWS) and/or Google Cloud Platform to identify and redact Social Security Numbers, Dates of Birth, and other personally identifiable information (PII) in digitized archival records. 

This pilot project will screen digitized pages already in the National Archives Catalog (NAC or the Catalog) and both internal NARA and external partner digitized pages that are in the queue to be added to the Catalog. PII Detection pilot can detect PII information in all documents and parent document groups that have National Archives Identifier (NAID) associated with them and are accessible via NARA Catalog API. PII Detection pilot uses a weighted scoring algorithm to rank the documents with most sensitive information (defined by agency needs) with higher scores. 

Agency further plans to enhance this prototype into a User Interface driven tool that can be used by the Legal, Business and Security team to run preliminary scans on unpublished Information. Agency also plans to enhance to this prototype by further adding custom entities for detection.","The NARA Information Service team is collaborating with other departments on a pilot project to use AI tools to identify and redact personally identifiable information (PII) in digitized archival records. The project will screen both existing and upcoming digitized records for PII, and the agency plans to develop a user interface-driven tool for preliminary scans and add custom entities for detection.","The NARA Information Service team is collaborating with other departments on a pilot project to use AI tools to identify and redact personally identifiable information (PII) in digitized archival records. The project will screen both existing and upcoming digitized records for PII, and the agency plans to develop a user interface-driven tool for preliminary scans and add custom entities for detection.",,,False,False
DOC-0020-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Coral Reef Watch,"For more than 20 years, NOAA Coral Reef Watch (CRW) has been using remote sensing, 
modeled, and in situ data to operate a Decision Support System (DSS) to help resource 
managers (our target audience), researchers, decision makers, and other stakeholders 
around the world prepare for and respond to coral reef ecosystem stressors, 
predominantly resulting from climate change and warming of the Earth's oceans. Offering 
the world's only global early-warning system of coral reef ecosystem physical 
environmental changes, CRW remotely monitors conditions that can cause coral 
bleaching, disease, and death; delivers information and early warnings in near real-time to 
our user community; and uses operational climate forecasts to provide outlooks of 
stressful environmental conditions at targeted reef locations worldwide. CRW products 
are primarily sea surface temperature (SST)-based but also incorporate light and ocean 
color, among other variables.",,,,Department of Commerce,"Coral Reef Watch: 
For more than 20 years, NOAA Coral Reef Watch (CRW) has been using remote sensing, 
modeled, and in situ data to operate a Decision Support System (DSS) to help resource 
managers (our target audience), researchers, decision makers, and other stakeholders 
around the world prepare for and respond to coral reef ecosystem stressors, 
predominantly resulting from climate change and warming of the Earth's oceans. Offering 
the world's only global early-warning system of coral reef ecosystem physical 
environmental changes, CRW remotely monitors conditions that can cause coral 
bleaching, disease, and death; delivers information and early warnings in near real-time to 
our user community; and uses operational climate forecasts to provide outlooks of 
stressful environmental conditions at targeted reef locations worldwide. CRW products 
are primarily sea surface temperature (SST)-based but also incorporate light and ocean 
color, among other variables.","NOAA Coral Reef Watch (CRW) has been using remote sensing, modeled, and in situ data for over 20 years to operate a Decision Support System (DSS) that helps resource managers, researchers, decision makers, and stakeholders worldwide prepare for and respond to coral reef ecosystem stressors caused by climate change and warming oceans. CRW offers the world's only global early-warning system for coral reef ecosystem changes, monitoring conditions that can lead to coral bleaching, disease, and death, and providing near real-time information and early warnings to users. Their products primarily focus on sea surface temperature but also include other variables such as light and ocean color.","NOAA Coral Reef Watch (CRW) has been using remote sensing, modeled, and in situ data for over 20 years to operate a Decision Support System (DSS) that helps resource managers, researchers, decision makers, and stakeholders worldwide prepare for and respond to coral reef ecosystem stressors caused by climate change and warming oceans. CRW offers the world's only global early-warning system for coral reef ecosystem changes, monitoring conditions that can lead to coral bleaching, disease, and death, and providing near real-time information and early warnings to users. Their products primarily focus on sea surface temperature but also include other variables such as light and ocean color.",,,False,False
DHS-0024-2023,DHS,Cybersecurity and Infrastructure Security Agency,,Security Information and Event Management (SIEM) Alerting Models,"Threat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of log data. Manually developed detection alerts and automatic correlation in Security Information and Event Management tool are common, but not comprehensive. Many cyber attacks can be probabilistically determined given sufficient training data and time. Analysts  use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and curated subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ",Initiation,Machine Learning,,Department of Homeland Security,"Security Information and Event Management (SIEM) Alerting Models: 
Threat hunting and Security Operations Center (SOC) analysts are provided terabytes per day of log data. Manually developed detection alerts and automatic correlation in Security Information and Event Management tool are common, but not comprehensive. Many cyber attacks can be probabilistically determined given sufficient training data and time. Analysts  use automated tooling to further refine the alerts they receive and produce additional automated alerts based on aggregated information and curated subject matter expertise. This tooling allows CISA analysts the capabilities to comb through data in an automated fashion with mathematically and probabilistically based models to ensure high fidelity anomalies are detected in a timely manner. ","Threat hunting and SOC analysts receive a large amount of log data daily. Although they use manual and automatic detection alerts, they are not enough to detect all cyber attacks. Analysts use automated tooling to refine and produce additional alerts based on aggregated information and expertise, allowing them to detect anomalies accurately and quickly.","Threat hunting and SOC analysts receive a large amount of log data daily. Although they use manual and automatic detection alerts, they are not enough to detect all cyber attacks. Analysts use automated tooling to refine and produce additional alerts based on aggregated information and expertise, allowing them to detect anomalies accurately and quickly.",,,False,False
USAID-0011-2023,USAID,Bureau for Latin America and the Caribbean,,NASA SERVIR - Bias Correcting Historical GEOGloWS ECMWF Streamflow Service (GESS) data using Machine Learning (ML) Techniques,"GEOGloWS ECMWF Streamflow Service (GESS) helps to organize the international community engaged in the hydrologic sciences, observations, and their application to forecasting and provides a forum for government-to-government collaboration, and engagement with the academic and private sectors to achieve the delivery of actionable water information. Since the formal creation of the initiative in 2017, the most significant element of GEOGloWS has been the application of Earth Observations (EO) to create a system that forecasts flow on every river of the world while also providing a 40-year simulated historical flow.

This application uses Long Short Term Memory (LSTM) Model with the time series of discharge data to bias correct the globally available GESS discharge information locally.",Development and Acquisition,,,U.S. Agency for International Development,"NASA SERVIR - Bias Correcting Historical GEOGloWS ECMWF Streamflow Service (GESS) data using Machine Learning (ML) Techniques: 
GEOGloWS ECMWF Streamflow Service (GESS) helps to organize the international community engaged in the hydrologic sciences, observations, and their application to forecasting and provides a forum for government-to-government collaboration, and engagement with the academic and private sectors to achieve the delivery of actionable water information. Since the formal creation of the initiative in 2017, the most significant element of GEOGloWS has been the application of Earth Observations (EO) to create a system that forecasts flow on every river of the world while also providing a 40-year simulated historical flow.

This application uses Long Short Term Memory (LSTM) Model with the time series of discharge data to bias correct the globally available GESS discharge information locally.","NASA SERVIR is using machine learning techniques, specifically the Long Short Term Memory (LSTM) Model, to bias correct historical streamflow data from the GEOGloWS ECMWF Streamflow Service (GESS). This correction allows for more accurate local information from the globally available GESS discharge data, which is used to forecast flow on every river worldwide.","NASA SERVIR is using machine learning techniques, specifically the Long Short Term Memory (LSTM) Model, to bias correct historical streamflow data from the GEOGloWS ECMWF Streamflow Service (GESS). This correction allows for more accurate local information from the globally available GESS discharge data, which is used to forecast flow on every river worldwide.",,,False,False
DOS-0011-2023,DOS,CSO,,ServiceNow AI-Powered Virtual Agent (Chatbot),IRM’s BMP Systems is planning to incorporate ServiceNow’s Virtual Agent into our existing applications to connect users with support and data requests. The Artificial Intelligence (AI) is provided by ServiceNow as part of their Platform as a Service (PaaS).,,,,Department of State,"ServiceNow AI-Powered Virtual Agent (Chatbot): 
IRM’s BMP Systems is planning to incorporate ServiceNow’s Virtual Agent into our existing applications to connect users with support and data requests. The Artificial Intelligence (AI) is provided by ServiceNow as part of their Platform as a Service (PaaS).","IRM's BMP Systems intends to integrate ServiceNow's Virtual Agent into their current applications to facilitate user interaction with support and data inquiries. The Virtual Agent utilizes ServiceNow's AI technology, which is offered as part of their Platform as a Service (PaaS) solution.","IRM's BMP Systems intends to integrate ServiceNow's Virtual Agent into their current applications to facilitate user interaction with support and data inquiries. The Virtual Agent utilizes ServiceNow's AI technology, which is offered as part of their Platform as a Service (PaaS) solution.",,,False,False
DOI-0016-2023,DOI,USGS,,Aluminum Criteria Development in Massachusetts,"The USGS, in cooperation with MassDEP, will collect water-quality data at freshwater sites in Massachusetts, and use those data to demonstrate a process for calculating aluminum criteria based on a sites water chemistry (pH, DOC, and hardness) using a multiple linear regression model developed by the EPA (2017).",Implementation,Random Forest Classification and Regression,,Department of Interior,"Aluminum Criteria Development in Massachusetts: 
The USGS, in cooperation with MassDEP, will collect water-quality data at freshwater sites in Massachusetts, and use those data to demonstrate a process for calculating aluminum criteria based on a sites water chemistry (pH, DOC, and hardness) using a multiple linear regression model developed by the EPA (2017).","The USGS and MassDEP will gather water-quality data at freshwater sites in Massachusetts to establish aluminum criteria. They will use a multiple linear regression model developed by the EPA in 2017, which considers water chemistry factors such as pH, DOC, and hardness to calculate the criteria.","The USGS and MassDEP will gather water-quality data at freshwater sites in Massachusetts to establish aluminum criteria. They will use a multiple linear regression model developed by the EPA in 2017, which considers water chemistry factors such as pH, DOC, and hardness to calculate the criteria.",,,False,False
HHS-0049-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Central Data Abstraction Tool-Modernized (Modernized-CDAT)- Intake Process Automation (PA) Tool,"Intake PA uses advanced capabilities (NLP, OCR, AI, ML) to automate, modernize, and reduce manual efforts related to medical record review functions within MA RADV audits",Operation and Maintenance,,,Department of Health and Human Services,"Central Data Abstraction Tool-Modernized (Modernized-CDAT)- Intake Process Automation (PA) Tool: 
Intake PA uses advanced capabilities (NLP, OCR, AI, ML) to automate, modernize, and reduce manual efforts related to medical record review functions within MA RADV audits","The Modernized-CDAT Intake Process Automation (PA) Tool utilizes advanced technologies such as NLP, OCR, AI, and ML to automate and modernize the medical record review process in MA RADV audits. This tool aims to reduce the need for manual efforts in this aspect of the audits.","The Modernized-CDAT Intake Process Automation (PA) Tool utilizes advanced technologies such as NLP, OCR, AI, and ML to automate and modernize the medical record review process in MA RADV audits. This tool aims to reduce the need for manual efforts in this aspect of the audits.",,,False,False
HHS-0125-2023,HHS,NIH,National Institutes of Health (NIH) NIGMS,Similarity-based Application and Investigator Matching (SAIM),The SAIM system uses natural language processing to identify non-NIH grants awarded to NIGMS Principal Investigators. The system aids in identifying whether a grant application has significant unnecessary overlap with one funded by another agency.,Development and Acquisition,,,Department of Health and Human Services,"Similarity-based Application and Investigator Matching (SAIM): 
The SAIM system uses natural language processing to identify non-NIH grants awarded to NIGMS Principal Investigators. The system aids in identifying whether a grant application has significant unnecessary overlap with one funded by another agency.",The SAIM system utilizes natural language processing to detect non-NIH grants received by NIGMS Principal Investigators. It helps identify if a grant application has excessive overlap with another agency's funded grant.,The SAIM system utilizes natural language processing to detect non-NIH grants received by NIGMS Principal Investigators. It helps identify if a grant application has excessive overlap with another agency's funded grant.,,,False,False
DOE-0004-2023,DOE,Fermi National Accelerator,,Extreme data reduction for the edge,"This projects develops AI algorithms and tools for near-sensor data 
reduction in custom hardware.",,"Artificial Intelligence, Big Data, Neural Networks, Novel Spectroscopic Technology",,Department of Energy,"Extreme data reduction for the edge: 
This projects develops AI algorithms and tools for near-sensor data 
reduction in custom hardware.",This project aims to create artificial intelligence algorithms and tools that can efficiently reduce data near the sensor in customized hardware for edge devices. The goal is to enable extreme data reduction for improved performance and efficiency.,This project aims to create artificial intelligence algorithms and tools that can efficiently reduce data near the sensor in customized hardware for edge devices. The goal is to enable extreme data reduction for improved performance and efficiency.,,,False,False
VA-0003-2023,VA,,,Acute kidney injury (AKI),"This project, a collaboration with Google DeepMind, focuses on detecting acute kidney injury (AKI), ranging from minor loss of kidney function to complete kidney failure. The artificial intelligence can also detect AKI that may be the result of another illness.",,,,Department of Veterans Affairs,"Acute kidney injury (AKI): 
This project, a collaboration with Google DeepMind, focuses on detecting acute kidney injury (AKI), ranging from minor loss of kidney function to complete kidney failure. The artificial intelligence can also detect AKI that may be the result of another illness.","This project, in partnership with Google DeepMind, aims to identify acute kidney injury (AKI) which can range from mild to severe kidney function loss and even kidney failure. The artificial intelligence system developed can also identify AKI caused by other illnesses.","This project, in partnership with Google DeepMind, aims to identify acute kidney injury (AKI) which can range from mild to severe kidney function loss and even kidney failure. The artificial intelligence system developed can also identify AKI caused by other illnesses.",,,False,False
DOL-0015-2023,DOL,,,OEWS Occupation Autocoder,The input is state submitted response files that include occupation title and sometimes job description of the surveyed units. The autocoder reads the job title and assigns up to two 6-digit Standard Occupational Classification (SOC) codes along with their probabilities as recommendations for human coders. Codes above a certain threshold are appended to the submitted response file and sent back to states to assist them with their SOC code assignment.,Operation and Maintenance,"Natural Langauge Processing, Logistic Regression, Classification",,Department of Labor,"OEWS Occupation Autocoder: 
The input is state submitted response files that include occupation title and sometimes job description of the surveyed units. The autocoder reads the job title and assigns up to two 6-digit Standard Occupational Classification (SOC) codes along with their probabilities as recommendations for human coders. Codes above a certain threshold are appended to the submitted response file and sent back to states to assist them with their SOC code assignment.","The OEWS Occupation Autocoder is a tool that takes state submitted response files containing occupation titles and job descriptions and assigns up to two Standard Occupational Classification (SOC) codes to each title. These codes, along with their probabilities, are sent back to the states to assist human coders in assigning SOC codes to the responses.","The OEWS Occupation Autocoder is a tool that takes state submitted response files containing occupation titles and job descriptions and assigns up to two Standard Occupational Classification (SOC) codes to each title. These codes, along with their probabilities, are sent back to the states to assist human coders in assigning SOC codes to the responses.",,,False,False
DOE-0029-2023,DOE,National Energy Technology Laboratory,,Advanced Image Segmentation,"U-Net CNN segmentation to isolate pore and fluid from computed 
tomography scans of multiphase transport in cores.",,"Neural Networks, Other",,Department of Energy,"Advanced Image Segmentation: 
U-Net CNN segmentation to isolate pore and fluid from computed 
tomography scans of multiphase transport in cores.",The U-Net CNN segmentation technique is used to separate and isolate pores and fluids in computed tomography scans of multiphase transport in cores. This advanced image segmentation method improves the accuracy of analyzing and understanding the structure and behavior of the transport system.,The U-Net CNN segmentation technique is used to separate and isolate pores and fluids in computed tomography scans of multiphase transport in cores. This advanced image segmentation method improves the accuracy of analyzing and understanding the structure and behavior of the transport system.,,,False,False
USAID-0012-2023,USAID,Bureau for Latin America and the Caribbean,,"NASA SERVIR - Using artificial intelligence to forecast harmful algae blooms in Lake Atitlán, Guatemala","This application uses machine learning with Earth observations and weather-modeled data to forecast daily algal blooms in Lake Atitlán, Guatemala. The forecasting system is being used by Lake Authorities, such as the  Authority for Sustainable Management of the Lake Atitlan Basin and its surroundings (AMSCLAE),  to inform their Harmful Algal Blooms Alert System. This work is also supported by National Geographic and Microsoft through their Artificial Intelligence (AI) for Innovation grants. ",Implementation,,,U.S. Agency for International Development,"NASA SERVIR - Using artificial intelligence to forecast harmful algae blooms in Lake Atitlán, Guatemala: 
This application uses machine learning with Earth observations and weather-modeled data to forecast daily algal blooms in Lake Atitlán, Guatemala. The forecasting system is being used by Lake Authorities, such as the  Authority for Sustainable Management of the Lake Atitlan Basin and its surroundings (AMSCLAE),  to inform their Harmful Algal Blooms Alert System. This work is also supported by National Geographic and Microsoft through their Artificial Intelligence (AI) for Innovation grants. ","NASA SERVIR has developed an application that utilizes artificial intelligence and machine learning to predict daily algal blooms in Lake Atitlán, Guatemala. The forecasting system is being used by Lake Authorities to enhance their Harmful Algal Blooms Alert System, with support from National Geographic and Microsoft.","NASA SERVIR has developed an application that utilizes artificial intelligence and machine learning to predict daily algal blooms in Lake Atitlán, Guatemala. The forecasting system is being used by Lake Authorities to enhance their Harmful Algal Blooms Alert System, with support from National Geographic and Microsoft.",,,False,False
VA-0032-2023,VA,,,Predicting hepatocellular carcinoma in patients with hepatitis C,This prognostic study used data on patients with hepatitis C virus (HCV)-related cirrhosis in the national Veterans Health Administration who had at least 3 years of follow-up after the diagnosis of cirrhosis. The data was used to examine whether deep learning recurrent neural network (RNN) models that use raw longitudinal data extracted directly from electronic health records outperform conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC).,,,,Department of Veterans Affairs,"Predicting hepatocellular carcinoma in patients with hepatitis C: 
This prognostic study used data on patients with hepatitis C virus (HCV)-related cirrhosis in the national Veterans Health Administration who had at least 3 years of follow-up after the diagnosis of cirrhosis. The data was used to examine whether deep learning recurrent neural network (RNN) models that use raw longitudinal data extracted directly from electronic health records outperform conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC).","This study examined whether deep learning recurrent neural network (RNN) models, using raw longitudinal data from electronic health records, outperformed conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC) in patients with hepatitis C virus (HCV)-related cirrhosis. The study used data from patients in the national Veterans Health Administration with at least 3 years of follow-up after their cirrhosis diagnosis.","This study examined whether deep learning recurrent neural network (RNN) models, using raw longitudinal data from electronic health records, outperformed conventional regression models in predicting the risk of developing hepatocellular carcinoma (HCC) in patients with hepatitis C virus (HCV)-related cirrhosis. The study used data from patients in the national Veterans Health Administration with at least 3 years of follow-up after their cirrhosis diagnosis.",,,False,False
DHS-0009-2023,DHS,Customs and Border Protection,,Integrated Digital Environment,"The Integrated Digital Environment provides managers with a better understanding of end user workflows, most and least used applications, and opportunities for improvement. 

The AI/ML model applies to end user activity data (e.g., use of applications, flow between applications) to help CBP identify opportunities for more efficient or effective configuration of interfaces, use of resources, or development and deployment of CBP’s applications.  It tailors analytics and insight generation to allow metrics gathering, usage recording/observation, dashboarding, and workflow experimentations/suggestions to support analysts utilizing the entire suite of agency and open-source data systems. It also customizes existing capabilities to allow the exact automations needed for agency applications and systems, creating an integrated digital environment for greater connectivity and security between applications, and better ability for CBP administrators to manage and optimize use of applications by end users.",Development and Acquisition,Natural Language Processing (NLP),,Department of Homeland Security,"Integrated Digital Environment: 
The Integrated Digital Environment provides managers with a better understanding of end user workflows, most and least used applications, and opportunities for improvement. 

The AI/ML model applies to end user activity data (e.g., use of applications, flow between applications) to help CBP identify opportunities for more efficient or effective configuration of interfaces, use of resources, or development and deployment of CBP’s applications.  It tailors analytics and insight generation to allow metrics gathering, usage recording/observation, dashboarding, and workflow experimentations/suggestions to support analysts utilizing the entire suite of agency and open-source data systems. It also customizes existing capabilities to allow the exact automations needed for agency applications and systems, creating an integrated digital environment for greater connectivity and security between applications, and better ability for CBP administrators to manage and optimize use of applications by end users.","The Integrated Digital Environment improves managers' understanding of end user workflows and identifies opportunities for improvement. It uses AI/ML models to analyze end user activity data and provides tailored analytics, metrics gathering, and workflow suggestions. This creates a connected and secure environment for CBP applications and allows administrators to optimize their use.","The Integrated Digital Environment improves managers' understanding of end user workflows and identifies opportunities for improvement. It uses AI/ML models to analyze end user activity data and provides tailored analytics, metrics gathering, and workflow suggestions. This creates a connected and secure environment for CBP applications and allows administrators to optimize their use.",,,False,False
SSA-0011-2023,SSA,"Office of Disability Information Systems, Office of Hearing Operations, Office of Appellate Operations",,Handwriting recognition from forms,AI performs OCR against handwritten entries on specific standard forms submitted by clients. This use case is in support of an Robtic Process Automation effort as well as a standalone use.,,,,Social Security Administration,"Handwriting recognition from forms: 
AI performs OCR against handwritten entries on specific standard forms submitted by clients. This use case is in support of an Robtic Process Automation effort as well as a standalone use.",AI technology is used to recognize and interpret handwritten entries on standard forms. This is done to support robotic process automation and can also be used independently.,AI technology is used to recognize and interpret handwritten entries on standard forms. This is done to support robotic process automation and can also be used independently.,,,False,False
TREAS-0003-2023,TREAS,,,Collection Chat Bot,"The Natural Language Understanding (NLU) model will be located inside 
the eGain intent engine. This NLU will take customer typed text input aka 
– Utterances.  It will map the utterance to a specific intent and return the 
appropriate knowledge article.",In production: less than six months,,,Department of Treasury,"Collection Chat Bot: 
The Natural Language Understanding (NLU) model will be located inside 
the eGain intent engine. This NLU will take customer typed text input aka 
– Utterances.  It will map the utterance to a specific intent and return the 
appropriate knowledge article.","The Collection Chat Bot will contain a Natural Language Understanding (NLU) model, which will be housed in the eGain intent engine. This NLU will analyze text input from customers, known as utterances, and match them with a relevant intent, providing the appropriate knowledge article in response.","The Collection Chat Bot will contain a Natural Language Understanding (NLU) model, which will be housed in the eGain intent engine. This NLU will analyze text input from customers, known as utterances, and match them with a relevant intent, providing the appropriate knowledge article in response.",,,False,False
HHS-0086-2023,HHS,FDA,CDER/Office of Translational Sciences/Office of Biostatistics,Automatic Recognition of Individuals by Pharmacokinetic Profiles to Identify Data Anomalies,"In efforts to detect data anomalies under ANDA, Office of Biostatistics, Division of Biometrics VIII created an R shiny application, DABERS (Data Anomalies in BioEquivalence R Shiny) to support OSIS and OGD. Despite its demonstrated effectiveness, a major drawback is that the pharmacokinetics and pharmacodynamics may be too complicated to describe with a single statistic. Indeed, the current practice offers no practical guidelines regarding how similar PK profiles from different subjects can be in order to be considered valid. This makes it difficult to assess the adequacy of data to be accepted for an ANDA and requires additional information requests to applicants. This project will address the current gap in identifying the data anomalies and potential data manipulations by use of state-of-the-art statistical methods, specifically focusing on machine learning and data augmentation. The purpose of the project is twofold.  First, from a regulatory perspective, our project will provide a data driven method that can model complex patterns of PK data to identify potential data manipulations under an ANDA. Second, from a public health research and drug development point of view, the proposed study can potentially be used to understand and quantify the variability in drug response, to guide stratification and targeting of patient subgroups, and to provide insight into what the right drug and right range of doses are for those subgroups.",Development and Acquisition,,,Department of Health and Human Services,"Automatic Recognition of Individuals by Pharmacokinetic Profiles to Identify Data Anomalies: 
In efforts to detect data anomalies under ANDA, Office of Biostatistics, Division of Biometrics VIII created an R shiny application, DABERS (Data Anomalies in BioEquivalence R Shiny) to support OSIS and OGD. Despite its demonstrated effectiveness, a major drawback is that the pharmacokinetics and pharmacodynamics may be too complicated to describe with a single statistic. Indeed, the current practice offers no practical guidelines regarding how similar PK profiles from different subjects can be in order to be considered valid. This makes it difficult to assess the adequacy of data to be accepted for an ANDA and requires additional information requests to applicants. This project will address the current gap in identifying the data anomalies and potential data manipulations by use of state-of-the-art statistical methods, specifically focusing on machine learning and data augmentation. The purpose of the project is twofold.  First, from a regulatory perspective, our project will provide a data driven method that can model complex patterns of PK data to identify potential data manipulations under an ANDA. Second, from a public health research and drug development point of view, the proposed study can potentially be used to understand and quantify the variability in drug response, to guide stratification and targeting of patient subgroups, and to provide insight into what the right drug and right range of doses are for those subgroups.","The text explains that a new R shiny application called DABERS has been created to detect data anomalies in ANDA. However, there is a difficulty in assessing the validity of pharmacokinetic profiles and determining how similar they should be. To address this gap, the project aims to use machine learning and data augmentation to identify potential data manipulations and provide a data-driven method for modeling complex patterns of PK data. This will have regulatory benefits in identifying anomalies under an ANDA and also contribute to public health research and drug development by understanding drug response variability and guiding patient subgroup targeting.","The text explains that a new R shiny application called DABERS has been created to detect data anomalies in ANDA. However, there is a difficulty in assessing the validity of pharmacokinetic profiles and determining how similar they should be. To address this gap, the project aims to use machine learning and data augmentation to identify potential data manipulations and provide a data-driven method for modeling complex patterns of PK data. This will have regulatory benefits in identifying anomalies under an ANDA and also contribute to public health research and drug development by understanding drug response variability and guiding patient subgroup targeting.",,,False,False
DOE-0086-2023,DOE,National Energy Technology Laboratory,,"To design, proto-type and demonstrate a miniaturized implementation of a multi-process, high-spatial-resolution monitoring system for boiler condition management.","Project will develop control logic for automated control of bituminous 
coal-fired boiler. Plant operational data will be compared against 
monitoring data to determine when different sensor output from a 
miniaturized high temperature multi-process, high-spatial-resolution 
monitoring system signifies damaging conditions in that region of the 
boiler, and what operational changes can be made to eliminate the 
damaging condition. The control logic will be developed for automated 
control of soot-blowing and other boiler operations",,,,Department of Energy,"To design, proto-type and demonstrate a miniaturized implementation of a multi-process, high-spatial-resolution monitoring system for boiler condition management.: 
Project will develop control logic for automated control of bituminous 
coal-fired boiler. Plant operational data will be compared against 
monitoring data to determine when different sensor output from a 
miniaturized high temperature multi-process, high-spatial-resolution 
monitoring system signifies damaging conditions in that region of the 
boiler, and what operational changes can be made to eliminate the 
damaging condition. The control logic will be developed for automated 
control of soot-blowing and other boiler operations",The project aims to create a smaller version of a monitoring system for managing the condition of a boiler. It will develop control logic to automate the control of a coal-fired boiler and compare operational data with monitoring data to identify damaging conditions and suggest operational changes. The focus will be on automating soot-blowing and other boiler operations.,The project aims to create a smaller version of a monitoring system for managing the condition of a boiler. It will develop control logic to automate the control of a coal-fired boiler and compare operational data with monitoring data to identify damaging conditions and suggest operational changes. The focus will be on automating soot-blowing and other boiler operations.,,,False,False
TREAS-0008-2023,TREAS,,,Inventory Item Replenishment MLR Modeling POC - Phase 1a,"The Bureau of Engraving and Printing wanted to establish a proof of 
concept (POC) for Predictive Analytics at the BEP. This POC consisted of 
developing a Multiple Linear Regression (MLR) model to predict Processing 
Lead Times for the Office of Supply Chain Management (OSCM). 
Processing Lead Times are the numbers of days it takes an item to be 
delivered to the target facility from the time the purchase order (PO) was 
approved. The model utilizes historical requisition, vendor, and item 
specific data to come up with numerical predictions, which are then used 
to determine whether an item will be delivered on-time or if the OSCM 
should expect a delay. If a delay is expected, the OSCM can be proactive in 
their decision making to prepare for a potential inventory shortage.",Development and Acquisition,,,Department of Treasury,"Inventory Item Replenishment MLR Modeling POC - Phase 1a: 
The Bureau of Engraving and Printing wanted to establish a proof of 
concept (POC) for Predictive Analytics at the BEP. This POC consisted of 
developing a Multiple Linear Regression (MLR) model to predict Processing 
Lead Times for the Office of Supply Chain Management (OSCM). 
Processing Lead Times are the numbers of days it takes an item to be 
delivered to the target facility from the time the purchase order (PO) was 
approved. The model utilizes historical requisition, vendor, and item 
specific data to come up with numerical predictions, which are then used 
to determine whether an item will be delivered on-time or if the OSCM 
should expect a delay. If a delay is expected, the OSCM can be proactive in 
their decision making to prepare for a potential inventory shortage.","The Bureau of Engraving and Printing conducted a proof of concept (POC) to test the use of predictive analytics in predicting processing lead times for their supply chain management. The POC involved developing a Multiple Linear Regression (MLR) model that utilizes historical data to predict delivery times for items. This model helps the Bureau determine if an item will be delivered on time or if there will be a delay, allowing them to make proactive decisions to avoid inventory shortages.","The Bureau of Engraving and Printing conducted a proof of concept (POC) to test the use of predictive analytics in predicting processing lead times for their supply chain management. The POC involved developing a Multiple Linear Regression (MLR) model that utilizes historical data to predict delivery times for items. This model helps the Bureau determine if an item will be delivered on time or if there will be a delay, allowing them to make proactive decisions to avoid inventory shortages.",,,False,False
DOE-0120-2023,DOE,National Energy Technology Laboratory,,To implement novel SSC-CCS sensing technology and associated condition-based monitoring (CBM) software for improved understanding of the boiler tube failure mechanisms,"A preliminary condition-based monitoring (CBM) package with graphic 
user interface (GUI) will be developed. This CUI will allow the operators 
to view the current and historical signals of temperature profiles of the 
boiler tube at specific sensor locations. Combining the pre-existing 
conditions and the opinions from designers/operators/experts’ 
experiences, the system will be integrated with EPRI’s Boiler Failure 
Reduction Program to provide assessments on the health conditions of 
the boiler tubes, warnings/diagnoses on potential failures and locations, 
and suggestions on maintenance locations and schedules.",,,,Department of Energy,"To implement novel SSC-CCS sensing technology and associated condition-based monitoring (CBM) software for improved understanding of the boiler tube failure mechanisms: 
A preliminary condition-based monitoring (CBM) package with graphic 
user interface (GUI) will be developed. This CUI will allow the operators 
to view the current and historical signals of temperature profiles of the 
boiler tube at specific sensor locations. Combining the pre-existing 
conditions and the opinions from designers/operators/experts’ 
experiences, the system will be integrated with EPRI’s Boiler Failure 
Reduction Program to provide assessments on the health conditions of 
the boiler tubes, warnings/diagnoses on potential failures and locations, 
and suggestions on maintenance locations and schedules.","A condition-based monitoring (CBM) package with a user interface (GUI) will be created to monitor the temperature profiles of boiler tubes. This system will integrate with EPRI's Boiler Failure Reduction Program to assess the health of the tubes, provide warnings and diagnoses for potential failures, and offer suggestions for maintenance.","A condition-based monitoring (CBM) package with a user interface (GUI) will be created to monitor the temperature profiles of boiler tubes. This system will integrate with EPRI's Boiler Failure Reduction Program to assess the health of the tubes, provide warnings and diagnoses for potential failures, and offer suggestions for maintenance.",,,False,False
DOE-0038-2023,DOE,National Energy Technology Laboratory,,Creation of polymer datasets and inverse design of polymers with targeted backbones having High CO2 permeability and high CO2/N2 selectivity.,"Machine learning models were developed to predict CO2 permeability 
and CO2/N2 selectivity of polymers. Novel methods were developed to 
generate polymer datasets. Furthermore, a novel machine learning 
technique is being developed to inverse design the polymers that will 
have targeted properties.",,Other,,Department of Energy,"Creation of polymer datasets and inverse design of polymers with targeted backbones having High CO2 permeability and high CO2/N2 selectivity.: 
Machine learning models were developed to predict CO2 permeability 
and CO2/N2 selectivity of polymers. Novel methods were developed to 
generate polymer datasets. Furthermore, a novel machine learning 
technique is being developed to inverse design the polymers that will 
have targeted properties.","Machine learning models were created to accurately forecast the CO2 permeability and CO2/N2 selectivity of polymers. Additionally, innovative approaches were developed to generate polymer datasets and a novel machine learning technique is currently being developed to design polymers with specific properties.","Machine learning models were created to accurately forecast the CO2 permeability and CO2/N2 selectivity of polymers. Additionally, innovative approaches were developed to generate polymer datasets and a novel machine learning technique is currently being developed to design polymers with specific properties.",,,False,False
DOI-0001-2023,DOI,BOR,,Seasonal/Temporary Wetland/Floodplain Delineation using Remote Sensing and Deep Learning,"Reclamation was interested in determining if recent advancements in machine learning, specifically convolutional neural network architecture in deep learning, can provide improved seasonal/temporary wetland/floodplain delineation (mapping) when high temporal and spatial resolution remote sensing data is available? If so, then these new mappings could inform the management of protected species and provide critical information to decision-makers during scenario analysis for operations and planning.",Completed,Image classification using Joint Unsupervised Learning (JULE),,Department of Interior,"Seasonal/Temporary Wetland/Floodplain Delineation using Remote Sensing and Deep Learning: 
Reclamation was interested in determining if recent advancements in machine learning, specifically convolutional neural network architecture in deep learning, can provide improved seasonal/temporary wetland/floodplain delineation (mapping) when high temporal and spatial resolution remote sensing data is available? If so, then these new mappings could inform the management of protected species and provide critical information to decision-makers during scenario analysis for operations and planning.","Reclamation wanted to assess if advancements in machine learning, particularly deep learning with convolutional neural networks, could enhance the mapping of seasonal/temporary wetlands/floodplains using high-resolution remote sensing data. If successful, these improved mappings could support the management of protected species and offer valuable information for decision-making in operations and planning scenarios.","Reclamation wanted to assess if advancements in machine learning, particularly deep learning with convolutional neural networks, could enhance the mapping of seasonal/temporary wetlands/floodplains using high-resolution remote sensing data. If successful, these improved mappings could support the management of protected species and offer valuable information for decision-making in operations and planning scenarios.",,,False,False
HHS-0014-2023,HHS,ASPR,Chief Data Officer,Data Modernization,Develop open data management architecture that enables optimized business intelligence (BI) and machine learning (ML) on all ASPR data.,Initiation,,,Department of Health and Human Services,"Data Modernization: 
Develop open data management architecture that enables optimized business intelligence (BI) and machine learning (ML) on all ASPR data.",The text suggests the need to create a data management architecture that allows for efficient utilization of business intelligence and machine learning on all data owned by ASPR. This modernization aims to optimize the analysis and utilization of data within the organization.,The text suggests the need to create a data management architecture that allows for efficient utilization of business intelligence and machine learning on all data owned by ASPR. This modernization aims to optimize the analysis and utilization of data within the organization.,,,False,False
DOS-0002-2023,DOS,A,,Tailored Integration Logistics Management System (ILMS) User Analytics,A/LM plans to use available ILMS transactional data and planned transactions to develop tailored user experiences and analytics to meet the specifics needs of the user at that moment. By mining real system actions and clicks we can extract more meaningful information about our users to simplify their interactions with the system and reduce time to complete their daily actions.,,,,Department of State,"Tailored Integration Logistics Management System (ILMS) User Analytics: 
A/LM plans to use available ILMS transactional data and planned transactions to develop tailored user experiences and analytics to meet the specifics needs of the user at that moment. By mining real system actions and clicks we can extract more meaningful information about our users to simplify their interactions with the system and reduce time to complete their daily actions.","The Tailored Integration Logistics Management System (ILMS) User Analytics by A/LM aims to enhance user experiences and simplify interactions with the system. By analyzing real system actions and clicks, meaningful information can be extracted to meet the specific needs of users, reducing the time required to complete daily tasks.","The Tailored Integration Logistics Management System (ILMS) User Analytics by A/LM aims to enhance user experiences and simplify interactions with the system. By analyzing real system actions and clicks, meaningful information can be extracted to meet the specific needs of users, reducing the time required to complete daily tasks.",,,False,False
DOC-0006-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Fisheries Electronic Monitoring Image Library,"The Fisheries Electronic Monitoring Library (FEML) will be the central repository for 
electronic monitoring (EM) data related to marine life.",,,,Department of Commerce,"Fisheries Electronic Monitoring Image Library: 
The Fisheries Electronic Monitoring Library (FEML) will be the central repository for 
electronic monitoring (EM) data related to marine life.",The Fisheries Electronic Monitoring Library (FEML) is a central database that stores electronic monitoring data on marine life. It serves as a repository for information related to the monitoring of fisheries.,The Fisheries Electronic Monitoring Library (FEML) is a central database that stores electronic monitoring data on marine life. It serves as a repository for information related to the monitoring of fisheries.,,,False,False
DOL-0013-2023,DOL,,,Automatic Data Processing Workflow with Form Recognizer,Automatic processing of current complex worflow to extract required data.,Initiation,Classification machine learning model involving computer vision,,Department of Labor,"Automatic Data Processing Workflow with Form Recognizer: 
Automatic processing of current complex worflow to extract required data.","Form Recognizer offers automatic data processing workflow, efficiently extracting the necessary information from complex forms. This technology simplifies the task of data extraction from various documents, streamlining the overall workflow.","Form Recognizer offers automatic data processing workflow, efficiently extracting the necessary information from complex forms. This technology simplifies the task of data extraction from various documents, streamlining the overall workflow.",,,False,False
DOL-0001-2023,DOL,,,Language Translation,Language translation of published documents and website using natural language processing models.,Implementation,Cloud based commercial-off-the-shelf pre-trained NLP models,,Department of Labor,"Language Translation: 
Language translation of published documents and website using natural language processing models.",The text describes a service that offers language translation for published documents and websites. This service utilizes natural language processing models to achieve accurate translations.,The text describes a service that offers language translation for published documents and websites. This service utilizes natural language processing models to achieve accurate translations.,,,False,False
DOE-0000-2023,DOE,Brookhaven National Laboratory,,Automated sorting of high repetition rate coherent diffraction data from XFELS,"""Coherent X-rays are routinely provided today by the latest Synchrotron 
and X-ray Free-electron Laser Sources. When these diffract from a 
crystal containing defects, interference leads to the formation of a 
modulated diffraction pattern called """"speckle"""". When the defects move 
around, they can be quantified by a correlation analysis technique called 
X-ray Photon Correlation Spectroscopy. But the speckles also change 
when the beam moves on the sample. By scanning the beam in a 
controlled way, the overlap between the adjacent regions gives 
redundancy to the data, which allows a solution of the inherent phase 
problem. This is the basis of the coherent X-ray ptychography method 
which can achieve image resolutions of 10nm, but only if the probe 
positions are known.
The goal of this proposal will be to separate """"genuine"""" fluctuations of a 
material sample from the inherent beam fluctuations at the high data 
rates of XFELs. Algorithms will be developed to calculate the 
correlations between all the coherent diffraction patterns arriving in a 
time series, then used to separate the two sources of fluctuation using 
the criterion that the """"natural"""" thermal fluctuations do not repeat, while 
beam ones do.  We separate the data stream into image and beam 
""""modes"""" automatically.""",,,,Department of Energy,"Automated sorting of high repetition rate coherent diffraction data from XFELS: 
""Coherent X-rays are routinely provided today by the latest Synchrotron 
and X-ray Free-electron Laser Sources. When these diffract from a 
crystal containing defects, interference leads to the formation of a 
modulated diffraction pattern called """"speckle"""". When the defects move 
around, they can be quantified by a correlation analysis technique called 
X-ray Photon Correlation Spectroscopy. But the speckles also change 
when the beam moves on the sample. By scanning the beam in a 
controlled way, the overlap between the adjacent regions gives 
redundancy to the data, which allows a solution of the inherent phase 
problem. This is the basis of the coherent X-ray ptychography method 
which can achieve image resolutions of 10nm, but only if the probe 
positions are known.
The goal of this proposal will be to separate """"genuine"""" fluctuations of a 
material sample from the inherent beam fluctuations at the high data 
rates of XFELs. Algorithms will be developed to calculate the 
correlations between all the coherent diffraction patterns arriving in a 
time series, then used to separate the two sources of fluctuation using 
the criterion that the """"natural"""" thermal fluctuations do not repeat, while 
beam ones do.  We separate the data stream into image and beam 
""""modes"""" automatically.""","The text discusses the use of automated sorting techniques for coherent diffraction data obtained from synchrotron and X-ray Free-electron Laser Sources. These sources produce interference patterns called ""speckles"" when diffracted from a crystal containing defects. By analyzing the correlations between the diffraction patterns, algorithms can separate the genuine fluctuations of the material sample from the inherent beam fluctuations, allowing for more accurate data analysis and image resolutions.","The text discusses the use of automated sorting techniques for coherent diffraction data obtained from synchrotron and X-ray Free-electron Laser Sources. These sources produce interference patterns called ""speckles"" when diffracted from a crystal containing defects. By analyzing the correlations between the diffraction patterns, algorithms can separate the genuine fluctuations of the material sample from the inherent beam fluctuations, allowing for more accurate data analysis and image resolutions.",,,False,False
VA-0033-2023,VA,,,Computer-aided detection and classification of colorectal polyps,This study is investigating the use of artificial intelligence models for improving clinical management of colorectal polyps. The models receive video frames from colonoscopy video streams and analyze them in real time in order to (1) detect whether a polyp is in the frame and (2) predict the polyp's malignant potential.,,,,Department of Veterans Affairs,"Computer-aided detection and classification of colorectal polyps: 
This study is investigating the use of artificial intelligence models for improving clinical management of colorectal polyps. The models receive video frames from colonoscopy video streams and analyze them in real time in order to (1) detect whether a polyp is in the frame and (2) predict the polyp's malignant potential.",This study aims to improve the clinical management of colorectal polyps by using artificial intelligence models. These models analyze video frames from colonoscopy videos in real time to detect the presence of polyps and predict their potential malignancy.,This study aims to improve the clinical management of colorectal polyps by using artificial intelligence models. These models analyze video frames from colonoscopy videos in real time to detect the presence of polyps and predict their potential malignancy.,,,False,False
DOE-0154-2023,DOE,National Energy Technology Laboratory,,Using time-series classification to assist in automated analysis of sensor data taken during experiments on the MHD test channel.,"The measurements of chemical composition will be combined with 
resistance measurements to validate CFD models of the MHD channel 
system. Specifically, validated CFD models will be able to separate the 
contribution of the bulk and boundary layer resistance to the overall 
resistance of the MHD channel.",,Other,,Department of Energy,"Using time-series classification to assist in automated analysis of sensor data taken during experiments on the MHD test channel.: 
The measurements of chemical composition will be combined with 
resistance measurements to validate CFD models of the MHD channel 
system. Specifically, validated CFD models will be able to separate the 
contribution of the bulk and boundary layer resistance to the overall 
resistance of the MHD channel.",Time-series classification is being utilized to automatically analyze sensor data from experiments on the MHD test channel. This analysis involves combining chemical composition measurements with resistance measurements to validate CFD models of the MHD channel system. The objective is to distinguish the contribution of bulk and boundary layer resistance to the overall resistance of the MHD channel using validated CFD models.,Time-series classification is being utilized to automatically analyze sensor data from experiments on the MHD test channel. This analysis involves combining chemical composition measurements with resistance measurements to validate CFD models of the MHD channel system. The objective is to distinguish the contribution of bulk and boundary layer resistance to the overall resistance of the MHD channel using validated CFD models.,,,False,False
HHS-0036-2023,HHS,CDC,NCHS,PII detection using Private AI,"NCHS has been evaluating Private AI's NLP solution designed to identify, redact, and replace PII in text data. This suite of models is intended to be used to safely identify and remove PII from free text data sets across platforms within the CDC network.",Development and Acquisition,,,Department of Health and Human Services,"PII detection using Private AI: 
NCHS has been evaluating Private AI's NLP solution designed to identify, redact, and replace PII in text data. This suite of models is intended to be used to safely identify and remove PII from free text data sets across platforms within the CDC network.","The National Center for Health Statistics (NCHS) has been testing Private AI's NLP solution, which can detect and replace personally identifiable information (PII) in text data. The purpose of this suite of models is to securely identify and remove PII from various text datasets within the CDC network.","The National Center for Health Statistics (NCHS) has been testing Private AI's NLP solution, which can detect and replace personally identifiable information (PII) in text data. The purpose of this suite of models is to securely identify and remove PII from various text datasets within the CDC network.",,,False,False
HHS-0135-2023,HHS,NIH,National Institutes of Health (NIH) NLM,Biomedical Citation Selector (BmCS),"Automation of article selection allows NLM to more efficiently and effectively index and host relevant information for the public. Through automation, NLM is able standardize article selection and reduce the amount of time it takes to process MEDLINE articles.",Implementation,,,Department of Health and Human Services,"Biomedical Citation Selector (BmCS): 
Automation of article selection allows NLM to more efficiently and effectively index and host relevant information for the public. Through automation, NLM is able standardize article selection and reduce the amount of time it takes to process MEDLINE articles.","The Biomedical Citation Selector (BmCS) automates the selection of articles, enabling the National Library of Medicine (NLM) to efficiently index and provide relevant information to the public. This automation helps NLM standardize article selection and decrease the processing time for MEDLINE articles.","The Biomedical Citation Selector (BmCS) automates the selection of articles, enabling the National Library of Medicine (NLM) to efficiently index and provide relevant information to the public. This automation helps NLM standardize article selection and decrease the processing time for MEDLINE articles.",,,False,False
DOE-0083-2023,DOE,National Energy Technology Laboratory,,To demonstrate multi-gamma based sensor technology for as-fired coal property measurement,"Applying an advanced multigamma attenuation (MGA) sensor to 
accurately and precisely measure coal properties at the point of 
injection into burners.  
One research objective is to perform MGA testing and databases 
development for neural network developed fingerprinting of coal 
properties. This will include neural network refinement with MGA data 
and to upgrade Microbeam’s Combustion System Performance Indices 
(CSPI) – CoalTracker (CT) program with MGA-based neural network 
algorithms.",,"Artificial Intelligence, Neural Networks",,Department of Energy,"To demonstrate multi-gamma based sensor technology for as-fired coal property measurement: 
Applying an advanced multigamma attenuation (MGA) sensor to 
accurately and precisely measure coal properties at the point of 
injection into burners.  
One research objective is to perform MGA testing and databases 
development for neural network developed fingerprinting of coal 
properties. This will include neural network refinement with MGA data 
and to upgrade Microbeam’s Combustion System Performance Indices 
(CSPI) – CoalTracker (CT) program with MGA-based neural network 
algorithms.",The purpose of this research is to use multi-gamma based sensor technology to accurately measure coal properties as it is injected into burners. The goal is to develop a database and refine neural network algorithms to improve the accuracy of measuring coal properties using the MGA sensor. This will be integrated into Microbeam's Combustion System Performance Indices program.,The purpose of this research is to use multi-gamma based sensor technology to accurately measure coal properties as it is injected into burners. The goal is to develop a database and refine neural network algorithms to improve the accuracy of measuring coal properties using the MGA sensor. This will be integrated into Microbeam's Combustion System Performance Indices program.,,,False,False
DOS-0021-2023,DOS,PM,,K-Means clustering into tiers,Cluster countries into tiers based off data collected from open source and bureau data using k-means clustering,,,,Department of State,"K-Means clustering into tiers: 
Cluster countries into tiers based off data collected from open source and bureau data using k-means clustering",The text suggests using K-Means clustering to categorize countries into tiers. This can be achieved by analyzing data gathered from open source and bureau sources.,The text suggests using K-Means clustering to categorize countries into tiers. This can be achieved by analyzing data gathered from open source and bureau sources.,,,False,False
NASA-0015-2023,NASA,Jet Propulsion Laboratory,,Onboard Planner for Mars2020 Rover (Perseverance),"The M2020 onboard scheduler incrementally constructs a feasible schedule by iterating through activities in priority-
first order. When considering each activity it computes the valid time intervals for placement, taking into account
preheating, maintenance heating, and wake/sleep of the rover as required. After an activity is placed (other than a
preheat/maintenance or wake/sleep), the activity is never reconsidered by the scheduler for deletion or moving.
Therefore the scheduler can be considered non backtracking, and only searches in the sense that it computes valid
timeline intervals for legal activity placement. Meta Search: Because the onboard scheduler will be invoked many
times in a given sol (Martian Day) with a range of possible contexts (due to execution variations), its non
backtracking nature leaves its vulnerable to brittleness. In order to mitigate this potential brittleness, the Copilot
systems perform a monte carlo based stochastic analysis to set meta parameters of the scheduler - primarily activity
priority but also potentially preferred time and temporal constraints. Also: Research, experiments, and
engineering to empower future rovers with onboard autonomy; planning, scheduling & execution; path planning;
onboard science; image processing; terrain classification; fault diagnosis; and location estimation. This is a multi-
faceted effort and includes experimentation and demonstrations on-site at JPL's simulated mars navigation yard.",In mission,,,National Aeronautics and Space Administration,"Onboard Planner for Mars2020 Rover (Perseverance): 
The M2020 onboard scheduler incrementally constructs a feasible schedule by iterating through activities in priority-
first order. When considering each activity it computes the valid time intervals for placement, taking into account
preheating, maintenance heating, and wake/sleep of the rover as required. After an activity is placed (other than a
preheat/maintenance or wake/sleep), the activity is never reconsidered by the scheduler for deletion or moving.
Therefore the scheduler can be considered non backtracking, and only searches in the sense that it computes valid
timeline intervals for legal activity placement. Meta Search: Because the onboard scheduler will be invoked many
times in a given sol (Martian Day) with a range of possible contexts (due to execution variations), its non
backtracking nature leaves its vulnerable to brittleness. In order to mitigate this potential brittleness, the Copilot
systems perform a monte carlo based stochastic analysis to set meta parameters of the scheduler - primarily activity
priority but also potentially preferred time and temporal constraints. Also: Research, experiments, and
engineering to empower future rovers with onboard autonomy; planning, scheduling & execution; path planning;
onboard science; image processing; terrain classification; fault diagnosis; and location estimation. This is a multi-
faceted effort and includes experimentation and demonstrations on-site at JPL's simulated mars navigation yard.","The onboard planner for the Mars2020 Rover (Perseverance) uses an incremental scheduling approach to create a feasible schedule based on activity priorities. It considers factors like preheating, maintenance, and rover's wake/sleep cycles when determining valid time intervals for activity placement. To address potential brittleness, the Copilot systems perform a stochastic analysis to set meta parameters for the scheduler. Additionally, research and experiments are being conducted to enhance future rovers' autonomy in various aspects such as planning, execution, image processing, and fault diagnosis, with on-site demonstrations at JPL's simulated mars navigation yard.","The onboard planner for the Mars2020 Rover (Perseverance) uses an incremental scheduling approach to create a feasible schedule based on activity priorities. It considers factors like preheating, maintenance, and rover's wake/sleep cycles when determining valid time intervals for activity placement. To address potential brittleness, the Copilot systems perform a stochastic analysis to set meta parameters for the scheduler. Additionally, research and experiments are being conducted to enhance future rovers' autonomy in various aspects such as planning, execution, image processing, and fault diagnosis, with on-site demonstrations at JPL's simulated mars navigation yard.",,,False,False
GSA-0011-2023,GSA,TTS/IAE,,IAE FSD CCAI Virtual Agent,The virtual agent uses manual learning to understand customer needs and provide a response appropriately. Our AI is named SAM and uses natural language.,Operation and Maintenance,Manual Learning/Natural Language,,U.S. General Services Administration,"IAE FSD CCAI Virtual Agent: 
The virtual agent uses manual learning to understand customer needs and provide a response appropriately. Our AI is named SAM and uses natural language.","The IAE FSD CCAI Virtual Agent, known as SAM, is an AI-powered virtual assistant that utilizes manual learning to comprehend customer requirements and deliver suitable responses. SAM is designed to understand natural language and effectively address customer needs.","The IAE FSD CCAI Virtual Agent, known as SAM, is an AI-powered virtual assistant that utilizes manual learning to comprehend customer requirements and deliver suitable responses. SAM is designed to understand natural language and effectively address customer needs.",,,False,False
HHS-0094-2023,HHS,FDA,CTP/OS/DRSI,ASSIST4TOBACCO,ASSIST4Tobacco is a semantic search system that helps CTP stakeholders find tobacco authorization applications more accurately and efficiently.,Implementation,,,Department of Health and Human Services,"ASSIST4TOBACCO: 
ASSIST4Tobacco is a semantic search system that helps CTP stakeholders find tobacco authorization applications more accurately and efficiently.",ASSIST4Tobacco is a search system that uses semantic technology to assist CTP stakeholders in finding tobacco authorization applications with improved accuracy and efficiency.,ASSIST4Tobacco is a search system that uses semantic technology to assist CTP stakeholders in finding tobacco authorization applications with improved accuracy and efficiency.,,,False,False
DOE-0152-2023,DOE,National Energy Technology Laboratory,,Using natural language processing to explore and extract information from historical literature/pdfs,"Training and adaptation of natural lanaguage processing algorithms to 
improve exploration and extraction of information from old, historical 
scientific literature.  Extraction of knowledge and data, as well as 
preservation of key information.",,"Big Data, Natural Language Processing, Other",,Department of Energy,"Using natural language processing to explore and extract information from historical literature/pdfs: 
Training and adaptation of natural lanaguage processing algorithms to 
improve exploration and extraction of information from old, historical 
scientific literature.  Extraction of knowledge and data, as well as 
preservation of key information.","Natural language processing algorithms can be trained and adapted to enhance the exploration and extraction of information from old scientific literature and pdfs. This enables the extraction of valuable knowledge and data, while also ensuring the preservation of essential information from historical sources.","Natural language processing algorithms can be trained and adapted to enhance the exploration and extraction of information from old scientific literature and pdfs. This enables the extraction of valuable knowledge and data, while also ensuring the preservation of essential information from historical sources.",,,False,False
VA-0002-2023,VA,,,AI Cure,AICURE is a phone app that monitors adherence to orally prescribed medications during clinical or pharmaceutical sponsor  drug studies.,,,,Department of Veterans Affairs,"AI Cure: 
AICURE is a phone app that monitors adherence to orally prescribed medications during clinical or pharmaceutical sponsor  drug studies.",AICURE is a phone app that tracks how well patients follow their prescribed medications in clinical or pharmaceutical sponsor drug studies. It uses artificial intelligence to monitor and ensure adherence to oral medications.,AICURE is a phone app that tracks how well patients follow their prescribed medications in clinical or pharmaceutical sponsor drug studies. It uses artificial intelligence to monitor and ensure adherence to oral medications.,,,False,False
DOC-0023-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Ice seal detection and species classification in multispectral aerial imagery,"Refine and improve detection and classification pipelines with the goal of reducing false 
positive rates (to < 50%) while maintaining > 90% accuracy and significantly reducing or 
eliminating the labor intensive, post survey review process.",,,,Department of Commerce,"Ice seal detection and species classification in multispectral aerial imagery: 
Refine and improve detection and classification pipelines with the goal of reducing false 
positive rates (to < 50%) while maintaining > 90% accuracy and significantly reducing or 
eliminating the labor intensive, post survey review process.","The aim of this study is to enhance the accuracy of ice seal detection and species classification in multispectral aerial imagery. This will be achieved by refining and improving the existing pipelines to decrease false positive rates to below 50%, while maintaining a high accuracy of over 90%. Additionally, the goal is to minimize the need for labor-intensive post-survey review by significantly reducing or eliminating it altogether.","The aim of this study is to enhance the accuracy of ice seal detection and species classification in multispectral aerial imagery. This will be achieved by refining and improving the existing pipelines to decrease false positive rates to below 50%, while maintaining a high accuracy of over 90%. Additionally, the goal is to minimize the need for labor-intensive post-survey review by significantly reducing or eliminating it altogether.",,,False,False
DOE-0008-2023,DOE,Fermi National Accelerator,,In-storage computing for multi- messenger astronomy in neutrino experiments and cosmological surveys,"This project aims to address the big-data challenges and stringent time 
constraints facing multi-messenger astronomy (MMA) in neutrino 
experiments and cosomological surveys. Instead of following the 
traditional computing paradigm of moving data to the compute 
elements, it does the opposite to embed computation in the data where 
processing is performed in situ. This will be achieved through emerging 
computational storage accelerators on which ML algorithms may be 
deployed to execute MMA tasks quickly so alerts can be disseminated 
promptly.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"In-storage computing for multi- messenger astronomy in neutrino experiments and cosmological surveys: 
This project aims to address the big-data challenges and stringent time 
constraints facing multi-messenger astronomy (MMA) in neutrino 
experiments and cosomological surveys. Instead of following the 
traditional computing paradigm of moving data to the compute 
elements, it does the opposite to embed computation in the data where 
processing is performed in situ. This will be achieved through emerging 
computational storage accelerators on which ML algorithms may be 
deployed to execute MMA tasks quickly so alerts can be disseminated 
promptly.","This project focuses on solving the challenges of big-data and time constraints in multi-messenger astronomy in neutrino experiments and cosmological surveys. It proposes a new approach where computation is embedded in the data itself, allowing for faster processing and prompt dissemination of alerts through the use of computational storage accelerators and machine learning algorithms.","This project focuses on solving the challenges of big-data and time constraints in multi-messenger astronomy in neutrino experiments and cosmological surveys. It proposes a new approach where computation is embedded in the data itself, allowing for faster processing and prompt dissemination of alerts through the use of computational storage accelerators and machine learning algorithms.",,,False,False
DOI-0007-2023,DOI,BOR,,Improving UAS-derived photogrammetric data and analysis accuracy and confidence for high-resolution data sets using artificial intelligence and machine learning,"UAS derived photogrammetric products contain a large amount of potential information that can be less accurate than required for analysis and time consuming to analyze manually. By formulating a standard reference protocol and applying machine learning/artificial intelligence, this information will be unlocked to provide detailed analysis of Reclamation's assets for better informed decision making.",Proof-of-concept completed,,,Department of Interior,"Improving UAS-derived photogrammetric data and analysis accuracy and confidence for high-resolution data sets using artificial intelligence and machine learning: 
UAS derived photogrammetric products contain a large amount of potential information that can be less accurate than required for analysis and time consuming to analyze manually. By formulating a standard reference protocol and applying machine learning/artificial intelligence, this information will be unlocked to provide detailed analysis of Reclamation's assets for better informed decision making.","The use of artificial intelligence and machine learning can improve the accuracy and confidence of high-resolution data obtained from unmanned aerial systems (UAS) in photogrammetry. By establishing a standard reference protocol and utilizing these technologies, the potential information contained in UAS-derived photogrammetric products can be analyzed in detail, enabling better-informed decision-making regarding Reclamation's assets.","The use of artificial intelligence and machine learning can improve the accuracy and confidence of high-resolution data obtained from unmanned aerial systems (UAS) in photogrammetry. By establishing a standard reference protocol and utilizing these technologies, the potential information contained in UAS-derived photogrammetric products can be analyzed in detail, enabling better-informed decision-making regarding Reclamation's assets.",,,False,False
DOL-0005-2023,DOL,,,Website Chatbot Assistant,"The chatbot helps the end user with basic information about the program, information on who to contact, or seeking petition case status.",Implementation,Cloud based commercial-off-the-shelf pre-trained chatbot,,Department of Labor,"Website Chatbot Assistant: 
The chatbot helps the end user with basic information about the program, information on who to contact, or seeking petition case status.","The website chatbot assistant provides assistance to users by offering basic information about the program, providing contact details, and helping in tracking petition case status.","The website chatbot assistant provides assistance to users by offering basic information about the program, providing contact details, and helping in tracking petition case status.",,,False,False
TREAS-0012-2023,TREAS,,,TAS Virtual Assistant,"The TAS Virtual Assistant Chatbot will capture utterances from 
taxpayers/end-users to direct them to helpful resources on IRS and TAS 
public websites.",Initiation,,,Department of Treasury,"TAS Virtual Assistant: 
The TAS Virtual Assistant Chatbot will capture utterances from 
taxpayers/end-users to direct them to helpful resources on IRS and TAS 
public websites.",The TAS Virtual Assistant Chatbot collects information from taxpayers and guides them to useful resources on the IRS and TAS public websites. It helps users find the information they need efficiently.,The TAS Virtual Assistant Chatbot collects information from taxpayers and guides them to useful resources on the IRS and TAS public websites. It helps users find the information they need efficiently.,,,False,False
HHS-0033-2023,HHS,CDC,NCHS,Coding cause of death information on death certificates to ICD-10,MedCoder ICD-10 cause of death codes to the literal text cause of death description provided by the cause of death certifier on the death certificate.  This includes codes for the underlying and contributing causes of death.,Operation and Maintenance,,,Department of Health and Human Services,"Coding cause of death information on death certificates to ICD-10: 
MedCoder ICD-10 cause of death codes to the literal text cause of death description provided by the cause of death certifier on the death certificate.  This includes codes for the underlying and contributing causes of death.",The process involves assigning ICD-10 codes to the cause of death information on death certificates. These codes represent the literal text description provided by the certifier and include both the underlying and contributing causes of death.,The process involves assigning ICD-10 codes to the cause of death information on death certificates. These codes represent the literal text description provided by the certifier and include both the underlying and contributing causes of death.,,,False,False
DOE-0035-2023,DOE,National Energy Technology Laboratory,,ANN Submodels of Reaction Physics,ANN development of flow physics for code acceleration,,Other,,Department of Energy,"ANN Submodels of Reaction Physics: 
ANN development of flow physics for code acceleration",The text discusses the development of Artificial Neural Network (ANN) submodels for reaction physics in order to accelerate code. These submodels aim to improve the understanding and prediction of flow physics.,The text discusses the development of Artificial Neural Network (ANN) submodels for reaction physics in order to accelerate code. These submodels aim to improve the understanding and prediction of flow physics.,,,False,False
USDA-0027-2023,USDA,USDA,NASS,List Frame Deadwood Identification,"The deadwood model leverages boosted regression trees with inputs such as  administrative linkage data, frame data, and historical response information as inputs, to produce a propensity score representing a relative likelihood of a farm operation being out of business.  Common tree splits were identified using the model and combined with expert knowledge to develop a recurring process for deadwood clean up.",Operation and Management,Machine Learning,,Department of Agriculture,"List Frame Deadwood Identification: 
The deadwood model leverages boosted regression trees with inputs such as  administrative linkage data, frame data, and historical response information as inputs, to produce a propensity score representing a relative likelihood of a farm operation being out of business.  Common tree splits were identified using the model and combined with expert knowledge to develop a recurring process for deadwood clean up.","The deadwood identification process uses a model that combines various data inputs to predict the likelihood of a farm operation going out of business. By analyzing common tree splits identified by the model and incorporating expert knowledge, a recurring process for removing deadwood is developed.","The deadwood identification process uses a model that combines various data inputs to predict the likelihood of a farm operation going out of business. By analyzing common tree splits identified by the model and incorporating expert knowledge, a recurring process for removing deadwood is developed.",,,False,False
HHS-0003-2023,HHS,ASPR,BARDA (CBRN & DRIVe),R+2:18eDIRECT: Clarivate,AI to identify drug repurposing candidates,Operation and Maintenance,,,Department of Health and Human Services,"R+2:18eDIRECT: Clarivate: 
AI to identify drug repurposing candidates","Clarivate, an information services company, has developed an AI technology called R+2:18eDIRECT, which can identify potential drug repurposing candidates. This innovative tool aims to accelerate the drug discovery process by analyzing vast amounts of data and providing valuable insights for researchers and pharmaceutical companies.","Clarivate, an information services company, has developed an AI technology called R+2:18eDIRECT, which can identify potential drug repurposing candidates. This innovative tool aims to accelerate the drug discovery process by analyzing vast amounts of data and providing valuable insights for researchers and pharmaceutical companies.",,,False,False
USDA-0023-2023,USDA,USDA,Forest Service,Landscape Change Monitoring System (LCMS),"The Landscape Change Monitoring System (LCMS) is a National landsat/sentinal remote sensing-based data produced by the USDA Forest Service for mapping and monitoring changes related to vegetation canopy cover, as well as land cover and land use. The process utilizes temporal change classifications together with training data in a supervised classification process for vegetation gain, and loss as well as land cover and use.",Development and Acquisition,"Machine Learning,Visual Analysis",,Department of Agriculture,"Landscape Change Monitoring System (LCMS): 
The Landscape Change Monitoring System (LCMS) is a National landsat/sentinal remote sensing-based data produced by the USDA Forest Service for mapping and monitoring changes related to vegetation canopy cover, as well as land cover and land use. The process utilizes temporal change classifications together with training data in a supervised classification process for vegetation gain, and loss as well as land cover and use.","The Landscape Change Monitoring System (LCMS) is a data system created by the USDA Forest Service that uses remote sensing to monitor changes in vegetation canopy cover and land cover and use. It employs a supervised classification process with temporal change classifications and training data to identify vegetation gain, loss, and changes in land cover and use.","The Landscape Change Monitoring System (LCMS) is a data system created by the USDA Forest Service that uses remote sensing to monitor changes in vegetation canopy cover and land cover and use. It employs a supervised classification process with temporal change classifications and training data to identify vegetation gain, loss, and changes in land cover and use.",,,False,False
DHS-0029-2023,DHS,Immigration and Customs Enforcement,,Email Analytics,"The Email Analytics application enables a user to review and analyze email data acquired through legal process.  AI is incorporated to accomplish spam message classification, and named entity recognition (NER) for entity extraction of names, organizations, locations, etc.  It also integrates machine translation capabilities using a commercial product.",Implementation,"Machine Learning, Natural Language Processing (NLP)",,Department of Homeland Security,"Email Analytics: 
The Email Analytics application enables a user to review and analyze email data acquired through legal process.  AI is incorporated to accomplish spam message classification, and named entity recognition (NER) for entity extraction of names, organizations, locations, etc.  It also integrates machine translation capabilities using a commercial product.","The Email Analytics application allows users to analyze and review email data obtained legally. It utilizes AI to classify spam messages and extract entities such as names, organizations, and locations. Additionally, it integrates machine translation capabilities with a commercial product.","The Email Analytics application allows users to analyze and review email data obtained legally. It utilizes AI to classify spam messages and extract entities such as names, organizations, and locations. Additionally, it integrates machine translation capabilities with a commercial product.",,,False,False
DOE-0022-2023,DOE,Lawrence Livermore National Laboratory,,"Biology, genomics, and synthetic biology","Combining experimental and computational methods to perform 
fundamental and applied research in genomics, molecular toxicology, 
nanotechnology, host–pathogen biology, structural biology, genetics, 
microbial systems, and medical countermeasures",,,,Department of Energy,"Biology, genomics, and synthetic biology: 
Combining experimental and computational methods to perform 
fundamental and applied research in genomics, molecular toxicology, 
nanotechnology, host–pathogen biology, structural biology, genetics, 
microbial systems, and medical countermeasures","This text discusses the integration of experimental and computational methods in the fields of biology, genomics, and synthetic biology. These methods are used to conduct research in various areas such as genomics, molecular toxicology, nanotechnology, host-pathogen biology, structural biology, genetics, microbial systems, and medical countermeasures.","This text discusses the integration of experimental and computational methods in the fields of biology, genomics, and synthetic biology. These methods are used to conduct research in various areas such as genomics, molecular toxicology, nanotechnology, host-pathogen biology, structural biology, genetics, microbial systems, and medical countermeasures.",,,False,False
HHS-0093-2023,HHS,FDA,CTP/OS/DRSI,SSTAT,Self-Service Text Analytics Tool (SSTAT) is used to explore the topics of a set of documents. Documents can be submitted to the tool in order to generate a set of topics and associated keywords. A visual listing of the documents and their associated topics is automatically produced to help quickly snapshot the submitted documents.,Operation and Maintenance,,,Department of Health and Human Services,"SSTAT: 
Self-Service Text Analytics Tool (SSTAT) is used to explore the topics of a set of documents. Documents can be submitted to the tool in order to generate a set of topics and associated keywords. A visual listing of the documents and their associated topics is automatically produced to help quickly snapshot the submitted documents.","SSTAT is a self-service text analytics tool that allows users to analyze the topics of a group of documents. By submitting documents to the tool, users can generate a list of topics and keywords associated with them. The tool also provides a visual representation of the submitted documents and their respective topics, aiding in quickly understanding the content.","SSTAT is a self-service text analytics tool that allows users to analyze the topics of a group of documents. By submitting documents to the tool, users can generate a list of topics and keywords associated with them. The tool also provides a visual representation of the submitted documents and their respective topics, aiding in quickly understanding the content.",,,False,False
TREAS-0009-2023,TREAS,,,Inventory Item Replenishment MLR Modeling POC - Phase 2,"The Bureau of Engraving and Printing wanted to operationalize a model 
using their newly deployed Cloudera Data Science Workbench (CDSW) 
application to predict whether an item would be delivered by the vendor 
Promised Date. This date is the date the vendor promises an item to be 
delivered to BEP. The model utilizes historical requisition, vendor, and 
item specific data to come up with binary (0 or 1) predictions, which are 
then used to determine whether an item will be delivered on-time or if the 
OSCM should expect a delay. If the model outputs a 1, we expect that the 
item will be delayed and the OSCM can be proactive in their decision 
making to prepare for a potential inventory shortage.",Development and Acquisition,,,Department of Treasury,"Inventory Item Replenishment MLR Modeling POC - Phase 2: 
The Bureau of Engraving and Printing wanted to operationalize a model 
using their newly deployed Cloudera Data Science Workbench (CDSW) 
application to predict whether an item would be delivered by the vendor 
Promised Date. This date is the date the vendor promises an item to be 
delivered to BEP. The model utilizes historical requisition, vendor, and 
item specific data to come up with binary (0 or 1) predictions, which are 
then used to determine whether an item will be delivered on-time or if the 
OSCM should expect a delay. If the model outputs a 1, we expect that the 
item will be delayed and the OSCM can be proactive in their decision 
making to prepare for a potential inventory shortage.","The Bureau of Engraving and Printing wanted to use their new Cloudera Data Science Workbench application to predict if an item will be delivered on time by the vendor. The model uses historical data to make binary predictions, allowing the Bureau to prepare for potential inventory shortages if the model predicts a delay.","The Bureau of Engraving and Printing wanted to use their new Cloudera Data Science Workbench application to predict if an item will be delivered on time by the vendor. The model uses historical data to make binary predictions, allowing the Bureau to prepare for potential inventory shortages if the model predicts a delay.",,,False,False
HHS-0109-2023,HHS,NIH,National Institutes of Health (NIH) CSR,Assisted Referral Tool,To provide assistance in assigning appropriate scientific areas for grant applications.,Operation and Maintenance,,,Department of Health and Human Services,"Assisted Referral Tool: 
To provide assistance in assigning appropriate scientific areas for grant applications.",The Assisted Referral Tool is designed to help assign suitable scientific areas for grant applications. It offers assistance in the process of determining the most appropriate areas for these applications.,The Assisted Referral Tool is designed to help assign suitable scientific areas for grant applications. It offers assistance in the process of determining the most appropriate areas for these applications.,,,False,False
HHS-0103-2023,HHS,FDA,NCTR,Artificial Intelligence (AI)-based Natural Language Processing (NLP) for FDA labeling documents,"FDA has historically generated and continues to generate a variety of documents during the product-review process, which are typically unstructured text and often not follows the use of standards. Therefore, analysis of semantic relationships plays a vital role to extract useful information from the FDA documents to facilitate the regulatory science research and improve FDA product review process. The rapid advancement in artificial intelligence (AI) for Natural Language Processing (NLP) offers an unprecedent opportunity to analyze the semantic text data by using the language models that are trained with large biomedical corpus. This study is to assess the AI based NLP for the FDA documents with a focus on the FDA labeling documents. Specifically, we will apply the publicly available language models (e.g., BERT and BioBERT) to the FDA drug labeling documents available from the FDA Label tool that manages over 120K labeling documents including over 40K Human Prescription Drug and Biological Products. We will investigate three areas of AI applications that are important to the regulatory science research: (1) the interpretation and classification of drug properties (e.g., safety and efficacy) with AI reading, (2) text summarization to provide highlights of labeling sections, (3) automatic anomaly analysis (AAA) for signal identification, and (4) information retrieval with Amazon-like Questions/Answer. We will compare the AI based NLP with MedDRA based approach whenever possible for drug safety and efficacy. The study will provide a benchmark for fit-for-purpose application of the public language models to the FDA documents and, moreover, the outcome of the study could provide a scientific basis to support the future development of FDALabel tool which is widely used in CDER review process.",Implementation,,,Department of Health and Human Services,"Artificial Intelligence (AI)-based Natural Language Processing (NLP) for FDA labeling documents: 
FDA has historically generated and continues to generate a variety of documents during the product-review process, which are typically unstructured text and often not follows the use of standards. Therefore, analysis of semantic relationships plays a vital role to extract useful information from the FDA documents to facilitate the regulatory science research and improve FDA product review process. The rapid advancement in artificial intelligence (AI) for Natural Language Processing (NLP) offers an unprecedent opportunity to analyze the semantic text data by using the language models that are trained with large biomedical corpus. This study is to assess the AI based NLP for the FDA documents with a focus on the FDA labeling documents. Specifically, we will apply the publicly available language models (e.g., BERT and BioBERT) to the FDA drug labeling documents available from the FDA Label tool that manages over 120K labeling documents including over 40K Human Prescription Drug and Biological Products. We will investigate three areas of AI applications that are important to the regulatory science research: (1) the interpretation and classification of drug properties (e.g., safety and efficacy) with AI reading, (2) text summarization to provide highlights of labeling sections, (3) automatic anomaly analysis (AAA) for signal identification, and (4) information retrieval with Amazon-like Questions/Answer. We will compare the AI based NLP with MedDRA based approach whenever possible for drug safety and efficacy. The study will provide a benchmark for fit-for-purpose application of the public language models to the FDA documents and, moreover, the outcome of the study could provide a scientific basis to support the future development of FDALabel tool which is widely used in CDER review process.","The FDA generates various unstructured documents during the product-review process, and analyzing the semantic relationships within these documents is crucial for extracting useful information and improving the review process. The use of AI-based NLP, specifically language models like BERT and BioBERT, can help interpret drug properties, provide text summaries, identify anomalies, and retrieve information from FDA labeling documents. This study aims to assess the effectiveness of AI-based NLP compared to the MedDRA approach and provide a benchmark for future development of the FDALabel tool.","The FDA generates various unstructured documents during the product-review process, and analyzing the semantic relationships within these documents is crucial for extracting useful information and improving the review process. The use of AI-based NLP, specifically language models like BERT and BioBERT, can help interpret drug properties, provide text summaries, identify anomalies, and retrieve information from FDA labeling documents. This study aims to assess the effectiveness of AI-based NLP compared to the MedDRA approach and provide a benchmark for future development of the FDALabel tool.",,,False,False
HHS-0065-2023,HHS,FDA,CBER/OBPV/DABRA,To develop novel approaches to expand and/or modify the vaccine AESI phenotypes in order to further improve adverse event detection,Developing a BERT-like ML model to improve detection of adverse events of special interest by applying a clinical-oriented language models pre-trained using the clinical documents from UCSF,Implementation,,,Department of Health and Human Services,"To develop novel approaches to expand and/or modify the vaccine AESI phenotypes in order to further improve adverse event detection: 
Developing a BERT-like ML model to improve detection of adverse events of special interest by applying a clinical-oriented language models pre-trained using the clinical documents from UCSF","The goal is to enhance the identification of adverse events in vaccines by creating a BERT-like machine learning model. This model will be trained using clinical documents from UCSF, focusing on language relevant to adverse event detection.","The goal is to enhance the identification of adverse events in vaccines by creating a BERT-like machine learning model. This model will be trained using clinical documents from UCSF, focusing on language relevant to adverse event detection.",,,False,False
USDA-0022-2023,USDA,USDA,Forest Service,TreeMap 2016,"TreeMap 2016 provides a tree-level model of the forests of the conterminous United States. It matches forest plot data from Forest Inventory and Analysis (FIA) to a 30x30 meter (m) grid. TreeMap 2016 is being used in both the private and public sectors for projects including fuel treatment planning, snag hazard mapping, and estimation of terrestrial carbon resources. A random forests machine-learning algorithm was used to impute the forest plot data to a set of target rasters provided by Landscape Fire and Resource Management Planning Tools (LANDFIRE: https://landfire.gov). Predictor variables consisted of percent forest cover, height, and vegetation type, as well as topography (slope, elevation, and aspect), location (latitude and longitude), biophysical variables (photosynthetically active radiation, precipitation, maximum temperature, minimum temperature, relative humidity, and vapour pressure deficit), and disturbance history (time since disturbance and disturbance type) for the landscape circa 2016.",Operation and Management,Machine Learning,,Department of Agriculture,"TreeMap 2016: 
TreeMap 2016 provides a tree-level model of the forests of the conterminous United States. It matches forest plot data from Forest Inventory and Analysis (FIA) to a 30x30 meter (m) grid. TreeMap 2016 is being used in both the private and public sectors for projects including fuel treatment planning, snag hazard mapping, and estimation of terrestrial carbon resources. A random forests machine-learning algorithm was used to impute the forest plot data to a set of target rasters provided by Landscape Fire and Resource Management Planning Tools (LANDFIRE: https://landfire.gov). Predictor variables consisted of percent forest cover, height, and vegetation type, as well as topography (slope, elevation, and aspect), location (latitude and longitude), biophysical variables (photosynthetically active radiation, precipitation, maximum temperature, minimum temperature, relative humidity, and vapour pressure deficit), and disturbance history (time since disturbance and disturbance type) for the landscape circa 2016.","TreeMap 2016 is a model that represents the forests of the conterminous United States by matching forest plot data to a 30x30 meter grid. It is used in various sectors for projects such as fuel treatment planning and estimating carbon resources. The model was created using a random forests machine-learning algorithm, which imputed the forest plot data to target rasters provided by LANDFIRE, using predictor variables such as forest cover, height, vegetation type, topography, location, biophysical variables, and disturbance history.","TreeMap 2016 is a model that represents the forests of the conterminous United States by matching forest plot data to a 30x30 meter grid. It is used in various sectors for projects such as fuel treatment planning and estimating carbon resources. The model was created using a random forests machine-learning algorithm, which imputed the forest plot data to target rasters provided by LANDFIRE, using predictor variables such as forest cover, height, vegetation type, topography, location, biophysical variables, and disturbance history.",,,False,False
DOC-0031-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,"BANTER, a machine learning acoustic event classifier",A supervised machine learning acoustic event classifier using hierarchical random forests,,,,Department of Commerce,"BANTER, a machine learning acoustic event classifier: 
A supervised machine learning acoustic event classifier using hierarchical random forests",BANTER is a machine learning acoustic event classifier that utilizes hierarchical random forests. This supervised system is designed to accurately classify and categorize acoustic events based on their audio characteristics.,BANTER is a machine learning acoustic event classifier that utilizes hierarchical random forests. This supervised system is designed to accurately classify and categorize acoustic events based on their audio characteristics.,,,False,False
DOT-0001-2023,DOT,ANG,,Determining Surface Winds with Machine Learning Software,Successfully demonstrated use of an AI capability to analyze camera images of a wind sock to produce highly accurate surface wind speed and direction information in remote areas that don’t have a weather observing sensor.,Successfully tested but not in production.,AI,,Department of Transportation,"Determining Surface Winds with Machine Learning Software: 
Successfully demonstrated use of an AI capability to analyze camera images of a wind sock to produce highly accurate surface wind speed and direction information in remote areas that don’t have a weather observing sensor.",Machine learning software has been proven effective in analyzing camera images of a wind sock to accurately determine surface wind speed and direction in areas without weather observing sensors. This technology provides reliable information in remote locations where traditional weather monitoring systems are not available.,Machine learning software has been proven effective in analyzing camera images of a wind sock to accurately determine surface wind speed and direction in areas without weather observing sensors. This technology provides reliable information in remote locations where traditional weather monitoring systems are not available.,,,False,False
HHS-0006-2023,HHS,ASPR,BARDA (CBRN),Burn & Blast MCMs: Philips,AI-based algorithms on Lumify handheld ultrasound system to detect lung injury and infectious diseases,Development and Acquisition,,,Department of Health and Human Services,"Burn & Blast MCMs: Philips: 
AI-based algorithms on Lumify handheld ultrasound system to detect lung injury and infectious diseases","Philips has developed AI-based algorithms for their Lumify handheld ultrasound system to detect lung injury and infectious diseases. These algorithms help in identifying and monitoring such conditions, making the ultrasound system a valuable tool for healthcare professionals.","Philips has developed AI-based algorithms for their Lumify handheld ultrasound system to detect lung injury and infectious diseases. These algorithms help in identifying and monitoring such conditions, making the ultrasound system a valuable tool for healthcare professionals.",,,False,False
DOE-0174-2023,DOE,Pacific Northwest National Laboratory,,"Scalable, Efficient and Accelerated Causal Reasoning Operators, Graphs and Spikes for Earth and Embedded Systems (SEA-CROGS)","Establish a center for scalable and efficient physics-informed machine 
learning for science and engineering that will accelerate modeling, 
inference, causal reasoning, etiology and pathway discovery for earth 
systems and embedded systems. Advances will lead to a higher level of 
abstraction of operator regression to be implemented in next generation 
neuromorphic computers.",,,,Department of Energy,"Scalable, Efficient and Accelerated Causal Reasoning Operators, Graphs and Spikes for Earth and Embedded Systems (SEA-CROGS): 
Establish a center for scalable and efficient physics-informed machine 
learning for science and engineering that will accelerate modeling, 
inference, causal reasoning, etiology and pathway discovery for earth 
systems and embedded systems. Advances will lead to a higher level of 
abstraction of operator regression to be implemented in next generation 
neuromorphic computers.","The SEA-CROGS project aims to establish a center for scalable and efficient physics-informed machine learning for science and engineering. This will accelerate modeling, inference, causal reasoning, etiology, and pathway discovery for earth systems and embedded systems, ultimately leading to advancements in operator regression for next-generation neuromorphic computers.","The SEA-CROGS project aims to establish a center for scalable and efficient physics-informed machine learning for science and engineering. This will accelerate modeling, inference, causal reasoning, etiology, and pathway discovery for earth systems and embedded systems, ultimately leading to advancements in operator regression for next-generation neuromorphic computers.",,,False,False
VA-0026-2023,VA,,,Machine learning models to predict disease progression among veterans with hepatitis C virus,A machine learning model is used to predict disease progression among veterans with hepatitis C virus.,,,,Department of Veterans Affairs,"Machine learning models to predict disease progression among veterans with hepatitis C virus: 
A machine learning model is used to predict disease progression among veterans with hepatitis C virus.",Researchers have developed a machine learning model that accurately predicts the progression of hepatitis C virus in veterans. This model can aid in early detection and intervention for better patient outcomes.,Researchers have developed a machine learning model that accurately predicts the progression of hepatitis C virus in veterans. This model can aid in early detection and intervention for better patient outcomes.,,,False,False
EPA-0000-2023,EPA,,,Use of random forest model to predict exposure pathways,"Prioritizing the potential risk posed to human health by chemicals requires tools that can estimate exposure from limited information. In this study, chemical structure and physicochemical properties were used to predict the probability that a chemical might be associated with any of four exposure pathways leading from sources-consumer (near-field), dietary, far-field industrial, and far-field pesticide-to the general population. The balanced accuracies of these source-based exposure pathway models range from 73 to 81%, with the error rate for identifying positive chemicals ranging from 17 to 36%. We then used exposure pathways to organize predictions from 13 different exposure models as well as other predictors of human intake rates. We created a consensus, meta-model using the Systematic Empirical Evaluation of Models framework in which the predictors of exposure were combined by pathway and weighted according to predictive ability for chemical intake rates inferred from human biomonitoring data for 114 chemicals. The consensus model yields an R2 of ∼0.8. We extrapolate to predict relevant pathway(s), median intake rate, and credible interval for 479 926 chemicals, mostly with minimal exposure information. This approach identifies 1880 chemicals for which the median population intake rates may exceed 0.1 mg/kg bodyweight/day, while there is 95% confidence that the median intake rate is below 1 μg/kg BW/day for 474572 compounds.
Consensus Modeling of Median Chemical Intake for the U.S. Population Based on Predictions of Exposure Pathways",,,,U.S. Environmental Protection Agency,"Use of random forest model to predict exposure pathways: 
Prioritizing the potential risk posed to human health by chemicals requires tools that can estimate exposure from limited information. In this study, chemical structure and physicochemical properties were used to predict the probability that a chemical might be associated with any of four exposure pathways leading from sources-consumer (near-field), dietary, far-field industrial, and far-field pesticide-to the general population. The balanced accuracies of these source-based exposure pathway models range from 73 to 81%, with the error rate for identifying positive chemicals ranging from 17 to 36%. We then used exposure pathways to organize predictions from 13 different exposure models as well as other predictors of human intake rates. We created a consensus, meta-model using the Systematic Empirical Evaluation of Models framework in which the predictors of exposure were combined by pathway and weighted according to predictive ability for chemical intake rates inferred from human biomonitoring data for 114 chemicals. The consensus model yields an R2 of ∼0.8. We extrapolate to predict relevant pathway(s), median intake rate, and credible interval for 479 926 chemicals, mostly with minimal exposure information. This approach identifies 1880 chemicals for which the median population intake rates may exceed 0.1 mg/kg bodyweight/day, while there is 95% confidence that the median intake rate is below 1 μg/kg BW/day for 474572 compounds.
Consensus Modeling of Median Chemical Intake for the U.S. Population Based on Predictions of Exposure Pathways","The study used a random forest model to predict the likelihood of chemicals being associated with different exposure pathways. The model achieved a balanced accuracy of 73-81% in identifying these pathways. By combining this information with other predictors of human intake rates, a consensus model was created that predicted relevant pathways, median intake rates, and credible intervals for a large number of chemicals.","The study used a random forest model to predict the likelihood of chemicals being associated with different exposure pathways. The model achieved a balanced accuracy of 73-81% in identifying these pathways. By combining this information with other predictors of human intake rates, a consensus model was created that predicted relevant pathways, median intake rates, and credible intervals for a large number of chemicals.",,,False,False
VA-0006-2023,VA,,,Automatic speech transcription engines to aid scoring neuropsychological tests.,Automated speech transcription engines analyze the cognitive decline of older VA patients. Digitally recorded speech responses are transcribed using multiple artificial intelligence-based speech-to-text engines. The transcriptions are fused together to reduce or obviate the need for manual transcription of patient speech in order to score the neuropsychological tests.,,,,Department of Veterans Affairs,"Automatic speech transcription engines to aid scoring neuropsychological tests.: 
Automated speech transcription engines analyze the cognitive decline of older VA patients. Digitally recorded speech responses are transcribed using multiple artificial intelligence-based speech-to-text engines. The transcriptions are fused together to reduce or obviate the need for manual transcription of patient speech in order to score the neuropsychological tests.",Automatic speech transcription engines are used to analyze the cognitive decline of older VA patients by transcribing their digitally recorded speech responses using AI-based speech-to-text engines. This eliminates the need for manual transcription of patient speech in order to score the neuropsychological tests.,Automatic speech transcription engines are used to analyze the cognitive decline of older VA patients by transcribing their digitally recorded speech responses using AI-based speech-to-text engines. This eliminates the need for manual transcription of patient speech in order to score the neuropsychological tests.,,,False,False
HHS-0138-2023,HHS,NIH,National Institutes of Health (NIH) NLM,MetaMap,"MetaMap is a widely available program providing access from biomedical text to the concepts in the unified medical language system (UMLS) Metathesaurus. MetaMap uses NLP to provide a link between the text of biomedical literature and the knowledge, including synonymy relationships, embedded in the Metathesaurus. The flexible architecture in which to explore mapping strategies and their application are made available. MTI uses the MetaMap to generate potential indexing terms. ",Operation and Maintenance,,,Department of Health and Human Services,"MetaMap: 
MetaMap is a widely available program providing access from biomedical text to the concepts in the unified medical language system (UMLS) Metathesaurus. MetaMap uses NLP to provide a link between the text of biomedical literature and the knowledge, including synonymy relationships, embedded in the Metathesaurus. The flexible architecture in which to explore mapping strategies and their application are made available. MTI uses the MetaMap to generate potential indexing terms. ","MetaMap is a program that allows access to concepts in the UMLS Metathesaurus from biomedical text. It uses NLP to link the text to the knowledge in the Metathesaurus, including synonymy relationships. MTI uses MetaMap to generate indexing terms.","MetaMap is a program that allows access to concepts in the UMLS Metathesaurus from biomedical text. It uses NLP to link the text to the knowledge in the Metathesaurus, including synonymy relationships. MTI uses MetaMap to generate indexing terms.",,,False,False
DOI-0034-2023,DOI,USGS,,SWFL Habitat GIS Model,"Objective 1 – Update and maintain a seamless digital library of predicted flycatcher breeding habitat displayed (rendered) as binary or 5-class probability maps. This effort is ongoing. Landsat reimages the same location every 16 days. Currently, the digital library that is housed within ESRI’s AGOL library contains SWFL habitat maps from 2013 – 2022, spanning 57 Landsat scenes (see Hatten, 2016 for details) output by GEE._x000D_
Objective 2 – Update and maintain the SWFL Habitat Viewer so users can leverage and display the satellite model’s range-wide database and produce a habitat map for any stream reach in the flycatcher’s range. The web based (AGOL) application will allow one to query, _x000D_
display, and download flycatcher habitat maps from 2013 to present by leveraging a library of existing habitat maps generated with GEE, create a habitat time series for a given reach, produce a change detection map between two time periods, and produce metadata records based upon the scene’s date and digital footprint. The SWFL Habitat Viewer can also quantify or simulate beetle impacts to flycatcher habitat on a reach-by-reach basis, but simulations are dependent upon the availability of tamarisk maps.   _x000D_
 Objective 3 – Participate on regional workgroups, symposia, and conferences to inform potential and existing users about the SWFL Habitat Viewer. Currently, the RiversEdge West biannual conference and NAU’s biannual Colorado Plateau Research conference are the major outlets for presentations, but other regional conference candidates may be in Colorado, Nevada, New Mexico, or California._x000D_
Objective 4 - Collaborate in efforts to improve and extend the utility of the flycatcher satellite model by exploring cutting-edge modeling techniques (e.g., occupancy modeling, climate-wildlife modeling). For example, the flycatcher satellite model is being used to develop a regional database that contains patch attributes of SWFL habitat across the entire range of flycatchers. Such information is invaluable for exploring the relationships between patch occupancy and neighborhood characteristics (e.g., number of patches within a given radii, age of patches, distance between patches). The SWFL model is also being integrated into a regionwide project that focuses on linking interdisciplinary scientific data and models with artificial intelligence techniques, with a focus on hydrologic and ecological model integration in the Colorado River Basin, to better address drought and climate change.",Initiation,Bagged trees (aka random forest) classification,,Department of Interior,"SWFL Habitat GIS Model: 
Objective 1 – Update and maintain a seamless digital library of predicted flycatcher breeding habitat displayed (rendered) as binary or 5-class probability maps. This effort is ongoing. Landsat reimages the same location every 16 days. Currently, the digital library that is housed within ESRI’s AGOL library contains SWFL habitat maps from 2013 – 2022, spanning 57 Landsat scenes (see Hatten, 2016 for details) output by GEE._x000D_
Objective 2 – Update and maintain the SWFL Habitat Viewer so users can leverage and display the satellite model’s range-wide database and produce a habitat map for any stream reach in the flycatcher’s range. The web based (AGOL) application will allow one to query, _x000D_
display, and download flycatcher habitat maps from 2013 to present by leveraging a library of existing habitat maps generated with GEE, create a habitat time series for a given reach, produce a change detection map between two time periods, and produce metadata records based upon the scene’s date and digital footprint. The SWFL Habitat Viewer can also quantify or simulate beetle impacts to flycatcher habitat on a reach-by-reach basis, but simulations are dependent upon the availability of tamarisk maps.   _x000D_
 Objective 3 – Participate on regional workgroups, symposia, and conferences to inform potential and existing users about the SWFL Habitat Viewer. Currently, the RiversEdge West biannual conference and NAU’s biannual Colorado Plateau Research conference are the major outlets for presentations, but other regional conference candidates may be in Colorado, Nevada, New Mexico, or California._x000D_
Objective 4 - Collaborate in efforts to improve and extend the utility of the flycatcher satellite model by exploring cutting-edge modeling techniques (e.g., occupancy modeling, climate-wildlife modeling). For example, the flycatcher satellite model is being used to develop a regional database that contains patch attributes of SWFL habitat across the entire range of flycatchers. Such information is invaluable for exploring the relationships between patch occupancy and neighborhood characteristics (e.g., number of patches within a given radii, age of patches, distance between patches). The SWFL model is also being integrated into a regionwide project that focuses on linking interdisciplinary scientific data and models with artificial intelligence techniques, with a focus on hydrologic and ecological model integration in the Colorado River Basin, to better address drought and climate change.","The SWFL Habitat GIS Model aims to update and maintain a digital library of predicted flycatcher breeding habitat, as well as provide a habitat viewer for users to access and display habitat maps. The model also collaborates with other efforts to improve and extend the utility of the flycatcher satellite model through cutting-edge modeling techniques. Additionally, the model participates in regional workgroups and conferences to inform potential and existing users about the SWFL Habitat Viewer.","The SWFL Habitat GIS Model aims to update and maintain a digital library of predicted flycatcher breeding habitat, as well as provide a habitat viewer for users to access and display habitat maps. The model also collaborates with other efforts to improve and extend the utility of the flycatcher satellite model through cutting-edge modeling techniques. Additionally, the model participates in regional workgroups and conferences to inform potential and existing users about the SWFL Habitat Viewer.",,,False,False
DOS-0000-2023,DOS,A,,Federal Procurement Data System (FPDS) Auto-Populate Bot,"A/LM collaborated with A/OPE to develop a bot to automate the data entry in the Federal Procurement Data System (FPDS), reducing the burden on post’s procurement staff and driving improved compliance on DATA Act reporting. This bot is now used to update ~300 FPDS awards per week.  A/LM also partnered with WHA to develop a bot to automate closeout reminders for federal assistance grants nearing the end of the period of performance and begin developing bots to automate receiving report validation and customer service inbox monitoring.",,,,Department of State,"Federal Procurement Data System (FPDS) Auto-Populate Bot: 
A/LM collaborated with A/OPE to develop a bot to automate the data entry in the Federal Procurement Data System (FPDS), reducing the burden on post’s procurement staff and driving improved compliance on DATA Act reporting. This bot is now used to update ~300 FPDS awards per week.  A/LM also partnered with WHA to develop a bot to automate closeout reminders for federal assistance grants nearing the end of the period of performance and begin developing bots to automate receiving report validation and customer service inbox monitoring.","A bot was developed by A/LM and A/OPE to automate data entry in the Federal Procurement Data System (FPDS), reducing the workload for procurement staff and improving compliance with DATA Act reporting. The bot is currently being used to update approximately 300 FPDS awards each week. Additionally, A/LM collaborated with WHA to create a bot that automates closeout reminders for federal assistance grants and is working on developing bots for receiving report validation and customer service inbox monitoring.","A bot was developed by A/LM and A/OPE to automate data entry in the Federal Procurement Data System (FPDS), reducing the workload for procurement staff and improving compliance with DATA Act reporting. The bot is currently being used to update approximately 300 FPDS awards each week. Additionally, A/LM collaborated with WHA to create a bot that automates closeout reminders for federal assistance grants and is working on developing bots for receiving report validation and customer service inbox monitoring.",,,False,False
USDA-0013-2023,USDA,USDA,ERS,Westat,"A competition to find automated, yet effective, ways of linking USDA nutrition information to 750K food items in a proprietary data set of food purchases and acquisitions. Competing teams used a number of  AI methods including Natural Language Processing (NLP), random forest, and semantic matching.",Operation and Management,"Natural Language Processing,Machine Learning,Other",,Department of Agriculture,"Westat: 
A competition to find automated, yet effective, ways of linking USDA nutrition information to 750K food items in a proprietary data set of food purchases and acquisitions. Competing teams used a number of  AI methods including Natural Language Processing (NLP), random forest, and semantic matching.","Westat held a competition to discover automated methods for connecting USDA nutrition information to a large dataset of 750,000 food items. Teams competing in the challenge utilized various AI techniques like Natural Language Processing, random forest, and semantic matching.","Westat held a competition to discover automated methods for connecting USDA nutrition information to a large dataset of 750,000 food items. Teams competing in the challenge utilized various AI techniques like Natural Language Processing, random forest, and semantic matching.",,,False,False
NASA-0010-2023,NASA,Jet Propulsion Laboratory,,ASPEN Mission Planner,"Based on AI techniques, ASPEN is a modular, reconfigurable application framework which is capable of supporting a
wide variety of planning and scheduling applications. ASPEN provides a set of reusable software components that
implement the elements commonly found in complex planning/scheduling systems, including: an expressive
modeling language, a resource management system, a temporal reasoning system, and a graphical interface. ASPEN
has been used for many space missions including: Modified Antarctic Mapping Mission, Orbital Express, Earth
Observing One, and ESA's Rosetta Orbitter.",In mission,constraint-based heuristic Search,,National Aeronautics and Space Administration,"ASPEN Mission Planner: 
Based on AI techniques, ASPEN is a modular, reconfigurable application framework which is capable of supporting a
wide variety of planning and scheduling applications. ASPEN provides a set of reusable software components that
implement the elements commonly found in complex planning/scheduling systems, including: an expressive
modeling language, a resource management system, a temporal reasoning system, and a graphical interface. ASPEN
has been used for many space missions including: Modified Antarctic Mapping Mission, Orbital Express, Earth
Observing One, and ESA's Rosetta Orbitter.","ASPEN Mission Planner is an AI-based application framework that supports various planning and scheduling applications. It offers reusable software components such as modeling language, resource management, temporal reasoning, and graphical interface. ASPEN has been successfully utilized in several space missions, including the Modified Antarctic Mapping Mission, Orbital Express, Earth Observing One, and ESA's Rosetta Orbitter.","ASPEN Mission Planner is an AI-based application framework that supports various planning and scheduling applications. It offers reusable software components such as modeling language, resource management, temporal reasoning, and graphical interface. ASPEN has been successfully utilized in several space missions, including the Modified Antarctic Mapping Mission, Orbital Express, Earth Observing One, and ESA's Rosetta Orbitter.",,,False,False
DOE-0034-2023,DOE,National Energy Technology Laboratory,,Analysis to Assess Offshore CCS Trends and Gaps,"Providing expertise, input, and support for the development of a DOE 
(NETL/FECM) carbon storage technical resources catalog that 
facilitates searching for information about datasets, models and tools, 
publications and reports, and competencies resulting from DOE-
FECM/NETL’s offshore and CSP activities.  this project will complete a 
review and analysis of knowledge and data resources resulting from 
international offshore CCS projects. Outcomes of this analysis are 
expected to include the integration of key data and tools into the EDX-
hosted Open Carbon Storage Database and DisCO2ver platform (in 
development via the EDX4CCS FWP), as well as geo-data science 
based analysis and recommendations on geologic and metocean 
insights from international studies and their alignment or relevance to 
U.S. Federal offshore settings.",,Other,,Department of Energy,"Analysis to Assess Offshore CCS Trends and Gaps: 
Providing expertise, input, and support for the development of a DOE 
(NETL/FECM) carbon storage technical resources catalog that 
facilitates searching for information about datasets, models and tools, 
publications and reports, and competencies resulting from DOE-
FECM/NETL’s offshore and CSP activities.  this project will complete a 
review and analysis of knowledge and data resources resulting from 
international offshore CCS projects. Outcomes of this analysis are 
expected to include the integration of key data and tools into the EDX-
hosted Open Carbon Storage Database and DisCO2ver platform (in 
development via the EDX4CCS FWP), as well as geo-data science 
based analysis and recommendations on geologic and metocean 
insights from international studies and their alignment or relevance to 
U.S. Federal offshore settings.",This text describes an analysis project that aims to assess trends and gaps in offshore carbon capture and storage (CCS) activities. The project will involve reviewing and analyzing international offshore CCS projects to gather knowledge and data resources. The outcomes of the analysis will include integrating key data and tools into a carbon storage database and providing recommendations on the relevance of international studies to U.S. federal offshore settings.,This text describes an analysis project that aims to assess trends and gaps in offshore carbon capture and storage (CCS) activities. The project will involve reviewing and analyzing international offshore CCS projects to gather knowledge and data resources. The outcomes of the analysis will include integrating key data and tools into a carbon storage database and providing recommendations on the relevance of international studies to U.S. federal offshore settings.,,,False,False
DOS-0022-2023,DOS,R,,Optical Character Recognition – text extraction,Extract text from images using standard python libraries; inputs have been websites to collect data,,,,Department of State,"Optical Character Recognition – text extraction: 
Extract text from images using standard python libraries; inputs have been websites to collect data",The text explains that Optical Character Recognition (OCR) is a method to extract text from images. This can be achieved by utilizing standard python libraries. The input for this process is websites from which data is collected.,The text explains that Optical Character Recognition (OCR) is a method to extract text from images. This can be achieved by utilizing standard python libraries. The input for this process is websites from which data is collected.,,,False,False
NARA-0003-2023,NARA,Information Service,,Semantic Search for National Archives Catalog - an Artificial Intelligence (AI) / Machine Learning (ML) Pilot Program,"The National Archives and Records Administration (NARA) is responsible for preserving and
providing access to the records of the United States federal government. The NARA Catalog
contains millions of records and documents critical to researchers, historians, and the general
public and finding the correct records or documents can be a time-consuming and challenging task. 

Semantic search can solve this problem by allowing users to search the catalog using natural language queries. Semantic search is a data searching technique that not only finds the matching keywords based on user search terms but also understands the user’s intent and contextual meaning behind the search terms. Semantic search can also help to improve the accuracy and relevance of search results. By analyzing the meaning and context of search queries, semantic search can provide more accurate and relevant results than traditional keyword-based search methods. This can help researchers and historians to find the records and documents they need more quickly and easily.

Additionally, semantic search can help to identify the relationships between records and documents in the NARA catalog. This can help to provide a more comprehensive understanding of the historical events and processes represented in the records and can facilitate new insights and discoveries.",Planned (not in production),,,National Archives and Records Administration,"Semantic Search for National Archives Catalog - an Artificial Intelligence (AI) / Machine Learning (ML) Pilot Program: 
The National Archives and Records Administration (NARA) is responsible for preserving and
providing access to the records of the United States federal government. The NARA Catalog
contains millions of records and documents critical to researchers, historians, and the general
public and finding the correct records or documents can be a time-consuming and challenging task. 

Semantic search can solve this problem by allowing users to search the catalog using natural language queries. Semantic search is a data searching technique that not only finds the matching keywords based on user search terms but also understands the user’s intent and contextual meaning behind the search terms. Semantic search can also help to improve the accuracy and relevance of search results. By analyzing the meaning and context of search queries, semantic search can provide more accurate and relevant results than traditional keyword-based search methods. This can help researchers and historians to find the records and documents they need more quickly and easily.

Additionally, semantic search can help to identify the relationships between records and documents in the NARA catalog. This can help to provide a more comprehensive understanding of the historical events and processes represented in the records and can facilitate new insights and discoveries.","The National Archives and Records Administration (NARA) is using semantic search, an AI/ML pilot program, to make it easier and faster for researchers and historians to find records and documents in the NARA Catalog. Semantic search understands the user's intent and provides more accurate and relevant search results, while also identifying relationships between records and documents to facilitate new insights and discoveries.","The National Archives and Records Administration (NARA) is using semantic search, an AI/ML pilot program, to make it easier and faster for researchers and historians to find records and documents in the NARA Catalog. Semantic search understands the user's intent and provides more accurate and relevant search results, while also identifying relationships between records and documents to facilitate new insights and discoveries.",,,False,False
DOC-0024-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,First Guess Excessive Rainfall Outlook,"Machine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is 
learned from the ERO with atmospheric variables. It is for the Day 4-7 products",,,,Department of Commerce,"First Guess Excessive Rainfall Outlook: 
Machine Learning Product that is a first guess for the WPC Excessive Rainfall Outlook - It is 
learned from the ERO with atmospheric variables. It is for the Day 4-7 products","The First Guess Excessive Rainfall Outlook is a machine learning tool used by the WPC to predict excessive rainfall. It is based on data from the ERO and atmospheric variables, and is specifically designed for the Day 4-7 forecast period.","The First Guess Excessive Rainfall Outlook is a machine learning tool used by the WPC to predict excessive rainfall. It is based on data from the ERO and atmospheric variables, and is specifically designed for the Day 4-7 forecast period.",,,False,False
USDA-0031-2023,USDA,USDA,NRCS,Ecological Site Descriptions (machine learning),"Analysis of over 20 million records of soils data and 20,000 text documents of ecological state and transition information. ",Development and Acquisition,Machine Learning,,Department of Agriculture,"Ecological Site Descriptions (machine learning): 
Analysis of over 20 million records of soils data and 20,000 text documents of ecological state and transition information. ","The text describes the use of machine learning to analyze a large amount of data, including over 20 million records of soils data and 20,000 text documents on ecological state and transition information. This analysis aims to provide ecological site descriptions based on the collected information.","The text describes the use of machine learning to analyze a large amount of data, including over 20 million records of soils data and 20,000 text documents on ecological state and transition information. This analysis aims to provide ecological site descriptions based on the collected information.",,,False,False
HHS-0116-2023,HHS,NIH,National Institutes of Health (NIH) NIAID,Research Area Tracking Tool,A dashboard that incorporates machine learning to help identify projects within certain high-priority research areas.,Operation and Maintenance,,,Department of Health and Human Services,"Research Area Tracking Tool: 
A dashboard that incorporates machine learning to help identify projects within certain high-priority research areas.","The Research Area Tracking Tool is a dashboard that utilizes machine learning to easily identify projects in specific high-priority research areas. With its advanced technology, the tool effectively assists in tracking and monitoring these projects.","The Research Area Tracking Tool is a dashboard that utilizes machine learning to easily identify projects in specific high-priority research areas. With its advanced technology, the tool effectively assists in tracking and monitoring these projects.",,,False,False
DOE-0063-2023,DOE,National Energy Technology Laboratory,,Neural networks used to compensate a drone-mounted magnetic sensor for maneuvering of the drone.,"Electromagnetic technology development and optimization for cased 
wells. Scalable solutions—getting to 100,000 wells/year through drone 
technology and ML technology. NETL will develop ML algorithms to 
compensate magnetic data for the maneuvering of drone aircraft. 
Magnetic noise can limit sensitivity of detection and resolution of 
anomalies in the magnetic data. The ML algorithms will reduce attitude- 
and heading-induced noise in drone magnetic surveys.",,"Neural Networks, Other",,Department of Energy,"Neural networks used to compensate a drone-mounted magnetic sensor for maneuvering of the drone.: 
Electromagnetic technology development and optimization for cased 
wells. Scalable solutions—getting to 100,000 wells/year through drone 
technology and ML technology. NETL will develop ML algorithms to 
compensate magnetic data for the maneuvering of drone aircraft. 
Magnetic noise can limit sensitivity of detection and resolution of 
anomalies in the magnetic data. The ML algorithms will reduce attitude- 
and heading-induced noise in drone magnetic surveys.","The use of neural networks helps to counteract the impact of drone movement on a magnetic sensor attached to the drone. ML algorithms will be developed to compensate for magnetic noise caused by the drone's maneuvering, improving the sensitivity and resolution of magnetic data collected during surveys. This technology aims to optimize electromagnetic technology for cased wells and enable scalable solutions for high-volume drone surveys.","The use of neural networks helps to counteract the impact of drone movement on a magnetic sensor attached to the drone. ML algorithms will be developed to compensate for magnetic noise caused by the drone's maneuvering, improving the sensitivity and resolution of magnetic data collected during surveys. This technology aims to optimize electromagnetic technology for cased wells and enable scalable solutions for high-volume drone surveys.",,,False,False
TREAS-0011-2023,TREAS,,,Predictive equipment maintenance system,"Predictive maintenance to increase equipment uptime, improve safety, 
lower maintenance cost. Researching feasibility and tools.",Initiation,,,Department of Treasury,"Predictive equipment maintenance system: 
Predictive maintenance to increase equipment uptime, improve safety, 
lower maintenance cost. Researching feasibility and tools.","The text discusses the implementation of a predictive equipment maintenance system, with the goal of improving equipment uptime, safety, and reducing maintenance costs. The research is focused on determining the feasibility of such a system and identifying the necessary tools for its successful implementation.","The text discusses the implementation of a predictive equipment maintenance system, with the goal of improving equipment uptime, safety, and reducing maintenance costs. The research is focused on determining the feasibility of such a system and identifying the necessary tools for its successful implementation.",,,False,False
HHS-0123-2023,HHS,NIH,National Institutes of Health (NIH) NIGMS,Stem Cell Auto Coder,"The Stem Cell Auto Coder uses natural language processing and machine learning to predict the Stem Cell Research subcategories of an application: human embryonic, non-human embryonic, human induced pluripotent, non-human induced pluripotent, human non-embryonic, and non-human non-embryonic.",Implementation,,,Department of Health and Human Services,"Stem Cell Auto Coder: 
The Stem Cell Auto Coder uses natural language processing and machine learning to predict the Stem Cell Research subcategories of an application: human embryonic, non-human embryonic, human induced pluripotent, non-human induced pluripotent, human non-embryonic, and non-human non-embryonic.","The Stem Cell Auto Coder is a tool that uses advanced technology to determine the specific type of stem cell research an application is related to. It can accurately predict whether the research involves human or non-human embryonic cells, human or non-human induced pluripotent cells, or human or non-human non-embryonic cells.","The Stem Cell Auto Coder is a tool that uses advanced technology to determine the specific type of stem cell research an application is related to. It can accurately predict whether the research involves human or non-human embryonic cells, human or non-human induced pluripotent cells, or human or non-human non-embryonic cells.",,,False,False
USDA-0010-2023,USDA,USDA,ARS,ARS Project Mapping,NLP of research project plans including term analysis and clustering enables national program leaders to work with an interactive dashboard to find synergies and patterns within and across the various ARS research program portfolios.,Operation and Management,Natural Language Processing,,Department of Agriculture,"ARS Project Mapping: 
NLP of research project plans including term analysis and clustering enables national program leaders to work with an interactive dashboard to find synergies and patterns within and across the various ARS research program portfolios.",The ARS Project Mapping allows national program leaders to analyze and cluster research project plans using NLP. This helps them identify patterns and synergies in the ARS research program portfolios through an interactive dashboard.,The ARS Project Mapping allows national program leaders to analyze and cluster research project plans using NLP. This helps them identify patterns and synergies in the ARS research program portfolios through an interactive dashboard.,,,False,False
SSA-0013-2023,SSA,Office of Systems,,Mobile Wage Reporting (MOBWR),Mobile Wage Reporting uses AI to extract text/data from scanned images/documents represeting pay stubs or payroll information to enable faster processing.,,,,Social Security Administration,"Mobile Wage Reporting (MOBWR): 
Mobile Wage Reporting uses AI to extract text/data from scanned images/documents represeting pay stubs or payroll information to enable faster processing.",Mobile Wage Reporting (MOBWR) utilizes AI to quickly extract text and data from scanned images or documents such as pay stubs or payroll information. This technology allows for expedited processing of these documents.,Mobile Wage Reporting (MOBWR) utilizes AI to quickly extract text and data from scanned images or documents such as pay stubs or payroll information. This technology allows for expedited processing of these documents.,,,False,False
DOC-0000-2023,DOC,International Trade Administration (ITA),,B2B Matchmaking,"The system's algorithms and AI technology qualifies data and makes B2B matches with 
event participants according to their specific needs and available opportunities.  The 
systems inputs are data related to event participants and the outputs are suggested B2B 
matches between participants and a match strength scorecard.",,,,Department of Commerce,"B2B Matchmaking: 
The system's algorithms and AI technology qualifies data and makes B2B matches with 
event participants according to their specific needs and available opportunities.  The 
systems inputs are data related to event participants and the outputs are suggested B2B 
matches between participants and a match strength scorecard.",The B2B matchmaking system utilizes algorithms and AI technology to analyze data and create matches between event participants based on their individual requirements and available opportunities. The system takes in information about the participants and provides suggested B2B matches along with a scorecard indicating the strength of the match.,The B2B matchmaking system utilizes algorithms and AI technology to analyze data and create matches between event participants based on their individual requirements and available opportunities. The system takes in information about the participants and provides suggested B2B matches along with a scorecard indicating the strength of the match.,,,False,False
DOS-0009-2023,DOS,CSO,,Automated Burning Detection,The Village Monitoring System program uses AI and machine learning to conduct daily scans of moderate resolution commercial satellite imagery to identify anomalies using the near-infrared band.,,,,Department of State,"Automated Burning Detection: 
The Village Monitoring System program uses AI and machine learning to conduct daily scans of moderate resolution commercial satellite imagery to identify anomalies using the near-infrared band.","The Village Monitoring System program utilizes AI and machine learning to analyze commercial satellite imagery on a daily basis. Its purpose is to detect anomalies by examining the near-infrared band, enabling automated identification of burning incidents.","The Village Monitoring System program utilizes AI and machine learning to analyze commercial satellite imagery on a daily basis. Its purpose is to detect anomalies by examining the near-infrared band, enabling automated identification of burning incidents.",,,False,False
DOC-0009-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Developing automation to determine species and count using optical survey data in the Gulf of Mexico,"VIAME - This project focuses on optical survey collected in the Gulf of Mexico: 1) develop 
an image library of landed catch, 2) develop of automated image processing (ML/DL) to 
identify and enumerate species from underwater imagery and 3) develop automated 
algorithms to process imagery in near real time and download information to central 
database.",,,,Department of Commerce,"Developing automation to determine species and count using optical survey data in the Gulf of Mexico: 
VIAME - This project focuses on optical survey collected in the Gulf of Mexico: 1) develop 
an image library of landed catch, 2) develop of automated image processing (ML/DL) to 
identify and enumerate species from underwater imagery and 3) develop automated 
algorithms to process imagery in near real time and download information to central 
database.","The VIAME project aims to develop automation tools for analyzing optical survey data in the Gulf of Mexico. This includes building an image library of landed catch, developing machine learning and deep learning algorithms to identify and count species from underwater imagery, and creating automated processes to analyze imagery in near real time and store the information in a central database.","The VIAME project aims to develop automation tools for analyzing optical survey data in the Gulf of Mexico. This includes building an image library of landed catch, developing machine learning and deep learning algorithms to identify and count species from underwater imagery, and creating automated processes to analyze imagery in near real time and store the information in a central database.",,,False,False
USDA-0028-2023,USDA,USDA,NASS,Census of Agricuilture Response Propensity Scores,"The response propensity scores to the COA are derived from random forest models that use historical data, control data, and other survey data. These scores are used to help target more effective data collection.",Operation and Management,Machine Learning,,Department of Agriculture,"Census of Agricuilture Response Propensity Scores: 
The response propensity scores to the COA are derived from random forest models that use historical data, control data, and other survey data. These scores are used to help target more effective data collection.","Response propensity scores for the Census of Agriculture (COA) are calculated using random forest models that incorporate historical data, control data, and other survey data. These scores aid in optimizing data collection efforts by identifying areas or individuals with higher likelihoods of responding to the COA.","Response propensity scores for the Census of Agriculture (COA) are calculated using random forest models that incorporate historical data, control data, and other survey data. These scores aid in optimizing data collection efforts by identifying areas or individuals with higher likelihoods of responding to the COA.",,,False,False
GSA-0000-2023,GSA,FAS,,Acquisition Analytics,Takes Detailed Data on transactions and classifies each transaction within the Government-wide Category Management Taxonomy,Operation and Maintenance,Supervised Machine Learning - Classification,,U.S. General Services Administration,"Acquisition Analytics: 
Takes Detailed Data on transactions and classifies each transaction within the Government-wide Category Management Taxonomy",Acquisition Analytics utilizes comprehensive transaction data to categorize each transaction within the Government-wide Category Management Taxonomy.,Acquisition Analytics utilizes comprehensive transaction data to categorize each transaction within the Government-wide Category Management Taxonomy.,,,False,False
DOC-0003-2023,DOC,International Trade Administration (ITA),,AD/CVD Self Initiation,"The ADCVD program investigates allegations of dumping and/or countervailing of duties.  
Investigations are initiated when a harmed US entity files a petition identifying the alleged 
offence and the specific harm inflicted.  Self-Initiation will allow ITA to monitor trade 
patterns for this activity and preemptively initiate investigations by identifying harmed US 
entities, often before these entities are aware of the harm.",,,,Department of Commerce,"AD/CVD Self Initiation: 
The ADCVD program investigates allegations of dumping and/or countervailing of duties.  
Investigations are initiated when a harmed US entity files a petition identifying the alleged 
offence and the specific harm inflicted.  Self-Initiation will allow ITA to monitor trade 
patterns for this activity and preemptively initiate investigations by identifying harmed US 
entities, often before these entities are aware of the harm.",The AD/CVD program investigates dumping and countervailing duties based on complaints filed by US entities. Self-initiation allows the ITA to proactively monitor trade patterns and initiate investigations before the harmed entities are even aware of the harm.,The AD/CVD program investigates dumping and countervailing duties based on complaints filed by US entities. Self-initiation allows the ITA to proactively monitor trade patterns and initiate investigations before the harmed entities are even aware of the harm.,,,False,False
HHS-0101-2023,HHS,FDA,NCTR,Opioid agonists/antagonists knowledgebase (OAK) to assist review and development of analgesic products for pain management and opioid use disorder treatment,"The number of deaths caused by opioid overdose in the United States has been increasing dramatically for the last decade. misuse and abuse continue at alarmingly high rates. Opioid use disorder (OUD) often starts with use of prescription opioid analgesics. Therefore, the development of abuse-deterrent analgesic products may significantly impact the trajectory of the opioid crisis. In addition, FDA is making new efforts to support novel product innovation for pain management and the treatment of OUD to combat this opioid crisis. 
Opioid agonists bind and activate opioid receptors to decrease calcium influx and  cyclic adenosine monophosphate (cAMP), leading to hyperpolarization that inhibits pain transmission. Opioid antagonists bind and inhibit or block opioid receptors. Both opioid agonists and antagonists are used in drug products for pain management and treatment of opioid addiction. An opioid agonists/antagonists knowledgebase (OAK) would be useful for FDA reviewers to inform evaluation and to assist development of analgesics and of additional treatments for OUD.
To create a comprehensive OAK, we propose to curate the experimental data on opioid agonist/antagonist activity from the public domain, experimentally test some 2800 drugs in functional opioid receptor assays using quantitative high-throughput screen (qHTS) platform, and develop and validate in silico models to predict opioid agonist/antagonist activity. The created OAK knowledgebase could be used for retrieving experimental opioid agonist/antagonist activity data and the related experimental protocols. For chemicals without experimental data, read-across methods could be used to find similar chemicals in OAK to estimate the opioid agonist/antagonist activity, and the in silico models in OAK could be used to predict the opioid agonist/antagonist activity. The retrieved or predicted activity data can then be used to inform regulatory review or to assist in the development of analgesics.",Implementation,,,Department of Health and Human Services,"Opioid agonists/antagonists knowledgebase (OAK) to assist review and development of analgesic products for pain management and opioid use disorder treatment: 
The number of deaths caused by opioid overdose in the United States has been increasing dramatically for the last decade. misuse and abuse continue at alarmingly high rates. Opioid use disorder (OUD) often starts with use of prescription opioid analgesics. Therefore, the development of abuse-deterrent analgesic products may significantly impact the trajectory of the opioid crisis. In addition, FDA is making new efforts to support novel product innovation for pain management and the treatment of OUD to combat this opioid crisis. 
Opioid agonists bind and activate opioid receptors to decrease calcium influx and  cyclic adenosine monophosphate (cAMP), leading to hyperpolarization that inhibits pain transmission. Opioid antagonists bind and inhibit or block opioid receptors. Both opioid agonists and antagonists are used in drug products for pain management and treatment of opioid addiction. An opioid agonists/antagonists knowledgebase (OAK) would be useful for FDA reviewers to inform evaluation and to assist development of analgesics and of additional treatments for OUD.
To create a comprehensive OAK, we propose to curate the experimental data on opioid agonist/antagonist activity from the public domain, experimentally test some 2800 drugs in functional opioid receptor assays using quantitative high-throughput screen (qHTS) platform, and develop and validate in silico models to predict opioid agonist/antagonist activity. The created OAK knowledgebase could be used for retrieving experimental opioid agonist/antagonist activity data and the related experimental protocols. For chemicals without experimental data, read-across methods could be used to find similar chemicals in OAK to estimate the opioid agonist/antagonist activity, and the in silico models in OAK could be used to predict the opioid agonist/antagonist activity. The retrieved or predicted activity data can then be used to inform regulatory review or to assist in the development of analgesics.","The Opioid agonists/antagonists knowledgebase (OAK) is being developed to assist in the review and development of analgesic products for pain management and opioid use disorder treatment. The knowledgebase will curate experimental data on opioid agonist/antagonist activity, test drugs using a quantitative high-throughput screen, and develop predictive models. This knowledgebase will help inform regulatory review and support the development of abuse-deterrent analgesic products to combat the opioid crisis.","The Opioid agonists/antagonists knowledgebase (OAK) is being developed to assist in the review and development of analgesic products for pain management and opioid use disorder treatment. The knowledgebase will curate experimental data on opioid agonist/antagonist activity, test drugs using a quantitative high-throughput screen, and develop predictive models. This knowledgebase will help inform regulatory review and support the development of abuse-deterrent analgesic products to combat the opioid crisis.",,,False,False
DOC-0004-2023,DOC,International Trade Administration (ITA),,Market Diversification Toolkit,"The Market Diversification Tool identifies potential new export markets using current 
trade patterns. A user enters what products they make and the markets they currently 
export to.  The Market Diversification Tool applies a ML algorithm to identify and compare 
markets that should be considered.  The tool brings together product-specific trade and 
tariff data and economy-level macroeconomic and governance data to provide a picture 
of which markets make sense for further market research. Users can limit the markets in 
the results to only the ones they want to consider and modify how each of the eleven 
indicators in the tool contributes to a country’s overall score. Users can export all the data 
to a spreadsheet for further analysis.",,,,Department of Commerce,"Market Diversification Toolkit: 
The Market Diversification Tool identifies potential new export markets using current 
trade patterns. A user enters what products they make and the markets they currently 
export to.  The Market Diversification Tool applies a ML algorithm to identify and compare 
markets that should be considered.  The tool brings together product-specific trade and 
tariff data and economy-level macroeconomic and governance data to provide a picture 
of which markets make sense for further market research. Users can limit the markets in 
the results to only the ones they want to consider and modify how each of the eleven 
indicators in the tool contributes to a country’s overall score. Users can export all the data 
to a spreadsheet for further analysis.","The Market Diversification Toolkit is a tool that helps users identify potential new export markets based on their current trade patterns. By entering the products they make and the markets they currently export to, the tool utilizes a ML algorithm to compare and identify markets that should be considered. The tool provides a comprehensive analysis by combining product-specific trade and tariff data with macroeconomic and governance data, allowing users to narrow down the results and modify the indicators to fit their needs. Additionally, users have the option to export all the data to a spreadsheet for further analysis.","The Market Diversification Toolkit is a tool that helps users identify potential new export markets based on their current trade patterns. By entering the products they make and the markets they currently export to, the tool utilizes a ML algorithm to compare and identify markets that should be considered. The tool provides a comprehensive analysis by combining product-specific trade and tariff data with macroeconomic and governance data, allowing users to narrow down the results and modify the indicators to fit their needs. Additionally, users have the option to export all the data to a spreadsheet for further analysis.",,,False,False
DOC-0008-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,AI-based automation of acoustic detection of marine mammals,"Timely processing of these data is critical for adapting mitigation measures as climate 
change continues to impact Arctic marine mammals.  Infrastructure for Noise and 
Soundscape Tolerant Investigation of Nonspecific Call Types (INSTINCT) is command line 
software which was developed in-house for model training, evaluation, and deployment 
of machine learning models for the purpose of marine mammal detection in passive 
acoustic data. It also includes annotation workflows for labeling and validation. INSTINCT 
has been successfully deployed in several analyses, and further development of detectors 
within INSTINCT is desired for future novel studies and automation. Continued integration 
of AI methods into existing processes of the CAEP acoustics group requires a skilled 
operator familiar with INSTINCT, machine learning, and acoustic repertoire of Alaska 
region marine mammals.",,,,Department of Commerce,"AI-based automation of acoustic detection of marine mammals: 
Timely processing of these data is critical for adapting mitigation measures as climate 
change continues to impact Arctic marine mammals.  Infrastructure for Noise and 
Soundscape Tolerant Investigation of Nonspecific Call Types (INSTINCT) is command line 
software which was developed in-house for model training, evaluation, and deployment 
of machine learning models for the purpose of marine mammal detection in passive 
acoustic data. It also includes annotation workflows for labeling and validation. INSTINCT 
has been successfully deployed in several analyses, and further development of detectors 
within INSTINCT is desired for future novel studies and automation. Continued integration 
of AI methods into existing processes of the CAEP acoustics group requires a skilled 
operator familiar with INSTINCT, machine learning, and acoustic repertoire of Alaska 
region marine mammals.","The software INSTINCT was developed to automate the detection of marine mammals in passive acoustic data. Its purpose is to quickly process data and adapt mitigation measures to climate change impacts on Arctic marine mammals. Skilled operators familiar with INSTINCT, machine learning, and the acoustic repertoire of Alaska region marine mammals are needed for continued integration of AI methods into existing processes.","The software INSTINCT was developed to automate the detection of marine mammals in passive acoustic data. Its purpose is to quickly process data and adapt mitigation measures to climate change impacts on Arctic marine mammals. Skilled operators familiar with INSTINCT, machine learning, and the acoustic repertoire of Alaska region marine mammals are needed for continued integration of AI methods into existing processes.",,,False,False
HHS-0114-2023,HHS,NIH,National Institutes of Health (NIH) NIAID,Scientific Research Data Management System Natural Language Processing Conflict of Interest Tool,"A tool that identifies entities within a grant application to allow NIAID's Scientific Review Program team to more easily identify conflicts of interest (COI) between grant reviewers and applicants using NLP methods (e.g., OCR, text extraction).",Operation and Maintenance,,,Department of Health and Human Services,"Scientific Research Data Management System Natural Language Processing Conflict of Interest Tool: 
A tool that identifies entities within a grant application to allow NIAID's Scientific Review Program team to more easily identify conflicts of interest (COI) between grant reviewers and applicants using NLP methods (e.g., OCR, text extraction).","The Scientific Research Data Management System Natural Language Processing Conflict of Interest Tool is designed to help the NIAID's Scientific Review Program team in identifying conflicts of interest between grant reviewers and applicants. This tool uses NLP techniques such as OCR and text extraction to identify entities within grant applications, making the identification process more efficient.","The Scientific Research Data Management System Natural Language Processing Conflict of Interest Tool is designed to help the NIAID's Scientific Review Program team in identifying conflicts of interest between grant reviewers and applicants. This tool uses NLP techniques such as OCR and text extraction to identify entities within grant applications, making the identification process more efficient.",,,False,False
DOE-0036-2023,DOE,National Energy Technology Laboratory,,Computational capabilities to support experimental efforts,"This subtask will leverage NETL’s in-house computational capabilities 
and existing university collaborators to support experimental efforts by 
providing atomic-level DFT and microkinetic modeling calculations for 
catalyst systems. This work provides atomic-level details on reaction 
energetics and establishes key structure-property relationships used to 
optimize catalyst structure and formulation.",,,,Department of Energy,"Computational capabilities to support experimental efforts: 
This subtask will leverage NETL’s in-house computational capabilities 
and existing university collaborators to support experimental efforts by 
providing atomic-level DFT and microkinetic modeling calculations for 
catalyst systems. This work provides atomic-level details on reaction 
energetics and establishes key structure-property relationships used to 
optimize catalyst structure and formulation.","This subtask aims to use NETL's computational capabilities and university collaborators to assist experimental efforts by conducting atomic-level calculations and microkinetic modeling for catalyst systems. These calculations provide detailed information on reaction energetics and establish important relationships between catalyst structure and properties, ultimately helping to optimize catalyst structure and formulation.","This subtask aims to use NETL's computational capabilities and university collaborators to assist experimental efforts by conducting atomic-level calculations and microkinetic modeling for catalyst systems. These calculations provide detailed information on reaction energetics and establish important relationships between catalyst structure and properties, ultimately helping to optimize catalyst structure and formulation.",,,False,False
NASA-0008-2023,NASA,Goddard Space Flight Center,,Europa Ice Floe Detection (GSFC Planetary Sciences Lab),"Machine Learning applied to Galileo space probe imagery to detect and classify ice blocks in the chaos regions of
Jupiter's moon Europa. GANs were also used to generate simulated training data.",In-use,"Mask R-CNN, GANs",https://gitlab.grc.nasa.gov/kgansler/europa-ice-floe-detection,National Aeronautics and Space Administration,"Europa Ice Floe Detection (GSFC Planetary Sciences Lab): 
Machine Learning applied to Galileo space probe imagery to detect and classify ice blocks in the chaos regions of
Jupiter's moon Europa. GANs were also used to generate simulated training data.","The Planetary Sciences Lab at GSFC used Machine Learning techniques to identify and categorize ice blocks in the chaotic areas of Jupiter's moon Europa using imagery from the Galileo space probe. Additionally, they employed GANs to create simulated training data for their analysis.","The Planetary Sciences Lab at GSFC used Machine Learning techniques to identify and categorize ice blocks in the chaotic areas of Jupiter's moon Europa using imagery from the Galileo space probe. Additionally, they employed GANs to create simulated training data for their analysis.",,,False,False
NASA-0027-2023,NASA,Marshall Space Flight Center,,GCMD Keyword Recommender (GKR),Natural Language Processing-based science keyword suggestion tool,In-use,Natural Language Processing,,National Aeronautics and Space Administration,"GCMD Keyword Recommender (GKR): 
Natural Language Processing-based science keyword suggestion tool",The GCMD Keyword Recommender (GKR) is a tool that utilizes Natural Language Processing to suggest science keywords. It helps researchers and scientists find relevant keywords for their work more efficiently.,The GCMD Keyword Recommender (GKR) is a tool that utilizes Natural Language Processing to suggest science keywords. It helps researchers and scientists find relevant keywords for their work more efficiently.,,,False,False
TREAS-0004-2023,TREAS,,,Collection Voice Bot,"The Nuance Natural Language Understanding (NLU) model will be located 
inside the Automated Collections IVR (ACI) main menu. This NLU will take 
customer speech input aka – Utterances.  It will map the utterance to a 
specific intent and direct the taxpayer down to a certain call path.",In production: less than six months,,,Department of Treasury,"Collection Voice Bot: 
The Nuance Natural Language Understanding (NLU) model will be located 
inside the Automated Collections IVR (ACI) main menu. This NLU will take 
customer speech input aka – Utterances.  It will map the utterance to a 
specific intent and direct the taxpayer down to a certain call path.","The Nuance Natural Language Understanding (NLU) model will be integrated into the Automated Collections IVR (ACI) main menu. This model will analyze customer speech input and determine the intent, guiding them through the appropriate call path.","The Nuance Natural Language Understanding (NLU) model will be integrated into the Automated Collections IVR (ACI) main menu. This model will analyze customer speech input and determine the intent, guiding them through the appropriate call path.",,,False,False
OPM-0003-2023,OPM,RS/RO,,Retirement Services (RS) Chat Bot,"A chatbot is a computer program that uses artificial intelligence (AI) and natural language processing to understand customer questions and automate responses to them, simulating human conversation.  Retirement Services uses the chatbot to answer user questions related to Survivor Benefits. The bot initially started with a set of 13 questions and continues to grow based on reviews of user interaction.",Operation and Maintenance,Natural Language Processing,,U.S. Office of Personnel Management,"Retirement Services (RS) Chat Bot: 
A chatbot is a computer program that uses artificial intelligence (AI) and natural language processing to understand customer questions and automate responses to them, simulating human conversation.  Retirement Services uses the chatbot to answer user questions related to Survivor Benefits. The bot initially started with a set of 13 questions and continues to grow based on reviews of user interaction.",The Retirement Services (RS) Chat Bot is a computer program that uses AI and natural language processing to understand and respond to customer questions about Survivor Benefits. It began with 13 questions but has been expanding based on user feedback.,The Retirement Services (RS) Chat Bot is a computer program that uses AI and natural language processing to understand and respond to customer questions about Survivor Benefits. It began with 13 questions but has been expanding based on user feedback.,,,False,False
DOS-0004-2023,DOS,A,,Tailored Integration Logistics Management System (ILMS) Automated User Support Bot,ILMS developed and deployed an automated support desk assistant using ServiceNow Virtual Agent to simplify support desk interactions for ILMS customers and to deflect easily resolved issues from higher cost support desk agents.,,,,Department of State,"Tailored Integration Logistics Management System (ILMS) Automated User Support Bot: 
ILMS developed and deployed an automated support desk assistant using ServiceNow Virtual Agent to simplify support desk interactions for ILMS customers and to deflect easily resolved issues from higher cost support desk agents.",ILMS has created an automated support bot to assist customers with their support desk inquiries. The bot aims to streamline interactions and reduce the workload of costly support desk agents by resolving simple issues.,ILMS has created an automated support bot to assist customers with their support desk inquiries. The bot aims to streamline interactions and reduce the workload of costly support desk agents by resolving simple issues.,,,False,False
USDA-0020-2023,USDA,USDA,Forest Service,CLT Knowledge Database,"The CLT knowledge database catalogs cross-laminated timber information in an interface that helps users find relevant information. The information system uses data aggregator bots that search the internet for relevant information. These bots search for hundreds of keywords and use machine learning to determine if what is found is relevant. The search engine uses intelligent software to locate and update pertinent CLT references, as well as categorize information with respect to common application and interest areas. As of 2/24/2022, the CLT knowledge database has cataloged >3,600 publications on various aspects of CLT. This system fosters growth of mass timber markets by disseminating knowledge and facilitating collaboration among stakeholders, and by reducing the risk of duplication of efforts. Manufacturers, researchers, design professionals, code officials, government agencies, and other stakeholders directly benefit from the tool, thereby supporting the increasing use of mass timber, which benefits forest health by increasing the economic value of forests.",Operation and Management,Machine Learning,,Department of Agriculture,"CLT Knowledge Database: 
The CLT knowledge database catalogs cross-laminated timber information in an interface that helps users find relevant information. The information system uses data aggregator bots that search the internet for relevant information. These bots search for hundreds of keywords and use machine learning to determine if what is found is relevant. The search engine uses intelligent software to locate and update pertinent CLT references, as well as categorize information with respect to common application and interest areas. As of 2/24/2022, the CLT knowledge database has cataloged >3,600 publications on various aspects of CLT. This system fosters growth of mass timber markets by disseminating knowledge and facilitating collaboration among stakeholders, and by reducing the risk of duplication of efforts. Manufacturers, researchers, design professionals, code officials, government agencies, and other stakeholders directly benefit from the tool, thereby supporting the increasing use of mass timber, which benefits forest health by increasing the economic value of forests.","The CLT knowledge database is an information system that uses data aggregator bots and intelligent software to collect and update cross-laminated timber (CLT) information. It has cataloged over 3,600 publications and helps stakeholders in the mass timber industry by disseminating knowledge, facilitating collaboration, and reducing duplication of efforts. This tool supports the use of mass timber, which benefits forest health by increasing the economic value of forests.","The CLT knowledge database is an information system that uses data aggregator bots and intelligent software to collect and update cross-laminated timber (CLT) information. It has cataloged over 3,600 publications and helps stakeholders in the mass timber industry by disseminating knowledge, facilitating collaboration, and reducing duplication of efforts. This tool supports the use of mass timber, which benefits forest health by increasing the economic value of forests.",,,False,False
VA-0021-2023,VA,,,Using machine learning to predict perfusionists’ critical decision-making during cardiac surgery,"A machine learning approach is used to build predictive models of perfusionists’ decision-making during critical situations that occur in the cardiopulmonary bypass phase of cardiac surgery. Results may inform future development of computerized clinical decision support tools to be embedded into the operating room, improving patient safety and surgical outcomes.",,,,Department of Veterans Affairs,"Using machine learning to predict perfusionists’ critical decision-making during cardiac surgery: 
A machine learning approach is used to build predictive models of perfusionists’ decision-making during critical situations that occur in the cardiopulmonary bypass phase of cardiac surgery. Results may inform future development of computerized clinical decision support tools to be embedded into the operating room, improving patient safety and surgical outcomes.",Machine learning is utilized to create predictive models of perfusionists' decision-making during critical cardiac surgery situations. The findings have the potential to enhance patient safety and surgical outcomes by guiding the development of computerized clinical decision support tools for use in the operating room.,Machine learning is utilized to create predictive models of perfusionists' decision-making during critical cardiac surgery situations. The findings have the potential to enhance patient safety and surgical outcomes by guiding the development of computerized clinical decision support tools for use in the operating room.,,,False,False
DOE-0139-2023,DOE,National Energy Technology Laboratory,,To use ML to help identify promising oxygen carrier materials.,"A combination of experimental data and computational results  will be 
used both to understand O2 production and to develop a machine 
learning model that can be used to identify promising carrier 
compositions. These compositions will be evaluated on two primary 
criteria, performance and ability to be synthesized. Once the model has 
identified promising candidates, these materials will be synthesized and 
compared to existing carriers. This new data will then be used to refine 
the models.",,Other,,Department of Energy,"To use ML to help identify promising oxygen carrier materials.: 
A combination of experimental data and computational results  will be 
used both to understand O2 production and to develop a machine 
learning model that can be used to identify promising carrier 
compositions. These compositions will be evaluated on two primary 
criteria, performance and ability to be synthesized. Once the model has 
identified promising candidates, these materials will be synthesized and 
compared to existing carriers. This new data will then be used to refine 
the models.","The text explains that a machine learning model will be developed using a combination of experimental data and computational results to identify promising oxygen carrier materials. The model will evaluate the compositions based on performance and synthesizability, and the materials identified will be synthesized and compared to existing carriers to refine the model.","The text explains that a machine learning model will be developed using a combination of experimental data and computational results to identify promising oxygen carrier materials. The model will evaluate the compositions based on performance and synthesizability, and the materials identified will be synthesized and compared to existing carriers to refine the model.",,,False,False
HHS-0066-2023,HHS,FDA,CBER/OBPV/DABRA,"BEST Platform improves post-market surveillance efforts through the semi-automated detection, validation and reporting of adverse events.","The BEST Platform employs a suite of applications and techniques to improve the detection, validation and reporting of  biologics-related adverse events from electronic health records (EHRs). The Platform utilizes ML and NLP to detect potential adverse events, and extract the important features for clinicians to validate.  ",Implementation,,,Department of Health and Human Services,"BEST Platform improves post-market surveillance efforts through the semi-automated detection, validation and reporting of adverse events.: 
The BEST Platform employs a suite of applications and techniques to improve the detection, validation and reporting of  biologics-related adverse events from electronic health records (EHRs). The Platform utilizes ML and NLP to detect potential adverse events, and extract the important features for clinicians to validate.  ","The BEST Platform is a system that enhances post-market surveillance by automating the identification, confirmation, and documentation of adverse events. It utilizes advanced technologies such as machine learning and natural language processing to detect possible adverse events from electronic health records and extract relevant information for clinicians to verify.","The BEST Platform is a system that enhances post-market surveillance by automating the identification, confirmation, and documentation of adverse events. It utilizes advanced technologies such as machine learning and natural language processing to detect possible adverse events from electronic health records and extract relevant information for clinicians to verify.",,,False,False
DOE-0050-2023,DOE,National Energy Technology Laboratory,,Fluid migration from well-to-well communication will be inputted in AI to determine a costs-benefit analysis,"This project will develop an ML algorithm to predict the time when a 
growing fracture will reach the monitored well. The ML workflow will be 
trained on the distinctive tensile strain signature that precedes the 
growing fracture. The new workflow will be designed to work in 
conjunction with the fracture warning ML workflow developed in EY21. 
Together, these workflows will: (1) provide an early warning of well-to-
well communication, (2) predict the measured depths where the 
communication will happen, and (3) provide an estimated time until the 
beginning of well-to-well communication.",,"Artificial Intelligence, Big Data, Other",,Department of Energy,"Fluid migration from well-to-well communication will be inputted in AI to determine a costs-benefit analysis: 
This project will develop an ML algorithm to predict the time when a 
growing fracture will reach the monitored well. The ML workflow will be 
trained on the distinctive tensile strain signature that precedes the 
growing fracture. The new workflow will be designed to work in 
conjunction with the fracture warning ML workflow developed in EY21. 
Together, these workflows will: (1) provide an early warning of well-to-
well communication, (2) predict the measured depths where the 
communication will happen, and (3) provide an estimated time until the 
beginning of well-to-well communication.","An AI system will be used to analyze fluid migration between wells and determine the costs and benefits. The project aims to develop a machine learning algorithm that can predict when a growing fracture will reach a monitored well, based on the distinctive tensile strain signature that precedes it. This algorithm will work alongside an existing fracture warning system to provide early detection of well-to-well communication, predict the depths at which it will occur, and estimate the time until it begins.","An AI system will be used to analyze fluid migration between wells and determine the costs and benefits. The project aims to develop a machine learning algorithm that can predict when a growing fracture will reach a monitored well, based on the distinctive tensile strain signature that precedes it. This algorithm will work alongside an existing fracture warning system to provide early detection of well-to-well communication, predict the depths at which it will occur, and estimate the time until it begins.",,,False,False
USDA-0015-2023,USDA,USDA,FNS,Nutrition Education & Local Access Dashboard,"The goal of the this Dashboard is to provide a county-level visualization of FNS nutrition support, specifically nutrition education and local food access, alongside other metrics related to hunger and nutritional health. As part of this dashboard, the team developed a K-means clustering script to group States by 7 different clustering options:  Farm to School Intensity & Size, Program Activity Intensity, Ethnicity & Race, Fresh Food Access, School Size, and Program Participation. This allows users to find like-minded, or similar, States based on any of these characteristics, opening up avenues for partnerships with States that they otherwise may not have considered.",Operation and Management,"Machine Learning,K-Means Clustering,Visual Analysis",,Department of Agriculture,"Nutrition Education & Local Access Dashboard: 
The goal of the this Dashboard is to provide a county-level visualization of FNS nutrition support, specifically nutrition education and local food access, alongside other metrics related to hunger and nutritional health. As part of this dashboard, the team developed a K-means clustering script to group States by 7 different clustering options:  Farm to School Intensity & Size, Program Activity Intensity, Ethnicity & Race, Fresh Food Access, School Size, and Program Participation. This allows users to find like-minded, or similar, States based on any of these characteristics, opening up avenues for partnerships with States that they otherwise may not have considered.","The Nutrition Education & Local Access Dashboard aims to visually present data on FNS nutrition support at the county level, including nutrition education and local food access, as well as other metrics related to hunger and nutritional health. The dashboard includes a K-means clustering script that groups states into seven different clustering options, such as Farm to School Intensity & Size and Fresh Food Access, allowing users to identify states with similar characteristics for potential partnerships that they may not have previously considered.","The Nutrition Education & Local Access Dashboard aims to visually present data on FNS nutrition support at the county level, including nutrition education and local food access, as well as other metrics related to hunger and nutritional health. The dashboard includes a K-means clustering script that groups states into seven different clustering options, such as Farm to School Intensity & Size and Fresh Food Access, allowing users to identify states with similar characteristics for potential partnerships that they may not have previously considered.",,,False,False
DOI-0005-2023,DOI,BOR,,PyForecast,Pyforecast is a statistical/ML water supply forecasting software developed by Reclamation that uses a range of data-driven methods.  ,Implementation,Regression and related methods,https://github.com/usbr/PyForecast,Department of Interior,"PyForecast: 
Pyforecast is a statistical/ML water supply forecasting software developed by Reclamation that uses a range of data-driven methods.  ",PyForecast is a software designed by Reclamation for water supply forecasting. It utilizes various data-driven methods from statistics and machine learning to achieve accurate predictions.,PyForecast is a software designed by Reclamation for water supply forecasting. It utilizes various data-driven methods from statistics and machine learning to achieve accurate predictions.,,,False,False
DOE-0006-2023,DOE,Fermi National Accelerator,,hls4ml,"This project develops hardware-software AI codesign tools for FPGAs 
and ASICs for algorithms running at the extreme edge.",,"Artificial Intelligence, Big Data, Neural Networks",,Department of Energy,"hls4ml: 
This project develops hardware-software AI codesign tools for FPGAs 
and ASICs for algorithms running at the extreme edge.",The hls4ml project is focused on creating tools for hardware-software AI codesign on FPGAs and ASICs. These tools are designed specifically for algorithms that operate at the extreme edge.,The hls4ml project is focused on creating tools for hardware-software AI codesign on FPGAs and ASICs. These tools are designed specifically for algorithms that operate at the extreme edge.,,,False,False
DOE-0019-2023,DOE,Lawrence Livermore National Laboratory,,"Advanced energy, batteries, and industrial efficiency","Leveraging data science to navigate design space for better batteries 
and energy storage as well as scale up of various technologies",,,,Department of Energy,"Advanced energy, batteries, and industrial efficiency: 
Leveraging data science to navigate design space for better batteries 
and energy storage as well as scale up of various technologies","Data science is being used to improve battery design and energy storage, as well as to scale up various technologies in advanced energy and industrial efficiency. This involves analyzing data to navigate the design space and make advancements in battery technology and energy storage.","Data science is being used to improve battery design and energy storage, as well as to scale up various technologies in advanced energy and industrial efficiency. This involves analyzing data to navigate the design space and make advancements in battery technology and energy storage.",,,False,False
DOE-0148-2023,DOE,National Energy Technology Laboratory,,"Using AI to improve predcitions of subsurface properties, analyze multi- variate inputs, address knowledge and information gaps to improve predictions and modeli","Use of AI methods such as fuzzy logic, neural networks, tensor flow, 
and natural language processing to assist with knowledge and data 
exploration, transformation and integration, as well as modeling and 
analysis of multi-variate data used in the resource assessment method 
to improve outputs and predictions.",,"Artificial Intelligence, Big Data, Other",,Department of Energy,"Using AI to improve predcitions of subsurface properties, analyze multi- variate inputs, address knowledge and information gaps to improve predictions and modeli: 
Use of AI methods such as fuzzy logic, neural networks, tensor flow, 
and natural language processing to assist with knowledge and data 
exploration, transformation and integration, as well as modeling and 
analysis of multi-variate data used in the resource assessment method 
to improve outputs and predictions.","AI methods, like fuzzy logic, neural networks, tensor flow, and natural language processing, can be used to enhance predictions of subsurface properties. These methods can analyze multiple inputs, fill in knowledge gaps, and improve modeling and analysis of multi-variate data, ultimately leading to improved predictions and outputs in resource assessment.","AI methods, like fuzzy logic, neural networks, tensor flow, and natural language processing, can be used to enhance predictions of subsurface properties. These methods can analyze multiple inputs, fill in knowledge gaps, and improve modeling and analysis of multi-variate data, ultimately leading to improved predictions and outputs in resource assessment.",,,False,False
DOI-0025-2023,DOI,USGS,,WRA.NWC.EF Economic Valuation of Ecosystem Services in the Delaware River Basin,"The objectives of this project are to:  _x000D_
_x000D_
Create a data and model inventory plan to evaluate existing data and models. _x000D_
_x000D_
Develop a database for the existing fish data. _x000D_
_x000D_
Develop Artificial Intelligence/Machine Learning (AI/ML) models to predict fish abundances and size under alternate future climates and reservoir operations. _x000D_
_x000D_
Develop models for economic valuation of the fishery resource. _x000D_
_x000D_
Evaluate the validity of estimated economic models against alternative approaches. _x000D_
_x000D_
Link models together to allow evaluation of tradeoffs between water use and the fisheries resource. _x000D_
_x000D_
Provide a prototype web application with re-usable components for internal USGS use that promotes understanding of the models and allows assessment of resource tradeoffs. _x000D_
_x000D_
 ",Initiation,"Random forest regression, random forest classification",,Department of Interior,"WRA.NWC.EF Economic Valuation of Ecosystem Services in the Delaware River Basin: 
The objectives of this project are to:  _x000D_
_x000D_
Create a data and model inventory plan to evaluate existing data and models. _x000D_
_x000D_
Develop a database for the existing fish data. _x000D_
_x000D_
Develop Artificial Intelligence/Machine Learning (AI/ML) models to predict fish abundances and size under alternate future climates and reservoir operations. _x000D_
_x000D_
Develop models for economic valuation of the fishery resource. _x000D_
_x000D_
Evaluate the validity of estimated economic models against alternative approaches. _x000D_
_x000D_
Link models together to allow evaluation of tradeoffs between water use and the fisheries resource. _x000D_
_x000D_
Provide a prototype web application with re-usable components for internal USGS use that promotes understanding of the models and allows assessment of resource tradeoffs. _x000D_
_x000D_
 ","This project aims to evaluate the economic value of ecosystem services in the Delaware River Basin. It involves creating a plan to assess existing data and models, developing a database for fish data, using AI/ML models to predict fish abundances and size under different conditions, and creating economic valuation models for the fishery resource. The project also includes evaluating the validity of the economic models, linking the models to assess tradeoffs between water use and the fisheries resource, and creating a web application for internal use that promotes understanding of the models and allows for assessment of resource tradeoffs.","This project aims to evaluate the economic value of ecosystem services in the Delaware River Basin. It involves creating a plan to assess existing data and models, developing a database for fish data, using AI/ML models to predict fish abundances and size under different conditions, and creating economic valuation models for the fishery resource. The project also includes evaluating the validity of the economic models, linking the models to assess tradeoffs between water use and the fisheries resource, and creating a web application for internal use that promotes understanding of the models and allows for assessment of resource tradeoffs.",,,False,False
ED-0000-2023,ED,Federal Student Aid,,Aidan Chat-bot,"FSA's virtual assistant uses natural language processing to answer common financial aid questions and help customers get information about their federal aid on StudentAid.gov.
In just over two years, Aidan has interacted with over 2.6 million unique customers, resulting in more than 11 million user messages.",,,,Department of Education,"Aidan Chat-bot: 
FSA's virtual assistant uses natural language processing to answer common financial aid questions and help customers get information about their federal aid on StudentAid.gov.
In just over two years, Aidan has interacted with over 2.6 million unique customers, resulting in more than 11 million user messages.","Aidan Chat-bot is a virtual assistant developed by FSA that utilizes natural language processing to provide answers to financial aid queries and assist users in accessing federal aid information on StudentAid.gov. Since its launch, Aidan has engaged with over 2.6 million individuals, generating more than 11 million user messages.","Aidan Chat-bot is a virtual assistant developed by FSA that utilizes natural language processing to provide answers to financial aid queries and assist users in accessing federal aid information on StudentAid.gov. Since its launch, Aidan has engaged with over 2.6 million individuals, generating more than 11 million user messages.",,,False,False
DOS-0008-2023,DOS,CGFS,,Automatic Detection of Authentic Material,The Foreign Service Institute School of Language Studies is developing a tool for automated discovery of authentic native language texts classified for both topic and Interagency Language Roundtable (ILR) proficiency level to support foreign language curriculum and language testing kit development.,,,,Department of State,"Automatic Detection of Authentic Material: 
The Foreign Service Institute School of Language Studies is developing a tool for automated discovery of authentic native language texts classified for both topic and Interagency Language Roundtable (ILR) proficiency level to support foreign language curriculum and language testing kit development.","The Foreign Service Institute School of Language Studies is creating a tool that can automatically find authentic texts in native languages. These texts will be classified based on their topic and proficiency level, helping with the development of foreign language curriculum and language testing kits.","The Foreign Service Institute School of Language Studies is creating a tool that can automatically find authentic texts in native languages. These texts will be classified based on their topic and proficiency level, helping with the development of foreign language curriculum and language testing kits.",,,False,False
DOS-0020-2023,DOS,PM,,NLP to pull key information from unstructured text,Use NLP to extract information such as country names and agreement dates from dozens of pages of unstructured pdf document,,,,Department of State,"NLP to pull key information from unstructured text: 
Use NLP to extract information such as country names and agreement dates from dozens of pages of unstructured pdf document",NLP can be utilized to extract important details like country names and agreement dates from lengthy unstructured pdf documents. This allows for efficient retrieval of key information from large volumes of text.,NLP can be utilized to extract important details like country names and agreement dates from lengthy unstructured pdf documents. This allows for efficient retrieval of key information from large volumes of text.,,,False,False
USAID-0003-2023,USAID,"Bureau for Development, Democracy, and Innovation (DDI)",,Long-term impacts of land-use/land-cover dynamics on surface water quality in Botswana’s reservoirs using satellite data and artificial intelligence methods: Case study of the Botswana’s Limpopo River Basin (1984-2019),"For water supply, semi-arid Botswana relies on the reservoirs within the Botswana’s LRB. Reservoirs are particularly susceptible to the negative impacts of land-use and land-cover (LULC) activities and runoff because of their complex dynamics, relatively longer water residence times, and their role as an integrating sink for pollutants from their drainage basins. Despite these interrelationships and significance in regional and global economic stability, land and water (L-W) are often treated in “silos”. To understand the complex L-W nexus within the LRB, this study will use data-driven artificial intelligence for quantitative determination of the relationships between LULC change, together with socioeconomic development indicators and climate change, and their impacts on water quality and availability within the basin, both for 1984-2019 and to predict future scenarios (2020-2050). To advance data acquisition for LULC analysis and climate change, the study utilizes optical Earth-observation and meteorological satellite data. To provide near real-time and cost-effective approach for continuous monitoring of reservoir water quality within the basin, the study will develop empirical models for water quality estimation and water quality index mapping using 35-years of in-situ water quality measurements and water spectral observations using drone-borne spectrometer and optical satellite imagery through regression modeling and geospatial methods.",Development and Acquisition,,,U.S. Agency for International Development,"Long-term impacts of land-use/land-cover dynamics on surface water quality in Botswana’s reservoirs using satellite data and artificial intelligence methods: Case study of the Botswana’s Limpopo River Basin (1984-2019): 
For water supply, semi-arid Botswana relies on the reservoirs within the Botswana’s LRB. Reservoirs are particularly susceptible to the negative impacts of land-use and land-cover (LULC) activities and runoff because of their complex dynamics, relatively longer water residence times, and their role as an integrating sink for pollutants from their drainage basins. Despite these interrelationships and significance in regional and global economic stability, land and water (L-W) are often treated in “silos”. To understand the complex L-W nexus within the LRB, this study will use data-driven artificial intelligence for quantitative determination of the relationships between LULC change, together with socioeconomic development indicators and climate change, and their impacts on water quality and availability within the basin, both for 1984-2019 and to predict future scenarios (2020-2050). To advance data acquisition for LULC analysis and climate change, the study utilizes optical Earth-observation and meteorological satellite data. To provide near real-time and cost-effective approach for continuous monitoring of reservoir water quality within the basin, the study will develop empirical models for water quality estimation and water quality index mapping using 35-years of in-situ water quality measurements and water spectral observations using drone-borne spectrometer and optical satellite imagery through regression modeling and geospatial methods.","This study examines the long-term impacts of land-use/land-cover dynamics on surface water quality in Botswana's reservoirs, specifically in the Limpopo River Basin. The study aims to understand the relationships between land-use change, socioeconomic development, climate change, and their effects on water quality and availability in the basin. It will utilize satellite data, artificial intelligence methods, and in-situ water quality measurements to develop models for estimating water quality and mapping water quality indexes.","This study examines the long-term impacts of land-use/land-cover dynamics on surface water quality in Botswana's reservoirs, specifically in the Limpopo River Basin. The study aims to understand the relationships between land-use change, socioeconomic development, climate change, and their effects on water quality and availability in the basin. It will utilize satellite data, artificial intelligence methods, and in-situ water quality measurements to develop models for estimating water quality and mapping water quality indexes.",,,False,False
DOE-0049-2023,DOE,National Energy Technology Laboratory,,DOE AI Data Infrastructure System,"Leveraging generative AI and cloud enabled data infrastructure to 
improve CCS user experience and connectivity producing an adaptive 
user interface that streamlines connection of CCS stakeholders to what 
matters to them.",,"Artificial Intelligence, Big Data, Other",,Department of Energy,"DOE AI Data Infrastructure System: 
Leveraging generative AI and cloud enabled data infrastructure to 
improve CCS user experience and connectivity producing an adaptive 
user interface that streamlines connection of CCS stakeholders to what 
matters to them.",The DOE AI Data Infrastructure System aims to enhance the user experience and connectivity of CCS stakeholders by utilizing generative AI and cloud-based data infrastructure. The system creates an adaptive user interface that efficiently connects users to the information that is relevant to them.,The DOE AI Data Infrastructure System aims to enhance the user experience and connectivity of CCS stakeholders by utilizing generative AI and cloud-based data infrastructure. The system creates an adaptive user interface that efficiently connects users to the information that is relevant to them.,,,False,False
DOE-0145-2023,DOE,National Energy Technology Laboratory,,"Use ML to enable a geophysical monitoring toolkit, and assimilate real-time modeling and data.","ML-enabled rapid and autonomous geophysical monitoring and real-
time modeling and data assimilation tools (along with visualization and 
decision-support frameworks), work together to radically improve 
pressure and stress imaging.",,Other,,Department of Energy,"Use ML to enable a geophysical monitoring toolkit, and assimilate real-time modeling and data.: 
ML-enabled rapid and autonomous geophysical monitoring and real-
time modeling and data assimilation tools (along with visualization and 
decision-support frameworks), work together to radically improve 
pressure and stress imaging.","Using machine learning, a geophysical monitoring toolkit can be created that incorporates real-time modeling and data assimilation. This toolkit, along with visualization and decision-support frameworks, can greatly enhance pressure and stress imaging.","Using machine learning, a geophysical monitoring toolkit can be created that incorporates real-time modeling and data assimilation. This toolkit, along with visualization and decision-support frameworks, can greatly enhance pressure and stress imaging.",,,False,False
GSA-0007-2023,GSA,GSA IT (IDT),,Service Desk Generic Ticket Classification,"We are building a model to take generic Service Desk tickets and classify them so that they can be automatically re-routed to the correct team that handles these types of tickets. The process of re-routing generic tickets is currently done manually, so the model will allow us to automate it. The initial model will target the top 5 most common ticket types.",Implementation,Natural Language Processing,,U.S. General Services Administration,"Service Desk Generic Ticket Classification: 
We are building a model to take generic Service Desk tickets and classify them so that they can be automatically re-routed to the correct team that handles these types of tickets. The process of re-routing generic tickets is currently done manually, so the model will allow us to automate it. The initial model will target the top 5 most common ticket types.","A model is being developed to classify generic Service Desk tickets and automate the re-routing process to the appropriate team. Currently, this re-routing is done manually, but the model aims to automate it for the top 5 most common ticket types.","A model is being developed to classify generic Service Desk tickets and automate the re-routing process to the appropriate team. Currently, this re-routing is done manually, but the model aims to automate it for the top 5 most common ticket types.",,,False,False
DOC-0014-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Drought outlooks by using ML techniques,"Drought outlooks by using ML techniques with NCEP models. Simple NN and Deep 
Learning techniques used for GEFSv12 to predict Week 1-5 Prcp & T2m over CONUS",,,,Department of Commerce,"Drought outlooks by using ML techniques: 
Drought outlooks by using ML techniques with NCEP models. Simple NN and Deep 
Learning techniques used for GEFSv12 to predict Week 1-5 Prcp & T2m over CONUS","ML techniques, specifically simple neural networks and deep learning techniques, are being employed to generate drought outlooks using NCEP models. These techniques are focused on predicting precipitation and temperature over the CONUS region for a period of 1-5 weeks.","ML techniques, specifically simple neural networks and deep learning techniques, are being employed to generate drought outlooks using NCEP models. These techniques are focused on predicting precipitation and temperature over the CONUS region for a period of 1-5 weeks.",,,False,False
DOI-0023-2023,DOI,USGS,,WRA.NWC.IWAA National-Extent Groundwater Quality Prediction for the National Water Census and Regional Integrated Water Availability Assessments,"The primary objectives of this project are to (1) provide Nationally consistent predictions of groundwater quality (salinity and nutrients) relevant for human and ecological uses and its influence on surface-water, and (2) develop strategies for integrating these predictions into comprehensive water-availability assessments including the National Water Census and regional Integrated Water Availability Assessments. ",Initiation,convolutional neural networks,,Department of Interior,"WRA.NWC.IWAA National-Extent Groundwater Quality Prediction for the National Water Census and Regional Integrated Water Availability Assessments: 
The primary objectives of this project are to (1) provide Nationally consistent predictions of groundwater quality (salinity and nutrients) relevant for human and ecological uses and its influence on surface-water, and (2) develop strategies for integrating these predictions into comprehensive water-availability assessments including the National Water Census and regional Integrated Water Availability Assessments. ","The project aims to predict groundwater quality nationwide, focusing on salinity and nutrients and their impact on surface water for human and ecological purposes. Additionally, it aims to find ways to incorporate these predictions into comprehensive water availability assessments like the National Water Census and regional Integrated Water Availability Assessments.","The project aims to predict groundwater quality nationwide, focusing on salinity and nutrients and their impact on surface water for human and ecological purposes. Additionally, it aims to find ways to incorporate these predictions into comprehensive water availability assessments like the National Water Census and regional Integrated Water Availability Assessments.",,,False,False
NASA-0020-2023,NASA,Langley Research Center,,Lessons Learned Bot (LLB),"In near real-time, the Lessons Learned Bot, or LLB, brings lessons learned (LL) documents to users through a
Microsoft Excel add-in application locally installed to search for LL content relevant to the text within the selected
Excel cell. The application will encompass a corpus of documents, a trained Machine Learning (ML) model, built-in
ML tools to train user’s documents, and an easy-to-use user interface to allow for the streamlined discovery of LL
content. Today, NASA’s LL are online and searchable via keywords. Nevertheless, users often face a challenge to find
lessons relevant to their issues. Applying the advancement in Natural Language Processing (NLP) ML algorithm, the
LLB can find and rank LL records relevant to text in the user’s selected Excel cells, containing just a few words or
entire paragraphs of text. Results are displayed to the user in their existing Excel workflow. The LLB’s installation
package comes with a pre-trained NASA LL dataset and a NASA Scientific and Technical Information (STI) dataset, as
well as on-demand training tools allowing the user to apply the LLB search algorithm to their own discipline specific
datasets.Additionally, we also have an API version of this software that can be called from any application within the
Agency firewall.",In-use,,,National Aeronautics and Space Administration,"Lessons Learned Bot (LLB): 
In near real-time, the Lessons Learned Bot, or LLB, brings lessons learned (LL) documents to users through a
Microsoft Excel add-in application locally installed to search for LL content relevant to the text within the selected
Excel cell. The application will encompass a corpus of documents, a trained Machine Learning (ML) model, built-in
ML tools to train user’s documents, and an easy-to-use user interface to allow for the streamlined discovery of LL
content. Today, NASA’s LL are online and searchable via keywords. Nevertheless, users often face a challenge to find
lessons relevant to their issues. Applying the advancement in Natural Language Processing (NLP) ML algorithm, the
LLB can find and rank LL records relevant to text in the user’s selected Excel cells, containing just a few words or
entire paragraphs of text. Results are displayed to the user in their existing Excel workflow. The LLB’s installation
package comes with a pre-trained NASA LL dataset and a NASA Scientific and Technical Information (STI) dataset, as
well as on-demand training tools allowing the user to apply the LLB search algorithm to their own discipline specific
datasets.Additionally, we also have an API version of this software that can be called from any application within the
Agency firewall.","The Lessons Learned Bot (LLB) is a Microsoft Excel add-in application that uses a trained Machine Learning (ML) model to search for lessons learned (LL) documents relevant to the text in selected Excel cells. It can find and rank LL records based on just a few words or entire paragraphs of text, providing users with streamlined access to relevant information. In addition to the Excel add-in, there is also an API version of the software available for use within the Agency firewall.","The Lessons Learned Bot (LLB) is a Microsoft Excel add-in application that uses a trained Machine Learning (ML) model to search for lessons learned (LL) documents relevant to the text in selected Excel cells. It can find and rank LL records based on just a few words or entire paragraphs of text, providing users with streamlined access to relevant information. In addition to the Excel add-in, there is also an API version of the software available for use within the Agency firewall.",,,False,False
DOE-0105-2023,DOE,National Energy Technology Laboratory,,To drive insights on environmental performance of the natural gas system to inform effective mitigation strategies,"Life Cycle Analysis models will be used to define and estimate 
environmental parameters/performance",,"Big Data, Other",,Department of Energy,"To drive insights on environmental performance of the natural gas system to inform effective mitigation strategies: 
Life Cycle Analysis models will be used to define and estimate 
environmental parameters/performance",Life Cycle Analysis models will be utilized to determine and evaluate the environmental aspects and performance of the natural gas system. This information will be crucial in developing successful strategies to mitigate any negative impacts.,Life Cycle Analysis models will be utilized to determine and evaluate the environmental aspects and performance of the natural gas system. This information will be crucial in developing successful strategies to mitigate any negative impacts.,,,False,False
DOE-0082-2023,DOE,National Energy Technology Laboratory,,To create reduced order models for predicting long term performance degradation behavior of fuel cells and electrolyzers.,"Machine learning algorithms are being used to analyze large datasets of 
microstructural and perfromance degradation simulations of various 
electrode microstructres to develop reduced order models that can be 
used for long-term perfromance degradation predictions of large area 
fuel cell/electrolysis cells and cell stacks. The reduced order models can 
be used for dynamic simulations that can more accurately mimic the 
changing loading conditions of the modern grid.",,"Big Data, Other",,Department of Energy,"To create reduced order models for predicting long term performance degradation behavior of fuel cells and electrolyzers.: 
Machine learning algorithms are being used to analyze large datasets of 
microstructural and perfromance degradation simulations of various 
electrode microstructres to develop reduced order models that can be 
used for long-term perfromance degradation predictions of large area 
fuel cell/electrolysis cells and cell stacks. The reduced order models can 
be used for dynamic simulations that can more accurately mimic the 
changing loading conditions of the modern grid.","Machine learning algorithms are being utilized to analyze extensive datasets of microstructural and performance degradation simulations for different electrode microstructures. This analysis aims to develop reduced order models that can accurately predict long-term performance degradation of fuel cells and electrolyzers, particularly those used in large-scale applications. These reduced order models enable dynamic simulations that effectively replicate the changing loading conditions of the contemporary power grid.","Machine learning algorithms are being utilized to analyze extensive datasets of microstructural and performance degradation simulations for different electrode microstructures. This analysis aims to develop reduced order models that can accurately predict long-term performance degradation of fuel cells and electrolyzers, particularly those used in large-scale applications. These reduced order models enable dynamic simulations that effectively replicate the changing loading conditions of the contemporary power grid.",,,False,False
HHS-0074-2023,HHS,FDA,CDER/Office of Surveillance and Epidemiology (OSE),Artificial Intelligence-based Deduplication Algorithm for Classification of Duplicate Reports in the FDA Adverse Event Reports (FAERS),The deduplication algorithm is applied to nonpublic data in the FDA Adverse Event Reporting System (FAERS) to identify duplicate individual case safety reports (ICSRs). Unstructured data in free text FAERS narratives is processed through a natural language processing system to extract relevant clinical features. Both structured and unstructured data are then used in a probabilistic record linkage approach to identify duplicates. Application of the deduplication algorithm is optimized for processing entire FAERS database to support datamining. ,Development and Acquisition,,,Department of Health and Human Services,"Artificial Intelligence-based Deduplication Algorithm for Classification of Duplicate Reports in the FDA Adverse Event Reports (FAERS): 
The deduplication algorithm is applied to nonpublic data in the FDA Adverse Event Reporting System (FAERS) to identify duplicate individual case safety reports (ICSRs). Unstructured data in free text FAERS narratives is processed through a natural language processing system to extract relevant clinical features. Both structured and unstructured data are then used in a probabilistic record linkage approach to identify duplicates. Application of the deduplication algorithm is optimized for processing entire FAERS database to support datamining. ","The FDA uses an artificial intelligence-based deduplication algorithm to identify duplicate reports in the FAERS. This algorithm processes both structured and unstructured data, including free text narratives, to extract relevant clinical features and link duplicate reports together. This helps optimize data mining in the entire FAERS database.","The FDA uses an artificial intelligence-based deduplication algorithm to identify duplicate reports in the FAERS. This algorithm processes both structured and unstructured data, including free text narratives, to extract relevant clinical features and link duplicate reports together. This helps optimize data mining in the entire FAERS database.",,,False,False
HHS-0051-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),CMS Enterprise Portal Services (CMS Enterprise Portal-Chatbot),CMS Enterprise Portal AI for Process Efficiency Improvement| Knowledge Management,Operation and Maintenance,,,Department of Health and Human Services,"CMS Enterprise Portal Services (CMS Enterprise Portal-Chatbot): 
CMS Enterprise Portal AI for Process Efficiency Improvement| Knowledge Management","The CMS Enterprise Portal Services, also known as CMS Enterprise Portal-Chatbot, is an AI-powered tool that aims to improve process efficiency and knowledge management. It serves as a platform for users to access information and receive assistance, ultimately enhancing productivity and streamlining operations.","The CMS Enterprise Portal Services, also known as CMS Enterprise Portal-Chatbot, is an AI-powered tool that aims to improve process efficiency and knowledge management. It serves as a platform for users to access information and receive assistance, ultimately enhancing productivity and streamlining operations.",,,False,False
HHS-0001-2023,HHS,AHRQ,AHRQ,AHRQ Search,"Organization wide search that includes Relevancy Tailoring, Auto-generation Synonyms, Automated Suggestions,  Suggested Related Content ,Auto Tagging, and Did you mean to allow visitors to find specific content",Operation and Maintenance,,,Department of Health and Human Services,"AHRQ Search: 
Organization wide search that includes Relevancy Tailoring, Auto-generation Synonyms, Automated Suggestions,  Suggested Related Content ,Auto Tagging, and Did you mean to allow visitors to find specific content","The AHRQ search is a comprehensive search tool for an organization that includes various features such as relevancy tailoring, auto-generation synonyms, automated suggestions, suggested related content, auto tagging, and a ""did you mean"" function. These features aim to help visitors easily find specific content within the organization's website.","The AHRQ search is a comprehensive search tool for an organization that includes various features such as relevancy tailoring, auto-generation synonyms, automated suggestions, suggested related content, auto tagging, and a ""did you mean"" function. These features aim to help visitors easily find specific content within the organization's website.",,,False,False
VA-0000-2023,VA,,,Artificial Intelligence physical therapy app,This app is a physical therapy support tool.  It is a data source agnostic tool which takes input from a variety of wearable sensors and then analyzes the data to give feedback to the physical therapist in an explainable format. ,,,,Department of Veterans Affairs,"Artificial Intelligence physical therapy app: 
This app is a physical therapy support tool.  It is a data source agnostic tool which takes input from a variety of wearable sensors and then analyzes the data to give feedback to the physical therapist in an explainable format. ","The Artificial Intelligence physical therapy app is a versatile tool that supports physical therapy. It collects data from wearable sensors and uses AI to analyze the information, providing explainable feedback to the therapist.","The Artificial Intelligence physical therapy app is a versatile tool that supports physical therapy. It collects data from wearable sensors and uses AI to analyze the information, providing explainable feedback to the therapist.",,,False,False
NASA-0032-2023,NASA,Marshall Space Flight Center,,Similarity Search for Earth Science Image Archive,Self Supervised Based Learning approach to search image archives using a query image,In-use,,,National Aeronautics and Space Administration,"Similarity Search for Earth Science Image Archive: 
Self Supervised Based Learning approach to search image archives using a query image",The text describes a method called Self Supervised Based Learning for searching image archives in the field of Earth Science. This approach allows users to search for images by using a query image.,The text describes a method called Self Supervised Based Learning for searching image archives in the field of Earth Science. This approach allows users to search for images by using a query image.,,,False,False
DOC-0038-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Steller sea lion brand sighting,"Detection and identification of branded steller sea lions from remote camera images in 
the western Aleutian Islands, AK. The goal is to help streamline photo processing to 
reduce the effort required to review images.",,,,Department of Commerce,"Steller sea lion brand sighting: 
Detection and identification of branded steller sea lions from remote camera images in 
the western Aleutian Islands, AK. The goal is to help streamline photo processing to 
reduce the effort required to review images.","The text discusses the process of detecting and identifying branded steller sea lions from remote camera images in the western Aleutian Islands, AK. The objective is to simplify photo processing and decrease the workload needed for image review.","The text discusses the process of detecting and identifying branded steller sea lions from remote camera images in the western Aleutian Islands, AK. The objective is to simplify photo processing and decrease the workload needed for image review.",,,False,False
DOI-0008-2023,DOI,BOR,,Photogrammetric Data Set Crack Mapping Technology Search,"This project is exploring a specific application of photogrammetric products to process analysis of crack mapping on Reclamation facilites.  This analysis is time consuming and has typically required rope access or other means to photograph and locate areas that can now be reached with drones or other devices.  By formulating a standard reference protocol and applying machine learning/AI, this information will be used to provide detailed analysis of Reclamation assets for better decision making. ",Proof-of-concept completed,,,Department of Interior,"Photogrammetric Data Set Crack Mapping Technology Search: 
This project is exploring a specific application of photogrammetric products to process analysis of crack mapping on Reclamation facilites.  This analysis is time consuming and has typically required rope access or other means to photograph and locate areas that can now be reached with drones or other devices.  By formulating a standard reference protocol and applying machine learning/AI, this information will be used to provide detailed analysis of Reclamation assets for better decision making. ","The project aims to use photogrammetric products to analyze and map cracks on Reclamation facilities. Traditionally, this process was time-consuming and required physical access, but with the use of drones and other devices, it can now be done more efficiently. By developing a standard protocol and utilizing machine learning and AI, this data will be used to enhance decision-making regarding Reclamation assets.","The project aims to use photogrammetric products to analyze and map cracks on Reclamation facilities. Traditionally, this process was time-consuming and required physical access, but with the use of drones and other devices, it can now be done more efficiently. By developing a standard protocol and utilizing machine learning and AI, this data will be used to enhance decision-making regarding Reclamation assets.",,,False,False
NASA-0026-2023,NASA,Marshall Space Flight Center,,Forecasting Algal Blooms With Ai In Lake Atitlán,"Deep analyses on image datasets from different satellites. Machine learning will help to identify the variables that
could predict future algal blooms. Knowledge on what those triggers are can turn into precise preventative action,
not just in Lake Atitlan, but also in other freshwater bodies with similar conditions in Central and South America.",In-use,,,National Aeronautics and Space Administration,"Forecasting Algal Blooms With Ai In Lake Atitlán: 
Deep analyses on image datasets from different satellites. Machine learning will help to identify the variables that
could predict future algal blooms. Knowledge on what those triggers are can turn into precise preventative action,
not just in Lake Atitlan, but also in other freshwater bodies with similar conditions in Central and South America.","By analyzing image datasets from various satellites, artificial intelligence (AI) can forecast algal blooms in Lake Atitlán. Machine learning will identify the variables that can predict future blooms, allowing for proactive measures to prevent them not only in Lake Atitlán but also in similar freshwater bodies in Central and South America.","By analyzing image datasets from various satellites, artificial intelligence (AI) can forecast algal blooms in Lake Atitlán. Machine learning will identify the variables that can predict future blooms, allowing for proactive measures to prevent them not only in Lake Atitlán but also in similar freshwater bodies in Central and South America.",,,False,False
HHS-0126-2023,HHS,NIH,National Institutes of Health (NIH) NLM,Remediate Adobe .pdf documents to be more accessible,Many .pdf documents could be made available for public release if they conformed to Section 508 accessibility standards. NLM has been investigating the use of AI developed to remediate Adobe .pdf files not currently accessible to Section 508 standards.�The improved files are particularly more accessible to those like the blind who use assistive technology to read.,Development and Acquisition,,,Department of Health and Human Services,"Remediate Adobe .pdf documents to be more accessible: 
Many .pdf documents could be made available for public release if they conformed to Section 508 accessibility standards. NLM has been investigating the use of AI developed to remediate Adobe .pdf files not currently accessible to Section 508 standards.�The improved files are particularly more accessible to those like the blind who use assistive technology to read.","The NLM is using AI to make Adobe .pdf documents adhere to Section 508 accessibility standards, allowing them to be released to the public. This initiative aims to improve accessibility for individuals who are blind and rely on assistive technology for reading.","The NLM is using AI to make Adobe .pdf documents adhere to Section 508 accessibility standards, allowing them to be released to the public. This initiative aims to improve accessibility for individuals who are blind and rely on assistive technology for reading.",,,False,False
NARA-0001-2023,NARA,Information Service,,Auto-fill of Descriptive Metadata for Archival Descriptions,"Archival descriptions or Self-describing records is the process of filling out descriptive metadata for the records that will be released to the public. When records are released to the public, the records need to be described with summary, authorities and other fields that would allow the records to be surfaced during a search. NARA has released millions of pages of records to the public via the National Archives Catalog at catalog.archives.gov.  Most of the records have very minimal set of descriptive metadata as it is a very intensive manual process. The self-describing records will look at the content of the document and the various available metadata from the records management system such as originating agency etc. and predict values for the descriptive metadata. ",Planned (not in production),Standard Machine learning to predict values for descriptive metadata fields given various inputs such as the content and metadata from the records management system.,,National Archives and Records Administration,"Auto-fill of Descriptive Metadata for Archival Descriptions: 
Archival descriptions or Self-describing records is the process of filling out descriptive metadata for the records that will be released to the public. When records are released to the public, the records need to be described with summary, authorities and other fields that would allow the records to be surfaced during a search. NARA has released millions of pages of records to the public via the National Archives Catalog at catalog.archives.gov.  Most of the records have very minimal set of descriptive metadata as it is a very intensive manual process. The self-describing records will look at the content of the document and the various available metadata from the records management system such as originating agency etc. and predict values for the descriptive metadata. ","Auto-fill of descriptive metadata for archival descriptions is the process of automatically completing the necessary information for records that will be made public. The National Archives has released millions of pages of records with minimal descriptive metadata, so self-describing records use the document's content and available metadata to predict values for the descriptive information.","Auto-fill of descriptive metadata for archival descriptions is the process of automatically completing the necessary information for records that will be made public. The National Archives has released millions of pages of records with minimal descriptive metadata, so self-describing records use the document's content and available metadata to predict values for the descriptive information.",,,False,False
HHS-0037-2023,HHS,CDC,NCHS,Transcribing Cognitive Interviews with Whisper,"Current transcription processes for cognitive interviews are limited. Manual transcription is time-consuming and the current automated solution is low quality. Recently, open-sourced AI models have been released that appear to perform substantially better than previous technologies in automated transcription of video/audio. Of note is the model by OpenAI named Whisper (publication, code, model card) which has been made available for under a fully permissive license. Although Whisper is currently considered state-of-the-art compared to other AI models in standard benchmarks, it has not been tested with cognitive interviews. We hypothesize Whisper will produce production quality transcriptions for NCHS. We plan to do a comparison against both VideoBank and a manual transcription. If the results are encouraging, we plan to transcribe all videos from the CCQDER archive. ",Development and Acquisition,,,Department of Health and Human Services,"Transcribing Cognitive Interviews with Whisper: 
Current transcription processes for cognitive interviews are limited. Manual transcription is time-consuming and the current automated solution is low quality. Recently, open-sourced AI models have been released that appear to perform substantially better than previous technologies in automated transcription of video/audio. Of note is the model by OpenAI named Whisper (publication, code, model card) which has been made available for under a fully permissive license. Although Whisper is currently considered state-of-the-art compared to other AI models in standard benchmarks, it has not been tested with cognitive interviews. We hypothesize Whisper will produce production quality transcriptions for NCHS. We plan to do a comparison against both VideoBank and a manual transcription. If the results are encouraging, we plan to transcribe all videos from the CCQDER archive. ","Current transcription processes for cognitive interviews are limited and time-consuming, with low-quality automated solutions. However, recent open-sourced AI models such as Whisper by OpenAI show promise in automated transcription of video/audio. While Whisper is considered state-of-the-art, it has not been tested with cognitive interviews. A comparison will be conducted against VideoBank and manual transcription, and if successful, all videos from the CCQDER archive will be transcribed.","Current transcription processes for cognitive interviews are limited and time-consuming, with low-quality automated solutions. However, recent open-sourced AI models such as Whisper by OpenAI show promise in automated transcription of video/audio. While Whisper is considered state-of-the-art, it has not been tested with cognitive interviews. A comparison will be conducted against VideoBank and manual transcription, and if successful, all videos from the CCQDER archive will be transcribed.",,,False,False
DOE-0116-2023,DOE,National Energy Technology Laboratory,,To help automate data integration and exploration for geologic core properties related information.,"Using natural language processing, deep learning neural networks, and 
possibly tensor flow for image analytics.",,"Big Data, Natural Language Processing, Other",,Department of Energy,"To help automate data integration and exploration for geologic core properties related information.: 
Using natural language processing, deep learning neural networks, and 
possibly tensor flow for image analytics.","The text discusses the use of various technologies, including natural language processing, deep learning neural networks, and potentially tensor flow for image analytics, to automate data integration and exploration for geologic core properties related information. These technologies aim to make the process more efficient and accurate.","The text discusses the use of various technologies, including natural language processing, deep learning neural networks, and potentially tensor flow for image analytics, to automate data integration and exploration for geologic core properties related information. These technologies aim to make the process more efficient and accurate.",,,False,False
HHS-0120-2023,HHS,NIH,National Institutes of Health (NIH) NIEHS,SWIFT Active Screener,Applies statistical models designed to save screeners time and effort through active learning. Utilize user feedback to automatically prioritize studies. Supports literature screening for Division of Translational Toxicology evidence evaluations.,Operation and Maintenance,,,Department of Health and Human Services,"SWIFT Active Screener: 
Applies statistical models designed to save screeners time and effort through active learning. Utilize user feedback to automatically prioritize studies. Supports literature screening for Division of Translational Toxicology evidence evaluations.",The SWIFT Active Screener is a tool that uses statistical models to help screeners in the Division of Translational Toxicology save time and effort. It utilizes user feedback to automatically prioritize studies and supports literature screening for evidence evaluations.,The SWIFT Active Screener is a tool that uses statistical models to help screeners in the Division of Translational Toxicology save time and effort. It utilizes user feedback to automatically prioritize studies and supports literature screening for evidence evaluations.,,,False,False
GSA-0008-2023,GSA,GSA IT (IDT),,Service Desk Virtual Agent (Curie),"Virtual agent that uses ML to provide predictive results for chat entries. A natural language chatbot (virtual assistant), we named Curie, as part of a multi-model customer service experience for employee's IT service requests leveraging knowledge-based articles.",Operation and Maintenance,Assisted ML; Natural Language Processing,,U.S. General Services Administration,"Service Desk Virtual Agent (Curie): 
Virtual agent that uses ML to provide predictive results for chat entries. A natural language chatbot (virtual assistant), we named Curie, as part of a multi-model customer service experience for employee's IT service requests leveraging knowledge-based articles.","Curie is a virtual agent that utilizes machine learning to offer predictive outcomes for chat interactions. It is a natural language chatbot, also known as a virtual assistant, designed to enhance the customer service experience for employees' IT service needs by using knowledge-based articles.","Curie is a virtual agent that utilizes machine learning to offer predictive outcomes for chat interactions. It is a natural language chatbot, also known as a virtual assistant, designed to enhance the customer service experience for employees' IT service needs by using knowledge-based articles.",,,False,False
VA-0036-2023,VA,,,VA /IRB approved research study for finding colon polyps,This IRB approved research study uses  a randomized trial for finding colon polyps with artifical intelligence.,,,,Department of Veterans Affairs,"VA /IRB approved research study for finding colon polyps: 
This IRB approved research study uses  a randomized trial for finding colon polyps with artifical intelligence.",This text describes an approved research study that aims to find colon polyps using artificial intelligence. The study has been approved by the VA/IRB and will employ a randomized trial methodology.,This text describes an approved research study that aims to find colon polyps using artificial intelligence. The study has been approved by the VA/IRB and will employ a randomized trial methodology.,,,False,False
HHS-0143-2023,HHS,NIH,National Institutes of Health (NIH) OD/DPCPSI/OPA,Person-level disambiguation for PubMed authors and NIH grant applicants,"Correct attribution of grants, articles, and other products to individual researchers is critical for high quality person-level analysis. This improved method for disambiguation of authors on articles in PubMed and NIH grant applicants can inform data-driven decision making",Implementation,,,Department of Health and Human Services,"Person-level disambiguation for PubMed authors and NIH grant applicants: 
Correct attribution of grants, articles, and other products to individual researchers is critical for high quality person-level analysis. This improved method for disambiguation of authors on articles in PubMed and NIH grant applicants can inform data-driven decision making","The accurate identification of individual researchers is crucial for analyzing grants, articles, and other outputs at a person-level. A new and enhanced method has been developed to disambiguate authors in PubMed articles and NIH grant applications, providing valuable information for making data-based decisions.","The accurate identification of individual researchers is crucial for analyzing grants, articles, and other outputs at a person-level. A new and enhanced method has been developed to disambiguate authors in PubMed articles and NIH grant applications, providing valuable information for making data-based decisions.",,,False,False
DOE-0048-2023,DOE,National Energy Technology Laboratory,,"Development of new machine learning-based process modeling capabilities that assess the viability and efficiency, with uncertainty quantification, of the chemical processes involved in the carbon fiber production and its output quality","Provide sub-pilot-scale verification of lab-scale developments on the 
production of isotropic and mesophase coal-tar pitch (CTP) for carbon 
fiber production, using coals from several U.S. coal-producing regions. 
An extensive database and suite of tools for data analysis and economic 
modeling, with an associated web-based community portal, will be 
developed to relate process conditions to product quality, and to assess 
the economic viability of coals from different regions for producing 
specific high-value products.",,Artificial Intelligence Unknown,,Department of Energy,"Development of new machine learning-based process modeling capabilities that assess the viability and efficiency, with uncertainty quantification, of the chemical processes involved in the carbon fiber production and its output quality: 
Provide sub-pilot-scale verification of lab-scale developments on the 
production of isotropic and mesophase coal-tar pitch (CTP) for carbon 
fiber production, using coals from several U.S. coal-producing regions. 
An extensive database and suite of tools for data analysis and economic 
modeling, with an associated web-based community portal, will be 
developed to relate process conditions to product quality, and to assess 
the economic viability of coals from different regions for producing 
specific high-value products.","The text describes the development of machine learning-based process modeling capabilities to assess the effectiveness and uncertainty of chemical processes in carbon fiber production. This includes verifying lab-scale experiments for producing coal-tar pitch (CTP) and creating a database and tools for analyzing data and economic modeling. The goal is to determine the relationship between process conditions and product quality, as well as assess the economic viability of using different coal regions for high-value product production.","The text describes the development of machine learning-based process modeling capabilities to assess the effectiveness and uncertainty of chemical processes in carbon fiber production. This includes verifying lab-scale experiments for producing coal-tar pitch (CTP) and creating a database and tools for analyzing data and economic modeling. The goal is to determine the relationship between process conditions and product quality, as well as assess the economic viability of using different coal regions for high-value product production.",,,False,False
USDA-0005-2023,USDA,USDA,APHIS,Standardization of cut flower business names for message set data,"Natural language processing technique. Data are cleaned (e.g., remove punctuation) to facilitate matching. Cosine similarity is calculated, similar terms are matched, and the results are output.",Implementation,Natural Language Processing,,Department of Agriculture,"Standardization of cut flower business names for message set data: 
Natural language processing technique. Data are cleaned (e.g., remove punctuation) to facilitate matching. Cosine similarity is calculated, similar terms are matched, and the results are output.","This text discusses the process of standardizing cut flower business names for message set data using natural language processing. The data is cleaned by removing punctuation, allowing for easier matching. Similar terms are identified using cosine similarity and the results are then output.","This text discusses the process of standardizing cut flower business names for message set data using natural language processing. The data is cleaned by removing punctuation, allowing for easier matching. Similar terms are identified using cosine similarity and the results are then output.",,,False,False
GSA-0003-2023,GSA,FAS,,Key KPI Forecasts for GWCM,"Takes monthly historical data for underlying components used to calculate KPIs and creates near-term forecasts for the upcoming fiscal year. Pilot effort focuses on total agency/category spend (the denominator in multiple KPIs). If the pilot program is successful, the same methodology can be extended to other KPIs.",Implementation,Time Series Forecast,,U.S. General Services Administration,"Key KPI Forecasts for GWCM: 
Takes monthly historical data for underlying components used to calculate KPIs and creates near-term forecasts for the upcoming fiscal year. Pilot effort focuses on total agency/category spend (the denominator in multiple KPIs). If the pilot program is successful, the same methodology can be extended to other KPIs.","The Key KPI Forecasts for GWCM involves using monthly historical data to predict KPIs for the upcoming fiscal year. The initial focus is on total agency/category spend, and if the pilot program succeeds, the same approach can be applied to other KPIs.","The Key KPI Forecasts for GWCM involves using monthly historical data to predict KPIs for the upcoming fiscal year. The initial focus is on total agency/category spend, and if the pilot program succeeds, the same approach can be applied to other KPIs.",,,False,False
DOI-0017-2023,DOI,USGS,,Multi-scale modeling for ecosystem service economics,"Work continues to expand the existing ARIES modeling framework using artificial intelligence and a set of decision rules to build a system that can select models and data based on appropriate contextual factors (e.g., climate, vegetation, soils, socioeconomics). Using national and global datasets, this system will be capable of mapping ES at a much greater level of accuracy than before. I will work to expand and implement this intelligent modeling system to the United States, yielding a consistent, nationwide, AI-supported intelligent ES modeling system to support ES assessment and valuation nationwide and beyond. This includes the integration of national economic accounts data with ecosystem services data to provide more timely, up to date, and integrated data at the national and subnational levels.",Implementation,Neural network regression,,Department of Interior,"Multi-scale modeling for ecosystem service economics: 
Work continues to expand the existing ARIES modeling framework using artificial intelligence and a set of decision rules to build a system that can select models and data based on appropriate contextual factors (e.g., climate, vegetation, soils, socioeconomics). Using national and global datasets, this system will be capable of mapping ES at a much greater level of accuracy than before. I will work to expand and implement this intelligent modeling system to the United States, yielding a consistent, nationwide, AI-supported intelligent ES modeling system to support ES assessment and valuation nationwide and beyond. This includes the integration of national economic accounts data with ecosystem services data to provide more timely, up to date, and integrated data at the national and subnational levels.","The ARIES modeling framework is being expanded to incorporate artificial intelligence and decision rules in order to select appropriate models and data for ecosystem service (ES) economics. This intelligent modeling system will use national and global datasets to accurately map ES and will be implemented in the United States to provide nationwide, AI-supported ES assessment and valuation. The system will also integrate national economic accounts data with ecosystem services data to offer more timely and integrated data at both national and subnational levels.","The ARIES modeling framework is being expanded to incorporate artificial intelligence and decision rules in order to select appropriate models and data for ecosystem service (ES) economics. This intelligent modeling system will use national and global datasets to accurately map ES and will be implemented in the United States to provide nationwide, AI-supported ES assessment and valuation. The system will also integrate national economic accounts data with ecosystem services data to offer more timely and integrated data at both national and subnational levels.",,,False,False
DOE-0062-2023,DOE,National Energy Technology Laboratory,,Natural Language Processing,"Information and articles on energy storage will be gathered and 
reviewed. Developed natural language processing (NLP) algorithms will 
be used to help categorize and understand various energy storage 
efforts in the R&D communities. Additionally, trends within the 
discovered and selected topical focus areas in energy storage will be 
examined. This will provide a view of energy storage R&D, which is not 
biased or limited to known search terms.",,"Big Data, Natural Language Processing, Other",,Department of Energy,"Natural Language Processing: 
Information and articles on energy storage will be gathered and 
reviewed. Developed natural language processing (NLP) algorithms will 
be used to help categorize and understand various energy storage 
efforts in the R&D communities. Additionally, trends within the 
discovered and selected topical focus areas in energy storage will be 
examined. This will provide a view of energy storage R&D, which is not 
biased or limited to known search terms.","The text states that information and articles on energy storage will be collected and analyzed using natural language processing algorithms. These algorithms will help categorize and understand different energy storage efforts in research and development communities, and trends within the selected focus areas will also be examined. Overall, this approach will provide an unbiased and comprehensive view of energy storage R&D beyond known search terms.","The text states that information and articles on energy storage will be collected and analyzed using natural language processing algorithms. These algorithms will help categorize and understand different energy storage efforts in research and development communities, and trends within the selected focus areas will also be examined. Overall, this approach will provide an unbiased and comprehensive view of energy storage R&D beyond known search terms.",,,False,False
HHS-0053-2023,HHS,Centers for Medicare & Medicaid Services (CMS),Centers for Medicare & Medicaid Services (CMS),Marketplace Learning Management System (MLMS),MLMS AI for Language Interpretation and Translation,Operation and Maintenance,,,Department of Health and Human Services,"Marketplace Learning Management System (MLMS): 
MLMS AI for Language Interpretation and Translation",The Marketplace Learning Management System (MLMS) incorporates artificial intelligence (AI) to provide language interpretation and translation services. It efficiently assists users in understanding and communicating in different languages.,The Marketplace Learning Management System (MLMS) incorporates artificial intelligence (AI) to provide language interpretation and translation services. It efficiently assists users in understanding and communicating in different languages.,,,False,False
DOE-0173-2023,DOE,Pacific Northwest National Laboratory,,Regional waste feedstock conversion to biofuels,"Unsupervised ML is used sequentially to group waste sources into 
different regions.  Calibrated game theoretic models are used to assess 
the behavior and economic viability of different waste-to-energy 
pathways within a region.",,,,Department of Energy,"Regional waste feedstock conversion to biofuels: 
Unsupervised ML is used sequentially to group waste sources into 
different regions.  Calibrated game theoretic models are used to assess 
the behavior and economic viability of different waste-to-energy 
pathways within a region.",The text explains that unsupervised machine learning is utilized to categorize waste sources into distinct regions. These regions are then analyzed using calibrated game theoretic models to evaluate the feasibility and economic potential of various waste-to-energy conversion methods.,The text explains that unsupervised machine learning is utilized to categorize waste sources into distinct regions. These regions are then analyzed using calibrated game theoretic models to evaluate the feasibility and economic potential of various waste-to-energy conversion methods.,,,False,False
DOJ-0002-2023,DOJ,Justice Management Division,,Intelligent Records Consolidation Tool,"The Office of Records Management Policy 
uses an AI and Natural Language Processing 
(NLP) tool to assess the similarity of records 
schedules across all Department records 
schedules. The tool provides clusters of 
similar items to significantly reduce the time 
that the Records Manager spends manually 
reviewing schedules for possible 
consolidation. An AI powered dashboard 
provides recommendations for schedule 
consolidation and review, while also 
providing the Records Manager with the 
ability to review by cluster or by individual 
record. The solution's technical approach 
has applicability with other domains that 
require text similarity analysis.",In production: more than 1 year,,,Department of Justice,"Intelligent Records Consolidation Tool: 
The Office of Records Management Policy 
uses an AI and Natural Language Processing 
(NLP) tool to assess the similarity of records 
schedules across all Department records 
schedules. The tool provides clusters of 
similar items to significantly reduce the time 
that the Records Manager spends manually 
reviewing schedules for possible 
consolidation. An AI powered dashboard 
provides recommendations for schedule 
consolidation and review, while also 
providing the Records Manager with the 
ability to review by cluster or by individual 
record. The solution's technical approach 
has applicability with other domains that 
require text similarity analysis.","The Office of Records Management Policy uses an AI and NLP tool to compare records schedules and identify similar items. This tool saves time for the Records Manager by automatically suggesting schedule consolidation and providing a dashboard for easy review. Additionally, the tool's approach can be applied to other domains that need text similarity analysis.","The Office of Records Management Policy uses an AI and NLP tool to compare records schedules and identify similar items. This tool saves time for the Records Manager by automatically suggesting schedule consolidation and providing a dashboard for easy review. Additionally, the tool's approach can be applied to other domains that need text similarity analysis.",,,False,False
DOE-0058-2023,DOE,National Energy Technology Laboratory,,Machine learning to tool and model applications for CCS needs,"Utilze and apply different machine learning approaches to help model 
and analyze Class VI well regulatation data, CCS infrastructure 
optimization, CCS data visualization, and interaction with “really big” 
(petabyte-scale) datasets used for CCS resource characterization and 
risk reduction (e.g., reflection seismic surveys) within the EDX multi-
cloud ecosystem.",,"Big Data, Other",,Department of Energy,"Machine learning to tool and model applications for CCS needs: 
Utilze and apply different machine learning approaches to help model 
and analyze Class VI well regulatation data, CCS infrastructure 
optimization, CCS data visualization, and interaction with “really big” 
(petabyte-scale) datasets used for CCS resource characterization and 
risk reduction (e.g., reflection seismic surveys) within the EDX multi-
cloud ecosystem.","Machine learning is used to develop and analyze models for CCS applications. It helps optimize CCS infrastructure, visualize data, and interact with large datasets within the EDX multi-cloud ecosystem.","Machine learning is used to develop and analyze models for CCS applications. It helps optimize CCS infrastructure, visualize data, and interact with large datasets within the EDX multi-cloud ecosystem.",,,False,False
HHS-0146-2023,HHS,NIH,National Institutes of Health (NIH) OD/DPCPSI/OPA,Machine learning system to predict translational progress in biomedical research,A machine learning system that detects whether a research paper is likely to be cited by a future clinical trial or guideline. Translational progress in biomedicine can therefore be assessed and predicted in real time based on information conveyed by the scientific community's early reaction to a paper. For more information see the publication describing this system: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000416),Operation and Maintenance,,,Department of Health and Human Services,"Machine learning system to predict translational progress in biomedical research: 
A machine learning system that detects whether a research paper is likely to be cited by a future clinical trial or guideline. Translational progress in biomedicine can therefore be assessed and predicted in real time based on information conveyed by the scientific community's early reaction to a paper. For more information see the publication describing this system: Hutchins et al 2019 (https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000416)","A machine learning system has been developed to determine the likelihood of a research paper being cited by a future clinical trial or guideline, enabling real-time assessment and prediction of translational progress in biomedicine. The system analyzes the early reaction of the scientific community to a paper to gather information.","A machine learning system has been developed to determine the likelihood of a research paper being cited by a future clinical trial or guideline, enabling real-time assessment and prediction of translational progress in biomedicine. The system analyzes the early reaction of the scientific community to a paper to gather information.",,,False,False
USDA-0012-2023,USDA,USDA,ERS,Democratizing Data,"The purpose of this project is to use AI tools, machine learning and natural language processing to understand how publicly-funded data and evidence are used to serve science and society.",Implementation,Natural Language Processing,,Department of Agriculture,"Democratizing Data: 
The purpose of this project is to use AI tools, machine learning and natural language processing to understand how publicly-funded data and evidence are used to serve science and society.","The project aims to make data and evidence accessible to all by utilizing AI tools, machine learning, and natural language processing. It seeks to understand how publicly-funded data and evidence contribute to scientific advancements and societal benefits.","The project aims to make data and evidence accessible to all by utilizing AI tools, machine learning, and natural language processing. It seeks to understand how publicly-funded data and evidence contribute to scientific advancements and societal benefits.",,,False,False
SSA-0000-2023,SSA,"Office of Analytics, Review, and Oversight",,Modernized Development Worksheet (MDW),This process uses AI to review textual data that is part of claim development tasks so it can be categorized into workload topics using natural language processing to facilitate faster technician review.,,,,Social Security Administration,"Modernized Development Worksheet (MDW): 
This process uses AI to review textual data that is part of claim development tasks so it can be categorized into workload topics using natural language processing to facilitate faster technician review.",The Modernized Development Worksheet (MDW) utilizes artificial intelligence (AI) and natural language processing to quickly categorize textual data from claim development tasks. This streamlines the technician review process and improves efficiency.,The Modernized Development Worksheet (MDW) utilizes artificial intelligence (AI) and natural language processing to quickly categorize textual data from claim development tasks. This streamlines the technician review process and improves efficiency.,,,False,False
DOC-0018-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,NN Radiation,"Developing fast and accurate NN LW- and SW radiations for GFS and GEFS.  NN LW- and 
SW radiations have been successfully developed for previous version of GFS, see: doi: 
10.1175/2009MWR3149.1 and the stability and robustness of the approach used was 
demonstrated, see:  https://arxiv.org/ftp/arxiv/papers/2103/2103.07024.pdf  NN LW- and 
SW radiations will be developed for the current versions of for GFS and GEFS.",,,,Department of Commerce,"NN Radiation: 
Developing fast and accurate NN LW- and SW radiations for GFS and GEFS.  NN LW- and 
SW radiations have been successfully developed for previous version of GFS, see: doi: 
10.1175/2009MWR3149.1 and the stability and robustness of the approach used was 
demonstrated, see:  https://arxiv.org/ftp/arxiv/papers/2103/2103.07024.pdf  NN LW- and 
SW radiations will be developed for the current versions of for GFS and GEFS.","NN radiation for GFS and GEFS, specifically in the LW and SW regions, has been successfully developed in previous versions of GFS. The stability and robustness of this approach have been demonstrated, and now efforts are underway to develop NN LW and SW radiations for the current versions of GFS and GEFS.","NN radiation for GFS and GEFS, specifically in the LW and SW regions, has been successfully developed in previous versions of GFS. The stability and robustness of this approach have been demonstrated, and now efforts are underway to develop NN LW and SW radiations for the current versions of GFS and GEFS.",,,False,False
DOC-0019-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,NN training software for the new generation of NCEP models,"Optimize NCEP EMC Training and Validation System for efficient handling of high spatial 
resolution model data produced by the new generation of NCEP's operational models",,,,Department of Commerce,"NN training software for the new generation of NCEP models: 
Optimize NCEP EMC Training and Validation System for efficient handling of high spatial 
resolution model data produced by the new generation of NCEP's operational models",The NN training software is designed to enhance the NCEP EMC Training and Validation System by efficiently managing the high-resolution model data from the new NCEP operational models. This software aims to optimize the training process and ensure effective handling of the data produced by these advanced models.,The NN training software is designed to enhance the NCEP EMC Training and Validation System by efficiently managing the high-resolution model data from the new NCEP operational models. This software aims to optimize the training process and ensure effective handling of the data produced by these advanced models.,,,False,False
DOI-0026-2023,DOI,USGS,,WRA.NWC.IWAA Model Application for the National IWAAs and NWC,"In support of both the periodic National Water Availability Assessment reports and the routinely updated National Water Census, the Model Application for the National IWAAs and NWC (MAPPNAT) project will have four major objectives related to model application development: 1) Provide initial applications of models for the National IWAAs reports and the National Water Census, 2) Provide periodic long-term projections for the National IWAAs reports and the National Water Census, 3) Provide routine model updates of current or near-current conditions for the National IWAAs reports and the National Water Census, and 4) Provide operational short-term forecasts for the National Water Census. These four objectives will ultimately cover multiple hydrologic sub-disciplines—including water budgets, water use, water quality, aquatic ecosystems, and drought. Objective 1 will require a combination of on-project and off-project modeling activities to provide the needed model applications for National IWAAs and NWC version 1. Objectives 2, 3, and 4 will begin with strategic planning activities before implementation using the available model applications. As new models are developed, the staffing, organization, and approach for this project will be developed in an integrated manner that can accommodate multiple sub-disciplines and differing domain expertise. ",Initiation,"Random forest regression, random forest classification, random survival forests, neural networks, long-short term memory, recurrent neural networks",,Department of Interior,"WRA.NWC.IWAA Model Application for the National IWAAs and NWC: 
In support of both the periodic National Water Availability Assessment reports and the routinely updated National Water Census, the Model Application for the National IWAAs and NWC (MAPPNAT) project will have four major objectives related to model application development: 1) Provide initial applications of models for the National IWAAs reports and the National Water Census, 2) Provide periodic long-term projections for the National IWAAs reports and the National Water Census, 3) Provide routine model updates of current or near-current conditions for the National IWAAs reports and the National Water Census, and 4) Provide operational short-term forecasts for the National Water Census. These four objectives will ultimately cover multiple hydrologic sub-disciplines—including water budgets, water use, water quality, aquatic ecosystems, and drought. Objective 1 will require a combination of on-project and off-project modeling activities to provide the needed model applications for National IWAAs and NWC version 1. Objectives 2, 3, and 4 will begin with strategic planning activities before implementation using the available model applications. As new models are developed, the staffing, organization, and approach for this project will be developed in an integrated manner that can accommodate multiple sub-disciplines and differing domain expertise. ","The Model Application for the National IWAAs and NWC (MAPPNAT) project aims to develop and apply models for the National IWAAs reports and the National Water Census. It will provide initial applications, long-term projections, routine updates, and short-term forecasts for various hydrologic sub-disciplines. The project will involve a combination of modeling activities and strategic planning to accommodate multiple sub-disciplines and different areas of expertise.","The Model Application for the National IWAAs and NWC (MAPPNAT) project aims to develop and apply models for the National IWAAs reports and the National Water Census. It will provide initial applications, long-term projections, routine updates, and short-term forecasts for various hydrologic sub-disciplines. The project will involve a combination of modeling activities and strategic planning to accommodate multiple sub-disciplines and different areas of expertise.",,,False,False
DOE-0080-2023,DOE,National Energy Technology Laboratory,,To create a data-driven multiscale phytotechnology framework for identification and remediation of leached-metals-contaminated soil.,"The project objectives are to integrate satellite remote sensing, machine 
learning and image processing, geological engineering models, and soil 
science and plant pathology to: 1) identify potential leaching of metals 
from coal ash impoundments (Phase I), and 2) propose locally 
adaptable phytoextraction approaches to remediate contaminated 
regions (Phase II).",,Artificial Intelligence Unknown,,Department of Energy,"To create a data-driven multiscale phytotechnology framework for identification and remediation of leached-metals-contaminated soil.: 
The project objectives are to integrate satellite remote sensing, machine 
learning and image processing, geological engineering models, and soil 
science and plant pathology to: 1) identify potential leaching of metals 
from coal ash impoundments (Phase I), and 2) propose locally 
adaptable phytoextraction approaches to remediate contaminated 
regions (Phase II).","The objective of this project is to develop a framework that uses data and technology to identify and remediate soil contaminated with leached metals. This will be achieved by combining satellite remote sensing, machine learning, image processing, geological engineering models, soil science, and plant pathology to identify potential metal leaching and propose effective phytoextraction methods for remediation.","The objective of this project is to develop a framework that uses data and technology to identify and remediate soil contaminated with leached metals. This will be achieved by combining satellite remote sensing, machine learning, image processing, geological engineering models, soil science, and plant pathology to identify potential metal leaching and propose effective phytoextraction methods for remediation.",,,False,False
DOE-0141-2023,DOE,National Energy Technology Laboratory,,"Transform reservoir management decisions through rapid analysis of real time data to visualize forecasted behavior in an advanced control room ""human-in-the-loop"" format.","Improve low-fidelity model performance by transfer-learning with high-
fidelity data, and reduce uncertainty by combining high-fidelity and lower-
fidelity models for improved UQ performance.",,Other,,Department of Energy,"Transform reservoir management decisions through rapid analysis of real time data to visualize forecasted behavior in an advanced control room ""human-in-the-loop"" format.: 
Improve low-fidelity model performance by transfer-learning with high-
fidelity data, and reduce uncertainty by combining high-fidelity and lower-
fidelity models for improved UQ performance.",The text suggests that reservoir management decisions can be improved by analyzing real-time data and visualizing forecasted behavior in an advanced control room format. It also proposes enhancing low-fidelity model performance by using high-fidelity data through transfer-learning and reducing uncertainty by combining high-fidelity and lower-fidelity models for better performance in uncertainty quantification.,The text suggests that reservoir management decisions can be improved by analyzing real-time data and visualizing forecasted behavior in an advanced control room format. It also proposes enhancing low-fidelity model performance by using high-fidelity data through transfer-learning and reducing uncertainty by combining high-fidelity and lower-fidelity models for better performance in uncertainty quantification.,,,False,False
DOS-0023-2023,DOS,R,,Topic Modeling,Cluster text into themes based on frequency of used words in documents; has been applied to digital media articles as well as social media posts; performed using available Python libraries,,,,Department of State,"Topic Modeling: 
Cluster text into themes based on frequency of used words in documents; has been applied to digital media articles as well as social media posts; performed using available Python libraries",Topic modeling is a technique that groups text into themes by analyzing the frequency of words used in documents. This method has been used to analyze digital media articles and social media posts and can be easily implemented using Python libraries.,Topic modeling is a technique that groups text into themes by analyzing the frequency of words used in documents. This method has been used to analyze digital media articles and social media posts and can be easily implemented using Python libraries.,,,False,False
DOC-0021-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,Robotic microscopes and machine learning algorithms remotely and autonomously track lower trophic levels for improved ecosystem monitoring and assessment,"Phytoplankton are the foundation of marine food webs supporting fisheries and coastal 
communities. They respond rapidly to physical and chemical oceanography, and changes 
in phytoplankton communities can impact the structure and functioning of food webs. We 
use a robotic microscope called an Imaging Flow Cytobot (IFCB) to continuously collect 
images of phytoplankton from seawater. Automated taxonomic identification of imaged 
phytoplankton uses a supervised machine learning approach (random forest algorithm). 
We deploy the IFCB on fixed (docks) and roving (aboard survey ships) platforms to 
autonomously monitor phytoplankton communities in aquaculture areas in Puget Sound 
and in the California Current System. We map the distribution and abundance of 
phytoplankton functional groups and their relative food value to support fisheries and 
aquaculture and describe their changes in relation to ocean and climate variability and 
change.",,,,Department of Commerce,"Robotic microscopes and machine learning algorithms remotely and autonomously track lower trophic levels for improved ecosystem monitoring and assessment: 
Phytoplankton are the foundation of marine food webs supporting fisheries and coastal 
communities. They respond rapidly to physical and chemical oceanography, and changes 
in phytoplankton communities can impact the structure and functioning of food webs. We 
use a robotic microscope called an Imaging Flow Cytobot (IFCB) to continuously collect 
images of phytoplankton from seawater. Automated taxonomic identification of imaged 
phytoplankton uses a supervised machine learning approach (random forest algorithm). 
We deploy the IFCB on fixed (docks) and roving (aboard survey ships) platforms to 
autonomously monitor phytoplankton communities in aquaculture areas in Puget Sound 
and in the California Current System. We map the distribution and abundance of 
phytoplankton functional groups and their relative food value to support fisheries and 
aquaculture and describe their changes in relation to ocean and climate variability and 
change.","Robotic microscopes and machine learning algorithms are used to track and monitor phytoplankton, which are crucial for marine food webs. The Imaging Flow Cytobot (IFCB) collects images of phytoplankton, and a random forest algorithm is used to identify and classify them. The IFCB is deployed on both fixed and roving platforms to monitor phytoplankton communities in different areas and assess their distribution, abundance, and changes in relation to ocean and climate variability.","Robotic microscopes and machine learning algorithms are used to track and monitor phytoplankton, which are crucial for marine food webs. The Imaging Flow Cytobot (IFCB) collects images of phytoplankton, and a random forest algorithm is used to identify and classify them. The IFCB is deployed on both fixed and roving platforms to monitor phytoplankton communities in different areas and assess their distribution, abundance, and changes in relation to ocean and climate variability.",,,False,False
DOS-0006-2023,DOS,A,,Verified Imagery Pilot Project,"The Bureau of Conflict and Stabilization Operations ran a pilot project to test how the use of a technology service, Sealr, could verify the delivery of foreign assistance to conflict-affected areas where neither U.S. Department of State nor our implementing partner could go.  Sealr uses blockchain encryption to secure photographs taken on smartphones from digital tampering.  It also uses artificial intelligence to detect spoofs, like taking a picture of a picture of something.  Sealr also has some image recognition capabilities.  The pilot demonstrated technology like Sealr can be used as a way to strengthen remote monitoring of foreign assistance to dangerous or otherwise inaccessible areas.",,,,Department of State,"Verified Imagery Pilot Project: 
The Bureau of Conflict and Stabilization Operations ran a pilot project to test how the use of a technology service, Sealr, could verify the delivery of foreign assistance to conflict-affected areas where neither U.S. Department of State nor our implementing partner could go.  Sealr uses blockchain encryption to secure photographs taken on smartphones from digital tampering.  It also uses artificial intelligence to detect spoofs, like taking a picture of a picture of something.  Sealr also has some image recognition capabilities.  The pilot demonstrated technology like Sealr can be used as a way to strengthen remote monitoring of foreign assistance to dangerous or otherwise inaccessible areas.",The Bureau of Conflict and Stabilization Operations conducted a pilot project using a technology service called Sealr. Sealr utilizes blockchain encryption to secure photos taken on smartphones and uses artificial intelligence to detect tampering or spoofs. The pilot showed that Sealr and similar technologies can enhance remote monitoring of foreign assistance in conflict-affected or inaccessible regions.,The Bureau of Conflict and Stabilization Operations conducted a pilot project using a technology service called Sealr. Sealr utilizes blockchain encryption to secure photos taken on smartphones and uses artificial intelligence to detect tampering or spoofs. The pilot showed that Sealr and similar technologies can enhance remote monitoring of foreign assistance in conflict-affected or inaccessible regions.,,,False,False
DOS-0029-2023,DOS,R,,Image Clustering,"Uses a pretrained deep learning model to generate image embeddings, then uses hierarchical clustering to identify similar images.",,,,Department of State,"Image Clustering: 
Uses a pretrained deep learning model to generate image embeddings, then uses hierarchical clustering to identify similar images.","The text explains that image clustering technique involves utilizing a pre-trained deep learning model to create image embeddings. These embeddings are then employed for hierarchical clustering, enabling the identification of images that are similar to each other.","The text explains that image clustering technique involves utilizing a pre-trained deep learning model to create image embeddings. These embeddings are then employed for hierarchical clustering, enabling the identification of images that are similar to each other.",,,False,False
DOI-0003-2023,DOI,BOR,,Data Driven Streamflow Forecasting,"Reclamation, along with partners from the CEATI hydropower industry group (e.g. TVA, DOE-PNNL, and others) ran a year-long  evaluation of existing 10-day streamflow foreasting technologies and a companion prize competition open to the public, also focused on 10-day streamflow forecasts. Forecasts were issued every day for a year and verified agains observed flows. Across locations and metrics, the top perfoming foreacst product was a private, AI/ML forecasting company - UpstreamTech. Several competitors from the prize competition also performed strongly; outperforming benchmark forecasts from NOAA. Reclamation is working to further evaluate the UpstreamTech forecast products and also the top performers from the prize competition.  ",Development (not in production),"Range of data driven, AI/ML techniques (e.g. LSTMs)",,Department of Interior,"Data Driven Streamflow Forecasting: 
Reclamation, along with partners from the CEATI hydropower industry group (e.g. TVA, DOE-PNNL, and others) ran a year-long  evaluation of existing 10-day streamflow foreasting technologies and a companion prize competition open to the public, also focused on 10-day streamflow forecasts. Forecasts were issued every day for a year and verified agains observed flows. Across locations and metrics, the top perfoming foreacst product was a private, AI/ML forecasting company - UpstreamTech. Several competitors from the prize competition also performed strongly; outperforming benchmark forecasts from NOAA. Reclamation is working to further evaluate the UpstreamTech forecast products and also the top performers from the prize competition.  ","Reclamation and CEATI hydropower industry group conducted a year-long evaluation of 10-day streamflow forecasting technologies and held a public competition for the same. The top performing forecast product was from UpstreamTech, an AI/ML forecasting company, while other competitors also outperformed NOAA's benchmark forecasts. Reclamation is now focusing on evaluating UpstreamTech's forecast products and the top performers from the competition.","Reclamation and CEATI hydropower industry group conducted a year-long evaluation of 10-day streamflow forecasting technologies and held a public competition for the same. The top performing forecast product was from UpstreamTech, an AI/ML forecasting company, while other competitors also outperformed NOAA's benchmark forecasts. Reclamation is now focusing on evaluating UpstreamTech's forecast products and the top performers from the competition.",,,False,False
DOE-0161-2023,DOE,Office of Legacy Management,,Groundwater Modeling,Groundwater modeling includes parameter estimation,,,,Department of Energy,"Groundwater Modeling: 
Groundwater modeling includes parameter estimation","and simulation of groundwater flow and contaminant transport. It helps in understanding the behavior of groundwater systems and predicting the impact of various factors such as pumping, recharge, and land use changes. This modeling technique plays a crucial role in water resource management and environmental planning.","and simulation of groundwater flow and contaminant transport. It helps in understanding the behavior of groundwater systems and predicting the impact of various factors such as pumping, recharge, and land use changes. This modeling technique plays a crucial role in water resource management and environmental planning.",,,False,False
NASA-0004-2023,NASA,Ames Research Center,,Prediction of Mass Level in Radio Frequency Cryogenics,"Utilizing the Radio frequency signature of fluids in a tank, the ML model predicts the level of fluid in the tank. In
micro-gravity standard fluid level detection methods do not work because the fluid is not restricted to any shape or
Definition.",In-use,,,National Aeronautics and Space Administration,"Prediction of Mass Level in Radio Frequency Cryogenics: 
Utilizing the Radio frequency signature of fluids in a tank, the ML model predicts the level of fluid in the tank. In
micro-gravity standard fluid level detection methods do not work because the fluid is not restricted to any shape or
Definition.",The ML model predicts the level of fluid in a tank in radio frequency cryogenics by analyzing the radio frequency signature of the fluids. This method is particularly useful in microgravity environments where standard fluid level detection methods are ineffective due to the fluid's unrestricted shape and definition.,The ML model predicts the level of fluid in a tank in radio frequency cryogenics by analyzing the radio frequency signature of the fluids. This method is particularly useful in microgravity environments where standard fluid level detection methods are ineffective due to the fluid's unrestricted shape and definition.,,,False,False
DOL-0002-2023,DOL,,,Audio Transcription,Transcription of speech to text for records keeping using natural language processing models.,Operation and Maintenance,Cloud based commercial-off-the-shelf pre-trained NLP models,,Department of Labor,"Audio Transcription: 
Transcription of speech to text for records keeping using natural language processing models.",The text refers to the process of converting spoken words into written text using natural language processing models. This transcription is done for the purpose of keeping records.,The text refers to the process of converting spoken words into written text using natural language processing models. This transcription is done for the purpose of keeping records.,,,False,False
NASA-0018-2023,NASA,Langley Research Center,,Autonomous WAiting Room Evaluation (AWARE),"Using an existing security camera and YOLO Machine Learning model to detect and count number of people waiting
for service at Langley's Badge & Pass Office. When a predetermined threshold of people is exceeded, automated
texts and emails are sent to request additional help at the service counters.",In-use,Convolutional Neural Network,,National Aeronautics and Space Administration,"Autonomous WAiting Room Evaluation (AWARE): 
Using an existing security camera and YOLO Machine Learning model to detect and count number of people waiting
for service at Langley's Badge & Pass Office. When a predetermined threshold of people is exceeded, automated
texts and emails are sent to request additional help at the service counters.",The AWARE system utilizes a security camera and YOLO Machine Learning model to identify and count individuals waiting for service at Langley's Badge & Pass Office. It automatically sends texts and emails requesting extra assistance when the number of people surpasses a predefined limit.,The AWARE system utilizes a security camera and YOLO Machine Learning model to identify and count individuals waiting for service at Langley's Badge & Pass Office. It automatically sends texts and emails requesting extra assistance when the number of people surpasses a predefined limit.,,,False,False
USDA-0032-2023,USDA,USDA,NRCS,Conservation Effects Assessment Project,"The goal is to predict conservation benefits at the field level. The model uses farmer survey data, APEX modeling results and environmental data.",Development and Acquisition,Machine Learning,,Department of Agriculture,"Conservation Effects Assessment Project: 
The goal is to predict conservation benefits at the field level. The model uses farmer survey data, APEX modeling results and environmental data.","The Conservation Effects Assessment Project aims to forecast the benefits of conservation at the individual field level. It achieves this by utilizing farmer survey data, APEX modeling outcomes, and environmental data in its model.","The Conservation Effects Assessment Project aims to forecast the benefits of conservation at the individual field level. It achieves this by utilizing farmer survey data, APEX modeling outcomes, and environmental data in its model.",,,False,False
DOE-0027-2023,DOE,Lawrence Livermore National Laboratory,,Quantum computing and information systems,"Machine learning and quantum computing applied towards optimization, 
quantum chemistry, material science, and cryptography",,,,Department of Energy,"Quantum computing and information systems: 
Machine learning and quantum computing applied towards optimization, 
quantum chemistry, material science, and cryptography","Quantum computing and information systems utilize machine learning and quantum computing techniques to enhance various fields such as optimization, quantum chemistry, material science, and cryptography. These advanced technologies have the potential to revolutionize these domains by providing more efficient and secure solutions.","Quantum computing and information systems utilize machine learning and quantum computing techniques to enhance various fields such as optimization, quantum chemistry, material science, and cryptography. These advanced technologies have the potential to revolutionize these domains by providing more efficient and secure solutions.",,,False,False
DOE-0101-2023,DOE,National Energy Technology Laboratory,,To develop high fidelity tools which run in near real time not only help in the field to guide and optimize complex operations but can be used as digital twins,"To develop high fidelity tools which run in near real time not only help in 
the field to guide and optimize complex operations but can be used as 
digital twins for cyber security and cyber-physical modeling.",,Big Data,,Department of Energy,"To develop high fidelity tools which run in near real time not only help in the field to guide and optimize complex operations but can be used as digital twins: 
To develop high fidelity tools which run in near real time not only help in 
the field to guide and optimize complex operations but can be used as 
digital twins for cyber security and cyber-physical modeling.","High fidelity tools that run in near real time are beneficial in guiding and optimizing complex operations in the field. Additionally, these tools can serve as digital twins for cyber security and cyber-physical modeling.","High fidelity tools that run in near real time are beneficial in guiding and optimizing complex operations in the field. Additionally, these tools can serve as digital twins for cyber security and cyber-physical modeling.",,,False,False
VA-0030-2023,VA,,,Use of machine learning to predict surgery in Crohn’s disease,"Machine learning analyzes patient demographics, medication use, and longitudinal laboratory values collected between 2001 and 2015 from adult patients in the Veterans Integrated Service Networks (VISN) 10 cohort. The data was used for analysis in prediction of Crohn’s disease and to model future surgical outcomes within 1 year.",,,,Department of Veterans Affairs,"Use of machine learning to predict surgery in Crohn’s disease: 
Machine learning analyzes patient demographics, medication use, and longitudinal laboratory values collected between 2001 and 2015 from adult patients in the Veterans Integrated Service Networks (VISN) 10 cohort. The data was used for analysis in prediction of Crohn’s disease and to model future surgical outcomes within 1 year.","Machine learning was utilized to analyze patient data from 2001 to 2015 in order to predict the occurrence of surgery in individuals with Crohn's disease. The study focused on patient demographics, medication usage, and longitudinal laboratory values to create a model that could forecast surgical outcomes within a year.","Machine learning was utilized to analyze patient data from 2001 to 2015 in order to predict the occurrence of surgery in individuals with Crohn's disease. The study focused on patient demographics, medication usage, and longitudinal laboratory values to create a model that could forecast surgical outcomes within a year.",,,False,False
DOC-0007-2023,DOC,National Oceanic and Atmospheric Administration (NOAA),,"Passive acoustic analysis using ML in Cook Inlet, AK","Passive acoustic data is analyzed for detection of beluga whales and classification of the 
different signals emitted by these species. Detection and classification are done with an 
ensemble of 4 CNN models and weighted scoring developed in collaboration with 
Microsoft. Results are being used to inform seasonal distribution, habitat use, and impact 
from anthropogenic disturbance within Cook Inlet beluga critical habitat. The project is 
aimed to expand to other cetacean species as well as anthropogenic noise.",,,,Department of Commerce,"Passive acoustic analysis using ML in Cook Inlet, AK: 
Passive acoustic data is analyzed for detection of beluga whales and classification of the 
different signals emitted by these species. Detection and classification are done with an 
ensemble of 4 CNN models and weighted scoring developed in collaboration with 
Microsoft. Results are being used to inform seasonal distribution, habitat use, and impact 
from anthropogenic disturbance within Cook Inlet beluga critical habitat. The project is 
aimed to expand to other cetacean species as well as anthropogenic noise.","Passive acoustic data in Cook Inlet, AK is analyzed using machine learning techniques to detect and classify signals emitted by beluga whales. This analysis, done with a set of 4 CNN models and weighted scoring developed in collaboration with Microsoft, is providing valuable information on the seasonal distribution, habitat use, and impact of human disturbance on beluga whales in Cook Inlet. The project also aims to extend its scope to include other cetacean species and anthropogenic noise.","Passive acoustic data in Cook Inlet, AK is analyzed using machine learning techniques to detect and classify signals emitted by beluga whales. This analysis, done with a set of 4 CNN models and weighted scoring developed in collaboration with Microsoft, is providing valuable information on the seasonal distribution, habitat use, and impact of human disturbance on beluga whales in Cook Inlet. The project also aims to extend its scope to include other cetacean species and anthropogenic noise.",,,False,False
DOE-0076-2023,DOE,National Energy Technology Laboratory,,To apply machine learning methods to explore the inter-well uncertainty in the Goldsmith Landreth San Andres Unit and to update reservoir models.,"Engineered water can lower interfacial tension and minimize capillary 
forces that gravity can push the oil up and out of the matrix. This 
proposal is to test this technology in the field scale, in Goldsmith 
Landreth San Andres Unit. Apply history matching of flexible interface-
based reservoir models and ML methods such as generative 
adversarial networks that provide new methods to explore the inter-well 
uncertainty and to update the reservoir models.",,Artificial Intelligence Unknown,,Department of Energy,"To apply machine learning methods to explore the inter-well uncertainty in the Goldsmith Landreth San Andres Unit and to update reservoir models.: 
Engineered water can lower interfacial tension and minimize capillary 
forces that gravity can push the oil up and out of the matrix. This 
proposal is to test this technology in the field scale, in Goldsmith 
Landreth San Andres Unit. Apply history matching of flexible interface-
based reservoir models and ML methods such as generative 
adversarial networks that provide new methods to explore the inter-well 
uncertainty and to update the reservoir models.",Machine learning methods will be used to analyze and update reservoir models in the Goldsmith Landreth San Andres Unit. The proposal aims to test the effectiveness of engineered water in reducing interfacial tension and minimizing capillary forces to prevent oil from being pushed out of the matrix.,Machine learning methods will be used to analyze and update reservoir models in the Goldsmith Landreth San Andres Unit. The proposal aims to test the effectiveness of engineered water in reducing interfacial tension and minimizing capillary forces to prevent oil from being pushed out of the matrix.,,,False,False
HHS-0040-2023,HHS,CDC,NCIRD,NCIRD SmartFind ChatBots - Public and Internal,"Develop conversational ChatBots (Public Flu, Public COVID-19 Vaccination, Internal Knowledge-Bot) that analyze free text questions entered by the public, healthcare providers, partners, and internal staff, and provide agency-cleared answers which best match the question. Developed in collaboration with Microsoft staff during COVID-19 pandemic using their Cognitive Services, Search,�QnA Maker, Azure Healthcare Bot, Power Automate, SharePoint, and webapps.",Operation and Maintenance,,,Department of Health and Human Services,"NCIRD SmartFind ChatBots - Public and Internal: 
Develop conversational ChatBots (Public Flu, Public COVID-19 Vaccination, Internal Knowledge-Bot) that analyze free text questions entered by the public, healthcare providers, partners, and internal staff, and provide agency-cleared answers which best match the question. Developed in collaboration with Microsoft staff during COVID-19 pandemic using their Cognitive Services, Search,�QnA Maker, Azure Healthcare Bot, Power Automate, SharePoint, and webapps.","NCIRD has developed conversational ChatBots for public flu, public COVID-19 vaccination, and internal knowledge-bot. These ChatBots analyze free text questions from the public, healthcare providers, partners, and internal staff, and provide accurate answers. These ChatBots were developed in collaboration with Microsoft staff using various tools and services.","NCIRD has developed conversational ChatBots for public flu, public COVID-19 vaccination, and internal knowledge-bot. These ChatBots analyze free text questions from the public, healthcare providers, partners, and internal staff, and provide accurate answers. These ChatBots were developed in collaboration with Microsoft staff using various tools and services.",,,False,False
DOL-0010-2023,DOL,,,Electronic Records Management,"Meeting NARA metadata standards for (permanent) federal documents by using AI to identify data within the document, and also using NLP to classify and summarize documents.",Initiation,Custom text classification machine learning model,,Department of Labor,"Electronic Records Management: 
Meeting NARA metadata standards for (permanent) federal documents by using AI to identify data within the document, and also using NLP to classify and summarize documents.","The text discusses the use of AI and NLP in electronic records management to meet NARA metadata standards for permanent federal documents. It suggests that using AI can help identify data within the documents, while NLP can aid in classifying and summarizing them.","The text discusses the use of AI and NLP in electronic records management to meet NARA metadata standards for permanent federal documents. It suggests that using AI can help identify data within the documents, while NLP can aid in classifying and summarizing them.",,,False,False
